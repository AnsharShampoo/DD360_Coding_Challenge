{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DD360 Coding Challenge: análisis del ciclo de desarrollo\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paquetes necesarios "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 02:38:10.406413: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-26 02:38:10.583705: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-26 02:38:10.585177: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-26 02:38:11.748127: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación y limpieza del Data Frame\n",
    "Partimos importando el dataset mediante pandas y procederemos a hacer un análisis exploratorio de los datos.\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 981 entries, 0 to 980\n",
      "Data columns (total 35 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   main_name             981 non-null    object \n",
      " 1   subtitle              981 non-null    object \n",
      " 2   link                  981 non-null    object \n",
      " 3   location              981 non-null    object \n",
      " 4   price                 981 non-null    object \n",
      " 5   attributes            981 non-null    object \n",
      " 6   timestamp             981 non-null    object \n",
      " 7   id                    981 non-null    int64  \n",
      " 8   address               702 non-null    object \n",
      " 9   since                 981 non-null    object \n",
      " 10  description           981 non-null    object \n",
      " 11  vendor                981 non-null    object \n",
      " 12  lat                   981 non-null    float64\n",
      " 13  lon                   981 non-null    float64\n",
      " 14  price_mod             981 non-null    float64\n",
      " 15  price_currency        981 non-null    object \n",
      " 16  since_period          981 non-null    object \n",
      " 17  since_value           981 non-null    int64  \n",
      " 18  days_on_site          981 non-null    float64\n",
      " 19  amenities             981 non-null    float64\n",
      " 20  age_in_years          981 non-null    float64\n",
      " 21  bathrooms             981 non-null    float64\n",
      " 22  cellars               52 non-null     float64\n",
      " 23  num_floors            84 non-null     float64\n",
      " 24  monthly_fee           128 non-null    object \n",
      " 25  apartments_per_floor  15 non-null     float64\n",
      " 26  disposition           20 non-null     object \n",
      " 27  parking_lots          981 non-null    int64  \n",
      " 28  floor_situated        24 non-null     float64\n",
      " 29  orientation           8 non-null      object \n",
      " 30  num_bedrooms          981 non-null    float64\n",
      " 31  department_type       39 non-null     object \n",
      " 32  m2                    981 non-null    float64\n",
      " 33  final_price           981 non-null    float64\n",
      " 34  price_square_meter    981 non-null    float64\n",
      "dtypes: float64(15), int64(3), object(17)\n",
      "memory usage: 268.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv(r'reto_precios.csv')\n",
    "raw_data['amenities'] = raw_data['amenities'].fillna(raw_data['amenities'].mean())\n",
    "print(raw_data.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se implementó una función para limpiar el DataSet y manetner unicamente las columnas con features definidos en cada una de las observaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols_with_no_nans(df,col_type):\n",
    "    '''\n",
    "    Arguments :\n",
    "    df : The dataframe to process\n",
    "    col_type : \n",
    "          num : to only get numerical columns with no nans\n",
    "          no_num : to only get nun-numerical columns with no nans\n",
    "          all : to get any columns with no nans    \n",
    "    '''\n",
    "    if (col_type == 'num'):\n",
    "        predictors = df.select_dtypes(exclude=['object'])\n",
    "    elif (col_type == 'no_num'):\n",
    "        predictors = df.select_dtypes(include=['object'])\n",
    "    elif (col_type == 'all'):\n",
    "        predictors = df\n",
    "    else :\n",
    "        print('Error : choose a type (num, no_num, all)')\n",
    "        return 0\n",
    "    cols_with_no_nans = []\n",
    "    for col in predictors.columns:\n",
    "        if not df[col].isnull().any():\n",
    "            cols_with_no_nans.append(col)\n",
    "    return cols_with_no_nans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se dividió el dataset entre los datos numéricos y no numéricos, aunque en un inicio se experimentó utilizando los datos no numéricos como parte del dataframe y codificandolos, no se obtuvieron buenos resultados por lo que se decidió trabajar únicamente con los datos numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of numerical columns with no nan values : 14\n",
      "Number of nun-numerical columns with no nan values : 12\n"
     ]
    }
   ],
   "source": [
    "num_cols = get_cols_with_no_nans(raw_data , 'num')\n",
    "cat_cols = get_cols_with_no_nans(raw_data , 'no_num')\n",
    "print ('Number of numerical columns with no nan values :',len(num_cols))\n",
    "print ('Number of nun-numerical columns with no nan values :',len(cat_cols))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impresión en histograma de las features útilies, mediante este análisis podemos observar el comportamiento de cada feautre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 981 entries, 0 to 980\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   id                  981 non-null    int64  \n",
      " 1   lat                 981 non-null    float64\n",
      " 2   lon                 981 non-null    float64\n",
      " 3   price_mod           981 non-null    float64\n",
      " 4   since_value         981 non-null    int64  \n",
      " 5   days_on_site        981 non-null    float64\n",
      " 6   amenities           981 non-null    float64\n",
      " 7   age_in_years        981 non-null    float64\n",
      " 8   bathrooms           981 non-null    float64\n",
      " 9   parking_lots        981 non-null    int64  \n",
      " 10  num_bedrooms        981 non-null    float64\n",
      " 11  m2                  981 non-null    float64\n",
      " 12  final_price         981 non-null    float64\n",
      " 13  price_square_meter  981 non-null    float64\n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 107.4 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "combined = raw_data[num_cols]\n",
    "combined.hist(figsize = (12,10))\n",
    "plt.show()\n",
    "print(combined.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante un análisis de la correlación entre los datos numéricos podemos notar que el precio por metro cuadrado depende principalmente de la ubicación y cantidad de baños, aunque también es posible apreciar que el precio final tiene una correlación grande con la cantidad de habitaciones y lugares de estacionamiento disponibles. Por la correlación existente entre el precio total y el precio por metro cuadrado, podemos suponer que todas las features mencionadas son parte importante en la predicción del costo por metro cuadrado en los inmuebles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = raw_data[num_cols]\n",
    "\n",
    "C_mat = train_data.corr()\n",
    "fig = plt.figure(figsize = (15,15))\n",
    "\n",
    "sb.heatmap(C_mat, vmax = .8, square = True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se generó la división del data set en training set y test set, con 600 observaciones de entrenamiento y el resto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_combined():\n",
    "    global train_data\n",
    "    train = train_data[:700]\n",
    "    test = train_data[700:]\n",
    "\n",
    "    return train , test \n",
    "  \n",
    "train, test = split_combined()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como consecuencia del análisis de los datos, dividimos nuestros dataframes de prueba y entrenamiento entre datos de entrada y salida.\n",
    "Así mismo se optó por eliminar el la antiguedad del inmuble pues podría causar problemas en la convergencia del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 700 entries, 0 to 699\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   lat           700 non-null    float64\n",
      " 1   lon           700 non-null    float64\n",
      " 2   amenities     700 non-null    float64\n",
      " 3   bathrooms     700 non-null    float64\n",
      " 4   parking_lots  700 non-null    int64  \n",
      " 5   num_bedrooms  700 non-null    float64\n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 32.9 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "train_x = train.drop(['final_price','price_square_meter','price_mod','id','age_in_years','m2','since_value','days_on_site'], axis=1)\n",
    "train_y = train['price_square_meter']\n",
    "test_x = test.drop(['final_price','price_square_meter','price_mod','id','age_in_years','m2','since_value','days_on_site'], axis=1)\n",
    "test_y = test['price_square_meter']\n",
    "print(train_x.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposición y entrenamiento del modelo\n",
    "Por la naturaleza del problema así como la cantidad \"baja\" de features en el dataset, se decidió entrenar tres modelos diferentes y llevar al primer ciclo de producción el más certero de ellos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Red Neuronal \n",
    "Para este modelo se decidió utilizar 3 capas escondidas cada una cond 256 neuronas, la función de activación de estas es una función ReLU y la función de activación de la capa de salida es una regresión lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 4)                 28        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 40        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 201\n",
      "Trainable params: 201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_model = Sequential()\n",
    "\n",
    "NN_model.add(Dense(4, kernel_initializer='normal',input_dim = train_x.shape[1], activation='relu'))\n",
    "\n",
    "NN_model.add(Dense(8, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(8, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(6, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se agregó un check_point para guardar la iteración con los valores más precisos dentro de 500 epochs de entrenamiento secuencial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'Weights-{epoch:05d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      " 1/18 [>.............................] - ETA: 14s - loss: 64199.1484 - mean_absolute_error: 64199.1484\n",
      "Epoch 1: val_loss improved from inf to 64939.62891, saving model to Weights-00001--64939.62891.hdf5\n",
      "18/18 [==============================] - 1s 14ms/step - loss: 62665.4727 - mean_absolute_error: 62665.4727 - val_loss: 64939.6289 - val_mean_absolute_error: 64939.6289\n",
      "Epoch 2/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 60702.7031 - mean_absolute_error: 60702.7031\n",
      "Epoch 2: val_loss improved from 64939.62891 to 64939.60156, saving model to Weights-00002--64939.60156.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 62665.4414 - mean_absolute_error: 62665.4414 - val_loss: 64939.6016 - val_mean_absolute_error: 64939.6016\n",
      "Epoch 3/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 65028.1172 - mean_absolute_error: 65028.1172\n",
      "Epoch 3: val_loss improved from 64939.60156 to 64939.52734, saving model to Weights-00003--64939.52734.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 62665.3984 - mean_absolute_error: 62665.3984 - val_loss: 64939.5273 - val_mean_absolute_error: 64939.5273\n",
      "Epoch 4/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 58215.8047 - mean_absolute_error: 58215.8047\n",
      "Epoch 4: val_loss improved from 64939.52734 to 64939.33594, saving model to Weights-00004--64939.33594.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 62665.2773 - mean_absolute_error: 62665.2773 - val_loss: 64939.3359 - val_mean_absolute_error: 64939.3359\n",
      "Epoch 5/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 63816.3984 - mean_absolute_error: 63816.3984\n",
      "Epoch 5: val_loss improved from 64939.33594 to 64938.84375, saving model to Weights-00005--64938.84375.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 62664.9844 - mean_absolute_error: 62664.9844 - val_loss: 64938.8438 - val_mean_absolute_error: 64938.8438\n",
      "Epoch 6/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 61504.2500 - mean_absolute_error: 61504.2500\n",
      "Epoch 6: val_loss improved from 64938.84375 to 64937.63672, saving model to Weights-00006--64937.63672.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 62664.1914 - mean_absolute_error: 62664.1914 - val_loss: 64937.6367 - val_mean_absolute_error: 64937.6367\n",
      "Epoch 7/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 63903.5312 - mean_absolute_error: 63903.5312\n",
      "Epoch 7: val_loss improved from 64937.63672 to 64934.99219, saving model to Weights-00007--64934.99219.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 62662.4141 - mean_absolute_error: 62662.4141 - val_loss: 64934.9922 - val_mean_absolute_error: 64934.9922\n",
      "Epoch 8/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 63019.8359 - mean_absolute_error: 63019.8359\n",
      "Epoch 8: val_loss improved from 64934.99219 to 64929.75000, saving model to Weights-00008--64929.75000.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 62658.7148 - mean_absolute_error: 62658.7148 - val_loss: 64929.7500 - val_mean_absolute_error: 64929.7500\n",
      "Epoch 9/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 66273.6719 - mean_absolute_error: 66273.6719\n",
      "Epoch 9: val_loss improved from 64929.75000 to 64920.10156, saving model to Weights-00009--64920.10156.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 62651.6445 - mean_absolute_error: 62651.6445 - val_loss: 64920.1016 - val_mean_absolute_error: 64920.1016\n",
      "Epoch 10/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 57957.1328 - mean_absolute_error: 57957.1328\n",
      "Epoch 10: val_loss improved from 64920.10156 to 64903.51562, saving model to Weights-00010--64903.51562.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 62639.0938 - mean_absolute_error: 62639.0938 - val_loss: 64903.5156 - val_mean_absolute_error: 64903.5156\n",
      "Epoch 11/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 57859.7109 - mean_absolute_error: 57859.7109\n",
      "Epoch 11: val_loss improved from 64903.51562 to 64876.48438, saving model to Weights-00011--64876.48438.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 62618.0859 - mean_absolute_error: 62618.0859 - val_loss: 64876.4844 - val_mean_absolute_error: 64876.4844\n",
      "Epoch 12/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 61501.6406 - mean_absolute_error: 61501.6406\n",
      "Epoch 12: val_loss improved from 64876.48438 to 64834.45703, saving model to Weights-00012--64834.45703.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 62584.6875 - mean_absolute_error: 62584.6875 - val_loss: 64834.4570 - val_mean_absolute_error: 64834.4570\n",
      "Epoch 13/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 63142.4141 - mean_absolute_error: 63142.4141\n",
      "Epoch 13: val_loss improved from 64834.45703 to 64771.64453, saving model to Weights-00013--64771.64453.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 62533.7656 - mean_absolute_error: 62533.7656 - val_loss: 64771.6445 - val_mean_absolute_error: 64771.6445\n",
      "Epoch 14/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 64870.5039 - mean_absolute_error: 64870.5039\n",
      "Epoch 14: val_loss improved from 64771.64453 to 64680.85156, saving model to Weights-00014--64680.85156.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 62458.9414 - mean_absolute_error: 62458.9414 - val_loss: 64680.8516 - val_mean_absolute_error: 64680.8516\n",
      "Epoch 15/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 61421.6758 - mean_absolute_error: 61421.6758\n",
      "Epoch 15: val_loss improved from 64680.85156 to 64553.40625, saving model to Weights-00015--64553.40625.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 62352.3789 - mean_absolute_error: 62352.3789 - val_loss: 64553.4062 - val_mean_absolute_error: 64553.4062\n",
      "Epoch 16/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 65910.2031 - mean_absolute_error: 65910.2031\n",
      "Epoch 16: val_loss improved from 64553.40625 to 64379.01953, saving model to Weights-00016--64379.01953.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 62204.6211 - mean_absolute_error: 62204.6211 - val_loss: 64379.0195 - val_mean_absolute_error: 64379.0195\n",
      "Epoch 17/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 60273.5078 - mean_absolute_error: 60273.5078\n",
      "Epoch 17: val_loss improved from 64379.01953 to 64145.98047, saving model to Weights-00017--64145.98047.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 62004.8438 - mean_absolute_error: 62004.8438 - val_loss: 64145.9805 - val_mean_absolute_error: 64145.9805\n",
      "Epoch 18/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 58165.1719 - mean_absolute_error: 58165.1719\n",
      "Epoch 18: val_loss improved from 64145.98047 to 63840.05078, saving model to Weights-00018--63840.05078.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 61741.0938 - mean_absolute_error: 61741.0938 - val_loss: 63840.0508 - val_mean_absolute_error: 63840.0508\n",
      "Epoch 19/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 62889.0977 - mean_absolute_error: 62889.0977\n",
      "Epoch 19: val_loss improved from 63840.05078 to 63445.26562, saving model to Weights-00019--63445.26562.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 61398.1016 - mean_absolute_error: 61398.1016 - val_loss: 63445.2656 - val_mean_absolute_error: 63445.2656\n",
      "Epoch 20/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 62394.4609 - mean_absolute_error: 62394.4609\n",
      "Epoch 20: val_loss improved from 63445.26562 to 62944.25781, saving model to Weights-00020--62944.25781.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 60958.1484 - mean_absolute_error: 60958.1484 - val_loss: 62944.2578 - val_mean_absolute_error: 62944.2578\n",
      "Epoch 21/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 57996.1406 - mean_absolute_error: 57996.1406\n",
      "Epoch 21: val_loss improved from 62944.25781 to 62315.92188, saving model to Weights-00021--62315.92188.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 60404.1055 - mean_absolute_error: 60404.1055 - val_loss: 62315.9219 - val_mean_absolute_error: 62315.9219\n",
      "Epoch 22/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 61751.4844 - mean_absolute_error: 61751.4844\n",
      "Epoch 22: val_loss improved from 62315.92188 to 61539.25781, saving model to Weights-00022--61539.25781.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 59713.0898 - mean_absolute_error: 59713.0898 - val_loss: 61539.2578 - val_mean_absolute_error: 61539.2578\n",
      "Epoch 23/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 63465.8789 - mean_absolute_error: 63465.8789\n",
      "Epoch 23: val_loss improved from 61539.25781 to 60588.30078, saving model to Weights-00023--60588.30078.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 58863.6836 - mean_absolute_error: 58863.6836 - val_loss: 60588.3008 - val_mean_absolute_error: 60588.3008\n",
      "Epoch 24/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 60730.4102 - mean_absolute_error: 60730.4102\n",
      "Epoch 24: val_loss improved from 60588.30078 to 59435.65234, saving model to Weights-00024--59435.65234.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 57830.1055 - mean_absolute_error: 57830.1055 - val_loss: 59435.6523 - val_mean_absolute_error: 59435.6523\n",
      "Epoch 25/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 53532.7031 - mean_absolute_error: 53532.7031\n",
      "Epoch 25: val_loss improved from 59435.65234 to 58059.58203, saving model to Weights-00025--58059.58203.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 56583.6602 - mean_absolute_error: 56583.6602 - val_loss: 58059.5820 - val_mean_absolute_error: 58059.5820\n",
      "Epoch 26/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 56044.8125 - mean_absolute_error: 56044.8125\n",
      "Epoch 26: val_loss improved from 58059.58203 to 56422.24609, saving model to Weights-00026--56422.24609.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 55110.4727 - mean_absolute_error: 55110.4727 - val_loss: 56422.2461 - val_mean_absolute_error: 56422.2461\n",
      "Epoch 27/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 55085.7578 - mean_absolute_error: 55085.7578\n",
      "Epoch 27: val_loss improved from 56422.24609 to 54493.48438, saving model to Weights-00027--54493.48438.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 53364.0938 - mean_absolute_error: 53364.0938 - val_loss: 54493.4844 - val_mean_absolute_error: 54493.4844\n",
      "Epoch 28/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 48756.0000 - mean_absolute_error: 48756.0000\n",
      "Epoch 28: val_loss improved from 54493.48438 to 52238.64453, saving model to Weights-00028--52238.64453.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 51314.1055 - mean_absolute_error: 51314.1055 - val_loss: 52238.6445 - val_mean_absolute_error: 52238.6445\n",
      "Epoch 29/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 48619.1836 - mean_absolute_error: 48619.1836\n",
      "Epoch 29: val_loss improved from 52238.64453 to 49627.30469, saving model to Weights-00029--49627.30469.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 48942.1211 - mean_absolute_error: 48942.1211 - val_loss: 49627.3047 - val_mean_absolute_error: 49627.3047\n",
      "Epoch 30/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 43361.0469 - mean_absolute_error: 43361.0469\n",
      "Epoch 30: val_loss improved from 49627.30469 to 46639.80078, saving model to Weights-00030--46639.80078.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 46196.3320 - mean_absolute_error: 46196.3320 - val_loss: 46639.8008 - val_mean_absolute_error: 46639.8008\n",
      "Epoch 31/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 46967.9141 - mean_absolute_error: 46967.9141\n",
      "Epoch 31: val_loss improved from 46639.80078 to 43223.88281, saving model to Weights-00031--43223.88281.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 43044.5156 - mean_absolute_error: 43044.5156 - val_loss: 43223.8828 - val_mean_absolute_error: 43223.8828\n",
      "Epoch 32/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 41216.2812 - mean_absolute_error: 41216.2812\n",
      "Epoch 32: val_loss improved from 43223.88281 to 39319.14062, saving model to Weights-00032--39319.14062.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 39425.5312 - mean_absolute_error: 39425.5312 - val_loss: 39319.1406 - val_mean_absolute_error: 39319.1406\n",
      "Epoch 33/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 39506.9922 - mean_absolute_error: 39506.9922\n",
      "Epoch 33: val_loss improved from 39319.14062 to 34898.76562, saving model to Weights-00033--34898.76562.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 35344.5469 - mean_absolute_error: 35344.5469 - val_loss: 34898.7656 - val_mean_absolute_error: 34898.7656\n",
      "Epoch 34/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 34750.3984 - mean_absolute_error: 34750.3984\n",
      "Epoch 34: val_loss improved from 34898.76562 to 30095.60352, saving model to Weights-00034--30095.60352.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 30731.9473 - mean_absolute_error: 30731.9473 - val_loss: 30095.6035 - val_mean_absolute_error: 30095.6035\n",
      "Epoch 35/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 27595.8691 - mean_absolute_error: 27595.8691\n",
      "Epoch 35: val_loss improved from 30095.60352 to 25111.47070, saving model to Weights-00035--25111.47070.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 25684.1543 - mean_absolute_error: 25684.1543 - val_loss: 25111.4707 - val_mean_absolute_error: 25111.4707\n",
      "Epoch 36/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 20397.8848 - mean_absolute_error: 20397.8848\n",
      "Epoch 36: val_loss improved from 25111.47070 to 20331.50391, saving model to Weights-00036--20331.50391.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 20300.4062 - mean_absolute_error: 20300.4062 - val_loss: 20331.5039 - val_mean_absolute_error: 20331.5039\n",
      "Epoch 37/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 19608.5098 - mean_absolute_error: 19608.5098\n",
      "Epoch 37: val_loss improved from 20331.50391 to 16675.05664, saving model to Weights-00037--16675.05664.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 15301.1514 - mean_absolute_error: 15301.1514 - val_loss: 16675.0566 - val_mean_absolute_error: 16675.0566\n",
      "Epoch 38/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 16327.4668 - mean_absolute_error: 16327.4668\n",
      "Epoch 38: val_loss improved from 16675.05664 to 14626.65723, saving model to Weights-00038--14626.65723.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 11935.9570 - mean_absolute_error: 11935.9570 - val_loss: 14626.6572 - val_mean_absolute_error: 14626.6572\n",
      "Epoch 39/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9631.8320 - mean_absolute_error: 9631.8320\n",
      "Epoch 39: val_loss improved from 14626.65723 to 13907.72266, saving model to Weights-00039--13907.72266.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10466.6201 - mean_absolute_error: 10466.6201 - val_loss: 13907.7227 - val_mean_absolute_error: 13907.7227\n",
      "Epoch 40/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11982.8633 - mean_absolute_error: 11982.8633\n",
      "Epoch 40: val_loss improved from 13907.72266 to 13869.21289, saving model to Weights-00040--13869.21289.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10331.0186 - mean_absolute_error: 10331.0186 - val_loss: 13869.2129 - val_mean_absolute_error: 13869.2129\n",
      "Epoch 41/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11210.5664 - mean_absolute_error: 11210.5664\n",
      "Epoch 41: val_loss did not improve from 13869.21289\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10320.9707 - mean_absolute_error: 10320.9707 - val_loss: 13876.8320 - val_mean_absolute_error: 13876.8320\n",
      "Epoch 42/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8465.9014 - mean_absolute_error: 8465.9014\n",
      "Epoch 42: val_loss did not improve from 13869.21289\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10319.5635 - mean_absolute_error: 10319.5635 - val_loss: 13880.3604 - val_mean_absolute_error: 13880.3604\n",
      "Epoch 43/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9384.6670 - mean_absolute_error: 9384.6670\n",
      "Epoch 43: val_loss did not improve from 13869.21289\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10320.7002 - mean_absolute_error: 10320.7002 - val_loss: 13878.0664 - val_mean_absolute_error: 13878.0664\n",
      "Epoch 44/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11115.5654 - mean_absolute_error: 11115.5654\n",
      "Epoch 44: val_loss did not improve from 13869.21289\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10321.9268 - mean_absolute_error: 10321.9268 - val_loss: 13885.1777 - val_mean_absolute_error: 13885.1777\n",
      "Epoch 45/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9502.1348 - mean_absolute_error: 9502.1348\n",
      "Epoch 45: val_loss did not improve from 13869.21289\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10320.2744 - mean_absolute_error: 10320.2744 - val_loss: 13889.7881 - val_mean_absolute_error: 13889.7881\n",
      "Epoch 46/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8753.7754 - mean_absolute_error: 8753.7754\n",
      "Epoch 46: val_loss did not improve from 13869.21289\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10316.6367 - mean_absolute_error: 10316.6367 - val_loss: 13911.0049 - val_mean_absolute_error: 13911.0049\n",
      "Epoch 47/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11257.6953 - mean_absolute_error: 11257.6953\n",
      "Epoch 47: val_loss did not improve from 13869.21289\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10317.0479 - mean_absolute_error: 10317.0479 - val_loss: 13911.7295 - val_mean_absolute_error: 13911.7295\n",
      "Epoch 48/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13286.2295 - mean_absolute_error: 13286.2295\n",
      "Epoch 48: val_loss did not improve from 13869.21289\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10320.1035 - mean_absolute_error: 10320.1035 - val_loss: 13884.1777 - val_mean_absolute_error: 13884.1777\n",
      "Epoch 49/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9105.5098 - mean_absolute_error: 9105.5098\n",
      "Epoch 49: val_loss did not improve from 13869.21289\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10313.2207 - mean_absolute_error: 10313.2207 - val_loss: 13886.7227 - val_mean_absolute_error: 13886.7227\n",
      "Epoch 50/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8712.7168 - mean_absolute_error: 8712.7168\n",
      "Epoch 50: val_loss did not improve from 13869.21289\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10313.9365 - mean_absolute_error: 10313.9365 - val_loss: 13904.9951 - val_mean_absolute_error: 13904.9951\n",
      "Epoch 51/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10397.6094 - mean_absolute_error: 10397.6094\n",
      "Epoch 51: val_loss did not improve from 13869.21289\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10315.4707 - mean_absolute_error: 10315.4707 - val_loss: 13887.3057 - val_mean_absolute_error: 13887.3057\n",
      "Epoch 52/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11445.3154 - mean_absolute_error: 11445.3154\n",
      "Epoch 52: val_loss did not improve from 13869.21289\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10311.8945 - mean_absolute_error: 10311.8945 - val_loss: 13894.8887 - val_mean_absolute_error: 13894.8887\n",
      "Epoch 53/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8326.6270 - mean_absolute_error: 8326.6270\n",
      "Epoch 53: val_loss did not improve from 13869.21289\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10314.4326 - mean_absolute_error: 10314.4326 - val_loss: 13870.2178 - val_mean_absolute_error: 13870.2178\n",
      "Epoch 54/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8155.6084 - mean_absolute_error: 8155.6084\n",
      "Epoch 54: val_loss did not improve from 13869.21289\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10309.5977 - mean_absolute_error: 10309.5977 - val_loss: 13882.6523 - val_mean_absolute_error: 13882.6523\n",
      "Epoch 55/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8057.1885 - mean_absolute_error: 8057.1885\n",
      "Epoch 55: val_loss did not improve from 13869.21289\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10311.9014 - mean_absolute_error: 10311.9014 - val_loss: 13901.9111 - val_mean_absolute_error: 13901.9111\n",
      "Epoch 56/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10924.3496 - mean_absolute_error: 10924.3496\n",
      "Epoch 56: val_loss did not improve from 13869.21289\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10307.8730 - mean_absolute_error: 10307.8730 - val_loss: 13891.5830 - val_mean_absolute_error: 13891.5830\n",
      "Epoch 57/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9911.6094 - mean_absolute_error: 9911.6094\n",
      "Epoch 57: val_loss improved from 13869.21289 to 13864.79492, saving model to Weights-00057--13864.79492.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10315.1543 - mean_absolute_error: 10315.1543 - val_loss: 13864.7949 - val_mean_absolute_error: 13864.7949\n",
      "Epoch 58/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12399.9492 - mean_absolute_error: 12399.9492\n",
      "Epoch 58: val_loss did not improve from 13864.79492\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10313.0264 - mean_absolute_error: 10313.0264 - val_loss: 13891.1807 - val_mean_absolute_error: 13891.1807\n",
      "Epoch 59/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9546.8350 - mean_absolute_error: 9546.8350\n",
      "Epoch 59: val_loss did not improve from 13864.79492\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10305.1514 - mean_absolute_error: 10305.1514 - val_loss: 13887.2607 - val_mean_absolute_error: 13887.2607\n",
      "Epoch 60/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11364.1172 - mean_absolute_error: 11364.1172\n",
      "Epoch 60: val_loss did not improve from 13864.79492\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10305.9727 - mean_absolute_error: 10305.9727 - val_loss: 13878.2910 - val_mean_absolute_error: 13878.2910\n",
      "Epoch 61/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13596.5996 - mean_absolute_error: 13596.5996\n",
      "Epoch 61: val_loss did not improve from 13864.79492\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10309.7842 - mean_absolute_error: 10309.7842 - val_loss: 13887.9551 - val_mean_absolute_error: 13887.9551\n",
      "Epoch 62/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10263.3672 - mean_absolute_error: 10263.3672\n",
      "Epoch 62: val_loss did not improve from 13864.79492\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10305.6016 - mean_absolute_error: 10305.6016 - val_loss: 13871.5928 - val_mean_absolute_error: 13871.5928\n",
      "Epoch 63/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 14200.0254 - mean_absolute_error: 14200.0254\n",
      "Epoch 63: val_loss did not improve from 13864.79492\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10303.2832 - mean_absolute_error: 10303.2832 - val_loss: 13867.8193 - val_mean_absolute_error: 13867.8193\n",
      "Epoch 64/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8029.3828 - mean_absolute_error: 8029.3828\n",
      "Epoch 64: val_loss did not improve from 13864.79492\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10303.4551 - mean_absolute_error: 10303.4551 - val_loss: 13875.5029 - val_mean_absolute_error: 13875.5029\n",
      "Epoch 65/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9122.4941 - mean_absolute_error: 9122.4941\n",
      "Epoch 65: val_loss did not improve from 13864.79492\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10303.2734 - mean_absolute_error: 10303.2734 - val_loss: 13903.9990 - val_mean_absolute_error: 13903.9990\n",
      "Epoch 66/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8037.8633 - mean_absolute_error: 8037.8633\n",
      "Epoch 66: val_loss did not improve from 13864.79492\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10301.6328 - mean_absolute_error: 10301.6328 - val_loss: 13883.2969 - val_mean_absolute_error: 13883.2969\n",
      "Epoch 67/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11203.7520 - mean_absolute_error: 11203.7520\n",
      "Epoch 67: val_loss did not improve from 13864.79492\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10316.9951 - mean_absolute_error: 10316.9951 - val_loss: 13866.4873 - val_mean_absolute_error: 13866.4873\n",
      "Epoch 68/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10323.2842 - mean_absolute_error: 10323.2842\n",
      "Epoch 68: val_loss did not improve from 13864.79492\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10299.6953 - mean_absolute_error: 10299.6953 - val_loss: 13866.1943 - val_mean_absolute_error: 13866.1943\n",
      "Epoch 69/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7753.9512 - mean_absolute_error: 7753.9512\n",
      "Epoch 69: val_loss did not improve from 13864.79492\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10297.8018 - mean_absolute_error: 10297.8018 - val_loss: 13885.3281 - val_mean_absolute_error: 13885.3281\n",
      "Epoch 70/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9959.5771 - mean_absolute_error: 9959.5771\n",
      "Epoch 70: val_loss did not improve from 13864.79492\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10301.6025 - mean_absolute_error: 10301.6025 - val_loss: 13872.5723 - val_mean_absolute_error: 13872.5723\n",
      "Epoch 71/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8109.2124 - mean_absolute_error: 8109.2124\n",
      "Epoch 71: val_loss did not improve from 13864.79492\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10317.3594 - mean_absolute_error: 10317.3594 - val_loss: 13915.9111 - val_mean_absolute_error: 13915.9111\n",
      "Epoch 72/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8114.8452 - mean_absolute_error: 8114.8452\n",
      "Epoch 72: val_loss did not improve from 13864.79492\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 10297.9102 - mean_absolute_error: 10297.9102 - val_loss: 13870.5586 - val_mean_absolute_error: 13870.5586\n",
      "Epoch 73/3000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 10327.1152 - mean_absolute_error: 10327.1152\n",
      "Epoch 73: val_loss did not improve from 13864.79492\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10296.8877 - mean_absolute_error: 10296.8877 - val_loss: 13877.1826 - val_mean_absolute_error: 13877.1826\n",
      "Epoch 74/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8432.2422 - mean_absolute_error: 8432.2422\n",
      "Epoch 74: val_loss did not improve from 13864.79492\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10305.0518 - mean_absolute_error: 10305.0518 - val_loss: 13891.2236 - val_mean_absolute_error: 13891.2236\n",
      "Epoch 75/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8935.2393 - mean_absolute_error: 8935.2393\n",
      "Epoch 75: val_loss did not improve from 13864.79492\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10296.7012 - mean_absolute_error: 10296.7012 - val_loss: 13883.6484 - val_mean_absolute_error: 13883.6484\n",
      "Epoch 76/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10946.6494 - mean_absolute_error: 10946.6494\n",
      "Epoch 76: val_loss improved from 13864.79492 to 13856.40332, saving model to Weights-00076--13856.40332.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10299.8486 - mean_absolute_error: 10299.8486 - val_loss: 13856.4033 - val_mean_absolute_error: 13856.4033\n",
      "Epoch 77/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11638.8125 - mean_absolute_error: 11638.8125\n",
      "Epoch 77: val_loss improved from 13856.40332 to 13852.80664, saving model to Weights-00077--13852.80664.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10295.2061 - mean_absolute_error: 10295.2061 - val_loss: 13852.8066 - val_mean_absolute_error: 13852.8066\n",
      "Epoch 78/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12256.5742 - mean_absolute_error: 12256.5742\n",
      "Epoch 78: val_loss did not improve from 13852.80664\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10299.2588 - mean_absolute_error: 10299.2588 - val_loss: 13858.2100 - val_mean_absolute_error: 13858.2100\n",
      "Epoch 79/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12331.4268 - mean_absolute_error: 12331.4268\n",
      "Epoch 79: val_loss did not improve from 13852.80664\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10291.1309 - mean_absolute_error: 10291.1309 - val_loss: 13892.5723 - val_mean_absolute_error: 13892.5723\n",
      "Epoch 80/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9135.0869 - mean_absolute_error: 9135.0869\n",
      "Epoch 80: val_loss did not improve from 13852.80664\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10292.8213 - mean_absolute_error: 10292.8213 - val_loss: 13898.6406 - val_mean_absolute_error: 13898.6406\n",
      "Epoch 81/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10976.5117 - mean_absolute_error: 10976.5117\n",
      "Epoch 81: val_loss did not improve from 13852.80664\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10293.3467 - mean_absolute_error: 10293.3467 - val_loss: 13864.6104 - val_mean_absolute_error: 13864.6104\n",
      "Epoch 82/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12964.3740 - mean_absolute_error: 12964.3740\n",
      "Epoch 82: val_loss did not improve from 13852.80664\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10289.2432 - mean_absolute_error: 10289.2432 - val_loss: 13871.0557 - val_mean_absolute_error: 13871.0557\n",
      "Epoch 83/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8343.7168 - mean_absolute_error: 8343.7168\n",
      "Epoch 83: val_loss did not improve from 13852.80664\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10298.6230 - mean_absolute_error: 10298.6230 - val_loss: 13885.3145 - val_mean_absolute_error: 13885.3145\n",
      "Epoch 84/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10437.5566 - mean_absolute_error: 10437.5566\n",
      "Epoch 84: val_loss did not improve from 13852.80664\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10290.3066 - mean_absolute_error: 10290.3066 - val_loss: 13881.4219 - val_mean_absolute_error: 13881.4219\n",
      "Epoch 85/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9880.2471 - mean_absolute_error: 9880.2471\n",
      "Epoch 85: val_loss did not improve from 13852.80664\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10283.9102 - mean_absolute_error: 10283.9102 - val_loss: 13854.8877 - val_mean_absolute_error: 13854.8877\n",
      "Epoch 86/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7537.4453 - mean_absolute_error: 7537.4453\n",
      "Epoch 86: val_loss improved from 13852.80664 to 13847.64844, saving model to Weights-00086--13847.64844.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10288.2109 - mean_absolute_error: 10288.2109 - val_loss: 13847.6484 - val_mean_absolute_error: 13847.6484\n",
      "Epoch 87/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13105.2188 - mean_absolute_error: 13105.2188\n",
      "Epoch 87: val_loss did not improve from 13847.64844\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10291.8486 - mean_absolute_error: 10291.8486 - val_loss: 13850.1318 - val_mean_absolute_error: 13850.1318\n",
      "Epoch 88/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10932.4492 - mean_absolute_error: 10932.4492\n",
      "Epoch 88: val_loss did not improve from 13847.64844\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10286.0674 - mean_absolute_error: 10286.0674 - val_loss: 13909.3174 - val_mean_absolute_error: 13909.3174\n",
      "Epoch 89/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12242.2148 - mean_absolute_error: 12242.2148\n",
      "Epoch 89: val_loss did not improve from 13847.64844\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10284.2402 - mean_absolute_error: 10284.2402 - val_loss: 13885.7178 - val_mean_absolute_error: 13885.7178\n",
      "Epoch 90/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10440.3438 - mean_absolute_error: 10440.3438\n",
      "Epoch 90: val_loss did not improve from 13847.64844\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10280.4219 - mean_absolute_error: 10280.4219 - val_loss: 13869.4287 - val_mean_absolute_error: 13869.4287\n",
      "Epoch 91/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9240.1670 - mean_absolute_error: 9240.1670\n",
      "Epoch 91: val_loss did not improve from 13847.64844\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10280.7832 - mean_absolute_error: 10280.7832 - val_loss: 13853.5186 - val_mean_absolute_error: 13853.5186\n",
      "Epoch 92/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10353.6133 - mean_absolute_error: 10353.6133\n",
      "Epoch 92: val_loss did not improve from 13847.64844\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10279.4111 - mean_absolute_error: 10279.4111 - val_loss: 13863.4023 - val_mean_absolute_error: 13863.4023\n",
      "Epoch 93/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11037.8662 - mean_absolute_error: 11037.8662\n",
      "Epoch 93: val_loss did not improve from 13847.64844\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10281.0469 - mean_absolute_error: 10281.0469 - val_loss: 13874.5488 - val_mean_absolute_error: 13874.5488\n",
      "Epoch 94/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9577.3457 - mean_absolute_error: 9577.3457\n",
      "Epoch 94: val_loss did not improve from 13847.64844\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10278.2031 - mean_absolute_error: 10278.2031 - val_loss: 13870.4600 - val_mean_absolute_error: 13870.4600\n",
      "Epoch 95/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8345.3145 - mean_absolute_error: 8345.3145\n",
      "Epoch 95: val_loss did not improve from 13847.64844\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10281.6299 - mean_absolute_error: 10281.6299 - val_loss: 13851.6660 - val_mean_absolute_error: 13851.6660\n",
      "Epoch 96/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8607.4590 - mean_absolute_error: 8607.4590\n",
      "Epoch 96: val_loss did not improve from 13847.64844\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10277.5303 - mean_absolute_error: 10277.5303 - val_loss: 13875.1211 - val_mean_absolute_error: 13875.1211\n",
      "Epoch 97/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9873.1748 - mean_absolute_error: 9873.1748\n",
      "Epoch 97: val_loss did not improve from 13847.64844\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10285.2822 - mean_absolute_error: 10285.2822 - val_loss: 13849.0049 - val_mean_absolute_error: 13849.0049\n",
      "Epoch 98/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8702.4004 - mean_absolute_error: 8702.4004\n",
      "Epoch 98: val_loss did not improve from 13847.64844\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10280.8594 - mean_absolute_error: 10280.8594 - val_loss: 13859.3359 - val_mean_absolute_error: 13859.3359\n",
      "Epoch 99/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12901.1465 - mean_absolute_error: 12901.1465\n",
      "Epoch 99: val_loss did not improve from 13847.64844\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10276.0996 - mean_absolute_error: 10276.0996 - val_loss: 13854.3799 - val_mean_absolute_error: 13854.3799\n",
      "Epoch 100/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9180.5566 - mean_absolute_error: 9180.5566\n",
      "Epoch 100: val_loss did not improve from 13847.64844\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10294.1777 - mean_absolute_error: 10294.1777 - val_loss: 13886.7822 - val_mean_absolute_error: 13886.7822\n",
      "Epoch 101/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12593.1885 - mean_absolute_error: 12593.1885\n",
      "Epoch 101: val_loss improved from 13847.64844 to 13840.84082, saving model to Weights-00101--13840.84082.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10275.2236 - mean_absolute_error: 10275.2236 - val_loss: 13840.8408 - val_mean_absolute_error: 13840.8408\n",
      "Epoch 102/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12251.7295 - mean_absolute_error: 12251.7295\n",
      "Epoch 102: val_loss did not improve from 13840.84082\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 10275.0498 - mean_absolute_error: 10275.0498 - val_loss: 13843.0342 - val_mean_absolute_error: 13843.0342\n",
      "Epoch 103/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8430.3750 - mean_absolute_error: 8430.3750\n",
      "Epoch 103: val_loss did not improve from 13840.84082\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10273.6689 - mean_absolute_error: 10273.6689 - val_loss: 13844.8184 - val_mean_absolute_error: 13844.8184\n",
      "Epoch 104/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10900.3525 - mean_absolute_error: 10900.3525\n",
      "Epoch 104: val_loss did not improve from 13840.84082\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10278.4307 - mean_absolute_error: 10278.4307 - val_loss: 13883.5303 - val_mean_absolute_error: 13883.5303\n",
      "Epoch 105/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13022.2461 - mean_absolute_error: 13022.2461\n",
      "Epoch 105: val_loss did not improve from 13840.84082\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10268.9258 - mean_absolute_error: 10268.9258 - val_loss: 13853.6670 - val_mean_absolute_error: 13853.6670\n",
      "Epoch 106/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10984.3301 - mean_absolute_error: 10984.3301\n",
      "Epoch 106: val_loss did not improve from 13840.84082\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10269.2002 - mean_absolute_error: 10269.2002 - val_loss: 13843.5771 - val_mean_absolute_error: 13843.5771\n",
      "Epoch 107/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7386.9419 - mean_absolute_error: 7386.9419\n",
      "Epoch 107: val_loss improved from 13840.84082 to 13838.34473, saving model to Weights-00107--13838.34473.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10273.4590 - mean_absolute_error: 10273.4590 - val_loss: 13838.3447 - val_mean_absolute_error: 13838.3447\n",
      "Epoch 108/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10622.2324 - mean_absolute_error: 10622.2324\n",
      "Epoch 108: val_loss did not improve from 13838.34473\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10265.5400 - mean_absolute_error: 10265.5400 - val_loss: 13849.6074 - val_mean_absolute_error: 13849.6074\n",
      "Epoch 109/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9944.5820 - mean_absolute_error: 9944.5820\n",
      "Epoch 109: val_loss did not improve from 13838.34473\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10264.9131 - mean_absolute_error: 10264.9131 - val_loss: 13857.7051 - val_mean_absolute_error: 13857.7051\n",
      "Epoch 110/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8489.3789 - mean_absolute_error: 8489.3789\n",
      "Epoch 110: val_loss did not improve from 13838.34473\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10268.1514 - mean_absolute_error: 10268.1514 - val_loss: 13876.1484 - val_mean_absolute_error: 13876.1484\n",
      "Epoch 111/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10331.6953 - mean_absolute_error: 10331.6953\n",
      "Epoch 111: val_loss did not improve from 13838.34473\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10266.3105 - mean_absolute_error: 10266.3105 - val_loss: 13858.4111 - val_mean_absolute_error: 13858.4111\n",
      "Epoch 112/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9956.9570 - mean_absolute_error: 9956.9570\n",
      "Epoch 112: val_loss did not improve from 13838.34473\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10264.5703 - mean_absolute_error: 10264.5703 - val_loss: 13847.8838 - val_mean_absolute_error: 13847.8838\n",
      "Epoch 113/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9248.7969 - mean_absolute_error: 9248.7969\n",
      "Epoch 113: val_loss did not improve from 13838.34473\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10264.2764 - mean_absolute_error: 10264.2764 - val_loss: 13842.5166 - val_mean_absolute_error: 13842.5166\n",
      "Epoch 114/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10128.0547 - mean_absolute_error: 10128.0547\n",
      "Epoch 114: val_loss did not improve from 13838.34473\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10264.9805 - mean_absolute_error: 10264.9805 - val_loss: 13864.9844 - val_mean_absolute_error: 13864.9844\n",
      "Epoch 115/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10946.1562 - mean_absolute_error: 10946.1562\n",
      "Epoch 115: val_loss did not improve from 13838.34473\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10260.7236 - mean_absolute_error: 10260.7236 - val_loss: 13848.7324 - val_mean_absolute_error: 13848.7324\n",
      "Epoch 116/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12777.3203 - mean_absolute_error: 12777.3203\n",
      "Epoch 116: val_loss improved from 13838.34473 to 13832.00781, saving model to Weights-00116--13832.00781.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10266.9424 - mean_absolute_error: 10266.9424 - val_loss: 13832.0078 - val_mean_absolute_error: 13832.0078\n",
      "Epoch 117/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10121.9336 - mean_absolute_error: 10121.9336\n",
      "Epoch 117: val_loss did not improve from 13832.00781\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10266.1592 - mean_absolute_error: 10266.1592 - val_loss: 13834.7656 - val_mean_absolute_error: 13834.7656\n",
      "Epoch 118/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10790.3789 - mean_absolute_error: 10790.3789\n",
      "Epoch 118: val_loss did not improve from 13832.00781\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10257.8184 - mean_absolute_error: 10257.8184 - val_loss: 13842.5039 - val_mean_absolute_error: 13842.5039\n",
      "Epoch 119/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12538.3574 - mean_absolute_error: 12538.3574\n",
      "Epoch 119: val_loss did not improve from 13832.00781\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10259.8594 - mean_absolute_error: 10259.8594 - val_loss: 13836.5732 - val_mean_absolute_error: 13836.5732\n",
      "Epoch 120/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12498.5840 - mean_absolute_error: 12498.5840\n",
      "Epoch 120: val_loss did not improve from 13832.00781\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10256.7871 - mean_absolute_error: 10256.7871 - val_loss: 13860.1455 - val_mean_absolute_error: 13860.1455\n",
      "Epoch 121/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10630.8809 - mean_absolute_error: 10630.8809\n",
      "Epoch 121: val_loss did not improve from 13832.00781\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10260.4697 - mean_absolute_error: 10260.4697 - val_loss: 13862.9736 - val_mean_absolute_error: 13862.9736\n",
      "Epoch 122/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11101.5713 - mean_absolute_error: 11101.5713\n",
      "Epoch 122: val_loss did not improve from 13832.00781\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10253.2344 - mean_absolute_error: 10253.2344 - val_loss: 13840.1641 - val_mean_absolute_error: 13840.1641\n",
      "Epoch 123/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9141.6729 - mean_absolute_error: 9141.6729\n",
      "Epoch 123: val_loss improved from 13832.00781 to 13825.03223, saving model to Weights-00123--13825.03223.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10259.1191 - mean_absolute_error: 10259.1191 - val_loss: 13825.0322 - val_mean_absolute_error: 13825.0322\n",
      "Epoch 124/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8747.9512 - mean_absolute_error: 8747.9512\n",
      "Epoch 124: val_loss did not improve from 13825.03223\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10257.9951 - mean_absolute_error: 10257.9951 - val_loss: 13852.1963 - val_mean_absolute_error: 13852.1963\n",
      "Epoch 125/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8971.1836 - mean_absolute_error: 8971.1836\n",
      "Epoch 125: val_loss did not improve from 13825.03223\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10253.9463 - mean_absolute_error: 10253.9463 - val_loss: 13851.3633 - val_mean_absolute_error: 13851.3633\n",
      "Epoch 126/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10190.5801 - mean_absolute_error: 10190.5801\n",
      "Epoch 126: val_loss did not improve from 13825.03223\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10255.6494 - mean_absolute_error: 10255.6494 - val_loss: 13825.3760 - val_mean_absolute_error: 13825.3760\n",
      "Epoch 127/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9227.2920 - mean_absolute_error: 9227.2920\n",
      "Epoch 127: val_loss did not improve from 13825.03223\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10251.6182 - mean_absolute_error: 10251.6182 - val_loss: 13841.3721 - val_mean_absolute_error: 13841.3721\n",
      "Epoch 128/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10984.1914 - mean_absolute_error: 10984.1914\n",
      "Epoch 128: val_loss did not improve from 13825.03223\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10257.7236 - mean_absolute_error: 10257.7236 - val_loss: 13852.3232 - val_mean_absolute_error: 13852.3232\n",
      "Epoch 129/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10416.0391 - mean_absolute_error: 10416.0391\n",
      "Epoch 129: val_loss did not improve from 13825.03223\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10243.0332 - mean_absolute_error: 10243.0332 - val_loss: 13825.5596 - val_mean_absolute_error: 13825.5596\n",
      "Epoch 130/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9744.7129 - mean_absolute_error: 9744.7129\n",
      "Epoch 130: val_loss improved from 13825.03223 to 13816.93750, saving model to Weights-00130--13816.93750.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10256.1387 - mean_absolute_error: 10256.1387 - val_loss: 13816.9375 - val_mean_absolute_error: 13816.9385\n",
      "Epoch 131/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12059.4590 - mean_absolute_error: 12059.4590\n",
      "Epoch 131: val_loss did not improve from 13816.93750\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10251.7588 - mean_absolute_error: 10251.7588 - val_loss: 13835.1299 - val_mean_absolute_error: 13835.1299\n",
      "Epoch 132/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11146.9824 - mean_absolute_error: 11146.9824\n",
      "Epoch 132: val_loss did not improve from 13816.93750\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10246.1494 - mean_absolute_error: 10246.1494 - val_loss: 13841.5703 - val_mean_absolute_error: 13841.5703\n",
      "Epoch 133/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11930.4766 - mean_absolute_error: 11930.4766\n",
      "Epoch 133: val_loss did not improve from 13816.93750\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10245.4775 - mean_absolute_error: 10245.4775 - val_loss: 13832.4668 - val_mean_absolute_error: 13832.4668\n",
      "Epoch 134/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6163.0283 - mean_absolute_error: 6163.0283\n",
      "Epoch 134: val_loss did not improve from 13816.93750\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10243.7559 - mean_absolute_error: 10243.7559 - val_loss: 13831.2598 - val_mean_absolute_error: 13831.2598\n",
      "Epoch 135/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10333.8037 - mean_absolute_error: 10333.8037\n",
      "Epoch 135: val_loss did not improve from 13816.93750\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10242.5215 - mean_absolute_error: 10242.5215 - val_loss: 13829.2695 - val_mean_absolute_error: 13829.2695\n",
      "Epoch 136/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9181.4912 - mean_absolute_error: 9181.4912\n",
      "Epoch 136: val_loss did not improve from 13816.93750\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10248.9785 - mean_absolute_error: 10248.9785 - val_loss: 13831.8398 - val_mean_absolute_error: 13831.8398\n",
      "Epoch 137/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9452.2578 - mean_absolute_error: 9452.2578\n",
      "Epoch 137: val_loss did not improve from 13816.93750\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10242.8906 - mean_absolute_error: 10242.8906 - val_loss: 13835.8213 - val_mean_absolute_error: 13835.8213\n",
      "Epoch 138/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8983.8174 - mean_absolute_error: 8983.8174\n",
      "Epoch 138: val_loss did not improve from 13816.93750\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10241.0010 - mean_absolute_error: 10241.0010 - val_loss: 13837.0293 - val_mean_absolute_error: 13837.0293\n",
      "Epoch 139/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9074.4121 - mean_absolute_error: 9074.4121\n",
      "Epoch 139: val_loss did not improve from 13816.93750\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10241.1133 - mean_absolute_error: 10241.1133 - val_loss: 13824.9863 - val_mean_absolute_error: 13824.9863\n",
      "Epoch 140/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11802.8828 - mean_absolute_error: 11802.8828\n",
      "Epoch 140: val_loss did not improve from 13816.93750\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10256.0166 - mean_absolute_error: 10256.0166 - val_loss: 13831.1143 - val_mean_absolute_error: 13831.1143\n",
      "Epoch 141/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12288.0176 - mean_absolute_error: 12288.0176\n",
      "Epoch 141: val_loss did not improve from 13816.93750\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10247.0781 - mean_absolute_error: 10247.0781 - val_loss: 13851.6396 - val_mean_absolute_error: 13851.6396\n",
      "Epoch 142/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8671.8301 - mean_absolute_error: 8671.8301\n",
      "Epoch 142: val_loss did not improve from 13816.93750\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10247.4873 - mean_absolute_error: 10247.4873 - val_loss: 13821.0869 - val_mean_absolute_error: 13821.0869\n",
      "Epoch 143/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9504.1836 - mean_absolute_error: 9504.1836\n",
      "Epoch 143: val_loss did not improve from 13816.93750\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10248.7344 - mean_absolute_error: 10248.7344 - val_loss: 13865.3213 - val_mean_absolute_error: 13865.3213\n",
      "Epoch 144/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8562.8818 - mean_absolute_error: 8562.8818\n",
      "Epoch 144: val_loss did not improve from 13816.93750\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10236.7783 - mean_absolute_error: 10236.7783 - val_loss: 13845.6611 - val_mean_absolute_error: 13845.6611\n",
      "Epoch 145/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9443.6211 - mean_absolute_error: 9443.6211\n",
      "Epoch 145: val_loss did not improve from 13816.93750\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10233.8311 - mean_absolute_error: 10233.8311 - val_loss: 13822.9707 - val_mean_absolute_error: 13822.9707\n",
      "Epoch 146/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13547.0664 - mean_absolute_error: 13547.0664\n",
      "Epoch 146: val_loss improved from 13816.93750 to 13815.54688, saving model to Weights-00146--13815.54688.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10241.5908 - mean_absolute_error: 10241.5908 - val_loss: 13815.5469 - val_mean_absolute_error: 13815.5469\n",
      "Epoch 147/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11496.9346 - mean_absolute_error: 11496.9346\n",
      "Epoch 147: val_loss did not improve from 13815.54688\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10243.8281 - mean_absolute_error: 10243.8281 - val_loss: 13821.9326 - val_mean_absolute_error: 13821.9326\n",
      "Epoch 148/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8283.4424 - mean_absolute_error: 8283.4424\n",
      "Epoch 148: val_loss improved from 13815.54688 to 13813.13672, saving model to Weights-00148--13813.13672.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10235.5205 - mean_absolute_error: 10235.5205 - val_loss: 13813.1367 - val_mean_absolute_error: 13813.1367\n",
      "Epoch 149/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8085.8423 - mean_absolute_error: 8085.8423\n",
      "Epoch 149: val_loss did not improve from 13813.13672\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10230.9521 - mean_absolute_error: 10230.9521 - val_loss: 13817.0674 - val_mean_absolute_error: 13817.0674\n",
      "Epoch 150/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12718.3262 - mean_absolute_error: 12718.3262\n",
      "Epoch 150: val_loss did not improve from 13813.13672\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10229.0596 - mean_absolute_error: 10229.0596 - val_loss: 13822.0566 - val_mean_absolute_error: 13822.0566\n",
      "Epoch 151/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9375.8662 - mean_absolute_error: 9375.8662\n",
      "Epoch 151: val_loss did not improve from 13813.13672\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10233.7363 - mean_absolute_error: 10233.7363 - val_loss: 13822.7832 - val_mean_absolute_error: 13822.7832\n",
      "Epoch 152/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10719.8135 - mean_absolute_error: 10719.8135\n",
      "Epoch 152: val_loss did not improve from 13813.13672\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10234.2529 - mean_absolute_error: 10234.2529 - val_loss: 13829.6797 - val_mean_absolute_error: 13829.6797\n",
      "Epoch 153/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8787.6953 - mean_absolute_error: 8787.6953\n",
      "Epoch 153: val_loss did not improve from 13813.13672\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10231.5781 - mean_absolute_error: 10231.5781 - val_loss: 13841.4326 - val_mean_absolute_error: 13841.4326\n",
      "Epoch 154/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11564.0811 - mean_absolute_error: 11564.0811\n",
      "Epoch 154: val_loss improved from 13813.13672 to 13813.05273, saving model to Weights-00154--13813.05273.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10228.9971 - mean_absolute_error: 10228.9971 - val_loss: 13813.0527 - val_mean_absolute_error: 13813.0527\n",
      "Epoch 155/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11212.8008 - mean_absolute_error: 11212.8008\n",
      "Epoch 155: val_loss did not improve from 13813.05273\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10224.5322 - mean_absolute_error: 10224.5322 - val_loss: 13818.1592 - val_mean_absolute_error: 13818.1592\n",
      "Epoch 156/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12017.3398 - mean_absolute_error: 12017.3398\n",
      "Epoch 156: val_loss did not improve from 13813.05273\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10224.9990 - mean_absolute_error: 10224.9990 - val_loss: 13822.3486 - val_mean_absolute_error: 13822.3486\n",
      "Epoch 157/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11028.2998 - mean_absolute_error: 11028.2998\n",
      "Epoch 157: val_loss improved from 13813.05273 to 13811.89453, saving model to Weights-00157--13811.89453.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10229.5840 - mean_absolute_error: 10229.5840 - val_loss: 13811.8945 - val_mean_absolute_error: 13811.8945\n",
      "Epoch 158/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7368.2012 - mean_absolute_error: 7368.2012\n",
      "Epoch 158: val_loss did not improve from 13811.89453\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10223.0645 - mean_absolute_error: 10223.0645 - val_loss: 13819.0039 - val_mean_absolute_error: 13819.0039\n",
      "Epoch 159/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8317.9482 - mean_absolute_error: 8317.9482\n",
      "Epoch 159: val_loss did not improve from 13811.89453\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10222.6758 - mean_absolute_error: 10222.6758 - val_loss: 13816.4980 - val_mean_absolute_error: 13816.4980\n",
      "Epoch 160/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12887.2344 - mean_absolute_error: 12887.2344\n",
      "Epoch 160: val_loss did not improve from 13811.89453\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10224.3066 - mean_absolute_error: 10224.3066 - val_loss: 13836.5977 - val_mean_absolute_error: 13836.5977\n",
      "Epoch 161/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9449.9873 - mean_absolute_error: 9449.9873\n",
      "Epoch 161: val_loss did not improve from 13811.89453\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10229.3545 - mean_absolute_error: 10229.3545 - val_loss: 13838.6504 - val_mean_absolute_error: 13838.6504\n",
      "Epoch 162/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10840.0371 - mean_absolute_error: 10840.0371\n",
      "Epoch 162: val_loss improved from 13811.89453 to 13803.73730, saving model to Weights-00162--13803.73730.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10222.0430 - mean_absolute_error: 10222.0430 - val_loss: 13803.7373 - val_mean_absolute_error: 13803.7373\n",
      "Epoch 163/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10230.9189 - mean_absolute_error: 10230.9189\n",
      "Epoch 163: val_loss did not improve from 13803.73730\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10221.4297 - mean_absolute_error: 10221.4297 - val_loss: 13816.1719 - val_mean_absolute_error: 13816.1719\n",
      "Epoch 164/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10867.1523 - mean_absolute_error: 10867.1523\n",
      "Epoch 164: val_loss did not improve from 13803.73730\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10221.9160 - mean_absolute_error: 10221.9160 - val_loss: 13807.3164 - val_mean_absolute_error: 13807.3164\n",
      "Epoch 165/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9918.4492 - mean_absolute_error: 9918.4492\n",
      "Epoch 165: val_loss did not improve from 13803.73730\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10226.4365 - mean_absolute_error: 10226.4365 - val_loss: 13827.0391 - val_mean_absolute_error: 13827.0391\n",
      "Epoch 166/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13934.3623 - mean_absolute_error: 13934.3623\n",
      "Epoch 166: val_loss did not improve from 13803.73730\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10217.2510 - mean_absolute_error: 10217.2510 - val_loss: 13826.1006 - val_mean_absolute_error: 13826.1006\n",
      "Epoch 167/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9959.0068 - mean_absolute_error: 9959.0068\n",
      "Epoch 167: val_loss did not improve from 13803.73730\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10216.9707 - mean_absolute_error: 10216.9707 - val_loss: 13810.2168 - val_mean_absolute_error: 13810.2168\n",
      "Epoch 168/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8435.4883 - mean_absolute_error: 8435.4883\n",
      "Epoch 168: val_loss did not improve from 13803.73730\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10215.5898 - mean_absolute_error: 10215.5898 - val_loss: 13811.9883 - val_mean_absolute_error: 13811.9883\n",
      "Epoch 169/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10961.1104 - mean_absolute_error: 10961.1104\n",
      "Epoch 169: val_loss improved from 13803.73730 to 13801.26562, saving model to Weights-00169--13801.26562.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10210.8789 - mean_absolute_error: 10210.8789 - val_loss: 13801.2656 - val_mean_absolute_error: 13801.2656\n",
      "Epoch 170/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8917.9043 - mean_absolute_error: 8917.9043\n",
      "Epoch 170: val_loss did not improve from 13801.26562\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10236.7764 - mean_absolute_error: 10236.7764 - val_loss: 13825.9326 - val_mean_absolute_error: 13825.9326\n",
      "Epoch 171/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7643.1060 - mean_absolute_error: 7643.1060\n",
      "Epoch 171: val_loss improved from 13801.26562 to 13797.31543, saving model to Weights-00171--13797.31543.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10211.9258 - mean_absolute_error: 10211.9258 - val_loss: 13797.3154 - val_mean_absolute_error: 13797.3154\n",
      "Epoch 172/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10123.9971 - mean_absolute_error: 10123.9971\n",
      "Epoch 172: val_loss did not improve from 13797.31543\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10213.8301 - mean_absolute_error: 10213.8301 - val_loss: 13806.2539 - val_mean_absolute_error: 13806.2539\n",
      "Epoch 173/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10760.8232 - mean_absolute_error: 10760.8232\n",
      "Epoch 173: val_loss did not improve from 13797.31543\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10211.0557 - mean_absolute_error: 10211.0557 - val_loss: 13810.2158 - val_mean_absolute_error: 13810.2158\n",
      "Epoch 174/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9251.4121 - mean_absolute_error: 9251.4121\n",
      "Epoch 174: val_loss did not improve from 13797.31543\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10206.4639 - mean_absolute_error: 10206.4639 - val_loss: 13802.0664 - val_mean_absolute_error: 13802.0664\n",
      "Epoch 175/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7654.2368 - mean_absolute_error: 7654.2368\n",
      "Epoch 175: val_loss did not improve from 13797.31543\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10212.6299 - mean_absolute_error: 10212.6299 - val_loss: 13809.4590 - val_mean_absolute_error: 13809.4590\n",
      "Epoch 176/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9802.1797 - mean_absolute_error: 9802.1797\n",
      "Epoch 176: val_loss did not improve from 13797.31543\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10213.6338 - mean_absolute_error: 10213.6338 - val_loss: 13799.8535 - val_mean_absolute_error: 13799.8535\n",
      "Epoch 177/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5969.8066 - mean_absolute_error: 5969.8066\n",
      "Epoch 177: val_loss did not improve from 13797.31543\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10204.3320 - mean_absolute_error: 10204.3320 - val_loss: 13801.8145 - val_mean_absolute_error: 13801.8145\n",
      "Epoch 178/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8040.9502 - mean_absolute_error: 8040.9502\n",
      "Epoch 178: val_loss did not improve from 13797.31543\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10205.1250 - mean_absolute_error: 10205.1250 - val_loss: 13820.8857 - val_mean_absolute_error: 13820.8857\n",
      "Epoch 179/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10486.5293 - mean_absolute_error: 10486.5293\n",
      "Epoch 179: val_loss did not improve from 13797.31543\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10205.1465 - mean_absolute_error: 10205.1465 - val_loss: 13804.1328 - val_mean_absolute_error: 13804.1328\n",
      "Epoch 180/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9632.3770 - mean_absolute_error: 9632.3770\n",
      "Epoch 180: val_loss did not improve from 13797.31543\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10204.7891 - mean_absolute_error: 10204.7891 - val_loss: 13801.2822 - val_mean_absolute_error: 13801.2822\n",
      "Epoch 181/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12690.6064 - mean_absolute_error: 12690.6064\n",
      "Epoch 181: val_loss did not improve from 13797.31543\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10205.9316 - mean_absolute_error: 10205.9316 - val_loss: 13799.1514 - val_mean_absolute_error: 13799.1514\n",
      "Epoch 182/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10825.9365 - mean_absolute_error: 10825.9365\n",
      "Epoch 182: val_loss improved from 13797.31543 to 13790.78125, saving model to Weights-00182--13790.78125.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10238.6328 - mean_absolute_error: 10238.6328 - val_loss: 13790.7812 - val_mean_absolute_error: 13790.7812\n",
      "Epoch 183/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9564.9844 - mean_absolute_error: 9564.9844\n",
      "Epoch 183: val_loss did not improve from 13790.78125\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10211.3379 - mean_absolute_error: 10211.3379 - val_loss: 13814.4639 - val_mean_absolute_error: 13814.4639\n",
      "Epoch 184/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9337.9414 - mean_absolute_error: 9337.9414\n",
      "Epoch 184: val_loss did not improve from 13790.78125\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10199.1348 - mean_absolute_error: 10199.1348 - val_loss: 13806.9707 - val_mean_absolute_error: 13806.9707\n",
      "Epoch 185/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10959.0723 - mean_absolute_error: 10959.0723\n",
      "Epoch 185: val_loss did not improve from 13790.78125\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10199.6299 - mean_absolute_error: 10199.6299 - val_loss: 13805.9414 - val_mean_absolute_error: 13805.9414\n",
      "Epoch 186/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8615.1562 - mean_absolute_error: 8615.1562\n",
      "Epoch 186: val_loss improved from 13790.78125 to 13788.31250, saving model to Weights-00186--13788.31250.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10230.7051 - mean_absolute_error: 10230.7051 - val_loss: 13788.3125 - val_mean_absolute_error: 13788.3125\n",
      "Epoch 187/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13754.9570 - mean_absolute_error: 13754.9570\n",
      "Epoch 187: val_loss did not improve from 13788.31250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10214.2646 - mean_absolute_error: 10214.2646 - val_loss: 13828.6279 - val_mean_absolute_error: 13828.6279\n",
      "Epoch 188/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10659.3730 - mean_absolute_error: 10659.3730\n",
      "Epoch 188: val_loss did not improve from 13788.31250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10198.0830 - mean_absolute_error: 10198.0830 - val_loss: 13807.6055 - val_mean_absolute_error: 13807.6055\n",
      "Epoch 189/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7237.8696 - mean_absolute_error: 7237.8696\n",
      "Epoch 189: val_loss did not improve from 13788.31250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10201.3594 - mean_absolute_error: 10201.3594 - val_loss: 13791.3779 - val_mean_absolute_error: 13791.3779\n",
      "Epoch 190/3000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 10182.8594 - mean_absolute_error: 10182.8594\n",
      "Epoch 190: val_loss did not improve from 13788.31250\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10192.3213 - mean_absolute_error: 10192.3213 - val_loss: 13802.0879 - val_mean_absolute_error: 13802.0879\n",
      "Epoch 191/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7909.3257 - mean_absolute_error: 7909.3257\n",
      "Epoch 191: val_loss did not improve from 13788.31250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10193.1084 - mean_absolute_error: 10193.1084 - val_loss: 13798.0459 - val_mean_absolute_error: 13798.0459\n",
      "Epoch 192/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12458.4609 - mean_absolute_error: 12458.4609\n",
      "Epoch 192: val_loss did not improve from 13788.31250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10192.4199 - mean_absolute_error: 10192.4199 - val_loss: 13797.4590 - val_mean_absolute_error: 13797.4590\n",
      "Epoch 193/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9748.1816 - mean_absolute_error: 9748.1816\n",
      "Epoch 193: val_loss did not improve from 13788.31250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10199.5156 - mean_absolute_error: 10199.5156 - val_loss: 13810.0908 - val_mean_absolute_error: 13810.0908\n",
      "Epoch 194/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11303.6797 - mean_absolute_error: 11303.6797\n",
      "Epoch 194: val_loss did not improve from 13788.31250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10187.1094 - mean_absolute_error: 10187.1094 - val_loss: 13796.8975 - val_mean_absolute_error: 13796.8975\n",
      "Epoch 195/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12822.2588 - mean_absolute_error: 12822.2588\n",
      "Epoch 195: val_loss improved from 13788.31250 to 13787.86133, saving model to Weights-00195--13787.86133.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10188.5459 - mean_absolute_error: 10188.5459 - val_loss: 13787.8613 - val_mean_absolute_error: 13787.8613\n",
      "Epoch 196/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9233.6250 - mean_absolute_error: 9233.6250\n",
      "Epoch 196: val_loss did not improve from 13787.86133\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10192.5977 - mean_absolute_error: 10192.5977 - val_loss: 13792.0430 - val_mean_absolute_error: 13792.0430\n",
      "Epoch 197/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12105.8574 - mean_absolute_error: 12105.8574\n",
      "Epoch 197: val_loss improved from 13787.86133 to 13786.16113, saving model to Weights-00197--13786.16113.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10188.0811 - mean_absolute_error: 10188.0811 - val_loss: 13786.1611 - val_mean_absolute_error: 13786.1611\n",
      "Epoch 198/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6519.5869 - mean_absolute_error: 6519.5869\n",
      "Epoch 198: val_loss did not improve from 13786.16113\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10185.7383 - mean_absolute_error: 10185.7383 - val_loss: 13791.1250 - val_mean_absolute_error: 13791.1250\n",
      "Epoch 199/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12124.1807 - mean_absolute_error: 12124.1807\n",
      "Epoch 199: val_loss did not improve from 13786.16113\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10185.3281 - mean_absolute_error: 10185.3281 - val_loss: 13810.7871 - val_mean_absolute_error: 13810.7871\n",
      "Epoch 200/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9936.9551 - mean_absolute_error: 9936.9551\n",
      "Epoch 200: val_loss did not improve from 13786.16113\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10190.7080 - mean_absolute_error: 10190.7080 - val_loss: 13791.9111 - val_mean_absolute_error: 13791.9111\n",
      "Epoch 201/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12555.7188 - mean_absolute_error: 12555.7188\n",
      "Epoch 201: val_loss did not improve from 13786.16113\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10228.3164 - mean_absolute_error: 10228.3164 - val_loss: 13824.7383 - val_mean_absolute_error: 13824.7383\n",
      "Epoch 202/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7628.4424 - mean_absolute_error: 7628.4424\n",
      "Epoch 202: val_loss improved from 13786.16113 to 13779.76562, saving model to Weights-00202--13779.76562.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10191.1611 - mean_absolute_error: 10191.1611 - val_loss: 13779.7656 - val_mean_absolute_error: 13779.7656\n",
      "Epoch 203/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9441.7812 - mean_absolute_error: 9441.7812\n",
      "Epoch 203: val_loss did not improve from 13779.76562\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10193.4570 - mean_absolute_error: 10193.4570 - val_loss: 13792.3486 - val_mean_absolute_error: 13792.3486\n",
      "Epoch 204/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6979.4722 - mean_absolute_error: 6979.4722\n",
      "Epoch 204: val_loss did not improve from 13779.76562\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10179.0293 - mean_absolute_error: 10179.0293 - val_loss: 13782.5264 - val_mean_absolute_error: 13782.5264\n",
      "Epoch 205/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9724.2793 - mean_absolute_error: 9724.2793\n",
      "Epoch 205: val_loss did not improve from 13779.76562\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10187.1875 - mean_absolute_error: 10187.1875 - val_loss: 13782.4238 - val_mean_absolute_error: 13782.4238\n",
      "Epoch 206/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5024.6938 - mean_absolute_error: 5024.6938\n",
      "Epoch 206: val_loss did not improve from 13779.76562\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10178.9609 - mean_absolute_error: 10178.9609 - val_loss: 13804.2656 - val_mean_absolute_error: 13804.2656\n",
      "Epoch 207/3000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 10126.3994 - mean_absolute_error: 10126.3994\n",
      "Epoch 207: val_loss did not improve from 13779.76562\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10189.2969 - mean_absolute_error: 10189.2969 - val_loss: 13792.2930 - val_mean_absolute_error: 13792.2930\n",
      "Epoch 208/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9663.9375 - mean_absolute_error: 9663.9375\n",
      "Epoch 208: val_loss did not improve from 13779.76562\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10180.2158 - mean_absolute_error: 10180.2158 - val_loss: 13791.6133 - val_mean_absolute_error: 13791.6133\n",
      "Epoch 209/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8310.3574 - mean_absolute_error: 8310.3574\n",
      "Epoch 209: val_loss did not improve from 13779.76562\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10176.2012 - mean_absolute_error: 10176.2012 - val_loss: 13785.3564 - val_mean_absolute_error: 13785.3564\n",
      "Epoch 210/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10578.1484 - mean_absolute_error: 10578.1484\n",
      "Epoch 210: val_loss did not improve from 13779.76562\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10183.8438 - mean_absolute_error: 10183.8438 - val_loss: 13780.5156 - val_mean_absolute_error: 13780.5156\n",
      "Epoch 211/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8959.4033 - mean_absolute_error: 8959.4033\n",
      "Epoch 211: val_loss did not improve from 13779.76562\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10176.3389 - mean_absolute_error: 10176.3389 - val_loss: 13790.2949 - val_mean_absolute_error: 13790.2949\n",
      "Epoch 212/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7706.6104 - mean_absolute_error: 7706.6104\n",
      "Epoch 212: val_loss did not improve from 13779.76562\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10175.3467 - mean_absolute_error: 10175.3467 - val_loss: 13786.8496 - val_mean_absolute_error: 13786.8496\n",
      "Epoch 213/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12231.4277 - mean_absolute_error: 12231.4277\n",
      "Epoch 213: val_loss did not improve from 13779.76562\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10171.6680 - mean_absolute_error: 10171.6680 - val_loss: 13785.4199 - val_mean_absolute_error: 13785.4199\n",
      "Epoch 214/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11048.9883 - mean_absolute_error: 11048.9883\n",
      "Epoch 214: val_loss did not improve from 13779.76562\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10173.0703 - mean_absolute_error: 10173.0703 - val_loss: 13786.1338 - val_mean_absolute_error: 13786.1338\n",
      "Epoch 215/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6879.5806 - mean_absolute_error: 6879.5806\n",
      "Epoch 215: val_loss did not improve from 13779.76562\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10184.1475 - mean_absolute_error: 10184.1475 - val_loss: 13795.6035 - val_mean_absolute_error: 13795.6035\n",
      "Epoch 216/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12077.8564 - mean_absolute_error: 12077.8564\n",
      "Epoch 216: val_loss improved from 13779.76562 to 13772.78223, saving model to Weights-00216--13772.78223.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10168.1621 - mean_absolute_error: 10168.1621 - val_loss: 13772.7822 - val_mean_absolute_error: 13772.7822\n",
      "Epoch 217/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10500.8467 - mean_absolute_error: 10500.8467\n",
      "Epoch 217: val_loss improved from 13772.78223 to 13772.15723, saving model to Weights-00217--13772.15723.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10174.3203 - mean_absolute_error: 10174.3203 - val_loss: 13772.1572 - val_mean_absolute_error: 13772.1572\n",
      "Epoch 218/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13539.7363 - mean_absolute_error: 13539.7363\n",
      "Epoch 218: val_loss did not improve from 13772.15723\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10171.4961 - mean_absolute_error: 10171.4961 - val_loss: 13782.0811 - val_mean_absolute_error: 13782.0811\n",
      "Epoch 219/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7045.8027 - mean_absolute_error: 7045.8027\n",
      "Epoch 219: val_loss did not improve from 13772.15723\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10168.0234 - mean_absolute_error: 10168.0234 - val_loss: 13778.4453 - val_mean_absolute_error: 13778.4453\n",
      "Epoch 220/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8245.6279 - mean_absolute_error: 8245.6279\n",
      "Epoch 220: val_loss did not improve from 13772.15723\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10166.6904 - mean_absolute_error: 10166.6904 - val_loss: 13780.8301 - val_mean_absolute_error: 13780.8301\n",
      "Epoch 221/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9334.4609 - mean_absolute_error: 9334.4609\n",
      "Epoch 221: val_loss did not improve from 13772.15723\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10164.6846 - mean_absolute_error: 10164.6846 - val_loss: 13773.4043 - val_mean_absolute_error: 13773.4043\n",
      "Epoch 222/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9682.2441 - mean_absolute_error: 9682.2441\n",
      "Epoch 222: val_loss did not improve from 13772.15723\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10170.6514 - mean_absolute_error: 10170.6514 - val_loss: 13781.0195 - val_mean_absolute_error: 13781.0195\n",
      "Epoch 223/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13345.2080 - mean_absolute_error: 13345.2080\n",
      "Epoch 223: val_loss did not improve from 13772.15723\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10164.3545 - mean_absolute_error: 10164.3545 - val_loss: 13782.1250 - val_mean_absolute_error: 13782.1250\n",
      "Epoch 224/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9758.9844 - mean_absolute_error: 9758.9844\n",
      "Epoch 224: val_loss did not improve from 13772.15723\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10159.6094 - mean_absolute_error: 10159.6094 - val_loss: 13773.1250 - val_mean_absolute_error: 13773.1250\n",
      "Epoch 225/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11504.6855 - mean_absolute_error: 11504.6855\n",
      "Epoch 225: val_loss did not improve from 13772.15723\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10163.8721 - mean_absolute_error: 10163.8721 - val_loss: 13773.7031 - val_mean_absolute_error: 13773.7031\n",
      "Epoch 226/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6518.9268 - mean_absolute_error: 6518.9268\n",
      "Epoch 226: val_loss did not improve from 13772.15723\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 10169.3281 - mean_absolute_error: 10169.3281 - val_loss: 13778.4766 - val_mean_absolute_error: 13778.4775\n",
      "Epoch 227/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9718.8291 - mean_absolute_error: 9718.8291\n",
      "Epoch 227: val_loss did not improve from 13772.15723\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10164.7334 - mean_absolute_error: 10164.7334 - val_loss: 13777.8008 - val_mean_absolute_error: 13777.8008\n",
      "Epoch 228/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7808.4131 - mean_absolute_error: 7808.4131\n",
      "Epoch 228: val_loss did not improve from 13772.15723\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10161.1992 - mean_absolute_error: 10161.1992 - val_loss: 13779.6182 - val_mean_absolute_error: 13779.6182\n",
      "Epoch 229/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9312.1387 - mean_absolute_error: 9312.1387\n",
      "Epoch 229: val_loss did not improve from 13772.15723\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10160.2500 - mean_absolute_error: 10160.2500 - val_loss: 13777.9443 - val_mean_absolute_error: 13777.9443\n",
      "Epoch 230/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7825.5605 - mean_absolute_error: 7825.5605\n",
      "Epoch 230: val_loss improved from 13772.15723 to 13767.34863, saving model to Weights-00230--13767.34863.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10153.4639 - mean_absolute_error: 10153.4639 - val_loss: 13767.3486 - val_mean_absolute_error: 13767.3486\n",
      "Epoch 231/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6330.5566 - mean_absolute_error: 6330.5566\n",
      "Epoch 231: val_loss improved from 13767.34863 to 13764.87598, saving model to Weights-00231--13764.87598.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10163.0781 - mean_absolute_error: 10163.0781 - val_loss: 13764.8760 - val_mean_absolute_error: 13764.8760\n",
      "Epoch 232/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9052.2480 - mean_absolute_error: 9052.2480\n",
      "Epoch 232: val_loss did not improve from 13764.87598\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10157.4336 - mean_absolute_error: 10157.4336 - val_loss: 13769.6982 - val_mean_absolute_error: 13769.6982\n",
      "Epoch 233/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9764.0938 - mean_absolute_error: 9764.0938\n",
      "Epoch 233: val_loss did not improve from 13764.87598\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10152.3594 - mean_absolute_error: 10152.3594 - val_loss: 13774.8721 - val_mean_absolute_error: 13774.8721\n",
      "Epoch 234/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11382.0098 - mean_absolute_error: 11382.0098\n",
      "Epoch 234: val_loss did not improve from 13764.87598\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10152.0898 - mean_absolute_error: 10152.0898 - val_loss: 13772.3232 - val_mean_absolute_error: 13772.3232\n",
      "Epoch 235/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12833.6797 - mean_absolute_error: 12833.6797\n",
      "Epoch 235: val_loss did not improve from 13764.87598\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10149.8799 - mean_absolute_error: 10149.8799 - val_loss: 13773.6055 - val_mean_absolute_error: 13773.6055\n",
      "Epoch 236/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10235.1631 - mean_absolute_error: 10235.1631\n",
      "Epoch 236: val_loss did not improve from 13764.87598\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10153.0518 - mean_absolute_error: 10153.0518 - val_loss: 13765.1377 - val_mean_absolute_error: 13765.1377\n",
      "Epoch 237/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8144.6631 - mean_absolute_error: 8144.6631\n",
      "Epoch 237: val_loss did not improve from 13764.87598\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10150.8848 - mean_absolute_error: 10150.8848 - val_loss: 13774.7881 - val_mean_absolute_error: 13774.7881\n",
      "Epoch 238/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10428.8037 - mean_absolute_error: 10428.8037\n",
      "Epoch 238: val_loss did not improve from 13764.87598\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10152.4619 - mean_absolute_error: 10152.4619 - val_loss: 13770.0312 - val_mean_absolute_error: 13770.0312\n",
      "Epoch 239/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8686.0020 - mean_absolute_error: 8686.0020\n",
      "Epoch 239: val_loss improved from 13764.87598 to 13761.28418, saving model to Weights-00239--13761.28418.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10154.8584 - mean_absolute_error: 10154.8584 - val_loss: 13761.2842 - val_mean_absolute_error: 13761.2842\n",
      "Epoch 240/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10293.0498 - mean_absolute_error: 10293.0498\n",
      "Epoch 240: val_loss did not improve from 13761.28418\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10149.5986 - mean_absolute_error: 10149.5986 - val_loss: 13771.2988 - val_mean_absolute_error: 13771.2988\n",
      "Epoch 241/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8622.2695 - mean_absolute_error: 8622.2695\n",
      "Epoch 241: val_loss did not improve from 13761.28418\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10149.1055 - mean_absolute_error: 10149.1055 - val_loss: 13773.3193 - val_mean_absolute_error: 13773.3193\n",
      "Epoch 242/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7928.4189 - mean_absolute_error: 7928.4189\n",
      "Epoch 242: val_loss did not improve from 13761.28418\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10152.8057 - mean_absolute_error: 10152.8057 - val_loss: 13773.1289 - val_mean_absolute_error: 13773.1289\n",
      "Epoch 243/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10711.0586 - mean_absolute_error: 10711.0586\n",
      "Epoch 243: val_loss did not improve from 13761.28418\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10145.4639 - mean_absolute_error: 10145.4639 - val_loss: 13768.1309 - val_mean_absolute_error: 13768.1309\n",
      "Epoch 244/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8893.7627 - mean_absolute_error: 8893.7627\n",
      "Epoch 244: val_loss did not improve from 13761.28418\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10152.0771 - mean_absolute_error: 10152.0771 - val_loss: 13779.2324 - val_mean_absolute_error: 13779.2324\n",
      "Epoch 245/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9467.2578 - mean_absolute_error: 9467.2578\n",
      "Epoch 245: val_loss improved from 13761.28418 to 13758.61133, saving model to Weights-00245--13758.61133.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10142.7051 - mean_absolute_error: 10142.7051 - val_loss: 13758.6113 - val_mean_absolute_error: 13758.6113\n",
      "Epoch 246/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12086.2598 - mean_absolute_error: 12086.2598\n",
      "Epoch 246: val_loss did not improve from 13758.61133\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10152.3076 - mean_absolute_error: 10152.3076 - val_loss: 13759.0352 - val_mean_absolute_error: 13759.0352\n",
      "Epoch 247/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10382.5869 - mean_absolute_error: 10382.5869\n",
      "Epoch 247: val_loss did not improve from 13758.61133\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10139.9424 - mean_absolute_error: 10139.9424 - val_loss: 13770.6846 - val_mean_absolute_error: 13770.6846\n",
      "Epoch 248/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9046.6904 - mean_absolute_error: 9046.6904\n",
      "Epoch 248: val_loss did not improve from 13758.61133\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10151.9121 - mean_absolute_error: 10151.9121 - val_loss: 13765.2969 - val_mean_absolute_error: 13765.2969\n",
      "Epoch 249/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10682.3564 - mean_absolute_error: 10682.3564\n",
      "Epoch 249: val_loss did not improve from 13758.61133\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10145.2900 - mean_absolute_error: 10145.2900 - val_loss: 13767.1094 - val_mean_absolute_error: 13767.1094\n",
      "Epoch 250/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8336.2852 - mean_absolute_error: 8336.2852\n",
      "Epoch 250: val_loss did not improve from 13758.61133\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10146.4131 - mean_absolute_error: 10146.4131 - val_loss: 13790.0254 - val_mean_absolute_error: 13790.0254\n",
      "Epoch 251/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8045.6348 - mean_absolute_error: 8045.6348\n",
      "Epoch 251: val_loss did not improve from 13758.61133\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10141.4531 - mean_absolute_error: 10141.4531 - val_loss: 13771.6543 - val_mean_absolute_error: 13771.6543\n",
      "Epoch 252/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12702.8848 - mean_absolute_error: 12702.8848\n",
      "Epoch 252: val_loss improved from 13758.61133 to 13756.80371, saving model to Weights-00252--13756.80371.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10134.3516 - mean_absolute_error: 10134.3516 - val_loss: 13756.8037 - val_mean_absolute_error: 13756.8037\n",
      "Epoch 253/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12865.3896 - mean_absolute_error: 12865.3896\n",
      "Epoch 253: val_loss did not improve from 13756.80371\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10146.8945 - mean_absolute_error: 10146.8945 - val_loss: 13762.2363 - val_mean_absolute_error: 13762.2363\n",
      "Epoch 254/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11338.2988 - mean_absolute_error: 11338.2988\n",
      "Epoch 254: val_loss did not improve from 13756.80371\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10134.6719 - mean_absolute_error: 10134.6719 - val_loss: 13759.5371 - val_mean_absolute_error: 13759.5371\n",
      "Epoch 255/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13111.9922 - mean_absolute_error: 13111.9922\n",
      "Epoch 255: val_loss improved from 13756.80371 to 13754.06641, saving model to Weights-00255--13754.06641.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10137.1523 - mean_absolute_error: 10137.1523 - val_loss: 13754.0664 - val_mean_absolute_error: 13754.0664\n",
      "Epoch 256/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8588.0254 - mean_absolute_error: 8588.0254\n",
      "Epoch 256: val_loss did not improve from 13754.06641\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10135.5801 - mean_absolute_error: 10135.5801 - val_loss: 13772.0166 - val_mean_absolute_error: 13772.0166\n",
      "Epoch 257/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12324.1348 - mean_absolute_error: 12324.1348\n",
      "Epoch 257: val_loss improved from 13754.06641 to 13754.02832, saving model to Weights-00257--13754.02832.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10135.3359 - mean_absolute_error: 10135.3359 - val_loss: 13754.0283 - val_mean_absolute_error: 13754.0283\n",
      "Epoch 258/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12526.6035 - mean_absolute_error: 12526.6035\n",
      "Epoch 258: val_loss did not improve from 13754.02832\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10133.2666 - mean_absolute_error: 10133.2666 - val_loss: 13755.3779 - val_mean_absolute_error: 13755.3779\n",
      "Epoch 259/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7536.3770 - mean_absolute_error: 7536.3770\n",
      "Epoch 259: val_loss improved from 13754.02832 to 13751.54785, saving model to Weights-00259--13751.54785.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10142.5117 - mean_absolute_error: 10142.5117 - val_loss: 13751.5479 - val_mean_absolute_error: 13751.5479\n",
      "Epoch 260/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7878.3682 - mean_absolute_error: 7878.3682\n",
      "Epoch 260: val_loss did not improve from 13751.54785\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10138.0986 - mean_absolute_error: 10138.0986 - val_loss: 13777.3955 - val_mean_absolute_error: 13777.3955\n",
      "Epoch 261/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10911.6426 - mean_absolute_error: 10911.6426\n",
      "Epoch 261: val_loss did not improve from 13751.54785\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10153.4531 - mean_absolute_error: 10153.4531 - val_loss: 13781.5938 - val_mean_absolute_error: 13781.5938\n",
      "Epoch 262/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11272.1973 - mean_absolute_error: 11272.1973\n",
      "Epoch 262: val_loss did not improve from 13751.54785\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10127.9346 - mean_absolute_error: 10127.9346 - val_loss: 13756.8018 - val_mean_absolute_error: 13756.8018\n",
      "Epoch 263/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8919.3594 - mean_absolute_error: 8919.3594\n",
      "Epoch 263: val_loss did not improve from 13751.54785\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10138.4336 - mean_absolute_error: 10138.4336 - val_loss: 13755.0273 - val_mean_absolute_error: 13755.0273\n",
      "Epoch 264/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9125.6582 - mean_absolute_error: 9125.6582\n",
      "Epoch 264: val_loss did not improve from 13751.54785\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10134.1514 - mean_absolute_error: 10134.1514 - val_loss: 13762.8066 - val_mean_absolute_error: 13762.8066\n",
      "Epoch 265/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8823.9023 - mean_absolute_error: 8823.9023\n",
      "Epoch 265: val_loss did not improve from 13751.54785\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10128.2012 - mean_absolute_error: 10128.2012 - val_loss: 13757.2764 - val_mean_absolute_error: 13757.2764\n",
      "Epoch 266/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8892.4883 - mean_absolute_error: 8892.4883\n",
      "Epoch 266: val_loss improved from 13751.54785 to 13751.15039, saving model to Weights-00266--13751.15039.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10130.9805 - mean_absolute_error: 10130.9805 - val_loss: 13751.1504 - val_mean_absolute_error: 13751.1504\n",
      "Epoch 267/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10447.2188 - mean_absolute_error: 10447.2188\n",
      "Epoch 267: val_loss improved from 13751.15039 to 13749.53906, saving model to Weights-00267--13749.53906.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10140.7275 - mean_absolute_error: 10140.7275 - val_loss: 13749.5391 - val_mean_absolute_error: 13749.5391\n",
      "Epoch 268/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8084.6724 - mean_absolute_error: 8084.6724\n",
      "Epoch 268: val_loss did not improve from 13749.53906\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10141.1719 - mean_absolute_error: 10141.1719 - val_loss: 13790.1348 - val_mean_absolute_error: 13790.1348\n",
      "Epoch 269/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10764.8848 - mean_absolute_error: 10764.8848\n",
      "Epoch 269: val_loss did not improve from 13749.53906\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10128.4004 - mean_absolute_error: 10128.4004 - val_loss: 13752.2197 - val_mean_absolute_error: 13752.2197\n",
      "Epoch 270/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10245.3945 - mean_absolute_error: 10245.3945\n",
      "Epoch 270: val_loss did not improve from 13749.53906\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10124.8281 - mean_absolute_error: 10124.8281 - val_loss: 13750.1035 - val_mean_absolute_error: 13750.1035\n",
      "Epoch 271/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11002.4902 - mean_absolute_error: 11002.4902\n",
      "Epoch 271: val_loss improved from 13749.53906 to 13748.41797, saving model to Weights-00271--13748.41797.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10124.6807 - mean_absolute_error: 10124.6807 - val_loss: 13748.4180 - val_mean_absolute_error: 13748.4180\n",
      "Epoch 272/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7718.5630 - mean_absolute_error: 7718.5630\n",
      "Epoch 272: val_loss did not improve from 13748.41797\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10136.0967 - mean_absolute_error: 10136.0967 - val_loss: 13766.1201 - val_mean_absolute_error: 13766.1201\n",
      "Epoch 273/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9176.6328 - mean_absolute_error: 9176.6328\n",
      "Epoch 273: val_loss did not improve from 13748.41797\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10117.1455 - mean_absolute_error: 10117.1455 - val_loss: 13749.1309 - val_mean_absolute_error: 13749.1309\n",
      "Epoch 274/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12330.9121 - mean_absolute_error: 12330.9121\n",
      "Epoch 274: val_loss did not improve from 13748.41797\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10117.7256 - mean_absolute_error: 10117.7256 - val_loss: 13749.2256 - val_mean_absolute_error: 13749.2256\n",
      "Epoch 275/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10622.6484 - mean_absolute_error: 10622.6484\n",
      "Epoch 275: val_loss did not improve from 13748.41797\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10119.5586 - mean_absolute_error: 10119.5586 - val_loss: 13757.7119 - val_mean_absolute_error: 13757.7119\n",
      "Epoch 276/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12850.9141 - mean_absolute_error: 12850.9141\n",
      "Epoch 276: val_loss improved from 13748.41797 to 13746.21973, saving model to Weights-00276--13746.21973.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10118.5986 - mean_absolute_error: 10118.5986 - val_loss: 13746.2197 - val_mean_absolute_error: 13746.2197\n",
      "Epoch 277/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11172.6016 - mean_absolute_error: 11172.6016\n",
      "Epoch 277: val_loss did not improve from 13746.21973\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10115.4502 - mean_absolute_error: 10115.4502 - val_loss: 13754.1055 - val_mean_absolute_error: 13754.1055\n",
      "Epoch 278/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9201.9648 - mean_absolute_error: 9201.9648\n",
      "Epoch 278: val_loss did not improve from 13746.21973\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10122.6211 - mean_absolute_error: 10122.6211 - val_loss: 13747.0322 - val_mean_absolute_error: 13747.0322\n",
      "Epoch 279/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11419.1445 - mean_absolute_error: 11419.1445\n",
      "Epoch 279: val_loss did not improve from 13746.21973\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10116.3867 - mean_absolute_error: 10116.3867 - val_loss: 13761.2861 - val_mean_absolute_error: 13761.2861\n",
      "Epoch 280/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8832.3994 - mean_absolute_error: 8832.3994\n",
      "Epoch 280: val_loss did not improve from 13746.21973\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10115.0312 - mean_absolute_error: 10115.0312 - val_loss: 13748.3193 - val_mean_absolute_error: 13748.3193\n",
      "Epoch 281/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9998.6494 - mean_absolute_error: 9998.6494\n",
      "Epoch 281: val_loss did not improve from 13746.21973\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10114.9639 - mean_absolute_error: 10114.9639 - val_loss: 13755.3457 - val_mean_absolute_error: 13755.3457\n",
      "Epoch 282/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12381.9727 - mean_absolute_error: 12381.9727\n",
      "Epoch 282: val_loss did not improve from 13746.21973\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10111.2314 - mean_absolute_error: 10111.2314 - val_loss: 13752.1016 - val_mean_absolute_error: 13752.1016\n",
      "Epoch 283/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10702.8359 - mean_absolute_error: 10702.8359\n",
      "Epoch 283: val_loss improved from 13746.21973 to 13742.51562, saving model to Weights-00283--13742.51562.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10133.5518 - mean_absolute_error: 10133.5518 - val_loss: 13742.5156 - val_mean_absolute_error: 13742.5156\n",
      "Epoch 284/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5968.9883 - mean_absolute_error: 5968.9883\n",
      "Epoch 284: val_loss did not improve from 13742.51562\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10124.7520 - mean_absolute_error: 10124.7520 - val_loss: 13770.6191 - val_mean_absolute_error: 13770.6191\n",
      "Epoch 285/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10965.5811 - mean_absolute_error: 10965.5811\n",
      "Epoch 285: val_loss did not improve from 13742.51562\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10112.1768 - mean_absolute_error: 10112.1768 - val_loss: 13758.7275 - val_mean_absolute_error: 13758.7275\n",
      "Epoch 286/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8296.2051 - mean_absolute_error: 8296.2051\n",
      "Epoch 286: val_loss improved from 13742.51562 to 13741.40137, saving model to Weights-00286--13741.40137.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10119.7090 - mean_absolute_error: 10119.7090 - val_loss: 13741.4014 - val_mean_absolute_error: 13741.4014\n",
      "Epoch 287/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7594.1313 - mean_absolute_error: 7594.1313\n",
      "Epoch 287: val_loss did not improve from 13741.40137\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10108.6250 - mean_absolute_error: 10108.6250 - val_loss: 13745.8496 - val_mean_absolute_error: 13745.8496\n",
      "Epoch 288/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9357.7422 - mean_absolute_error: 9357.7422\n",
      "Epoch 288: val_loss did not improve from 13741.40137\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10110.2656 - mean_absolute_error: 10110.2656 - val_loss: 13744.4961 - val_mean_absolute_error: 13744.4961\n",
      "Epoch 289/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8845.5498 - mean_absolute_error: 8845.5498\n",
      "Epoch 289: val_loss improved from 13741.40137 to 13740.79102, saving model to Weights-00289--13740.79102.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10104.6768 - mean_absolute_error: 10104.6768 - val_loss: 13740.7910 - val_mean_absolute_error: 13740.7910\n",
      "Epoch 290/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13130.7168 - mean_absolute_error: 13130.7168\n",
      "Epoch 290: val_loss did not improve from 13740.79102\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10115.5488 - mean_absolute_error: 10115.5488 - val_loss: 13741.3242 - val_mean_absolute_error: 13741.3242\n",
      "Epoch 291/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9111.9355 - mean_absolute_error: 9111.9355\n",
      "Epoch 291: val_loss did not improve from 13740.79102\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10103.8906 - mean_absolute_error: 10103.8906 - val_loss: 13741.2266 - val_mean_absolute_error: 13741.2266\n",
      "Epoch 292/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8802.7188 - mean_absolute_error: 8802.7188\n",
      "Epoch 292: val_loss improved from 13740.79102 to 13740.31934, saving model to Weights-00292--13740.31934.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10121.7354 - mean_absolute_error: 10121.7354 - val_loss: 13740.3193 - val_mean_absolute_error: 13740.3193\n",
      "Epoch 293/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11725.5566 - mean_absolute_error: 11725.5566\n",
      "Epoch 293: val_loss did not improve from 13740.31934\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10106.5107 - mean_absolute_error: 10106.5107 - val_loss: 13753.9434 - val_mean_absolute_error: 13753.9434\n",
      "Epoch 294/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8735.2207 - mean_absolute_error: 8735.2207\n",
      "Epoch 294: val_loss did not improve from 13740.31934\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10104.6279 - mean_absolute_error: 10104.6279 - val_loss: 13757.4238 - val_mean_absolute_error: 13757.4238\n",
      "Epoch 295/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13035.3496 - mean_absolute_error: 13035.3496\n",
      "Epoch 295: val_loss did not improve from 13740.31934\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10100.2344 - mean_absolute_error: 10100.2344 - val_loss: 13746.3213 - val_mean_absolute_error: 13746.3213\n",
      "Epoch 296/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6443.6250 - mean_absolute_error: 6443.6250\n",
      "Epoch 296: val_loss improved from 13740.31934 to 13737.82715, saving model to Weights-00296--13737.82715.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10100.8916 - mean_absolute_error: 10100.8916 - val_loss: 13737.8271 - val_mean_absolute_error: 13737.8271\n",
      "Epoch 297/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8803.2793 - mean_absolute_error: 8803.2793\n",
      "Epoch 297: val_loss improved from 13737.82715 to 13737.75293, saving model to Weights-00297--13737.75293.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10103.8350 - mean_absolute_error: 10103.8350 - val_loss: 13737.7529 - val_mean_absolute_error: 13737.7529\n",
      "Epoch 298/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9766.4404 - mean_absolute_error: 9766.4404\n",
      "Epoch 298: val_loss did not improve from 13737.75293\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10098.7832 - mean_absolute_error: 10098.7832 - val_loss: 13743.5254 - val_mean_absolute_error: 13743.5254\n",
      "Epoch 299/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11374.0488 - mean_absolute_error: 11374.0488\n",
      "Epoch 299: val_loss did not improve from 13737.75293\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10098.2129 - mean_absolute_error: 10098.2129 - val_loss: 13748.4326 - val_mean_absolute_error: 13748.4326\n",
      "Epoch 300/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9621.3066 - mean_absolute_error: 9621.3066\n",
      "Epoch 300: val_loss did not improve from 13737.75293\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10096.5830 - mean_absolute_error: 10096.5830 - val_loss: 13739.3652 - val_mean_absolute_error: 13739.3652\n",
      "Epoch 301/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8775.9023 - mean_absolute_error: 8775.9023\n",
      "Epoch 301: val_loss improved from 13737.75293 to 13735.65137, saving model to Weights-00301--13735.65137.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10113.3193 - mean_absolute_error: 10113.3193 - val_loss: 13735.6514 - val_mean_absolute_error: 13735.6514\n",
      "Epoch 302/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12009.9912 - mean_absolute_error: 12009.9912\n",
      "Epoch 302: val_loss did not improve from 13735.65137\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10105.3184 - mean_absolute_error: 10105.3184 - val_loss: 13753.7588 - val_mean_absolute_error: 13753.7588\n",
      "Epoch 303/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8775.6133 - mean_absolute_error: 8775.6133\n",
      "Epoch 303: val_loss did not improve from 13735.65137\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10106.0088 - mean_absolute_error: 10106.0088 - val_loss: 13736.7812 - val_mean_absolute_error: 13736.7812\n",
      "Epoch 304/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9918.8174 - mean_absolute_error: 9918.8174\n",
      "Epoch 304: val_loss did not improve from 13735.65137\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10094.1074 - mean_absolute_error: 10094.1074 - val_loss: 13737.9199 - val_mean_absolute_error: 13737.9189\n",
      "Epoch 305/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9347.8896 - mean_absolute_error: 9347.8896\n",
      "Epoch 305: val_loss did not improve from 13735.65137\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10095.1387 - mean_absolute_error: 10095.1387 - val_loss: 13741.6689 - val_mean_absolute_error: 13741.6689\n",
      "Epoch 306/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9352.2070 - mean_absolute_error: 9352.2070\n",
      "Epoch 306: val_loss improved from 13735.65137 to 13733.88965, saving model to Weights-00306--13733.88965.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10093.8809 - mean_absolute_error: 10093.8809 - val_loss: 13733.8896 - val_mean_absolute_error: 13733.8896\n",
      "Epoch 307/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13355.1348 - mean_absolute_error: 13355.1348\n",
      "Epoch 307: val_loss did not improve from 13733.88965\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10089.3320 - mean_absolute_error: 10089.3320 - val_loss: 13740.4229 - val_mean_absolute_error: 13740.4238\n",
      "Epoch 308/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11500.2793 - mean_absolute_error: 11500.2793\n",
      "Epoch 308: val_loss did not improve from 13733.88965\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10094.0732 - mean_absolute_error: 10094.0732 - val_loss: 13742.5752 - val_mean_absolute_error: 13742.5752\n",
      "Epoch 309/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10724.5703 - mean_absolute_error: 10724.5703\n",
      "Epoch 309: val_loss did not improve from 13733.88965\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10097.0371 - mean_absolute_error: 10097.0371 - val_loss: 13749.0391 - val_mean_absolute_error: 13749.0391\n",
      "Epoch 310/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8147.1045 - mean_absolute_error: 8147.1045\n",
      "Epoch 310: val_loss did not improve from 13733.88965\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10088.4805 - mean_absolute_error: 10088.4805 - val_loss: 13742.9951 - val_mean_absolute_error: 13742.9951\n",
      "Epoch 311/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12378.1406 - mean_absolute_error: 12378.1406\n",
      "Epoch 311: val_loss did not improve from 13733.88965\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10087.2295 - mean_absolute_error: 10087.2295 - val_loss: 13737.9951 - val_mean_absolute_error: 13737.9951\n",
      "Epoch 312/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8940.4277 - mean_absolute_error: 8940.4277\n",
      "Epoch 312: val_loss improved from 13733.88965 to 13732.85742, saving model to Weights-00312--13732.85742.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10089.0918 - mean_absolute_error: 10089.0918 - val_loss: 13732.8574 - val_mean_absolute_error: 13732.8574\n",
      "Epoch 313/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8705.0078 - mean_absolute_error: 8705.0078\n",
      "Epoch 313: val_loss did not improve from 13732.85742\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10088.9326 - mean_absolute_error: 10088.9326 - val_loss: 13733.3525 - val_mean_absolute_error: 13733.3525\n",
      "Epoch 314/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7038.8555 - mean_absolute_error: 7038.8555\n",
      "Epoch 314: val_loss did not improve from 13732.85742\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10083.8252 - mean_absolute_error: 10083.8252 - val_loss: 13750.1426 - val_mean_absolute_error: 13750.1426\n",
      "Epoch 315/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10240.4297 - mean_absolute_error: 10240.4297\n",
      "Epoch 315: val_loss did not improve from 13732.85742\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10089.2773 - mean_absolute_error: 10089.2773 - val_loss: 13738.8281 - val_mean_absolute_error: 13738.8281\n",
      "Epoch 316/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9694.3477 - mean_absolute_error: 9694.3477\n",
      "Epoch 316: val_loss did not improve from 13732.85742\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10081.3672 - mean_absolute_error: 10081.3672 - val_loss: 13736.4492 - val_mean_absolute_error: 13736.4492\n",
      "Epoch 317/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10505.1172 - mean_absolute_error: 10505.1172\n",
      "Epoch 317: val_loss did not improve from 13732.85742\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10083.7227 - mean_absolute_error: 10083.7227 - val_loss: 13738.5557 - val_mean_absolute_error: 13738.5557\n",
      "Epoch 318/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10355.0635 - mean_absolute_error: 10355.0635\n",
      "Epoch 318: val_loss did not improve from 13732.85742\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10079.5674 - mean_absolute_error: 10079.5674 - val_loss: 13733.0342 - val_mean_absolute_error: 13733.0342\n",
      "Epoch 319/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10548.4512 - mean_absolute_error: 10548.4512\n",
      "Epoch 319: val_loss improved from 13732.85742 to 13729.00391, saving model to Weights-00319--13729.00391.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10088.4844 - mean_absolute_error: 10088.4844 - val_loss: 13729.0039 - val_mean_absolute_error: 13729.0039\n",
      "Epoch 320/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9321.8027 - mean_absolute_error: 9321.8027\n",
      "Epoch 320: val_loss did not improve from 13729.00391\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10103.9385 - mean_absolute_error: 10103.9385 - val_loss: 13756.2637 - val_mean_absolute_error: 13756.2637\n",
      "Epoch 321/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7396.6318 - mean_absolute_error: 7396.6318\n",
      "Epoch 321: val_loss did not improve from 13729.00391\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10082.5586 - mean_absolute_error: 10082.5586 - val_loss: 13734.6934 - val_mean_absolute_error: 13734.6934\n",
      "Epoch 322/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9194.7051 - mean_absolute_error: 9194.7051\n",
      "Epoch 322: val_loss did not improve from 13729.00391\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10082.8320 - mean_absolute_error: 10082.8320 - val_loss: 13733.7832 - val_mean_absolute_error: 13733.7832\n",
      "Epoch 323/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9135.6406 - mean_absolute_error: 9135.6406\n",
      "Epoch 323: val_loss did not improve from 13729.00391\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10092.5244 - mean_absolute_error: 10092.5244 - val_loss: 13744.0215 - val_mean_absolute_error: 13744.0215\n",
      "Epoch 324/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11913.4043 - mean_absolute_error: 11913.4043\n",
      "Epoch 324: val_loss improved from 13729.00391 to 13726.90527, saving model to Weights-00324--13726.90527.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10095.8633 - mean_absolute_error: 10095.8633 - val_loss: 13726.9053 - val_mean_absolute_error: 13726.9053\n",
      "Epoch 325/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8022.2529 - mean_absolute_error: 8022.2529\n",
      "Epoch 325: val_loss did not improve from 13726.90527\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10075.3213 - mean_absolute_error: 10075.3213 - val_loss: 13741.1748 - val_mean_absolute_error: 13741.1748\n",
      "Epoch 326/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9331.4365 - mean_absolute_error: 9331.4365\n",
      "Epoch 326: val_loss did not improve from 13726.90527\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10080.6904 - mean_absolute_error: 10080.6904 - val_loss: 13749.7754 - val_mean_absolute_error: 13749.7754\n",
      "Epoch 327/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9470.2559 - mean_absolute_error: 9470.2559\n",
      "Epoch 327: val_loss did not improve from 13726.90527\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10087.2451 - mean_absolute_error: 10087.2451 - val_loss: 13731.6318 - val_mean_absolute_error: 13731.6318\n",
      "Epoch 328/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8477.3105 - mean_absolute_error: 8477.3105\n",
      "Epoch 328: val_loss did not improve from 13726.90527\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10081.8232 - mean_absolute_error: 10081.8232 - val_loss: 13747.0801 - val_mean_absolute_error: 13747.0801\n",
      "Epoch 329/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11244.2402 - mean_absolute_error: 11244.2402\n",
      "Epoch 329: val_loss did not improve from 13726.90527\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10080.1221 - mean_absolute_error: 10080.1221 - val_loss: 13728.2002 - val_mean_absolute_error: 13728.1992\n",
      "Epoch 330/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6861.4531 - mean_absolute_error: 6861.4531\n",
      "Epoch 330: val_loss did not improve from 13726.90527\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10071.3281 - mean_absolute_error: 10071.3281 - val_loss: 13734.2871 - val_mean_absolute_error: 13734.2871\n",
      "Epoch 331/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8061.3442 - mean_absolute_error: 8061.3442\n",
      "Epoch 331: val_loss did not improve from 13726.90527\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10069.6299 - mean_absolute_error: 10069.6299 - val_loss: 13731.5371 - val_mean_absolute_error: 13731.5371\n",
      "Epoch 332/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10314.1709 - mean_absolute_error: 10314.1709\n",
      "Epoch 332: val_loss did not improve from 13726.90527\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10070.9258 - mean_absolute_error: 10070.9258 - val_loss: 13729.1953 - val_mean_absolute_error: 13729.1953\n",
      "Epoch 333/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9888.3750 - mean_absolute_error: 9888.3750\n",
      "Epoch 333: val_loss did not improve from 13726.90527\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10074.8281 - mean_absolute_error: 10074.8281 - val_loss: 13743.0352 - val_mean_absolute_error: 13743.0352\n",
      "Epoch 334/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10967.4248 - mean_absolute_error: 10967.4248\n",
      "Epoch 334: val_loss did not improve from 13726.90527\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10066.0234 - mean_absolute_error: 10066.0234 - val_loss: 13731.0127 - val_mean_absolute_error: 13731.0127\n",
      "Epoch 335/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10320.0039 - mean_absolute_error: 10320.0039\n",
      "Epoch 335: val_loss did not improve from 13726.90527\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10078.4043 - mean_absolute_error: 10078.4043 - val_loss: 13731.1250 - val_mean_absolute_error: 13731.1250\n",
      "Epoch 336/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7368.9141 - mean_absolute_error: 7368.9141\n",
      "Epoch 336: val_loss did not improve from 13726.90527\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10066.2158 - mean_absolute_error: 10066.2158 - val_loss: 13729.8721 - val_mean_absolute_error: 13729.8721\n",
      "Epoch 337/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7692.3081 - mean_absolute_error: 7692.3081\n",
      "Epoch 337: val_loss did not improve from 13726.90527\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10068.4873 - mean_absolute_error: 10068.4873 - val_loss: 13736.0391 - val_mean_absolute_error: 13736.0391\n",
      "Epoch 338/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9052.5186 - mean_absolute_error: 9052.5186\n",
      "Epoch 338: val_loss did not improve from 13726.90527\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10081.5996 - mean_absolute_error: 10081.5996 - val_loss: 13730.6699 - val_mean_absolute_error: 13730.6699\n",
      "Epoch 339/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9185.9062 - mean_absolute_error: 9185.9062\n",
      "Epoch 339: val_loss did not improve from 13726.90527\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10062.7266 - mean_absolute_error: 10062.7266 - val_loss: 13735.6611 - val_mean_absolute_error: 13735.6611\n",
      "Epoch 340/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8499.5293 - mean_absolute_error: 8499.5293\n",
      "Epoch 340: val_loss did not improve from 13726.90527\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10061.9619 - mean_absolute_error: 10061.9619 - val_loss: 13736.5029 - val_mean_absolute_error: 13736.5029\n",
      "Epoch 341/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8161.7476 - mean_absolute_error: 8161.7476\n",
      "Epoch 341: val_loss did not improve from 13726.90527\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10065.8887 - mean_absolute_error: 10065.8887 - val_loss: 13732.9004 - val_mean_absolute_error: 13732.8994\n",
      "Epoch 342/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10945.9902 - mean_absolute_error: 10945.9902\n",
      "Epoch 342: val_loss improved from 13726.90527 to 13723.71387, saving model to Weights-00342--13723.71387.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10061.8135 - mean_absolute_error: 10061.8135 - val_loss: 13723.7139 - val_mean_absolute_error: 13723.7139\n",
      "Epoch 343/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9709.2090 - mean_absolute_error: 9709.2090\n",
      "Epoch 343: val_loss did not improve from 13723.71387\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10066.5342 - mean_absolute_error: 10066.5342 - val_loss: 13732.5420 - val_mean_absolute_error: 13732.5420\n",
      "Epoch 344/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11377.5762 - mean_absolute_error: 11377.5762\n",
      "Epoch 344: val_loss did not improve from 13723.71387\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10066.7012 - mean_absolute_error: 10066.7012 - val_loss: 13726.0361 - val_mean_absolute_error: 13726.0361\n",
      "Epoch 345/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7286.7734 - mean_absolute_error: 7286.7734\n",
      "Epoch 345: val_loss did not improve from 13723.71387\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10059.2031 - mean_absolute_error: 10059.2031 - val_loss: 13736.1348 - val_mean_absolute_error: 13736.1348\n",
      "Epoch 346/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10996.8242 - mean_absolute_error: 10996.8242\n",
      "Epoch 346: val_loss did not improve from 13723.71387\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10059.6377 - mean_absolute_error: 10059.6377 - val_loss: 13737.3848 - val_mean_absolute_error: 13737.3848\n",
      "Epoch 347/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8584.7773 - mean_absolute_error: 8584.7773\n",
      "Epoch 347: val_loss improved from 13723.71387 to 13722.62012, saving model to Weights-00347--13722.62012.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10060.6855 - mean_absolute_error: 10060.6855 - val_loss: 13722.6201 - val_mean_absolute_error: 13722.6201\n",
      "Epoch 348/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12608.2031 - mean_absolute_error: 12608.2031\n",
      "Epoch 348: val_loss did not improve from 13722.62012\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10062.8262 - mean_absolute_error: 10062.8262 - val_loss: 13736.5127 - val_mean_absolute_error: 13736.5127\n",
      "Epoch 349/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10376.4238 - mean_absolute_error: 10376.4238\n",
      "Epoch 349: val_loss did not improve from 13722.62012\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10061.6992 - mean_absolute_error: 10061.6992 - val_loss: 13730.3623 - val_mean_absolute_error: 13730.3623\n",
      "Epoch 350/3000\n",
      "18/18 [==============================] - ETA: 0s - loss: 10063.6650 - mean_absolute_error: 10063.6650\n",
      "Epoch 350: val_loss improved from 13722.62012 to 13722.09180, saving model to Weights-00350--13722.09180.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 10063.6650 - mean_absolute_error: 10063.6650 - val_loss: 13722.0918 - val_mean_absolute_error: 13722.0918\n",
      "Epoch 351/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11582.5801 - mean_absolute_error: 11582.5801\n",
      "Epoch 351: val_loss did not improve from 13722.09180\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10055.2158 - mean_absolute_error: 10055.2158 - val_loss: 13728.2227 - val_mean_absolute_error: 13728.2227\n",
      "Epoch 352/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10108.8945 - mean_absolute_error: 10108.8945\n",
      "Epoch 352: val_loss did not improve from 13722.09180\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10050.9258 - mean_absolute_error: 10050.9258 - val_loss: 13725.8477 - val_mean_absolute_error: 13725.8477\n",
      "Epoch 353/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10539.0625 - mean_absolute_error: 10539.0625\n",
      "Epoch 353: val_loss did not improve from 13722.09180\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10056.4795 - mean_absolute_error: 10056.4795 - val_loss: 13735.7695 - val_mean_absolute_error: 13735.7695\n",
      "Epoch 354/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11176.6797 - mean_absolute_error: 11176.6797\n",
      "Epoch 354: val_loss did not improve from 13722.09180\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10055.7109 - mean_absolute_error: 10055.7109 - val_loss: 13723.8701 - val_mean_absolute_error: 13723.8701\n",
      "Epoch 355/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10618.0859 - mean_absolute_error: 10618.0859\n",
      "Epoch 355: val_loss did not improve from 13722.09180\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10064.9219 - mean_absolute_error: 10064.9219 - val_loss: 13723.3076 - val_mean_absolute_error: 13723.3076\n",
      "Epoch 356/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11613.0859 - mean_absolute_error: 11613.0859\n",
      "Epoch 356: val_loss did not improve from 13722.09180\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10054.6240 - mean_absolute_error: 10054.6240 - val_loss: 13751.6543 - val_mean_absolute_error: 13751.6543\n",
      "Epoch 357/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8299.5918 - mean_absolute_error: 8299.5918\n",
      "Epoch 357: val_loss did not improve from 13722.09180\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10053.8047 - mean_absolute_error: 10053.8047 - val_loss: 13737.3271 - val_mean_absolute_error: 13737.3271\n",
      "Epoch 358/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9750.3203 - mean_absolute_error: 9750.3203\n",
      "Epoch 358: val_loss improved from 13722.09180 to 13720.99707, saving model to Weights-00358--13720.99707.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10045.2344 - mean_absolute_error: 10045.2344 - val_loss: 13720.9971 - val_mean_absolute_error: 13720.9971\n",
      "Epoch 359/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12693.0684 - mean_absolute_error: 12693.0684\n",
      "Epoch 359: val_loss improved from 13720.99707 to 13720.25195, saving model to Weights-00359--13720.25195.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10048.6797 - mean_absolute_error: 10048.6797 - val_loss: 13720.2520 - val_mean_absolute_error: 13720.2520\n",
      "Epoch 360/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6684.9277 - mean_absolute_error: 6684.9277\n",
      "Epoch 360: val_loss did not improve from 13720.25195\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10049.2139 - mean_absolute_error: 10049.2139 - val_loss: 13721.0586 - val_mean_absolute_error: 13721.0586\n",
      "Epoch 361/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13776.5186 - mean_absolute_error: 13776.5186\n",
      "Epoch 361: val_loss did not improve from 13720.25195\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10066.4727 - mean_absolute_error: 10066.4727 - val_loss: 13737.9678 - val_mean_absolute_error: 13737.9678\n",
      "Epoch 362/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10576.6221 - mean_absolute_error: 10576.6221\n",
      "Epoch 362: val_loss did not improve from 13720.25195\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10042.7285 - mean_absolute_error: 10042.7285 - val_loss: 13720.8252 - val_mean_absolute_error: 13720.8252\n",
      "Epoch 363/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9098.3799 - mean_absolute_error: 9098.3799\n",
      "Epoch 363: val_loss did not improve from 13720.25195\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10052.1748 - mean_absolute_error: 10052.1748 - val_loss: 13727.2715 - val_mean_absolute_error: 13727.2715\n",
      "Epoch 364/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8164.0068 - mean_absolute_error: 8164.0068\n",
      "Epoch 364: val_loss did not improve from 13720.25195\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10049.1934 - mean_absolute_error: 10049.1934 - val_loss: 13731.7852 - val_mean_absolute_error: 13731.7852\n",
      "Epoch 365/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13586.5771 - mean_absolute_error: 13586.5771\n",
      "Epoch 365: val_loss did not improve from 13720.25195\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10042.4648 - mean_absolute_error: 10042.4648 - val_loss: 13722.3789 - val_mean_absolute_error: 13722.3789\n",
      "Epoch 366/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13216.8027 - mean_absolute_error: 13216.8027\n",
      "Epoch 366: val_loss did not improve from 13720.25195\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10046.0801 - mean_absolute_error: 10046.0801 - val_loss: 13732.1191 - val_mean_absolute_error: 13732.1191\n",
      "Epoch 367/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8013.1719 - mean_absolute_error: 8013.1719\n",
      "Epoch 367: val_loss improved from 13720.25195 to 13717.49414, saving model to Weights-00367--13717.49414.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10042.4961 - mean_absolute_error: 10042.4961 - val_loss: 13717.4941 - val_mean_absolute_error: 13717.4941\n",
      "Epoch 368/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10589.9072 - mean_absolute_error: 10589.9072\n",
      "Epoch 368: val_loss did not improve from 13717.49414\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10046.7480 - mean_absolute_error: 10046.7480 - val_loss: 13730.0176 - val_mean_absolute_error: 13730.0186\n",
      "Epoch 369/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12403.8418 - mean_absolute_error: 12403.8418\n",
      "Epoch 369: val_loss did not improve from 13717.49414\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10041.2197 - mean_absolute_error: 10041.2197 - val_loss: 13722.8506 - val_mean_absolute_error: 13722.8506\n",
      "Epoch 370/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8565.1992 - mean_absolute_error: 8565.1992\n",
      "Epoch 370: val_loss did not improve from 13717.49414\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10040.6201 - mean_absolute_error: 10040.6201 - val_loss: 13728.4531 - val_mean_absolute_error: 13728.4531\n",
      "Epoch 371/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9794.6064 - mean_absolute_error: 9794.6064\n",
      "Epoch 371: val_loss did not improve from 13717.49414\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10038.9170 - mean_absolute_error: 10038.9170 - val_loss: 13724.5986 - val_mean_absolute_error: 13724.5986\n",
      "Epoch 372/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10917.7432 - mean_absolute_error: 10917.7432\n",
      "Epoch 372: val_loss did not improve from 13717.49414\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10040.8223 - mean_absolute_error: 10040.8223 - val_loss: 13718.6064 - val_mean_absolute_error: 13718.6064\n",
      "Epoch 373/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13512.2402 - mean_absolute_error: 13512.2402\n",
      "Epoch 373: val_loss did not improve from 13717.49414\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10041.5391 - mean_absolute_error: 10041.5391 - val_loss: 13722.9990 - val_mean_absolute_error: 13722.9990\n",
      "Epoch 374/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8639.0430 - mean_absolute_error: 8639.0430\n",
      "Epoch 374: val_loss did not improve from 13717.49414\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10037.6221 - mean_absolute_error: 10037.6221 - val_loss: 13731.9199 - val_mean_absolute_error: 13731.9199\n",
      "Epoch 375/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11028.0303 - mean_absolute_error: 11028.0303\n",
      "Epoch 375: val_loss did not improve from 13717.49414\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10031.0088 - mean_absolute_error: 10031.0088 - val_loss: 13718.2979 - val_mean_absolute_error: 13718.2979\n",
      "Epoch 376/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8251.1816 - mean_absolute_error: 8251.1816\n",
      "Epoch 376: val_loss did not improve from 13717.49414\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10032.9727 - mean_absolute_error: 10032.9727 - val_loss: 13723.9453 - val_mean_absolute_error: 13723.9453\n",
      "Epoch 377/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12912.8848 - mean_absolute_error: 12912.8848\n",
      "Epoch 377: val_loss improved from 13717.49414 to 13716.38184, saving model to Weights-00377--13716.38184.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10035.3770 - mean_absolute_error: 10035.3770 - val_loss: 13716.3818 - val_mean_absolute_error: 13716.3818\n",
      "Epoch 378/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6342.9248 - mean_absolute_error: 6342.9248\n",
      "Epoch 378: val_loss did not improve from 13716.38184\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10033.8740 - mean_absolute_error: 10033.8740 - val_loss: 13730.3457 - val_mean_absolute_error: 13730.3457\n",
      "Epoch 379/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12005.1230 - mean_absolute_error: 12005.1230\n",
      "Epoch 379: val_loss did not improve from 13716.38184\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10038.2852 - mean_absolute_error: 10038.2852 - val_loss: 13729.9287 - val_mean_absolute_error: 13729.9287\n",
      "Epoch 380/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13730.7959 - mean_absolute_error: 13730.7959\n",
      "Epoch 380: val_loss did not improve from 13716.38184\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10034.8662 - mean_absolute_error: 10034.8662 - val_loss: 13726.1914 - val_mean_absolute_error: 13726.1914\n",
      "Epoch 381/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7716.9229 - mean_absolute_error: 7716.9229\n",
      "Epoch 381: val_loss did not improve from 13716.38184\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10027.9346 - mean_absolute_error: 10027.9346 - val_loss: 13724.9814 - val_mean_absolute_error: 13724.9814\n",
      "Epoch 382/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8356.3398 - mean_absolute_error: 8356.3398\n",
      "Epoch 382: val_loss improved from 13716.38184 to 13715.62012, saving model to Weights-00382--13715.62012.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10029.4102 - mean_absolute_error: 10029.4102 - val_loss: 13715.6201 - val_mean_absolute_error: 13715.6201\n",
      "Epoch 383/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12362.8037 - mean_absolute_error: 12362.8037\n",
      "Epoch 383: val_loss did not improve from 13715.62012\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10030.6973 - mean_absolute_error: 10030.6973 - val_loss: 13722.1094 - val_mean_absolute_error: 13722.1094\n",
      "Epoch 384/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9152.7949 - mean_absolute_error: 9152.7949\n",
      "Epoch 384: val_loss did not improve from 13715.62012\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10030.3877 - mean_absolute_error: 10030.3877 - val_loss: 13725.6094 - val_mean_absolute_error: 13725.6094\n",
      "Epoch 385/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9154.1719 - mean_absolute_error: 9154.1719\n",
      "Epoch 385: val_loss did not improve from 13715.62012\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10023.9326 - mean_absolute_error: 10023.9326 - val_loss: 13716.1826 - val_mean_absolute_error: 13716.1826\n",
      "Epoch 386/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9808.6348 - mean_absolute_error: 9808.6348\n",
      "Epoch 386: val_loss did not improve from 13715.62012\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10031.3281 - mean_absolute_error: 10031.3281 - val_loss: 13723.2764 - val_mean_absolute_error: 13723.2764\n",
      "Epoch 387/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6821.0972 - mean_absolute_error: 6821.0972\n",
      "Epoch 387: val_loss did not improve from 13715.62012\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10024.9326 - mean_absolute_error: 10024.9326 - val_loss: 13724.4092 - val_mean_absolute_error: 13724.4092\n",
      "Epoch 388/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11302.0684 - mean_absolute_error: 11302.0684\n",
      "Epoch 388: val_loss did not improve from 13715.62012\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10051.8135 - mean_absolute_error: 10051.8135 - val_loss: 13717.5283 - val_mean_absolute_error: 13717.5283\n",
      "Epoch 389/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11459.5859 - mean_absolute_error: 11459.5859\n",
      "Epoch 389: val_loss did not improve from 13715.62012\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10034.8633 - mean_absolute_error: 10034.8633 - val_loss: 13734.5391 - val_mean_absolute_error: 13734.5391\n",
      "Epoch 390/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5824.6431 - mean_absolute_error: 5824.6431\n",
      "Epoch 390: val_loss did not improve from 13715.62012\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10026.9316 - mean_absolute_error: 10026.9316 - val_loss: 13715.9375 - val_mean_absolute_error: 13715.9375\n",
      "Epoch 391/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9084.0840 - mean_absolute_error: 9084.0840\n",
      "Epoch 391: val_loss did not improve from 13715.62012\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10022.7139 - mean_absolute_error: 10022.7139 - val_loss: 13718.3760 - val_mean_absolute_error: 13718.3760\n",
      "Epoch 392/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9802.4961 - mean_absolute_error: 9802.4961\n",
      "Epoch 392: val_loss did not improve from 13715.62012\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10018.7998 - mean_absolute_error: 10018.7998 - val_loss: 13721.6230 - val_mean_absolute_error: 13721.6230\n",
      "Epoch 393/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9394.4131 - mean_absolute_error: 9394.4131\n",
      "Epoch 393: val_loss improved from 13715.62012 to 13710.51562, saving model to Weights-00393--13710.51562.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10029.8760 - mean_absolute_error: 10029.8760 - val_loss: 13710.5156 - val_mean_absolute_error: 13710.5156\n",
      "Epoch 394/3000\n",
      "18/18 [==============================] - ETA: 0s - loss: 10028.3486 - mean_absolute_error: 10028.3486\n",
      "Epoch 394: val_loss did not improve from 13710.51562\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10028.3486 - mean_absolute_error: 10028.3486 - val_loss: 13727.6172 - val_mean_absolute_error: 13727.6172\n",
      "Epoch 395/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9677.2969 - mean_absolute_error: 9677.2969\n",
      "Epoch 395: val_loss did not improve from 13710.51562\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10020.1826 - mean_absolute_error: 10020.1826 - val_loss: 13719.6465 - val_mean_absolute_error: 13719.6465\n",
      "Epoch 396/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8221.9766 - mean_absolute_error: 8221.9766\n",
      "Epoch 396: val_loss did not improve from 13710.51562\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10017.3701 - mean_absolute_error: 10017.3701 - val_loss: 13718.3594 - val_mean_absolute_error: 13718.3594\n",
      "Epoch 397/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12388.0449 - mean_absolute_error: 12388.0449\n",
      "Epoch 397: val_loss improved from 13710.51562 to 13709.96973, saving model to Weights-00397--13709.96973.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10014.8223 - mean_absolute_error: 10014.8223 - val_loss: 13709.9697 - val_mean_absolute_error: 13709.9697\n",
      "Epoch 398/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13867.4844 - mean_absolute_error: 13867.4844\n",
      "Epoch 398: val_loss did not improve from 13709.96973\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10019.6523 - mean_absolute_error: 10019.6523 - val_loss: 13712.7168 - val_mean_absolute_error: 13712.7168\n",
      "Epoch 399/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7660.3120 - mean_absolute_error: 7660.3120\n",
      "Epoch 399: val_loss did not improve from 13709.96973\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10016.6699 - mean_absolute_error: 10016.6699 - val_loss: 13717.2715 - val_mean_absolute_error: 13717.2715\n",
      "Epoch 400/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13134.5410 - mean_absolute_error: 13134.5410\n",
      "Epoch 400: val_loss did not improve from 13709.96973\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10012.8682 - mean_absolute_error: 10012.8682 - val_loss: 13715.6074 - val_mean_absolute_error: 13715.6074\n",
      "Epoch 401/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10287.8320 - mean_absolute_error: 10287.8320\n",
      "Epoch 401: val_loss did not improve from 13709.96973\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10016.0586 - mean_absolute_error: 10016.0586 - val_loss: 13718.9219 - val_mean_absolute_error: 13718.9219\n",
      "Epoch 402/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11300.4258 - mean_absolute_error: 11300.4258\n",
      "Epoch 402: val_loss did not improve from 13709.96973\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10019.4375 - mean_absolute_error: 10019.4375 - val_loss: 13712.6836 - val_mean_absolute_error: 13712.6836\n",
      "Epoch 403/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8109.2778 - mean_absolute_error: 8109.2778\n",
      "Epoch 403: val_loss did not improve from 13709.96973\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10010.7383 - mean_absolute_error: 10010.7383 - val_loss: 13715.9229 - val_mean_absolute_error: 13715.9229\n",
      "Epoch 404/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8106.7324 - mean_absolute_error: 8106.7324\n",
      "Epoch 404: val_loss did not improve from 13709.96973\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10014.9004 - mean_absolute_error: 10014.9004 - val_loss: 13717.0049 - val_mean_absolute_error: 13717.0049\n",
      "Epoch 405/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13793.2227 - mean_absolute_error: 13793.2227\n",
      "Epoch 405: val_loss did not improve from 13709.96973\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10013.3213 - mean_absolute_error: 10013.3213 - val_loss: 13713.2422 - val_mean_absolute_error: 13713.2422\n",
      "Epoch 406/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10358.5312 - mean_absolute_error: 10358.5312\n",
      "Epoch 406: val_loss did not improve from 13709.96973\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10010.4844 - mean_absolute_error: 10010.4844 - val_loss: 13722.9521 - val_mean_absolute_error: 13722.9521\n",
      "Epoch 407/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7328.5938 - mean_absolute_error: 7328.5938\n",
      "Epoch 407: val_loss did not improve from 13709.96973\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10007.2305 - mean_absolute_error: 10007.2305 - val_loss: 13720.5176 - val_mean_absolute_error: 13720.5176\n",
      "Epoch 408/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10336.8320 - mean_absolute_error: 10336.8320\n",
      "Epoch 408: val_loss did not improve from 13709.96973\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10005.5576 - mean_absolute_error: 10005.5576 - val_loss: 13715.4766 - val_mean_absolute_error: 13715.4766\n",
      "Epoch 409/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11431.1982 - mean_absolute_error: 11431.1982\n",
      "Epoch 409: val_loss did not improve from 13709.96973\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10005.3389 - mean_absolute_error: 10005.3389 - val_loss: 13713.2910 - val_mean_absolute_error: 13713.2910\n",
      "Epoch 410/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13314.4453 - mean_absolute_error: 13314.4453\n",
      "Epoch 410: val_loss did not improve from 13709.96973\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10016.3574 - mean_absolute_error: 10016.3574 - val_loss: 13719.0088 - val_mean_absolute_error: 13719.0088\n",
      "Epoch 411/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6587.7080 - mean_absolute_error: 6587.7080\n",
      "Epoch 411: val_loss did not improve from 13709.96973\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10003.8535 - mean_absolute_error: 10003.8535 - val_loss: 13716.3525 - val_mean_absolute_error: 13716.3525\n",
      "Epoch 412/3000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 10016.4463 - mean_absolute_error: 10016.4463\n",
      "Epoch 412: val_loss improved from 13709.96973 to 13707.19531, saving model to Weights-00412--13707.19531.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 10012.4521 - mean_absolute_error: 10012.4521 - val_loss: 13707.1953 - val_mean_absolute_error: 13707.1953\n",
      "Epoch 413/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8885.7471 - mean_absolute_error: 8885.7471\n",
      "Epoch 413: val_loss did not improve from 13707.19531\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10005.3516 - mean_absolute_error: 10005.3516 - val_loss: 13716.5156 - val_mean_absolute_error: 13716.5156\n",
      "Epoch 414/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11379.0449 - mean_absolute_error: 11379.0449\n",
      "Epoch 414: val_loss did not improve from 13707.19531\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10005.4443 - mean_absolute_error: 10005.4443 - val_loss: 13728.0986 - val_mean_absolute_error: 13728.0986\n",
      "Epoch 415/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13363.2051 - mean_absolute_error: 13363.2051\n",
      "Epoch 415: val_loss did not improve from 13707.19531\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10002.2607 - mean_absolute_error: 10002.2607 - val_loss: 13718.0049 - val_mean_absolute_error: 13718.0049\n",
      "Epoch 416/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9563.2275 - mean_absolute_error: 9563.2275\n",
      "Epoch 416: val_loss did not improve from 13707.19531\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10000.1709 - mean_absolute_error: 10000.1709 - val_loss: 13707.5576 - val_mean_absolute_error: 13707.5576\n",
      "Epoch 417/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10401.9551 - mean_absolute_error: 10401.9551\n",
      "Epoch 417: val_loss did not improve from 13707.19531\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10011.8779 - mean_absolute_error: 10011.8779 - val_loss: 13716.1660 - val_mean_absolute_error: 13716.1660\n",
      "Epoch 418/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9173.8750 - mean_absolute_error: 9173.8750\n",
      "Epoch 418: val_loss did not improve from 13707.19531\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10004.1846 - mean_absolute_error: 10004.1846 - val_loss: 13719.9072 - val_mean_absolute_error: 13719.9072\n",
      "Epoch 419/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8530.1182 - mean_absolute_error: 8530.1182\n",
      "Epoch 419: val_loss did not improve from 13707.19531\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9999.6963 - mean_absolute_error: 9999.6963 - val_loss: 13710.6318 - val_mean_absolute_error: 13710.6318\n",
      "Epoch 420/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11504.3564 - mean_absolute_error: 11504.3564\n",
      "Epoch 420: val_loss did not improve from 13707.19531\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10001.0605 - mean_absolute_error: 10001.0605 - val_loss: 13708.2871 - val_mean_absolute_error: 13708.2871\n",
      "Epoch 421/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13651.0996 - mean_absolute_error: 13651.0996\n",
      "Epoch 421: val_loss did not improve from 13707.19531\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10000.1416 - mean_absolute_error: 10000.1416 - val_loss: 13717.0889 - val_mean_absolute_error: 13717.0889\n",
      "Epoch 422/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9834.5391 - mean_absolute_error: 9834.5391\n",
      "Epoch 422: val_loss did not improve from 13707.19531\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9997.1787 - mean_absolute_error: 9997.1787 - val_loss: 13710.8945 - val_mean_absolute_error: 13710.8945\n",
      "Epoch 423/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9215.6943 - mean_absolute_error: 9215.6943\n",
      "Epoch 423: val_loss did not improve from 13707.19531\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9995.4287 - mean_absolute_error: 9995.4287 - val_loss: 13709.4600 - val_mean_absolute_error: 13709.4600\n",
      "Epoch 424/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10418.8076 - mean_absolute_error: 10418.8076\n",
      "Epoch 424: val_loss did not improve from 13707.19531\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9995.0488 - mean_absolute_error: 9995.0488 - val_loss: 13710.4277 - val_mean_absolute_error: 13710.4277\n",
      "Epoch 425/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11883.0518 - mean_absolute_error: 11883.0518\n",
      "Epoch 425: val_loss did not improve from 13707.19531\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9993.8232 - mean_absolute_error: 9993.8232 - val_loss: 13711.8682 - val_mean_absolute_error: 13711.8682\n",
      "Epoch 426/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12813.4414 - mean_absolute_error: 12813.4414\n",
      "Epoch 426: val_loss did not improve from 13707.19531\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10000.2041 - mean_absolute_error: 10000.2041 - val_loss: 13721.2617 - val_mean_absolute_error: 13721.2617\n",
      "Epoch 427/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7099.7183 - mean_absolute_error: 7099.7183\n",
      "Epoch 427: val_loss improved from 13707.19531 to 13705.30859, saving model to Weights-00427--13705.30859.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9991.6904 - mean_absolute_error: 9991.6904 - val_loss: 13705.3086 - val_mean_absolute_error: 13705.3086\n",
      "Epoch 428/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12742.8438 - mean_absolute_error: 12742.8438\n",
      "Epoch 428: val_loss did not improve from 13705.30859\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9995.2461 - mean_absolute_error: 9995.2461 - val_loss: 13711.7539 - val_mean_absolute_error: 13711.7539\n",
      "Epoch 429/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9895.5156 - mean_absolute_error: 9895.5156\n",
      "Epoch 429: val_loss did not improve from 13705.30859\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9991.5928 - mean_absolute_error: 9991.5928 - val_loss: 13714.0186 - val_mean_absolute_error: 13714.0186\n",
      "Epoch 430/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8789.1836 - mean_absolute_error: 8789.1836\n",
      "Epoch 430: val_loss did not improve from 13705.30859\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9995.7334 - mean_absolute_error: 9995.7334 - val_loss: 13714.8691 - val_mean_absolute_error: 13714.8691\n",
      "Epoch 431/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8873.9941 - mean_absolute_error: 8873.9941\n",
      "Epoch 431: val_loss did not improve from 13705.30859\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9988.0371 - mean_absolute_error: 9988.0371 - val_loss: 13706.5947 - val_mean_absolute_error: 13706.5947\n",
      "Epoch 432/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11673.5137 - mean_absolute_error: 11673.5137\n",
      "Epoch 432: val_loss did not improve from 13705.30859\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9992.3389 - mean_absolute_error: 9992.3389 - val_loss: 13711.1836 - val_mean_absolute_error: 13711.1836\n",
      "Epoch 433/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9463.1309 - mean_absolute_error: 9463.1309\n",
      "Epoch 433: val_loss did not improve from 13705.30859\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9986.0449 - mean_absolute_error: 9986.0449 - val_loss: 13706.4590 - val_mean_absolute_error: 13706.4590\n",
      "Epoch 434/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10390.7090 - mean_absolute_error: 10390.7090\n",
      "Epoch 434: val_loss did not improve from 13705.30859\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9988.0576 - mean_absolute_error: 9988.0576 - val_loss: 13706.4541 - val_mean_absolute_error: 13706.4541\n",
      "Epoch 435/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8894.1172 - mean_absolute_error: 8894.1172\n",
      "Epoch 435: val_loss did not improve from 13705.30859\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9985.8770 - mean_absolute_error: 9985.8770 - val_loss: 13709.8281 - val_mean_absolute_error: 13709.8281\n",
      "Epoch 436/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12725.6953 - mean_absolute_error: 12725.6953\n",
      "Epoch 436: val_loss did not improve from 13705.30859\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 10005.2676 - mean_absolute_error: 10005.2676 - val_loss: 13720.6270 - val_mean_absolute_error: 13720.6270\n",
      "Epoch 437/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9766.9980 - mean_absolute_error: 9766.9980\n",
      "Epoch 437: val_loss improved from 13705.30859 to 13704.07812, saving model to Weights-00437--13704.07812.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9989.3457 - mean_absolute_error: 9989.3457 - val_loss: 13704.0781 - val_mean_absolute_error: 13704.0781\n",
      "Epoch 438/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10283.4277 - mean_absolute_error: 10283.4277\n",
      "Epoch 438: val_loss did not improve from 13704.07812\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9991.4053 - mean_absolute_error: 9991.4053 - val_loss: 13706.7520 - val_mean_absolute_error: 13706.7520\n",
      "Epoch 439/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11876.0684 - mean_absolute_error: 11876.0684\n",
      "Epoch 439: val_loss did not improve from 13704.07812\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9983.5225 - mean_absolute_error: 9983.5225 - val_loss: 13711.9844 - val_mean_absolute_error: 13711.9844\n",
      "Epoch 440/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9107.1953 - mean_absolute_error: 9107.1953\n",
      "Epoch 440: val_loss did not improve from 13704.07812\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9981.7500 - mean_absolute_error: 9981.7500 - val_loss: 13708.2764 - val_mean_absolute_error: 13708.2764\n",
      "Epoch 441/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9960.5059 - mean_absolute_error: 9960.5059\n",
      "Epoch 441: val_loss did not improve from 13704.07812\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9990.9287 - mean_absolute_error: 9990.9287 - val_loss: 13714.1221 - val_mean_absolute_error: 13714.1221\n",
      "Epoch 442/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8808.1445 - mean_absolute_error: 8808.1445\n",
      "Epoch 442: val_loss improved from 13704.07812 to 13701.20215, saving model to Weights-00442--13701.20215.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9985.6025 - mean_absolute_error: 9985.6025 - val_loss: 13701.2021 - val_mean_absolute_error: 13701.2021\n",
      "Epoch 443/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6820.6519 - mean_absolute_error: 6820.6519\n",
      "Epoch 443: val_loss did not improve from 13701.20215\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9982.7490 - mean_absolute_error: 9982.7490 - val_loss: 13713.5576 - val_mean_absolute_error: 13713.5576\n",
      "Epoch 444/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12036.7539 - mean_absolute_error: 12036.7539\n",
      "Epoch 444: val_loss did not improve from 13701.20215\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9984.0752 - mean_absolute_error: 9984.0752 - val_loss: 13714.7402 - val_mean_absolute_error: 13714.7402\n",
      "Epoch 445/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7301.8379 - mean_absolute_error: 7301.8379\n",
      "Epoch 445: val_loss did not improve from 13701.20215\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9986.2461 - mean_absolute_error: 9986.2461 - val_loss: 13701.5225 - val_mean_absolute_error: 13701.5225\n",
      "Epoch 446/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12095.5332 - mean_absolute_error: 12095.5332\n",
      "Epoch 446: val_loss did not improve from 13701.20215\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9978.0625 - mean_absolute_error: 9978.0625 - val_loss: 13710.6973 - val_mean_absolute_error: 13710.6973\n",
      "Epoch 447/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12223.2324 - mean_absolute_error: 12223.2324\n",
      "Epoch 447: val_loss did not improve from 13701.20215\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9983.2031 - mean_absolute_error: 9983.2031 - val_loss: 13712.8350 - val_mean_absolute_error: 13712.8350\n",
      "Epoch 448/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7550.6240 - mean_absolute_error: 7550.6240\n",
      "Epoch 448: val_loss improved from 13701.20215 to 13700.93164, saving model to Weights-00448--13700.93164.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9997.8730 - mean_absolute_error: 9997.8730 - val_loss: 13700.9316 - val_mean_absolute_error: 13700.9316\n",
      "Epoch 449/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10362.9463 - mean_absolute_error: 10362.9463\n",
      "Epoch 449: val_loss did not improve from 13700.93164\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9972.4766 - mean_absolute_error: 9972.4766 - val_loss: 13713.8135 - val_mean_absolute_error: 13713.8135\n",
      "Epoch 450/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7383.8135 - mean_absolute_error: 7383.8135\n",
      "Epoch 450: val_loss did not improve from 13700.93164\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9981.2461 - mean_absolute_error: 9981.2461 - val_loss: 13711.3057 - val_mean_absolute_error: 13711.3057\n",
      "Epoch 451/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7473.9980 - mean_absolute_error: 7473.9980\n",
      "Epoch 451: val_loss did not improve from 13700.93164\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9977.1572 - mean_absolute_error: 9977.1572 - val_loss: 13701.9824 - val_mean_absolute_error: 13701.9824\n",
      "Epoch 452/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11107.9141 - mean_absolute_error: 11107.9141\n",
      "Epoch 452: val_loss did not improve from 13700.93164\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9977.6221 - mean_absolute_error: 9977.6221 - val_loss: 13708.9502 - val_mean_absolute_error: 13708.9502\n",
      "Epoch 453/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8217.3799 - mean_absolute_error: 8217.3799\n",
      "Epoch 453: val_loss did not improve from 13700.93164\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9973.5078 - mean_absolute_error: 9973.5078 - val_loss: 13702.0156 - val_mean_absolute_error: 13702.0156\n",
      "Epoch 454/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8075.8071 - mean_absolute_error: 8075.8071\n",
      "Epoch 454: val_loss did not improve from 13700.93164\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9984.0840 - mean_absolute_error: 9984.0840 - val_loss: 13711.0664 - val_mean_absolute_error: 13711.0664\n",
      "Epoch 455/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8266.6973 - mean_absolute_error: 8266.6973\n",
      "Epoch 455: val_loss improved from 13700.93164 to 13699.31738, saving model to Weights-00455--13699.31738.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9974.6396 - mean_absolute_error: 9974.6396 - val_loss: 13699.3174 - val_mean_absolute_error: 13699.3174\n",
      "Epoch 456/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13837.6318 - mean_absolute_error: 13837.6318\n",
      "Epoch 456: val_loss did not improve from 13699.31738\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9976.0264 - mean_absolute_error: 9976.0264 - val_loss: 13712.0957 - val_mean_absolute_error: 13712.0957\n",
      "Epoch 457/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10560.8223 - mean_absolute_error: 10560.8223\n",
      "Epoch 457: val_loss did not improve from 13699.31738\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9973.3740 - mean_absolute_error: 9973.3740 - val_loss: 13715.1602 - val_mean_absolute_error: 13715.1602\n",
      "Epoch 458/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11393.4570 - mean_absolute_error: 11393.4570\n",
      "Epoch 458: val_loss did not improve from 13699.31738\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9969.1553 - mean_absolute_error: 9969.1553 - val_loss: 13704.0732 - val_mean_absolute_error: 13704.0732\n",
      "Epoch 459/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12543.5117 - mean_absolute_error: 12543.5117\n",
      "Epoch 459: val_loss improved from 13699.31738 to 13698.92188, saving model to Weights-00459--13698.92188.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9967.0332 - mean_absolute_error: 9967.0332 - val_loss: 13698.9219 - val_mean_absolute_error: 13698.9219\n",
      "Epoch 460/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11632.1816 - mean_absolute_error: 11632.1816\n",
      "Epoch 460: val_loss did not improve from 13698.92188\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9968.9678 - mean_absolute_error: 9968.9678 - val_loss: 13707.1240 - val_mean_absolute_error: 13707.1240\n",
      "Epoch 461/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8965.9424 - mean_absolute_error: 8965.9424\n",
      "Epoch 461: val_loss improved from 13698.92188 to 13697.32812, saving model to Weights-00461--13697.32812.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9977.1553 - mean_absolute_error: 9977.1553 - val_loss: 13697.3281 - val_mean_absolute_error: 13697.3281\n",
      "Epoch 462/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11103.3730 - mean_absolute_error: 11103.3730\n",
      "Epoch 462: val_loss did not improve from 13697.32812\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9967.1641 - mean_absolute_error: 9967.1641 - val_loss: 13703.9248 - val_mean_absolute_error: 13703.9248\n",
      "Epoch 463/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10921.9395 - mean_absolute_error: 10921.9395\n",
      "Epoch 463: val_loss did not improve from 13697.32812\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9966.3320 - mean_absolute_error: 9966.3320 - val_loss: 13703.3018 - val_mean_absolute_error: 13703.3018\n",
      "Epoch 464/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11525.0391 - mean_absolute_error: 11525.0391\n",
      "Epoch 464: val_loss improved from 13697.32812 to 13697.27539, saving model to Weights-00464--13697.27539.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9977.0986 - mean_absolute_error: 9977.0986 - val_loss: 13697.2754 - val_mean_absolute_error: 13697.2754\n",
      "Epoch 465/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 17270.0859 - mean_absolute_error: 17270.0859\n",
      "Epoch 465: val_loss did not improve from 13697.27539\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9964.6523 - mean_absolute_error: 9964.6523 - val_loss: 13701.3926 - val_mean_absolute_error: 13701.3926\n",
      "Epoch 466/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8453.1025 - mean_absolute_error: 8453.1025\n",
      "Epoch 466: val_loss did not improve from 13697.27539\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9961.5967 - mean_absolute_error: 9961.5967 - val_loss: 13701.8906 - val_mean_absolute_error: 13701.8906\n",
      "Epoch 467/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9128.5723 - mean_absolute_error: 9128.5723\n",
      "Epoch 467: val_loss improved from 13697.27539 to 13695.14062, saving model to Weights-00467--13695.14062.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9999.0342 - mean_absolute_error: 9999.0342 - val_loss: 13695.1406 - val_mean_absolute_error: 13695.1406\n",
      "Epoch 468/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10295.9453 - mean_absolute_error: 10295.9453\n",
      "Epoch 468: val_loss did not improve from 13695.14062\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9969.5752 - mean_absolute_error: 9969.5752 - val_loss: 13711.9883 - val_mean_absolute_error: 13711.9883\n",
      "Epoch 469/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9846.0713 - mean_absolute_error: 9846.0713\n",
      "Epoch 469: val_loss did not improve from 13695.14062\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9962.3623 - mean_absolute_error: 9962.3623 - val_loss: 13704.3691 - val_mean_absolute_error: 13704.3691\n",
      "Epoch 470/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9184.3555 - mean_absolute_error: 9184.3555\n",
      "Epoch 470: val_loss did not improve from 13695.14062\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9958.9980 - mean_absolute_error: 9958.9980 - val_loss: 13696.1084 - val_mean_absolute_error: 13696.1084\n",
      "Epoch 471/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8350.2588 - mean_absolute_error: 8350.2588\n",
      "Epoch 471: val_loss did not improve from 13695.14062\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9963.3457 - mean_absolute_error: 9963.3457 - val_loss: 13696.0537 - val_mean_absolute_error: 13696.0537\n",
      "Epoch 472/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8453.0820 - mean_absolute_error: 8453.0820\n",
      "Epoch 472: val_loss did not improve from 13695.14062\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9952.9805 - mean_absolute_error: 9952.9805 - val_loss: 13706.5498 - val_mean_absolute_error: 13706.5498\n",
      "Epoch 473/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9783.0420 - mean_absolute_error: 9783.0420\n",
      "Epoch 473: val_loss did not improve from 13695.14062\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9969.6133 - mean_absolute_error: 9969.6133 - val_loss: 13714.8564 - val_mean_absolute_error: 13714.8564\n",
      "Epoch 474/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9300.9443 - mean_absolute_error: 9300.9443\n",
      "Epoch 474: val_loss did not improve from 13695.14062\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9971.5049 - mean_absolute_error: 9971.5049 - val_loss: 13701.3301 - val_mean_absolute_error: 13701.3301\n",
      "Epoch 475/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8217.0771 - mean_absolute_error: 8217.0771\n",
      "Epoch 475: val_loss did not improve from 13695.14062\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9956.9775 - mean_absolute_error: 9956.9775 - val_loss: 13698.2002 - val_mean_absolute_error: 13698.2002\n",
      "Epoch 476/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8158.8027 - mean_absolute_error: 8158.8027\n",
      "Epoch 476: val_loss did not improve from 13695.14062\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9957.3125 - mean_absolute_error: 9957.3125 - val_loss: 13699.3672 - val_mean_absolute_error: 13699.3672\n",
      "Epoch 477/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7746.6758 - mean_absolute_error: 7746.6758\n",
      "Epoch 477: val_loss improved from 13695.14062 to 13693.76074, saving model to Weights-00477--13693.76074.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9950.0439 - mean_absolute_error: 9950.0439 - val_loss: 13693.7607 - val_mean_absolute_error: 13693.7607\n",
      "Epoch 478/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8964.3398 - mean_absolute_error: 8964.3398\n",
      "Epoch 478: val_loss improved from 13693.76074 to 13692.29297, saving model to Weights-00478--13692.29297.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9963.0791 - mean_absolute_error: 9963.0791 - val_loss: 13692.2930 - val_mean_absolute_error: 13692.2930\n",
      "Epoch 479/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7301.4043 - mean_absolute_error: 7301.4043\n",
      "Epoch 479: val_loss did not improve from 13692.29297\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9952.0430 - mean_absolute_error: 9952.0430 - val_loss: 13708.4238 - val_mean_absolute_error: 13708.4238\n",
      "Epoch 480/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12911.1816 - mean_absolute_error: 12911.1816\n",
      "Epoch 480: val_loss did not improve from 13692.29297\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9953.7920 - mean_absolute_error: 9953.7920 - val_loss: 13696.6514 - val_mean_absolute_error: 13696.6514\n",
      "Epoch 481/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10705.1680 - mean_absolute_error: 10705.1680\n",
      "Epoch 481: val_loss did not improve from 13692.29297\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9952.1494 - mean_absolute_error: 9952.1494 - val_loss: 13700.8984 - val_mean_absolute_error: 13700.8984\n",
      "Epoch 482/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10471.2285 - mean_absolute_error: 10471.2285\n",
      "Epoch 482: val_loss improved from 13692.29297 to 13691.15332, saving model to Weights-00482--13691.15332.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9956.0479 - mean_absolute_error: 9956.0479 - val_loss: 13691.1533 - val_mean_absolute_error: 13691.1523\n",
      "Epoch 483/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10672.9365 - mean_absolute_error: 10672.9365\n",
      "Epoch 483: val_loss did not improve from 13691.15332\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9947.5703 - mean_absolute_error: 9947.5703 - val_loss: 13700.9785 - val_mean_absolute_error: 13700.9785\n",
      "Epoch 484/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8452.5488 - mean_absolute_error: 8452.5488\n",
      "Epoch 484: val_loss did not improve from 13691.15332\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9948.3555 - mean_absolute_error: 9948.3555 - val_loss: 13699.3506 - val_mean_absolute_error: 13699.3506\n",
      "Epoch 485/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7567.2559 - mean_absolute_error: 7567.2559\n",
      "Epoch 485: val_loss did not improve from 13691.15332\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9947.8838 - mean_absolute_error: 9947.8838 - val_loss: 13697.4814 - val_mean_absolute_error: 13697.4814\n",
      "Epoch 486/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7896.6611 - mean_absolute_error: 7896.6611\n",
      "Epoch 486: val_loss did not improve from 13691.15332\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9950.1758 - mean_absolute_error: 9950.1758 - val_loss: 13695.3926 - val_mean_absolute_error: 13695.3926\n",
      "Epoch 487/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12202.7432 - mean_absolute_error: 12202.7432\n",
      "Epoch 487: val_loss did not improve from 13691.15332\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9945.7090 - mean_absolute_error: 9945.7090 - val_loss: 13697.0479 - val_mean_absolute_error: 13697.0479\n",
      "Epoch 488/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10030.0449 - mean_absolute_error: 10030.0449\n",
      "Epoch 488: val_loss did not improve from 13691.15332\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9947.8516 - mean_absolute_error: 9947.8516 - val_loss: 13691.7949 - val_mean_absolute_error: 13691.7949\n",
      "Epoch 489/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11334.7363 - mean_absolute_error: 11334.7363\n",
      "Epoch 489: val_loss did not improve from 13691.15332\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9946.5508 - mean_absolute_error: 9946.5508 - val_loss: 13699.2412 - val_mean_absolute_error: 13699.2412\n",
      "Epoch 490/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8911.6416 - mean_absolute_error: 8911.6416\n",
      "Epoch 490: val_loss did not improve from 13691.15332\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9943.8037 - mean_absolute_error: 9943.8037 - val_loss: 13696.9219 - val_mean_absolute_error: 13696.9219\n",
      "Epoch 491/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11198.9082 - mean_absolute_error: 11198.9082\n",
      "Epoch 491: val_loss did not improve from 13691.15332\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9940.0020 - mean_absolute_error: 9940.0020 - val_loss: 13691.2051 - val_mean_absolute_error: 13691.2051\n",
      "Epoch 492/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10138.8857 - mean_absolute_error: 10138.8857\n",
      "Epoch 492: val_loss did not improve from 13691.15332\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9942.5049 - mean_absolute_error: 9942.5049 - val_loss: 13694.5986 - val_mean_absolute_error: 13694.5986\n",
      "Epoch 493/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10867.3438 - mean_absolute_error: 10867.3438\n",
      "Epoch 493: val_loss did not improve from 13691.15332\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9944.2939 - mean_absolute_error: 9944.2939 - val_loss: 13698.2451 - val_mean_absolute_error: 13698.2451\n",
      "Epoch 494/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8698.0645 - mean_absolute_error: 8698.0645\n",
      "Epoch 494: val_loss did not improve from 13691.15332\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9941.2617 - mean_absolute_error: 9941.2617 - val_loss: 13695.7197 - val_mean_absolute_error: 13695.7197\n",
      "Epoch 495/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7760.7324 - mean_absolute_error: 7760.7324\n",
      "Epoch 495: val_loss improved from 13691.15332 to 13690.39453, saving model to Weights-00495--13690.39453.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9944.8613 - mean_absolute_error: 9944.8613 - val_loss: 13690.3945 - val_mean_absolute_error: 13690.3945\n",
      "Epoch 496/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11961.8389 - mean_absolute_error: 11961.8389\n",
      "Epoch 496: val_loss did not improve from 13690.39453\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9939.8467 - mean_absolute_error: 9939.8467 - val_loss: 13692.0186 - val_mean_absolute_error: 13692.0186\n",
      "Epoch 497/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9026.6289 - mean_absolute_error: 9026.6289\n",
      "Epoch 497: val_loss did not improve from 13690.39453\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9953.1787 - mean_absolute_error: 9953.1787 - val_loss: 13694.5879 - val_mean_absolute_error: 13694.5879\n",
      "Epoch 498/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7689.2446 - mean_absolute_error: 7689.2446\n",
      "Epoch 498: val_loss improved from 13690.39453 to 13689.00098, saving model to Weights-00498--13689.00098.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9938.4922 - mean_absolute_error: 9938.4922 - val_loss: 13689.0010 - val_mean_absolute_error: 13689.0010\n",
      "Epoch 499/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8201.1914 - mean_absolute_error: 8201.1914\n",
      "Epoch 499: val_loss improved from 13689.00098 to 13687.68262, saving model to Weights-00499--13687.68262.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9950.3301 - mean_absolute_error: 9950.3301 - val_loss: 13687.6826 - val_mean_absolute_error: 13687.6826\n",
      "Epoch 500/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12540.0332 - mean_absolute_error: 12540.0332\n",
      "Epoch 500: val_loss did not improve from 13687.68262\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9943.2617 - mean_absolute_error: 9943.2617 - val_loss: 13693.6182 - val_mean_absolute_error: 13693.6182\n",
      "Epoch 501/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10885.1660 - mean_absolute_error: 10885.1660\n",
      "Epoch 501: val_loss did not improve from 13687.68262\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9936.1621 - mean_absolute_error: 9936.1621 - val_loss: 13695.5732 - val_mean_absolute_error: 13695.5732\n",
      "Epoch 502/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9556.5361 - mean_absolute_error: 9556.5361\n",
      "Epoch 502: val_loss did not improve from 13687.68262\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9961.0947 - mean_absolute_error: 9961.0947 - val_loss: 13692.9346 - val_mean_absolute_error: 13692.9346\n",
      "Epoch 503/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6572.4839 - mean_absolute_error: 6572.4839\n",
      "Epoch 503: val_loss did not improve from 13687.68262\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9954.8857 - mean_absolute_error: 9954.8857 - val_loss: 13709.4727 - val_mean_absolute_error: 13709.4727\n",
      "Epoch 504/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11355.7988 - mean_absolute_error: 11355.7988\n",
      "Epoch 504: val_loss did not improve from 13687.68262\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9949.3623 - mean_absolute_error: 9949.3623 - val_loss: 13688.7930 - val_mean_absolute_error: 13688.7930\n",
      "Epoch 505/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7141.9736 - mean_absolute_error: 7141.9736\n",
      "Epoch 505: val_loss did not improve from 13687.68262\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9942.7734 - mean_absolute_error: 9942.7734 - val_loss: 13689.4736 - val_mean_absolute_error: 13689.4736\n",
      "Epoch 506/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8041.2578 - mean_absolute_error: 8041.2578\n",
      "Epoch 506: val_loss did not improve from 13687.68262\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9943.7939 - mean_absolute_error: 9943.7939 - val_loss: 13694.0420 - val_mean_absolute_error: 13694.0420\n",
      "Epoch 507/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7388.7207 - mean_absolute_error: 7388.7207\n",
      "Epoch 507: val_loss did not improve from 13687.68262\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9947.0596 - mean_absolute_error: 9947.0596 - val_loss: 13700.3789 - val_mean_absolute_error: 13700.3789\n",
      "Epoch 508/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11569.8066 - mean_absolute_error: 11569.8066\n",
      "Epoch 508: val_loss did not improve from 13687.68262\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9930.0166 - mean_absolute_error: 9930.0166 - val_loss: 13687.7783 - val_mean_absolute_error: 13687.7783\n",
      "Epoch 509/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7424.9238 - mean_absolute_error: 7424.9238\n",
      "Epoch 509: val_loss improved from 13687.68262 to 13686.00488, saving model to Weights-00509--13686.00488.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9934.4941 - mean_absolute_error: 9934.4941 - val_loss: 13686.0049 - val_mean_absolute_error: 13686.0049\n",
      "Epoch 510/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12243.4717 - mean_absolute_error: 12243.4717\n",
      "Epoch 510: val_loss did not improve from 13686.00488\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9934.9502 - mean_absolute_error: 9934.9502 - val_loss: 13700.6094 - val_mean_absolute_error: 13700.6094\n",
      "Epoch 511/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11781.1826 - mean_absolute_error: 11781.1826\n",
      "Epoch 511: val_loss did not improve from 13686.00488\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9935.9209 - mean_absolute_error: 9935.9209 - val_loss: 13686.6621 - val_mean_absolute_error: 13686.6621\n",
      "Epoch 512/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10859.2988 - mean_absolute_error: 10859.2988\n",
      "Epoch 512: val_loss did not improve from 13686.00488\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9924.4561 - mean_absolute_error: 9924.4561 - val_loss: 13693.6504 - val_mean_absolute_error: 13693.6504\n",
      "Epoch 513/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9491.0537 - mean_absolute_error: 9491.0537\n",
      "Epoch 513: val_loss did not improve from 13686.00488\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9928.2207 - mean_absolute_error: 9928.2207 - val_loss: 13697.4033 - val_mean_absolute_error: 13697.4033\n",
      "Epoch 514/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8420.9688 - mean_absolute_error: 8420.9688\n",
      "Epoch 514: val_loss did not improve from 13686.00488\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9928.4941 - mean_absolute_error: 9928.4941 - val_loss: 13688.0674 - val_mean_absolute_error: 13688.0674\n",
      "Epoch 515/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12775.3438 - mean_absolute_error: 12775.3438\n",
      "Epoch 515: val_loss improved from 13686.00488 to 13685.48438, saving model to Weights-00515--13685.48438.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9928.3262 - mean_absolute_error: 9928.3262 - val_loss: 13685.4844 - val_mean_absolute_error: 13685.4844\n",
      "Epoch 516/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12160.6250 - mean_absolute_error: 12160.6250\n",
      "Epoch 516: val_loss did not improve from 13685.48438\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9925.1221 - mean_absolute_error: 9925.1221 - val_loss: 13686.3691 - val_mean_absolute_error: 13686.3691\n",
      "Epoch 517/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11194.6865 - mean_absolute_error: 11194.6865\n",
      "Epoch 517: val_loss did not improve from 13685.48438\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9925.6934 - mean_absolute_error: 9925.6934 - val_loss: 13689.4873 - val_mean_absolute_error: 13689.4873\n",
      "Epoch 518/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10682.2832 - mean_absolute_error: 10682.2832\n",
      "Epoch 518: val_loss did not improve from 13685.48438\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9928.7344 - mean_absolute_error: 9928.7344 - val_loss: 13691.9111 - val_mean_absolute_error: 13691.9111\n",
      "Epoch 519/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10254.9043 - mean_absolute_error: 10254.9043\n",
      "Epoch 519: val_loss did not improve from 13685.48438\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9933.4248 - mean_absolute_error: 9933.4248 - val_loss: 13691.9072 - val_mean_absolute_error: 13691.9072\n",
      "Epoch 520/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10810.0039 - mean_absolute_error: 10810.0039\n",
      "Epoch 520: val_loss did not improve from 13685.48438\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9922.8320 - mean_absolute_error: 9922.8320 - val_loss: 13686.4141 - val_mean_absolute_error: 13686.4141\n",
      "Epoch 521/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13920.2988 - mean_absolute_error: 13920.2988\n",
      "Epoch 521: val_loss did not improve from 13685.48438\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9919.2959 - mean_absolute_error: 9919.2959 - val_loss: 13687.6250 - val_mean_absolute_error: 13687.6250\n",
      "Epoch 522/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10613.5088 - mean_absolute_error: 10613.5088\n",
      "Epoch 522: val_loss did not improve from 13685.48438\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9918.8340 - mean_absolute_error: 9918.8340 - val_loss: 13689.3584 - val_mean_absolute_error: 13689.3584\n",
      "Epoch 523/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10929.9355 - mean_absolute_error: 10929.9355\n",
      "Epoch 523: val_loss did not improve from 13685.48438\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9920.2002 - mean_absolute_error: 9920.2002 - val_loss: 13686.6055 - val_mean_absolute_error: 13686.6055\n",
      "Epoch 524/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10472.4102 - mean_absolute_error: 10472.4102\n",
      "Epoch 524: val_loss did not improve from 13685.48438\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9921.4629 - mean_absolute_error: 9921.4629 - val_loss: 13695.4404 - val_mean_absolute_error: 13695.4404\n",
      "Epoch 525/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13402.8516 - mean_absolute_error: 13402.8516\n",
      "Epoch 525: val_loss improved from 13685.48438 to 13684.18262, saving model to Weights-00525--13684.18262.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9920.3535 - mean_absolute_error: 9920.3535 - val_loss: 13684.1826 - val_mean_absolute_error: 13684.1826\n",
      "Epoch 526/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13984.2090 - mean_absolute_error: 13984.2090\n",
      "Epoch 526: val_loss did not improve from 13684.18262\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9927.7539 - mean_absolute_error: 9927.7539 - val_loss: 13684.9336 - val_mean_absolute_error: 13684.9336\n",
      "Epoch 527/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10260.1387 - mean_absolute_error: 10260.1387\n",
      "Epoch 527: val_loss did not improve from 13684.18262\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9919.1562 - mean_absolute_error: 9919.1562 - val_loss: 13689.1318 - val_mean_absolute_error: 13689.1318\n",
      "Epoch 528/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9800.8125 - mean_absolute_error: 9800.8125\n",
      "Epoch 528: val_loss did not improve from 13684.18262\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9913.8193 - mean_absolute_error: 9913.8193 - val_loss: 13685.8174 - val_mean_absolute_error: 13685.8174\n",
      "Epoch 529/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 16343.7676 - mean_absolute_error: 16343.7676\n",
      "Epoch 529: val_loss did not improve from 13684.18262\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9916.3076 - mean_absolute_error: 9916.3076 - val_loss: 13686.3486 - val_mean_absolute_error: 13686.3486\n",
      "Epoch 530/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10799.5273 - mean_absolute_error: 10799.5273\n",
      "Epoch 530: val_loss improved from 13684.18262 to 13682.72852, saving model to Weights-00530--13682.72852.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9913.6045 - mean_absolute_error: 9913.6045 - val_loss: 13682.7285 - val_mean_absolute_error: 13682.7285\n",
      "Epoch 531/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8790.5449 - mean_absolute_error: 8790.5449\n",
      "Epoch 531: val_loss did not improve from 13682.72852\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9921.2422 - mean_absolute_error: 9921.2422 - val_loss: 13697.1914 - val_mean_absolute_error: 13697.1914\n",
      "Epoch 532/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9752.6543 - mean_absolute_error: 9752.6543\n",
      "Epoch 532: val_loss did not improve from 13682.72852\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9915.3525 - mean_absolute_error: 9915.3525 - val_loss: 13684.7227 - val_mean_absolute_error: 13684.7227\n",
      "Epoch 533/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8562.3105 - mean_absolute_error: 8562.3105\n",
      "Epoch 533: val_loss did not improve from 13682.72852\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9914.4346 - mean_absolute_error: 9914.4346 - val_loss: 13685.9111 - val_mean_absolute_error: 13685.9111\n",
      "Epoch 534/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10602.3008 - mean_absolute_error: 10602.3008\n",
      "Epoch 534: val_loss did not improve from 13682.72852\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9931.2998 - mean_absolute_error: 9931.2998 - val_loss: 13696.4766 - val_mean_absolute_error: 13696.4766\n",
      "Epoch 535/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10824.5498 - mean_absolute_error: 10824.5498\n",
      "Epoch 535: val_loss improved from 13682.72852 to 13680.66504, saving model to Weights-00535--13680.66504.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9919.6641 - mean_absolute_error: 9919.6641 - val_loss: 13680.6650 - val_mean_absolute_error: 13680.6650\n",
      "Epoch 536/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8354.2314 - mean_absolute_error: 8354.2314\n",
      "Epoch 536: val_loss did not improve from 13680.66504\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9917.1201 - mean_absolute_error: 9917.1201 - val_loss: 13685.2021 - val_mean_absolute_error: 13685.2021\n",
      "Epoch 537/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10478.4980 - mean_absolute_error: 10478.4980\n",
      "Epoch 537: val_loss did not improve from 13680.66504\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9928.5479 - mean_absolute_error: 9928.5479 - val_loss: 13703.4717 - val_mean_absolute_error: 13703.4717\n",
      "Epoch 538/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7857.4990 - mean_absolute_error: 7857.4990\n",
      "Epoch 538: val_loss improved from 13680.66504 to 13680.58105, saving model to Weights-00538--13680.58105.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9924.5303 - mean_absolute_error: 9924.5303 - val_loss: 13680.5811 - val_mean_absolute_error: 13680.5811\n",
      "Epoch 539/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5625.0088 - mean_absolute_error: 5625.0088\n",
      "Epoch 539: val_loss did not improve from 13680.58105\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9907.9658 - mean_absolute_error: 9907.9658 - val_loss: 13688.9961 - val_mean_absolute_error: 13688.9961\n",
      "Epoch 540/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12096.9160 - mean_absolute_error: 12096.9160\n",
      "Epoch 540: val_loss did not improve from 13680.58105\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9939.5254 - mean_absolute_error: 9939.5254 - val_loss: 13681.4873 - val_mean_absolute_error: 13681.4873\n",
      "Epoch 541/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6119.0566 - mean_absolute_error: 6119.0566\n",
      "Epoch 541: val_loss did not improve from 13680.58105\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9910.6680 - mean_absolute_error: 9910.6680 - val_loss: 13707.4590 - val_mean_absolute_error: 13707.4590\n",
      "Epoch 542/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8610.7324 - mean_absolute_error: 8610.7324\n",
      "Epoch 542: val_loss did not improve from 13680.58105\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9914.2568 - mean_absolute_error: 9914.2568 - val_loss: 13686.6230 - val_mean_absolute_error: 13686.6230\n",
      "Epoch 543/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11194.3301 - mean_absolute_error: 11194.3301\n",
      "Epoch 543: val_loss did not improve from 13680.58105\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9906.3193 - mean_absolute_error: 9906.3193 - val_loss: 13682.3086 - val_mean_absolute_error: 13682.3086\n",
      "Epoch 544/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6338.2178 - mean_absolute_error: 6338.2178\n",
      "Epoch 544: val_loss improved from 13680.58105 to 13679.70898, saving model to Weights-00544--13679.70898.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9911.1602 - mean_absolute_error: 9911.1602 - val_loss: 13679.7090 - val_mean_absolute_error: 13679.7090\n",
      "Epoch 545/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9853.6328 - mean_absolute_error: 9853.6328\n",
      "Epoch 545: val_loss did not improve from 13679.70898\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9897.8750 - mean_absolute_error: 9897.8750 - val_loss: 13690.6631 - val_mean_absolute_error: 13690.6631\n",
      "Epoch 546/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6781.6245 - mean_absolute_error: 6781.6245\n",
      "Epoch 546: val_loss did not improve from 13679.70898\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9907.9404 - mean_absolute_error: 9907.9404 - val_loss: 13688.2021 - val_mean_absolute_error: 13688.2021\n",
      "Epoch 547/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9560.6836 - mean_absolute_error: 9560.6836\n",
      "Epoch 547: val_loss did not improve from 13679.70898\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9908.3711 - mean_absolute_error: 9908.3711 - val_loss: 13688.1084 - val_mean_absolute_error: 13688.1084\n",
      "Epoch 548/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11179.5098 - mean_absolute_error: 11179.5098\n",
      "Epoch 548: val_loss improved from 13679.70898 to 13678.29492, saving model to Weights-00548--13678.29492.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9899.4658 - mean_absolute_error: 9899.4658 - val_loss: 13678.2949 - val_mean_absolute_error: 13678.2949\n",
      "Epoch 549/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7273.2783 - mean_absolute_error: 7273.2783\n",
      "Epoch 549: val_loss did not improve from 13678.29492\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9917.3965 - mean_absolute_error: 9917.3965 - val_loss: 13692.0244 - val_mean_absolute_error: 13692.0244\n",
      "Epoch 550/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10819.3525 - mean_absolute_error: 10819.3525\n",
      "Epoch 550: val_loss did not improve from 13678.29492\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9908.1533 - mean_absolute_error: 9908.1533 - val_loss: 13678.6221 - val_mean_absolute_error: 13678.6221\n",
      "Epoch 551/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8692.0381 - mean_absolute_error: 8692.0381\n",
      "Epoch 551: val_loss improved from 13678.29492 to 13677.41211, saving model to Weights-00551--13677.41211.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9916.5957 - mean_absolute_error: 9916.5957 - val_loss: 13677.4121 - val_mean_absolute_error: 13677.4121\n",
      "Epoch 552/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8942.5371 - mean_absolute_error: 8942.5371\n",
      "Epoch 552: val_loss did not improve from 13677.41211\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9910.3643 - mean_absolute_error: 9910.3643 - val_loss: 13689.7656 - val_mean_absolute_error: 13689.7656\n",
      "Epoch 553/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7698.9106 - mean_absolute_error: 7698.9106\n",
      "Epoch 553: val_loss did not improve from 13677.41211\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9896.9639 - mean_absolute_error: 9896.9639 - val_loss: 13680.5410 - val_mean_absolute_error: 13680.5410\n",
      "Epoch 554/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10910.8203 - mean_absolute_error: 10910.8203\n",
      "Epoch 554: val_loss did not improve from 13677.41211\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9904.1572 - mean_absolute_error: 9904.1572 - val_loss: 13678.0303 - val_mean_absolute_error: 13678.0303\n",
      "Epoch 555/3000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9607.8486 - mean_absolute_error: 9607.8486\n",
      "Epoch 555: val_loss did not improve from 13677.41211\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9897.4922 - mean_absolute_error: 9897.4922 - val_loss: 13681.7520 - val_mean_absolute_error: 13681.7520\n",
      "Epoch 556/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9738.9844 - mean_absolute_error: 9738.9844\n",
      "Epoch 556: val_loss did not improve from 13677.41211\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9896.8740 - mean_absolute_error: 9896.8740 - val_loss: 13678.8164 - val_mean_absolute_error: 13678.8164\n",
      "Epoch 557/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10923.9609 - mean_absolute_error: 10923.9609\n",
      "Epoch 557: val_loss did not improve from 13677.41211\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9895.4443 - mean_absolute_error: 9895.4443 - val_loss: 13681.5156 - val_mean_absolute_error: 13681.5156\n",
      "Epoch 558/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9904.4297 - mean_absolute_error: 9904.4297\n",
      "Epoch 558: val_loss did not improve from 13677.41211\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9895.4082 - mean_absolute_error: 9895.4082 - val_loss: 13680.3838 - val_mean_absolute_error: 13680.3838\n",
      "Epoch 559/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6169.1162 - mean_absolute_error: 6169.1162\n",
      "Epoch 559: val_loss did not improve from 13677.41211\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9898.7676 - mean_absolute_error: 9898.7676 - val_loss: 13679.3174 - val_mean_absolute_error: 13679.3174\n",
      "Epoch 560/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7377.2656 - mean_absolute_error: 7377.2656\n",
      "Epoch 560: val_loss improved from 13677.41211 to 13676.92773, saving model to Weights-00560--13676.92773.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9903.7031 - mean_absolute_error: 9903.7031 - val_loss: 13676.9277 - val_mean_absolute_error: 13676.9277\n",
      "Epoch 561/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12167.1113 - mean_absolute_error: 12167.1113\n",
      "Epoch 561: val_loss did not improve from 13676.92773\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9892.6963 - mean_absolute_error: 9892.6963 - val_loss: 13691.1611 - val_mean_absolute_error: 13691.1611\n",
      "Epoch 562/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11980.9395 - mean_absolute_error: 11980.9395\n",
      "Epoch 562: val_loss improved from 13676.92773 to 13676.87988, saving model to Weights-00562--13676.87988.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9896.6270 - mean_absolute_error: 9896.6270 - val_loss: 13676.8799 - val_mean_absolute_error: 13676.8799\n",
      "Epoch 563/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10822.5566 - mean_absolute_error: 10822.5566\n",
      "Epoch 563: val_loss did not improve from 13676.87988\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9892.1934 - mean_absolute_error: 9892.1934 - val_loss: 13677.0146 - val_mean_absolute_error: 13677.0146\n",
      "Epoch 564/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7956.0161 - mean_absolute_error: 7956.0161\n",
      "Epoch 564: val_loss did not improve from 13676.87988\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9891.6562 - mean_absolute_error: 9891.6562 - val_loss: 13678.6299 - val_mean_absolute_error: 13678.6299\n",
      "Epoch 565/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10569.0762 - mean_absolute_error: 10569.0762\n",
      "Epoch 565: val_loss did not improve from 13676.87988\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9889.0830 - mean_absolute_error: 9889.0830 - val_loss: 13686.6611 - val_mean_absolute_error: 13686.6611\n",
      "Epoch 566/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10578.2344 - mean_absolute_error: 10578.2344\n",
      "Epoch 566: val_loss improved from 13676.87988 to 13675.52637, saving model to Weights-00566--13675.52637.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9892.6377 - mean_absolute_error: 9892.6377 - val_loss: 13675.5264 - val_mean_absolute_error: 13675.5264\n",
      "Epoch 567/3000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9687.3418 - mean_absolute_error: 9687.3418  \n",
      "Epoch 567: val_loss did not improve from 13675.52637\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9902.1367 - mean_absolute_error: 9902.1367 - val_loss: 13675.8408 - val_mean_absolute_error: 13675.8408\n",
      "Epoch 568/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11329.2031 - mean_absolute_error: 11329.2031\n",
      "Epoch 568: val_loss did not improve from 13675.52637\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9891.7861 - mean_absolute_error: 9891.7861 - val_loss: 13692.7139 - val_mean_absolute_error: 13692.7139\n",
      "Epoch 569/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7811.0107 - mean_absolute_error: 7811.0107\n",
      "Epoch 569: val_loss improved from 13675.52637 to 13674.37891, saving model to Weights-00569--13674.37891.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9907.3213 - mean_absolute_error: 9907.3213 - val_loss: 13674.3789 - val_mean_absolute_error: 13674.3779\n",
      "Epoch 570/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11903.0410 - mean_absolute_error: 11903.0410\n",
      "Epoch 570: val_loss did not improve from 13674.37891\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9899.9199 - mean_absolute_error: 9899.9199 - val_loss: 13682.9072 - val_mean_absolute_error: 13682.9082\n",
      "Epoch 571/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9969.3447 - mean_absolute_error: 9969.3447\n",
      "Epoch 571: val_loss did not improve from 13674.37891\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9885.7939 - mean_absolute_error: 9885.7939 - val_loss: 13676.8936 - val_mean_absolute_error: 13676.8936\n",
      "Epoch 572/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11025.2637 - mean_absolute_error: 11025.2637\n",
      "Epoch 572: val_loss did not improve from 13674.37891\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9887.7949 - mean_absolute_error: 9887.7949 - val_loss: 13678.1514 - val_mean_absolute_error: 13678.1514\n",
      "Epoch 573/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9624.2734 - mean_absolute_error: 9624.2734\n",
      "Epoch 573: val_loss did not improve from 13674.37891\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9887.7617 - mean_absolute_error: 9887.7617 - val_loss: 13675.0176 - val_mean_absolute_error: 13675.0176\n",
      "Epoch 574/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10101.2930 - mean_absolute_error: 10101.2930\n",
      "Epoch 574: val_loss did not improve from 13674.37891\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9889.1357 - mean_absolute_error: 9889.1357 - val_loss: 13676.2832 - val_mean_absolute_error: 13676.2832\n",
      "Epoch 575/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13111.4521 - mean_absolute_error: 13111.4521\n",
      "Epoch 575: val_loss did not improve from 13674.37891\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9888.6035 - mean_absolute_error: 9888.6035 - val_loss: 13681.8486 - val_mean_absolute_error: 13681.8486\n",
      "Epoch 576/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8256.3828 - mean_absolute_error: 8256.3828\n",
      "Epoch 576: val_loss improved from 13674.37891 to 13673.08203, saving model to Weights-00576--13673.08203.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9891.0156 - mean_absolute_error: 9891.0156 - val_loss: 13673.0820 - val_mean_absolute_error: 13673.0820\n",
      "Epoch 577/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8360.4893 - mean_absolute_error: 8360.4893\n",
      "Epoch 577: val_loss did not improve from 13673.08203\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9882.9834 - mean_absolute_error: 9882.9834 - val_loss: 13687.3174 - val_mean_absolute_error: 13687.3174\n",
      "Epoch 578/3000\n",
      "18/18 [==============================] - ETA: 0s - loss: 9887.4551 - mean_absolute_error: 9887.4551\n",
      "Epoch 578: val_loss did not improve from 13673.08203\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9887.4551 - mean_absolute_error: 9887.4551 - val_loss: 13683.7461 - val_mean_absolute_error: 13683.7461\n",
      "Epoch 579/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9618.2734 - mean_absolute_error: 9618.2734\n",
      "Epoch 579: val_loss improved from 13673.08203 to 13672.12598, saving model to Weights-00579--13672.12598.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9889.4375 - mean_absolute_error: 9889.4375 - val_loss: 13672.1260 - val_mean_absolute_error: 13672.1260\n",
      "Epoch 580/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7857.8213 - mean_absolute_error: 7857.8213\n",
      "Epoch 580: val_loss did not improve from 13672.12598\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9879.0986 - mean_absolute_error: 9879.0986 - val_loss: 13680.6084 - val_mean_absolute_error: 13680.6084\n",
      "Epoch 581/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12335.9277 - mean_absolute_error: 12335.9277\n",
      "Epoch 581: val_loss did not improve from 13672.12598\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9884.5361 - mean_absolute_error: 9884.5361 - val_loss: 13678.4326 - val_mean_absolute_error: 13678.4326\n",
      "Epoch 582/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12344.5098 - mean_absolute_error: 12344.5098\n",
      "Epoch 582: val_loss did not improve from 13672.12598\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9884.3447 - mean_absolute_error: 9884.3447 - val_loss: 13674.3389 - val_mean_absolute_error: 13674.3389\n",
      "Epoch 583/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11107.0879 - mean_absolute_error: 11107.0879\n",
      "Epoch 583: val_loss improved from 13672.12598 to 13671.55762, saving model to Weights-00583--13671.55762.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9886.4043 - mean_absolute_error: 9886.4043 - val_loss: 13671.5576 - val_mean_absolute_error: 13671.5576\n",
      "Epoch 584/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10319.0820 - mean_absolute_error: 10319.0820\n",
      "Epoch 584: val_loss did not improve from 13671.55762\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9872.7051 - mean_absolute_error: 9872.7051 - val_loss: 13681.8350 - val_mean_absolute_error: 13681.8350\n",
      "Epoch 585/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8610.0977 - mean_absolute_error: 8610.0977\n",
      "Epoch 585: val_loss did not improve from 13671.55762\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9879.6084 - mean_absolute_error: 9879.6084 - val_loss: 13686.8750 - val_mean_absolute_error: 13686.8750\n",
      "Epoch 586/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9577.3154 - mean_absolute_error: 9577.3154\n",
      "Epoch 586: val_loss did not improve from 13671.55762\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9877.4121 - mean_absolute_error: 9877.4121 - val_loss: 13675.5947 - val_mean_absolute_error: 13675.5947\n",
      "Epoch 587/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10971.8818 - mean_absolute_error: 10971.8818\n",
      "Epoch 587: val_loss improved from 13671.55762 to 13670.66113, saving model to Weights-00587--13670.66113.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9878.9111 - mean_absolute_error: 9878.9111 - val_loss: 13670.6611 - val_mean_absolute_error: 13670.6611\n",
      "Epoch 588/3000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9858.5635 - mean_absolute_error: 9858.5635  \n",
      "Epoch 588: val_loss did not improve from 13670.66113\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9876.4443 - mean_absolute_error: 9876.4443 - val_loss: 13680.5107 - val_mean_absolute_error: 13680.5107\n",
      "Epoch 589/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7326.6509 - mean_absolute_error: 7326.6509\n",
      "Epoch 589: val_loss did not improve from 13670.66113\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9877.6904 - mean_absolute_error: 9877.6904 - val_loss: 13673.2061 - val_mean_absolute_error: 13673.2061\n",
      "Epoch 590/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8537.1406 - mean_absolute_error: 8537.1406\n",
      "Epoch 590: val_loss did not improve from 13670.66113\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9879.0967 - mean_absolute_error: 9879.0967 - val_loss: 13676.1504 - val_mean_absolute_error: 13676.1504\n",
      "Epoch 591/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12688.0215 - mean_absolute_error: 12688.0215\n",
      "Epoch 591: val_loss did not improve from 13670.66113\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9875.8506 - mean_absolute_error: 9875.8506 - val_loss: 13673.8389 - val_mean_absolute_error: 13673.8389\n",
      "Epoch 592/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10230.3340 - mean_absolute_error: 10230.3340\n",
      "Epoch 592: val_loss did not improve from 13670.66113\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9875.2236 - mean_absolute_error: 9875.2236 - val_loss: 13678.3906 - val_mean_absolute_error: 13678.3906\n",
      "Epoch 593/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9707.7500 - mean_absolute_error: 9707.7500\n",
      "Epoch 593: val_loss improved from 13670.66113 to 13669.82324, saving model to Weights-00593--13669.82324.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9877.5400 - mean_absolute_error: 9877.5400 - val_loss: 13669.8232 - val_mean_absolute_error: 13669.8232\n",
      "Epoch 594/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 15214.8691 - mean_absolute_error: 15214.8691\n",
      "Epoch 594: val_loss did not improve from 13669.82324\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9868.2480 - mean_absolute_error: 9868.2480 - val_loss: 13677.2412 - val_mean_absolute_error: 13677.2412\n",
      "Epoch 595/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9983.1270 - mean_absolute_error: 9983.1270\n",
      "Epoch 595: val_loss did not improve from 13669.82324\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9875.8701 - mean_absolute_error: 9875.8701 - val_loss: 13671.9150 - val_mean_absolute_error: 13671.9150\n",
      "Epoch 596/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9386.0010 - mean_absolute_error: 9386.0010\n",
      "Epoch 596: val_loss improved from 13669.82324 to 13669.49121, saving model to Weights-00596--13669.49121.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9873.6211 - mean_absolute_error: 9873.6211 - val_loss: 13669.4912 - val_mean_absolute_error: 13669.4912\n",
      "Epoch 597/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12500.6230 - mean_absolute_error: 12500.6230\n",
      "Epoch 597: val_loss improved from 13669.49121 to 13669.40332, saving model to Weights-00597--13669.40332.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9878.9033 - mean_absolute_error: 9878.9033 - val_loss: 13669.4033 - val_mean_absolute_error: 13669.4033\n",
      "Epoch 598/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9055.5312 - mean_absolute_error: 9055.5312\n",
      "Epoch 598: val_loss did not improve from 13669.40332\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9870.5850 - mean_absolute_error: 9870.5850 - val_loss: 13680.7832 - val_mean_absolute_error: 13680.7832\n",
      "Epoch 599/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10672.2383 - mean_absolute_error: 10672.2383\n",
      "Epoch 599: val_loss did not improve from 13669.40332\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9873.7373 - mean_absolute_error: 9873.7373 - val_loss: 13669.7598 - val_mean_absolute_error: 13669.7598\n",
      "Epoch 600/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13470.7539 - mean_absolute_error: 13470.7539\n",
      "Epoch 600: val_loss did not improve from 13669.40332\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9888.0840 - mean_absolute_error: 9888.0840 - val_loss: 13680.4697 - val_mean_absolute_error: 13680.4697\n",
      "Epoch 601/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13296.4609 - mean_absolute_error: 13296.4609\n",
      "Epoch 601: val_loss improved from 13669.40332 to 13668.49609, saving model to Weights-00601--13668.49609.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9900.5273 - mean_absolute_error: 9900.5273 - val_loss: 13668.4961 - val_mean_absolute_error: 13668.4961\n",
      "Epoch 602/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12369.7168 - mean_absolute_error: 12369.7168\n",
      "Epoch 602: val_loss did not improve from 13668.49609\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9866.5664 - mean_absolute_error: 9866.5664 - val_loss: 13679.4287 - val_mean_absolute_error: 13679.4287\n",
      "Epoch 603/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11723.4062 - mean_absolute_error: 11723.4062\n",
      "Epoch 603: val_loss did not improve from 13668.49609\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9875.5518 - mean_absolute_error: 9875.5518 - val_loss: 13669.6182 - val_mean_absolute_error: 13669.6182\n",
      "Epoch 604/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9089.5449 - mean_absolute_error: 9089.5449\n",
      "Epoch 604: val_loss did not improve from 13668.49609\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9868.7998 - mean_absolute_error: 9868.7998 - val_loss: 13671.7236 - val_mean_absolute_error: 13671.7236\n",
      "Epoch 605/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8727.4219 - mean_absolute_error: 8727.4219\n",
      "Epoch 605: val_loss did not improve from 13668.49609\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9867.7373 - mean_absolute_error: 9867.7373 - val_loss: 13675.3164 - val_mean_absolute_error: 13675.3154\n",
      "Epoch 606/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8343.2227 - mean_absolute_error: 8343.2227\n",
      "Epoch 606: val_loss improved from 13668.49609 to 13667.27734, saving model to Weights-00606--13667.27734.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9864.9590 - mean_absolute_error: 9864.9590 - val_loss: 13667.2773 - val_mean_absolute_error: 13667.2773\n",
      "Epoch 607/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9153.9062 - mean_absolute_error: 9153.9062\n",
      "Epoch 607: val_loss did not improve from 13667.27734\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9866.2197 - mean_absolute_error: 9866.2197 - val_loss: 13670.5234 - val_mean_absolute_error: 13670.5234\n",
      "Epoch 608/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8229.0703 - mean_absolute_error: 8229.0703\n",
      "Epoch 608: val_loss improved from 13667.27734 to 13666.72070, saving model to Weights-00608--13666.72070.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9861.4648 - mean_absolute_error: 9861.4648 - val_loss: 13666.7207 - val_mean_absolute_error: 13666.7207\n",
      "Epoch 609/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11771.2422 - mean_absolute_error: 11771.2422\n",
      "Epoch 609: val_loss did not improve from 13666.72070\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9861.6465 - mean_absolute_error: 9861.6465 - val_loss: 13669.0117 - val_mean_absolute_error: 13669.0117\n",
      "Epoch 610/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12518.5146 - mean_absolute_error: 12518.5146\n",
      "Epoch 610: val_loss did not improve from 13666.72070\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9861.5127 - mean_absolute_error: 9861.5127 - val_loss: 13668.4170 - val_mean_absolute_error: 13668.4170\n",
      "Epoch 611/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7760.0889 - mean_absolute_error: 7760.0889\n",
      "Epoch 611: val_loss did not improve from 13666.72070\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9861.6650 - mean_absolute_error: 9861.6650 - val_loss: 13666.9111 - val_mean_absolute_error: 13666.9111\n",
      "Epoch 612/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8305.2012 - mean_absolute_error: 8305.2012\n",
      "Epoch 612: val_loss did not improve from 13666.72070\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9860.9414 - mean_absolute_error: 9860.9414 - val_loss: 13668.8477 - val_mean_absolute_error: 13668.8477\n",
      "Epoch 613/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5877.5117 - mean_absolute_error: 5877.5117\n",
      "Epoch 613: val_loss improved from 13666.72070 to 13665.34961, saving model to Weights-00613--13665.34961.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9871.9219 - mean_absolute_error: 9871.9219 - val_loss: 13665.3496 - val_mean_absolute_error: 13665.3496\n",
      "Epoch 614/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10048.3496 - mean_absolute_error: 10048.3496\n",
      "Epoch 614: val_loss did not improve from 13665.34961\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9864.1152 - mean_absolute_error: 9864.1152 - val_loss: 13674.5254 - val_mean_absolute_error: 13674.5254\n",
      "Epoch 615/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8397.4111 - mean_absolute_error: 8397.4111\n",
      "Epoch 615: val_loss did not improve from 13665.34961\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9863.1025 - mean_absolute_error: 9863.1025 - val_loss: 13666.1719 - val_mean_absolute_error: 13666.1719\n",
      "Epoch 616/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7460.7041 - mean_absolute_error: 7460.7041\n",
      "Epoch 616: val_loss did not improve from 13665.34961\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9875.2734 - mean_absolute_error: 9875.2734 - val_loss: 13674.2646 - val_mean_absolute_error: 13674.2646\n",
      "Epoch 617/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8019.2124 - mean_absolute_error: 8019.2124\n",
      "Epoch 617: val_loss improved from 13665.34961 to 13664.80176, saving model to Weights-00617--13664.80176.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9862.2627 - mean_absolute_error: 9862.2627 - val_loss: 13664.8018 - val_mean_absolute_error: 13664.8018\n",
      "Epoch 618/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13760.4121 - mean_absolute_error: 13760.4121\n",
      "Epoch 618: val_loss did not improve from 13664.80176\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9858.8613 - mean_absolute_error: 9858.8613 - val_loss: 13673.3193 - val_mean_absolute_error: 13673.3193\n",
      "Epoch 619/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12830.0801 - mean_absolute_error: 12830.0801\n",
      "Epoch 619: val_loss improved from 13664.80176 to 13664.18262, saving model to Weights-00619--13664.18262.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9859.4111 - mean_absolute_error: 9859.4111 - val_loss: 13664.1826 - val_mean_absolute_error: 13664.1826\n",
      "Epoch 620/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8694.8867 - mean_absolute_error: 8694.8867\n",
      "Epoch 620: val_loss did not improve from 13664.18262\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9868.3369 - mean_absolute_error: 9868.3369 - val_loss: 13673.0303 - val_mean_absolute_error: 13673.0303\n",
      "Epoch 621/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8035.0640 - mean_absolute_error: 8035.0640\n",
      "Epoch 621: val_loss improved from 13664.18262 to 13663.86230, saving model to Weights-00621--13663.86230.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9855.5449 - mean_absolute_error: 9855.5449 - val_loss: 13663.8623 - val_mean_absolute_error: 13663.8623\n",
      "Epoch 622/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8173.8022 - mean_absolute_error: 8173.8022\n",
      "Epoch 622: val_loss did not improve from 13663.86230\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9857.9326 - mean_absolute_error: 9857.9326 - val_loss: 13667.6992 - val_mean_absolute_error: 13667.6992\n",
      "Epoch 623/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8237.5000 - mean_absolute_error: 8237.5000\n",
      "Epoch 623: val_loss did not improve from 13663.86230\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9861.3896 - mean_absolute_error: 9861.3896 - val_loss: 13666.6270 - val_mean_absolute_error: 13666.6270\n",
      "Epoch 624/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9407.4551 - mean_absolute_error: 9407.4551\n",
      "Epoch 624: val_loss did not improve from 13663.86230\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9854.0078 - mean_absolute_error: 9854.0078 - val_loss: 13665.2139 - val_mean_absolute_error: 13665.2139\n",
      "Epoch 625/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 15157.9541 - mean_absolute_error: 15157.9541\n",
      "Epoch 625: val_loss improved from 13663.86230 to 13663.01758, saving model to Weights-00625--13663.01758.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9856.7822 - mean_absolute_error: 9856.7822 - val_loss: 13663.0176 - val_mean_absolute_error: 13663.0176\n",
      "Epoch 626/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10790.3379 - mean_absolute_error: 10790.3379\n",
      "Epoch 626: val_loss improved from 13663.01758 to 13662.86328, saving model to Weights-00626--13662.86328.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9861.7422 - mean_absolute_error: 9861.7422 - val_loss: 13662.8633 - val_mean_absolute_error: 13662.8633\n",
      "Epoch 627/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8251.3545 - mean_absolute_error: 8251.3545\n",
      "Epoch 627: val_loss did not improve from 13662.86328\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9858.1797 - mean_absolute_error: 9858.1797 - val_loss: 13668.7783 - val_mean_absolute_error: 13668.7783\n",
      "Epoch 628/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11280.7383 - mean_absolute_error: 11280.7383\n",
      "Epoch 628: val_loss improved from 13662.86328 to 13662.59277, saving model to Weights-00628--13662.59277.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9877.5098 - mean_absolute_error: 9877.5098 - val_loss: 13662.5928 - val_mean_absolute_error: 13662.5928\n",
      "Epoch 629/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8731.1221 - mean_absolute_error: 8731.1221\n",
      "Epoch 629: val_loss did not improve from 13662.59277\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9847.8516 - mean_absolute_error: 9847.8516 - val_loss: 13672.2764 - val_mean_absolute_error: 13672.2764\n",
      "Epoch 630/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8000.8779 - mean_absolute_error: 8000.8779\n",
      "Epoch 630: val_loss did not improve from 13662.59277\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9851.0820 - mean_absolute_error: 9851.0820 - val_loss: 13664.5303 - val_mean_absolute_error: 13664.5303\n",
      "Epoch 631/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9639.6582 - mean_absolute_error: 9639.6582\n",
      "Epoch 631: val_loss improved from 13662.59277 to 13661.91992, saving model to Weights-00631--13661.91992.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9852.6279 - mean_absolute_error: 9852.6279 - val_loss: 13661.9199 - val_mean_absolute_error: 13661.9199\n",
      "Epoch 632/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9424.9785 - mean_absolute_error: 9424.9785\n",
      "Epoch 632: val_loss did not improve from 13661.91992\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9857.5771 - mean_absolute_error: 9857.5771 - val_loss: 13662.5771 - val_mean_absolute_error: 13662.5771\n",
      "Epoch 633/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7723.4556 - mean_absolute_error: 7723.4556\n",
      "Epoch 633: val_loss did not improve from 13661.91992\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9852.4395 - mean_absolute_error: 9852.4395 - val_loss: 13670.5088 - val_mean_absolute_error: 13670.5088\n",
      "Epoch 634/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12292.3379 - mean_absolute_error: 12292.3379\n",
      "Epoch 634: val_loss did not improve from 13661.91992\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9846.6553 - mean_absolute_error: 9846.6553 - val_loss: 13664.8633 - val_mean_absolute_error: 13664.8633\n",
      "Epoch 635/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11783.7910 - mean_absolute_error: 11783.7910\n",
      "Epoch 635: val_loss improved from 13661.91992 to 13661.12305, saving model to Weights-00635--13661.12305.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9851.6064 - mean_absolute_error: 9851.6064 - val_loss: 13661.1230 - val_mean_absolute_error: 13661.1230\n",
      "Epoch 636/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9190.7314 - mean_absolute_error: 9190.7314\n",
      "Epoch 636: val_loss did not improve from 13661.12305\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9841.5254 - mean_absolute_error: 9841.5254 - val_loss: 13671.7002 - val_mean_absolute_error: 13671.7002\n",
      "Epoch 637/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8459.6260 - mean_absolute_error: 8459.6260\n",
      "Epoch 637: val_loss did not improve from 13661.12305\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9850.7402 - mean_absolute_error: 9850.7402 - val_loss: 13670.2520 - val_mean_absolute_error: 13670.2520\n",
      "Epoch 638/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8485.5527 - mean_absolute_error: 8485.5527\n",
      "Epoch 638: val_loss did not improve from 13661.12305\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9847.9551 - mean_absolute_error: 9847.9551 - val_loss: 13661.3203 - val_mean_absolute_error: 13661.3203\n",
      "Epoch 639/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9679.7129 - mean_absolute_error: 9679.7129\n",
      "Epoch 639: val_loss did not improve from 13661.12305\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9857.7949 - mean_absolute_error: 9857.7949 - val_loss: 13665.5459 - val_mean_absolute_error: 13665.5459\n",
      "Epoch 640/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9529.7051 - mean_absolute_error: 9529.7051\n",
      "Epoch 640: val_loss did not improve from 13661.12305\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9840.9883 - mean_absolute_error: 9840.9883 - val_loss: 13664.0566 - val_mean_absolute_error: 13664.0566\n",
      "Epoch 641/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10873.3008 - mean_absolute_error: 10873.3008\n",
      "Epoch 641: val_loss did not improve from 13661.12305\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9843.9346 - mean_absolute_error: 9843.9346 - val_loss: 13664.1514 - val_mean_absolute_error: 13664.1514\n",
      "Epoch 642/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8533.1699 - mean_absolute_error: 8533.1699\n",
      "Epoch 642: val_loss improved from 13661.12305 to 13659.90137, saving model to Weights-00642--13659.90137.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9850.7549 - mean_absolute_error: 9850.7549 - val_loss: 13659.9014 - val_mean_absolute_error: 13659.9014\n",
      "Epoch 643/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8477.6445 - mean_absolute_error: 8477.6445\n",
      "Epoch 643: val_loss did not improve from 13659.90137\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9840.1338 - mean_absolute_error: 9840.1338 - val_loss: 13660.8467 - val_mean_absolute_error: 13660.8467\n",
      "Epoch 644/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11909.4961 - mean_absolute_error: 11909.4961\n",
      "Epoch 644: val_loss did not improve from 13659.90137\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9834.6357 - mean_absolute_error: 9834.6357 - val_loss: 13670.6875 - val_mean_absolute_error: 13670.6875\n",
      "Epoch 645/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12562.2227 - mean_absolute_error: 12562.2227\n",
      "Epoch 645: val_loss did not improve from 13659.90137\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9842.7559 - mean_absolute_error: 9842.7559 - val_loss: 13667.3125 - val_mean_absolute_error: 13667.3125\n",
      "Epoch 646/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9126.8438 - mean_absolute_error: 9126.8438\n",
      "Epoch 646: val_loss did not improve from 13659.90137\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9837.6650 - mean_absolute_error: 9837.6650 - val_loss: 13661.0391 - val_mean_absolute_error: 13661.0391\n",
      "Epoch 647/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9592.0049 - mean_absolute_error: 9592.0049\n",
      "Epoch 647: val_loss did not improve from 13659.90137\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9839.5312 - mean_absolute_error: 9839.5312 - val_loss: 13661.6104 - val_mean_absolute_error: 13661.6104\n",
      "Epoch 648/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9694.3711 - mean_absolute_error: 9694.3711\n",
      "Epoch 648: val_loss did not improve from 13659.90137\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9843.8096 - mean_absolute_error: 9843.8096 - val_loss: 13667.0049 - val_mean_absolute_error: 13667.0049\n",
      "Epoch 649/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13277.5322 - mean_absolute_error: 13277.5322\n",
      "Epoch 649: val_loss improved from 13659.90137 to 13658.62012, saving model to Weights-00649--13658.62012.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9833.7344 - mean_absolute_error: 9833.7344 - val_loss: 13658.6201 - val_mean_absolute_error: 13658.6201\n",
      "Epoch 650/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13784.2344 - mean_absolute_error: 13784.2344\n",
      "Epoch 650: val_loss did not improve from 13658.62012\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9842.6377 - mean_absolute_error: 9842.6377 - val_loss: 13661.6650 - val_mean_absolute_error: 13661.6650\n",
      "Epoch 651/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 14485.1797 - mean_absolute_error: 14485.1797\n",
      "Epoch 651: val_loss did not improve from 13658.62012\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9835.5469 - mean_absolute_error: 9835.5469 - val_loss: 13658.7461 - val_mean_absolute_error: 13658.7461\n",
      "Epoch 652/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8622.0898 - mean_absolute_error: 8622.0898\n",
      "Epoch 652: val_loss improved from 13658.62012 to 13658.15527, saving model to Weights-00652--13658.15527.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9837.9961 - mean_absolute_error: 9837.9961 - val_loss: 13658.1553 - val_mean_absolute_error: 13658.1553\n",
      "Epoch 653/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9951.7344 - mean_absolute_error: 9951.7344\n",
      "Epoch 653: val_loss did not improve from 13658.15527\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9839.6836 - mean_absolute_error: 9839.6836 - val_loss: 13665.4277 - val_mean_absolute_error: 13665.4277\n",
      "Epoch 654/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8422.1680 - mean_absolute_error: 8422.1680\n",
      "Epoch 654: val_loss improved from 13658.15527 to 13658.02637, saving model to Weights-00654--13658.02637.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9832.7832 - mean_absolute_error: 9832.7832 - val_loss: 13658.0264 - val_mean_absolute_error: 13658.0264\n",
      "Epoch 655/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9478.3320 - mean_absolute_error: 9478.3320\n",
      "Epoch 655: val_loss improved from 13658.02637 to 13657.33887, saving model to Weights-00655--13657.33887.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9836.2666 - mean_absolute_error: 9836.2666 - val_loss: 13657.3389 - val_mean_absolute_error: 13657.3389\n",
      "Epoch 656/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7512.5176 - mean_absolute_error: 7512.5176\n",
      "Epoch 656: val_loss did not improve from 13657.33887\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9837.1992 - mean_absolute_error: 9837.1992 - val_loss: 13659.5469 - val_mean_absolute_error: 13659.5469\n",
      "Epoch 657/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8909.8281 - mean_absolute_error: 8909.8281\n",
      "Epoch 657: val_loss did not improve from 13657.33887\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9833.9414 - mean_absolute_error: 9833.9414 - val_loss: 13665.5049 - val_mean_absolute_error: 13665.5049\n",
      "Epoch 658/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13082.0156 - mean_absolute_error: 13082.0156\n",
      "Epoch 658: val_loss did not improve from 13657.33887\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9832.2969 - mean_absolute_error: 9832.2969 - val_loss: 13657.5801 - val_mean_absolute_error: 13657.5801\n",
      "Epoch 659/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7867.8896 - mean_absolute_error: 7867.8896\n",
      "Epoch 659: val_loss improved from 13657.33887 to 13656.59082, saving model to Weights-00659--13656.59082.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9838.7783 - mean_absolute_error: 9838.7783 - val_loss: 13656.5908 - val_mean_absolute_error: 13656.5908\n",
      "Epoch 660/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10973.6240 - mean_absolute_error: 10973.6240\n",
      "Epoch 660: val_loss did not improve from 13656.59082\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9834.7139 - mean_absolute_error: 9834.7139 - val_loss: 13668.2021 - val_mean_absolute_error: 13668.2021\n",
      "Epoch 661/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8848.7910 - mean_absolute_error: 8848.7910\n",
      "Epoch 661: val_loss did not improve from 13656.59082\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9829.1094 - mean_absolute_error: 9829.1094 - val_loss: 13657.2803 - val_mean_absolute_error: 13657.2803\n",
      "Epoch 662/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8011.4590 - mean_absolute_error: 8011.4590\n",
      "Epoch 662: val_loss improved from 13656.59082 to 13655.89062, saving model to Weights-00662--13655.89062.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9827.9502 - mean_absolute_error: 9827.9502 - val_loss: 13655.8906 - val_mean_absolute_error: 13655.8906\n",
      "Epoch 663/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7604.9600 - mean_absolute_error: 7604.9600\n",
      "Epoch 663: val_loss did not improve from 13655.89062\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9828.2344 - mean_absolute_error: 9828.2344 - val_loss: 13660.3428 - val_mean_absolute_error: 13660.3428\n",
      "Epoch 664/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10599.6426 - mean_absolute_error: 10599.6426\n",
      "Epoch 664: val_loss did not improve from 13655.89062\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9834.9307 - mean_absolute_error: 9834.9307 - val_loss: 13663.3994 - val_mean_absolute_error: 13663.3994\n",
      "Epoch 665/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8250.1699 - mean_absolute_error: 8250.1699\n",
      "Epoch 665: val_loss did not improve from 13655.89062\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9830.6094 - mean_absolute_error: 9830.6094 - val_loss: 13664.5977 - val_mean_absolute_error: 13664.5977\n",
      "Epoch 666/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9483.9424 - mean_absolute_error: 9483.9424\n",
      "Epoch 666: val_loss improved from 13655.89062 to 13655.19141, saving model to Weights-00666--13655.19141.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9857.7510 - mean_absolute_error: 9857.7510 - val_loss: 13655.1914 - val_mean_absolute_error: 13655.1914\n",
      "Epoch 667/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10028.8301 - mean_absolute_error: 10028.8301\n",
      "Epoch 667: val_loss did not improve from 13655.19141\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9828.3955 - mean_absolute_error: 9828.3955 - val_loss: 13668.7881 - val_mean_absolute_error: 13668.7881\n",
      "Epoch 668/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8857.4258 - mean_absolute_error: 8857.4258\n",
      "Epoch 668: val_loss improved from 13655.19141 to 13655.08008, saving model to Weights-00668--13655.08008.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9824.3311 - mean_absolute_error: 9824.3311 - val_loss: 13655.0801 - val_mean_absolute_error: 13655.0801\n",
      "Epoch 669/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6721.1924 - mean_absolute_error: 6721.1924\n",
      "Epoch 669: val_loss did not improve from 13655.08008\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9828.4092 - mean_absolute_error: 9828.4092 - val_loss: 13656.9863 - val_mean_absolute_error: 13656.9863\n",
      "Epoch 670/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6887.8242 - mean_absolute_error: 6887.8242\n",
      "Epoch 670: val_loss did not improve from 13655.08008\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9824.9844 - mean_absolute_error: 9824.9844 - val_loss: 13656.7598 - val_mean_absolute_error: 13656.7598\n",
      "Epoch 671/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7582.2471 - mean_absolute_error: 7582.2471\n",
      "Epoch 671: val_loss improved from 13655.08008 to 13654.40332, saving model to Weights-00671--13654.40332.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9822.7051 - mean_absolute_error: 9822.7051 - val_loss: 13654.4033 - val_mean_absolute_error: 13654.4033\n",
      "Epoch 672/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 14328.9678 - mean_absolute_error: 14328.9678\n",
      "Epoch 672: val_loss did not improve from 13654.40332\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9821.5625 - mean_absolute_error: 9821.5625 - val_loss: 13660.5742 - val_mean_absolute_error: 13660.5742\n",
      "Epoch 673/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10793.2539 - mean_absolute_error: 10793.2539\n",
      "Epoch 673: val_loss improved from 13654.40332 to 13654.35156, saving model to Weights-00673--13654.35156.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9820.9824 - mean_absolute_error: 9820.9824 - val_loss: 13654.3516 - val_mean_absolute_error: 13654.3516\n",
      "Epoch 674/3000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9866.6357 - mean_absolute_error: 9866.6357\n",
      "Epoch 674: val_loss did not improve from 13654.35156\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9825.6611 - mean_absolute_error: 9825.6611 - val_loss: 13654.6631 - val_mean_absolute_error: 13654.6631\n",
      "Epoch 675/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9605.6250 - mean_absolute_error: 9605.6250\n",
      "Epoch 675: val_loss improved from 13654.35156 to 13654.13379, saving model to Weights-00675--13654.13379.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9825.9072 - mean_absolute_error: 9825.9072 - val_loss: 13654.1338 - val_mean_absolute_error: 13654.1338\n",
      "Epoch 676/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8155.5806 - mean_absolute_error: 8155.5806\n",
      "Epoch 676: val_loss did not improve from 13654.13379\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9820.7920 - mean_absolute_error: 9820.7920 - val_loss: 13655.1592 - val_mean_absolute_error: 13655.1592\n",
      "Epoch 677/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9210.6475 - mean_absolute_error: 9210.6475\n",
      "Epoch 677: val_loss did not improve from 13654.13379\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9823.3604 - mean_absolute_error: 9823.3604 - val_loss: 13656.8438 - val_mean_absolute_error: 13656.8438\n",
      "Epoch 678/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12637.2148 - mean_absolute_error: 12637.2148\n",
      "Epoch 678: val_loss did not improve from 13654.13379\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9831.7549 - mean_absolute_error: 9831.7549 - val_loss: 13657.4424 - val_mean_absolute_error: 13657.4424\n",
      "Epoch 679/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9376.7422 - mean_absolute_error: 9376.7422\n",
      "Epoch 679: val_loss improved from 13654.13379 to 13653.65332, saving model to Weights-00679--13653.65332.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9825.9639 - mean_absolute_error: 9825.9639 - val_loss: 13653.6533 - val_mean_absolute_error: 13653.6533\n",
      "Epoch 680/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9322.0742 - mean_absolute_error: 9322.0742\n",
      "Epoch 680: val_loss did not improve from 13653.65332\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9826.4473 - mean_absolute_error: 9826.4473 - val_loss: 13668.2217 - val_mean_absolute_error: 13668.2217\n",
      "Epoch 681/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10917.9766 - mean_absolute_error: 10917.9766\n",
      "Epoch 681: val_loss improved from 13653.65332 to 13652.29004, saving model to Weights-00681--13652.29004.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9825.2822 - mean_absolute_error: 9825.2822 - val_loss: 13652.2900 - val_mean_absolute_error: 13652.2900\n",
      "Epoch 682/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7646.0098 - mean_absolute_error: 7646.0098\n",
      "Epoch 682: val_loss did not improve from 13652.29004\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9820.1689 - mean_absolute_error: 9820.1689 - val_loss: 13655.0400 - val_mean_absolute_error: 13655.0400\n",
      "Epoch 683/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12415.2676 - mean_absolute_error: 12415.2676\n",
      "Epoch 683: val_loss did not improve from 13652.29004\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9821.2930 - mean_absolute_error: 9821.2930 - val_loss: 13657.8750 - val_mean_absolute_error: 13657.8750\n",
      "Epoch 684/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10700.4277 - mean_absolute_error: 10700.4277\n",
      "Epoch 684: val_loss improved from 13652.29004 to 13651.84961, saving model to Weights-00684--13651.84961.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9816.5264 - mean_absolute_error: 9816.5264 - val_loss: 13651.8496 - val_mean_absolute_error: 13651.8506\n",
      "Epoch 685/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9861.4463 - mean_absolute_error: 9861.4463\n",
      "Epoch 685: val_loss improved from 13651.84961 to 13651.45312, saving model to Weights-00685--13651.45312.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9816.3232 - mean_absolute_error: 9816.3232 - val_loss: 13651.4531 - val_mean_absolute_error: 13651.4531\n",
      "Epoch 686/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10798.4072 - mean_absolute_error: 10798.4072\n",
      "Epoch 686: val_loss did not improve from 13651.45312\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9814.1123 - mean_absolute_error: 9814.1123 - val_loss: 13654.2334 - val_mean_absolute_error: 13654.2334\n",
      "Epoch 687/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5541.3828 - mean_absolute_error: 5541.3828\n",
      "Epoch 687: val_loss did not improve from 13651.45312\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9815.6201 - mean_absolute_error: 9815.6201 - val_loss: 13654.2324 - val_mean_absolute_error: 13654.2324\n",
      "Epoch 688/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7646.3979 - mean_absolute_error: 7646.3979\n",
      "Epoch 688: val_loss did not improve from 13651.45312\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9843.6846 - mean_absolute_error: 9843.6846 - val_loss: 13667.9521 - val_mean_absolute_error: 13667.9521\n",
      "Epoch 689/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11329.5557 - mean_absolute_error: 11329.5557\n",
      "Epoch 689: val_loss did not improve from 13651.45312\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9821.2227 - mean_absolute_error: 9821.2227 - val_loss: 13654.2988 - val_mean_absolute_error: 13654.2988\n",
      "Epoch 690/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10041.5488 - mean_absolute_error: 10041.5488\n",
      "Epoch 690: val_loss did not improve from 13651.45312\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9811.4609 - mean_absolute_error: 9811.4609 - val_loss: 13653.7715 - val_mean_absolute_error: 13653.7715\n",
      "Epoch 691/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7385.7900 - mean_absolute_error: 7385.7900\n",
      "Epoch 691: val_loss did not improve from 13651.45312\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9810.4951 - mean_absolute_error: 9810.4951 - val_loss: 13653.6836 - val_mean_absolute_error: 13653.6836\n",
      "Epoch 692/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12178.1387 - mean_absolute_error: 12178.1387\n",
      "Epoch 692: val_loss did not improve from 13651.45312\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9819.0273 - mean_absolute_error: 9819.0273 - val_loss: 13652.3555 - val_mean_absolute_error: 13652.3555\n",
      "Epoch 693/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8592.3672 - mean_absolute_error: 8592.3672\n",
      "Epoch 693: val_loss did not improve from 13651.45312\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9813.3564 - mean_absolute_error: 9813.3564 - val_loss: 13653.7217 - val_mean_absolute_error: 13653.7217\n",
      "Epoch 694/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10370.5820 - mean_absolute_error: 10370.5820\n",
      "Epoch 694: val_loss improved from 13651.45312 to 13650.04785, saving model to Weights-00694--13650.04785.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9819.1475 - mean_absolute_error: 9819.1475 - val_loss: 13650.0479 - val_mean_absolute_error: 13650.0479\n",
      "Epoch 695/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12821.6289 - mean_absolute_error: 12821.6289\n",
      "Epoch 695: val_loss did not improve from 13650.04785\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9816.2236 - mean_absolute_error: 9816.2236 - val_loss: 13651.9199 - val_mean_absolute_error: 13651.9189\n",
      "Epoch 696/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9802.9121 - mean_absolute_error: 9802.9121\n",
      "Epoch 696: val_loss did not improve from 13650.04785\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9810.2070 - mean_absolute_error: 9810.2070 - val_loss: 13654.0674 - val_mean_absolute_error: 13654.0674\n",
      "Epoch 697/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7793.7812 - mean_absolute_error: 7793.7812\n",
      "Epoch 697: val_loss improved from 13650.04785 to 13649.31934, saving model to Weights-00697--13649.31934.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9806.8184 - mean_absolute_error: 9806.8184 - val_loss: 13649.3193 - val_mean_absolute_error: 13649.3193\n",
      "Epoch 698/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11210.3828 - mean_absolute_error: 11210.3828\n",
      "Epoch 698: val_loss did not improve from 13649.31934\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9816.7656 - mean_absolute_error: 9816.7656 - val_loss: 13657.1699 - val_mean_absolute_error: 13657.1699\n",
      "Epoch 699/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13257.7129 - mean_absolute_error: 13257.7129\n",
      "Epoch 699: val_loss did not improve from 13649.31934\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9801.3926 - mean_absolute_error: 9801.3926 - val_loss: 13650.6104 - val_mean_absolute_error: 13650.6104\n",
      "Epoch 700/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7248.3037 - mean_absolute_error: 7248.3037\n",
      "Epoch 700: val_loss improved from 13649.31934 to 13648.60840, saving model to Weights-00700--13648.60840.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9813.8154 - mean_absolute_error: 9813.8154 - val_loss: 13648.6084 - val_mean_absolute_error: 13648.6084\n",
      "Epoch 701/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9163.2266 - mean_absolute_error: 9163.2266\n",
      "Epoch 701: val_loss did not improve from 13648.60840\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9807.2197 - mean_absolute_error: 9807.2197 - val_loss: 13653.0498 - val_mean_absolute_error: 13653.0498\n",
      "Epoch 702/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10412.2383 - mean_absolute_error: 10412.2383\n",
      "Epoch 702: val_loss did not improve from 13648.60840\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9816.3203 - mean_absolute_error: 9816.3203 - val_loss: 13651.2520 - val_mean_absolute_error: 13651.2510\n",
      "Epoch 703/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9678.5088 - mean_absolute_error: 9678.5088\n",
      "Epoch 703: val_loss did not improve from 13648.60840\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9817.4971 - mean_absolute_error: 9817.4971 - val_loss: 13653.2969 - val_mean_absolute_error: 13653.2959\n",
      "Epoch 704/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8915.3066 - mean_absolute_error: 8915.3066\n",
      "Epoch 704: val_loss did not improve from 13648.60840\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9806.1230 - mean_absolute_error: 9806.1230 - val_loss: 13649.7861 - val_mean_absolute_error: 13649.7861\n",
      "Epoch 705/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7668.3760 - mean_absolute_error: 7668.3760\n",
      "Epoch 705: val_loss did not improve from 13648.60840\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9809.1104 - mean_absolute_error: 9809.1104 - val_loss: 13652.0137 - val_mean_absolute_error: 13652.0137\n",
      "Epoch 706/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11957.0381 - mean_absolute_error: 11957.0381\n",
      "Epoch 706: val_loss did not improve from 13648.60840\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9806.3535 - mean_absolute_error: 9806.3535 - val_loss: 13655.2930 - val_mean_absolute_error: 13655.2930\n",
      "Epoch 707/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6844.9165 - mean_absolute_error: 6844.9165\n",
      "Epoch 707: val_loss improved from 13648.60840 to 13648.04785, saving model to Weights-00707--13648.04785.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9805.6924 - mean_absolute_error: 9805.6924 - val_loss: 13648.0479 - val_mean_absolute_error: 13648.0479\n",
      "Epoch 708/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8077.4204 - mean_absolute_error: 8077.4204\n",
      "Epoch 708: val_loss did not improve from 13648.04785\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9804.7451 - mean_absolute_error: 9804.7451 - val_loss: 13648.6875 - val_mean_absolute_error: 13648.6875\n",
      "Epoch 709/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10561.9668 - mean_absolute_error: 10561.9668\n",
      "Epoch 709: val_loss did not improve from 13648.04785\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9802.4961 - mean_absolute_error: 9802.4961 - val_loss: 13649.3711 - val_mean_absolute_error: 13649.3711\n",
      "Epoch 710/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9505.2070 - mean_absolute_error: 9505.2070\n",
      "Epoch 710: val_loss did not improve from 13648.04785\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9809.0986 - mean_absolute_error: 9809.0986 - val_loss: 13653.4346 - val_mean_absolute_error: 13653.4346\n",
      "Epoch 711/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9787.5918 - mean_absolute_error: 9787.5918\n",
      "Epoch 711: val_loss did not improve from 13648.04785\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9815.3027 - mean_absolute_error: 9815.3027 - val_loss: 13650.1104 - val_mean_absolute_error: 13650.1104\n",
      "Epoch 712/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7682.0005 - mean_absolute_error: 7682.0005\n",
      "Epoch 712: val_loss improved from 13648.04785 to 13646.80762, saving model to Weights-00712--13646.80762.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9800.6064 - mean_absolute_error: 9800.6064 - val_loss: 13646.8076 - val_mean_absolute_error: 13646.8076\n",
      "Epoch 713/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13070.1729 - mean_absolute_error: 13070.1729\n",
      "Epoch 713: val_loss did not improve from 13646.80762\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9802.6699 - mean_absolute_error: 9802.6699 - val_loss: 13648.4004 - val_mean_absolute_error: 13648.4004\n",
      "Epoch 714/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11455.6777 - mean_absolute_error: 11455.6777\n",
      "Epoch 714: val_loss did not improve from 13646.80762\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9802.4326 - mean_absolute_error: 9802.4326 - val_loss: 13649.2500 - val_mean_absolute_error: 13649.2500\n",
      "Epoch 715/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12394.1289 - mean_absolute_error: 12394.1289\n",
      "Epoch 715: val_loss did not improve from 13646.80762\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9798.1602 - mean_absolute_error: 9798.1602 - val_loss: 13647.1992 - val_mean_absolute_error: 13647.1992\n",
      "Epoch 716/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8581.4902 - mean_absolute_error: 8581.4902\n",
      "Epoch 716: val_loss improved from 13646.80762 to 13646.23730, saving model to Weights-00716--13646.23730.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9807.5889 - mean_absolute_error: 9807.5889 - val_loss: 13646.2373 - val_mean_absolute_error: 13646.2373\n",
      "Epoch 717/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8633.4609 - mean_absolute_error: 8633.4609\n",
      "Epoch 717: val_loss did not improve from 13646.23730\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9796.1162 - mean_absolute_error: 9796.1162 - val_loss: 13651.8799 - val_mean_absolute_error: 13651.8799\n",
      "Epoch 718/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9042.2266 - mean_absolute_error: 9042.2266\n",
      "Epoch 718: val_loss did not improve from 13646.23730\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9802.8262 - mean_absolute_error: 9802.8262 - val_loss: 13652.8633 - val_mean_absolute_error: 13652.8633\n",
      "Epoch 719/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13209.5352 - mean_absolute_error: 13209.5352\n",
      "Epoch 719: val_loss did not improve from 13646.23730\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9806.8447 - mean_absolute_error: 9806.8447 - val_loss: 13648.8105 - val_mean_absolute_error: 13648.8105\n",
      "Epoch 720/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6962.0225 - mean_absolute_error: 6962.0225\n",
      "Epoch 720: val_loss did not improve from 13646.23730\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9799.2354 - mean_absolute_error: 9799.2354 - val_loss: 13646.4639 - val_mean_absolute_error: 13646.4639\n",
      "Epoch 721/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10431.9766 - mean_absolute_error: 10431.9766\n",
      "Epoch 721: val_loss did not improve from 13646.23730\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9797.4111 - mean_absolute_error: 9797.4111 - val_loss: 13647.7656 - val_mean_absolute_error: 13647.7656\n",
      "Epoch 722/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9878.7773 - mean_absolute_error: 9878.7773\n",
      "Epoch 722: val_loss did not improve from 13646.23730\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9804.0811 - mean_absolute_error: 9804.0811 - val_loss: 13652.6934 - val_mean_absolute_error: 13652.6934\n",
      "Epoch 723/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10612.3398 - mean_absolute_error: 10612.3398\n",
      "Epoch 723: val_loss improved from 13646.23730 to 13645.60938, saving model to Weights-00723--13645.60938.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9800.0762 - mean_absolute_error: 9800.0762 - val_loss: 13645.6094 - val_mean_absolute_error: 13645.6094\n",
      "Epoch 724/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10946.0459 - mean_absolute_error: 10946.0459\n",
      "Epoch 724: val_loss improved from 13645.60938 to 13644.83398, saving model to Weights-00724--13644.83398.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9799.9844 - mean_absolute_error: 9799.9844 - val_loss: 13644.8340 - val_mean_absolute_error: 13644.8340\n",
      "Epoch 725/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9233.0293 - mean_absolute_error: 9233.0293\n",
      "Epoch 725: val_loss did not improve from 13644.83398\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9793.2744 - mean_absolute_error: 9793.2744 - val_loss: 13649.2568 - val_mean_absolute_error: 13649.2568\n",
      "Epoch 726/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6101.5488 - mean_absolute_error: 6101.5488\n",
      "Epoch 726: val_loss did not improve from 13644.83398\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9794.1113 - mean_absolute_error: 9794.1113 - val_loss: 13647.4658 - val_mean_absolute_error: 13647.4658\n",
      "Epoch 727/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12946.6973 - mean_absolute_error: 12946.6973\n",
      "Epoch 727: val_loss did not improve from 13644.83398\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9804.6826 - mean_absolute_error: 9804.6826 - val_loss: 13648.1826 - val_mean_absolute_error: 13648.1826\n",
      "Epoch 728/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10856.0156 - mean_absolute_error: 10856.0156\n",
      "Epoch 728: val_loss did not improve from 13644.83398\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9798.8359 - mean_absolute_error: 9798.8359 - val_loss: 13648.8223 - val_mean_absolute_error: 13648.8223\n",
      "Epoch 729/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10422.4746 - mean_absolute_error: 10422.4746\n",
      "Epoch 729: val_loss did not improve from 13644.83398\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9805.3418 - mean_absolute_error: 9805.3418 - val_loss: 13647.0176 - val_mean_absolute_error: 13647.0176\n",
      "Epoch 730/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10011.0977 - mean_absolute_error: 10011.0977\n",
      "Epoch 730: val_loss did not improve from 13644.83398\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9799.9385 - mean_absolute_error: 9799.9385 - val_loss: 13646.1660 - val_mean_absolute_error: 13646.1660\n",
      "Epoch 731/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 15072.3623 - mean_absolute_error: 15072.3623\n",
      "Epoch 731: val_loss did not improve from 13644.83398\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9789.8213 - mean_absolute_error: 9789.8213 - val_loss: 13650.7617 - val_mean_absolute_error: 13650.7617\n",
      "Epoch 732/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10892.7871 - mean_absolute_error: 10892.7871\n",
      "Epoch 732: val_loss did not improve from 13644.83398\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9792.4980 - mean_absolute_error: 9792.4980 - val_loss: 13648.8047 - val_mean_absolute_error: 13648.8047\n",
      "Epoch 733/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8591.5244 - mean_absolute_error: 8591.5244\n",
      "Epoch 733: val_loss did not improve from 13644.83398\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9808.6719 - mean_absolute_error: 9808.6719 - val_loss: 13659.0977 - val_mean_absolute_error: 13659.0977\n",
      "Epoch 734/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6995.0186 - mean_absolute_error: 6995.0186\n",
      "Epoch 734: val_loss did not improve from 13644.83398\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9807.6436 - mean_absolute_error: 9807.6436 - val_loss: 13647.5898 - val_mean_absolute_error: 13647.5898\n",
      "Epoch 735/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6963.2632 - mean_absolute_error: 6963.2632\n",
      "Epoch 735: val_loss did not improve from 13644.83398\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9788.7822 - mean_absolute_error: 9788.7822 - val_loss: 13650.0068 - val_mean_absolute_error: 13650.0068\n",
      "Epoch 736/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9351.0840 - mean_absolute_error: 9351.0840\n",
      "Epoch 736: val_loss did not improve from 13644.83398\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9791.2578 - mean_absolute_error: 9791.2578 - val_loss: 13645.6855 - val_mean_absolute_error: 13645.6855\n",
      "Epoch 737/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10000.0664 - mean_absolute_error: 10000.0664\n",
      "Epoch 737: val_loss did not improve from 13644.83398\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9790.9951 - mean_absolute_error: 9790.9951 - val_loss: 13645.3984 - val_mean_absolute_error: 13645.3984\n",
      "Epoch 738/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9046.6279 - mean_absolute_error: 9046.6279\n",
      "Epoch 738: val_loss did not improve from 13644.83398\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9788.6709 - mean_absolute_error: 9788.6709 - val_loss: 13653.0596 - val_mean_absolute_error: 13653.0596\n",
      "Epoch 739/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8260.2295 - mean_absolute_error: 8260.2295\n",
      "Epoch 739: val_loss improved from 13644.83398 to 13644.01953, saving model to Weights-00739--13644.01953.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9786.4336 - mean_absolute_error: 9786.4336 - val_loss: 13644.0195 - val_mean_absolute_error: 13644.0195\n",
      "Epoch 740/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8510.8701 - mean_absolute_error: 8510.8701\n",
      "Epoch 740: val_loss improved from 13644.01953 to 13642.62598, saving model to Weights-00740--13642.62598.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9795.9199 - mean_absolute_error: 9795.9199 - val_loss: 13642.6260 - val_mean_absolute_error: 13642.6260\n",
      "Epoch 741/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9664.2520 - mean_absolute_error: 9664.2520\n",
      "Epoch 741: val_loss did not improve from 13642.62598\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9808.2295 - mean_absolute_error: 9808.2295 - val_loss: 13647.1465 - val_mean_absolute_error: 13647.1465\n",
      "Epoch 742/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7436.0332 - mean_absolute_error: 7436.0332\n",
      "Epoch 742: val_loss did not improve from 13642.62598\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9791.4590 - mean_absolute_error: 9791.4590 - val_loss: 13654.4951 - val_mean_absolute_error: 13654.4951\n",
      "Epoch 743/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7913.4272 - mean_absolute_error: 7913.4272\n",
      "Epoch 743: val_loss did not improve from 13642.62598\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9786.5498 - mean_absolute_error: 9786.5498 - val_loss: 13643.9111 - val_mean_absolute_error: 13643.9111\n",
      "Epoch 744/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9912.7705 - mean_absolute_error: 9912.7705\n",
      "Epoch 744: val_loss did not improve from 13642.62598\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9788.2129 - mean_absolute_error: 9788.2129 - val_loss: 13644.3125 - val_mean_absolute_error: 13644.3125\n",
      "Epoch 745/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9751.7637 - mean_absolute_error: 9751.7637\n",
      "Epoch 745: val_loss improved from 13642.62598 to 13641.76758, saving model to Weights-00745--13641.76758.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9793.9590 - mean_absolute_error: 9793.9590 - val_loss: 13641.7676 - val_mean_absolute_error: 13641.7676\n",
      "Epoch 746/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10590.3096 - mean_absolute_error: 10590.3096\n",
      "Epoch 746: val_loss did not improve from 13641.76758\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9790.3281 - mean_absolute_error: 9790.3281 - val_loss: 13646.1289 - val_mean_absolute_error: 13646.1289\n",
      "Epoch 747/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8041.2129 - mean_absolute_error: 8041.2129\n",
      "Epoch 747: val_loss improved from 13641.76758 to 13641.30078, saving model to Weights-00747--13641.30078.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9779.7158 - mean_absolute_error: 9779.7158 - val_loss: 13641.3008 - val_mean_absolute_error: 13641.3008\n",
      "Epoch 748/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11438.9980 - mean_absolute_error: 11438.9980\n",
      "Epoch 748: val_loss improved from 13641.30078 to 13641.21289, saving model to Weights-00748--13641.21289.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9787.4385 - mean_absolute_error: 9787.4385 - val_loss: 13641.2129 - val_mean_absolute_error: 13641.2129\n",
      "Epoch 749/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8442.4375 - mean_absolute_error: 8442.4375\n",
      "Epoch 749: val_loss did not improve from 13641.21289\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9784.0420 - mean_absolute_error: 9784.0420 - val_loss: 13646.2197 - val_mean_absolute_error: 13646.2197\n",
      "Epoch 750/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9861.4863 - mean_absolute_error: 9861.4863\n",
      "Epoch 750: val_loss did not improve from 13641.21289\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9785.4131 - mean_absolute_error: 9785.4131 - val_loss: 13644.6572 - val_mean_absolute_error: 13644.6572\n",
      "Epoch 751/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7723.1362 - mean_absolute_error: 7723.1362\n",
      "Epoch 751: val_loss did not improve from 13641.21289\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9788.6836 - mean_absolute_error: 9788.6836 - val_loss: 13642.1162 - val_mean_absolute_error: 13642.1162\n",
      "Epoch 752/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12694.2090 - mean_absolute_error: 12694.2090\n",
      "Epoch 752: val_loss did not improve from 13641.21289\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9787.8594 - mean_absolute_error: 9787.8594 - val_loss: 13643.5713 - val_mean_absolute_error: 13643.5713\n",
      "Epoch 753/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8153.5854 - mean_absolute_error: 8153.5854\n",
      "Epoch 753: val_loss did not improve from 13641.21289\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9797.7295 - mean_absolute_error: 9797.7295 - val_loss: 13653.7881 - val_mean_absolute_error: 13653.7881\n",
      "Epoch 754/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9311.8506 - mean_absolute_error: 9311.8506\n",
      "Epoch 754: val_loss did not improve from 13641.21289\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9788.5488 - mean_absolute_error: 9788.5488 - val_loss: 13644.4043 - val_mean_absolute_error: 13644.4043\n",
      "Epoch 755/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7033.2969 - mean_absolute_error: 7033.2969\n",
      "Epoch 755: val_loss did not improve from 13641.21289\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9783.7227 - mean_absolute_error: 9783.7227 - val_loss: 13643.0654 - val_mean_absolute_error: 13643.0654\n",
      "Epoch 756/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9058.1426 - mean_absolute_error: 9058.1426\n",
      "Epoch 756: val_loss did not improve from 13641.21289\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9780.5420 - mean_absolute_error: 9780.5420 - val_loss: 13641.6885 - val_mean_absolute_error: 13641.6885\n",
      "Epoch 757/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9444.3350 - mean_absolute_error: 9444.3350\n",
      "Epoch 757: val_loss did not improve from 13641.21289\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9777.6953 - mean_absolute_error: 9777.6953 - val_loss: 13645.9951 - val_mean_absolute_error: 13645.9951\n",
      "Epoch 758/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12391.7012 - mean_absolute_error: 12391.7012\n",
      "Epoch 758: val_loss did not improve from 13641.21289\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9783.5449 - mean_absolute_error: 9783.5449 - val_loss: 13646.8125 - val_mean_absolute_error: 13646.8125\n",
      "Epoch 759/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9253.2676 - mean_absolute_error: 9253.2676\n",
      "Epoch 759: val_loss improved from 13641.21289 to 13641.19922, saving model to Weights-00759--13641.19922.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9781.4297 - mean_absolute_error: 9781.4297 - val_loss: 13641.1992 - val_mean_absolute_error: 13641.1992\n",
      "Epoch 760/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8016.0400 - mean_absolute_error: 8016.0400\n",
      "Epoch 760: val_loss improved from 13641.19922 to 13639.42285, saving model to Weights-00760--13639.42285.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9775.8418 - mean_absolute_error: 9775.8418 - val_loss: 13639.4229 - val_mean_absolute_error: 13639.4229\n",
      "Epoch 761/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10090.7012 - mean_absolute_error: 10090.7012\n",
      "Epoch 761: val_loss did not improve from 13639.42285\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9792.0889 - mean_absolute_error: 9792.0889 - val_loss: 13641.3428 - val_mean_absolute_error: 13641.3428\n",
      "Epoch 762/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6083.8311 - mean_absolute_error: 6083.8311\n",
      "Epoch 762: val_loss did not improve from 13639.42285\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9782.9443 - mean_absolute_error: 9782.9443 - val_loss: 13645.1133 - val_mean_absolute_error: 13645.1133\n",
      "Epoch 763/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8627.7539 - mean_absolute_error: 8627.7539\n",
      "Epoch 763: val_loss improved from 13639.42285 to 13639.31934, saving model to Weights-00763--13639.31934.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9780.2002 - mean_absolute_error: 9780.2002 - val_loss: 13639.3193 - val_mean_absolute_error: 13639.3193\n",
      "Epoch 764/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10228.3848 - mean_absolute_error: 10228.3848\n",
      "Epoch 764: val_loss did not improve from 13639.31934\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9782.1504 - mean_absolute_error: 9782.1504 - val_loss: 13645.7363 - val_mean_absolute_error: 13645.7363\n",
      "Epoch 765/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12313.7402 - mean_absolute_error: 12313.7402\n",
      "Epoch 765: val_loss did not improve from 13639.31934\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9775.5566 - mean_absolute_error: 9775.5566 - val_loss: 13640.0547 - val_mean_absolute_error: 13640.0547\n",
      "Epoch 766/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10660.7656 - mean_absolute_error: 10660.7656\n",
      "Epoch 766: val_loss did not improve from 13639.31934\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9789.7871 - mean_absolute_error: 9789.7871 - val_loss: 13640.9375 - val_mean_absolute_error: 13640.9375\n",
      "Epoch 767/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9280.9111 - mean_absolute_error: 9280.9111\n",
      "Epoch 767: val_loss did not improve from 13639.31934\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9779.9736 - mean_absolute_error: 9779.9736 - val_loss: 13648.3701 - val_mean_absolute_error: 13648.3701\n",
      "Epoch 768/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9981.8320 - mean_absolute_error: 9981.8320\n",
      "Epoch 768: val_loss did not improve from 13639.31934\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9774.3945 - mean_absolute_error: 9774.3945 - val_loss: 13640.7012 - val_mean_absolute_error: 13640.7012\n",
      "Epoch 769/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 14338.9727 - mean_absolute_error: 14338.9727\n",
      "Epoch 769: val_loss did not improve from 13639.31934\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9776.7520 - mean_absolute_error: 9776.7520 - val_loss: 13639.4746 - val_mean_absolute_error: 13639.4746\n",
      "Epoch 770/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11105.5312 - mean_absolute_error: 11105.5312\n",
      "Epoch 770: val_loss improved from 13639.31934 to 13639.20996, saving model to Weights-00770--13639.20996.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9774.3857 - mean_absolute_error: 9774.3857 - val_loss: 13639.2100 - val_mean_absolute_error: 13639.2100\n",
      "Epoch 771/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7354.3179 - mean_absolute_error: 7354.3179\n",
      "Epoch 771: val_loss did not improve from 13639.20996\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9778.2637 - mean_absolute_error: 9778.2637 - val_loss: 13639.3516 - val_mean_absolute_error: 13639.3525\n",
      "Epoch 772/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9281.3730 - mean_absolute_error: 9281.3730\n",
      "Epoch 772: val_loss did not improve from 13639.20996\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9773.5576 - mean_absolute_error: 9773.5576 - val_loss: 13644.0283 - val_mean_absolute_error: 13644.0283\n",
      "Epoch 773/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6884.8740 - mean_absolute_error: 6884.8740\n",
      "Epoch 773: val_loss improved from 13639.20996 to 13638.50391, saving model to Weights-00773--13638.50391.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9769.8994 - mean_absolute_error: 9769.8994 - val_loss: 13638.5039 - val_mean_absolute_error: 13638.5039\n",
      "Epoch 774/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10431.1777 - mean_absolute_error: 10431.1777\n",
      "Epoch 774: val_loss did not improve from 13638.50391\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9780.8359 - mean_absolute_error: 9780.8359 - val_loss: 13638.6719 - val_mean_absolute_error: 13638.6719\n",
      "Epoch 775/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9534.9551 - mean_absolute_error: 9534.9551\n",
      "Epoch 775: val_loss did not improve from 13638.50391\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9770.7705 - mean_absolute_error: 9770.7705 - val_loss: 13641.9922 - val_mean_absolute_error: 13641.9922\n",
      "Epoch 776/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11766.2520 - mean_absolute_error: 11766.2520\n",
      "Epoch 776: val_loss did not improve from 13638.50391\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9770.5420 - mean_absolute_error: 9770.5420 - val_loss: 13639.9365 - val_mean_absolute_error: 13639.9365\n",
      "Epoch 777/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9047.6348 - mean_absolute_error: 9047.6348\n",
      "Epoch 777: val_loss did not improve from 13638.50391\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9779.2080 - mean_absolute_error: 9779.2080 - val_loss: 13639.0156 - val_mean_absolute_error: 13639.0156\n",
      "Epoch 778/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9667.3809 - mean_absolute_error: 9667.3809\n",
      "Epoch 778: val_loss improved from 13638.50391 to 13637.19141, saving model to Weights-00778--13637.19141.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9781.0996 - mean_absolute_error: 9781.0996 - val_loss: 13637.1914 - val_mean_absolute_error: 13637.1914\n",
      "Epoch 779/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9558.9072 - mean_absolute_error: 9558.9072\n",
      "Epoch 779: val_loss did not improve from 13637.19141\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9777.1143 - mean_absolute_error: 9777.1143 - val_loss: 13638.0947 - val_mean_absolute_error: 13638.0947\n",
      "Epoch 780/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12140.1797 - mean_absolute_error: 12140.1797\n",
      "Epoch 780: val_loss improved from 13637.19141 to 13637.14062, saving model to Weights-00780--13637.14062.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9768.3955 - mean_absolute_error: 9768.3955 - val_loss: 13637.1406 - val_mean_absolute_error: 13637.1406\n",
      "Epoch 781/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9058.6426 - mean_absolute_error: 9058.6426\n",
      "Epoch 781: val_loss did not improve from 13637.14062\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9773.5420 - mean_absolute_error: 9773.5420 - val_loss: 13637.6826 - val_mean_absolute_error: 13637.6826\n",
      "Epoch 782/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13855.2061 - mean_absolute_error: 13855.2061\n",
      "Epoch 782: val_loss did not improve from 13637.14062\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9785.8311 - mean_absolute_error: 9785.8311 - val_loss: 13644.9326 - val_mean_absolute_error: 13644.9326\n",
      "Epoch 783/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10862.3662 - mean_absolute_error: 10862.3662\n",
      "Epoch 783: val_loss did not improve from 13637.14062\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9761.5547 - mean_absolute_error: 9761.5547 - val_loss: 13639.7373 - val_mean_absolute_error: 13639.7373\n",
      "Epoch 784/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7253.2920 - mean_absolute_error: 7253.2920\n",
      "Epoch 784: val_loss did not improve from 13637.14062\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9776.9180 - mean_absolute_error: 9776.9180 - val_loss: 13639.5869 - val_mean_absolute_error: 13639.5869\n",
      "Epoch 785/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11339.2021 - mean_absolute_error: 11339.2021\n",
      "Epoch 785: val_loss did not improve from 13637.14062\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9779.9727 - mean_absolute_error: 9779.9727 - val_loss: 13643.8281 - val_mean_absolute_error: 13643.8281\n",
      "Epoch 786/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7778.6543 - mean_absolute_error: 7778.6543\n",
      "Epoch 786: val_loss did not improve from 13637.14062\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9777.0908 - mean_absolute_error: 9777.0908 - val_loss: 13639.2510 - val_mean_absolute_error: 13639.2510\n",
      "Epoch 787/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11509.0957 - mean_absolute_error: 11509.0957\n",
      "Epoch 787: val_loss did not improve from 13637.14062\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9768.8076 - mean_absolute_error: 9768.8076 - val_loss: 13642.3438 - val_mean_absolute_error: 13642.3438\n",
      "Epoch 788/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8512.2207 - mean_absolute_error: 8512.2207\n",
      "Epoch 788: val_loss did not improve from 13637.14062\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9766.0479 - mean_absolute_error: 9766.0479 - val_loss: 13640.0908 - val_mean_absolute_error: 13640.0908\n",
      "Epoch 789/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8159.7788 - mean_absolute_error: 8159.7788\n",
      "Epoch 789: val_loss improved from 13637.14062 to 13634.90137, saving model to Weights-00789--13634.90137.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9771.8438 - mean_absolute_error: 9771.8438 - val_loss: 13634.9014 - val_mean_absolute_error: 13634.9014\n",
      "Epoch 790/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8193.0996 - mean_absolute_error: 8193.0996\n",
      "Epoch 790: val_loss did not improve from 13634.90137\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9768.3906 - mean_absolute_error: 9768.3906 - val_loss: 13637.1240 - val_mean_absolute_error: 13637.1240\n",
      "Epoch 791/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11069.9248 - mean_absolute_error: 11069.9248\n",
      "Epoch 791: val_loss did not improve from 13634.90137\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9769.5664 - mean_absolute_error: 9769.5664 - val_loss: 13643.0215 - val_mean_absolute_error: 13643.0215\n",
      "Epoch 792/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9182.7666 - mean_absolute_error: 9182.7666\n",
      "Epoch 792: val_loss did not improve from 13634.90137\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9764.8916 - mean_absolute_error: 9764.8916 - val_loss: 13640.1025 - val_mean_absolute_error: 13640.1025\n",
      "Epoch 793/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11652.0098 - mean_absolute_error: 11652.0098\n",
      "Epoch 793: val_loss improved from 13634.90137 to 13634.29883, saving model to Weights-00793--13634.29883.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9781.0459 - mean_absolute_error: 9781.0459 - val_loss: 13634.2988 - val_mean_absolute_error: 13634.2988\n",
      "Epoch 794/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7227.2402 - mean_absolute_error: 7227.2402\n",
      "Epoch 794: val_loss did not improve from 13634.29883\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9768.7070 - mean_absolute_error: 9768.7070 - val_loss: 13640.5576 - val_mean_absolute_error: 13640.5576\n",
      "Epoch 795/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7270.6475 - mean_absolute_error: 7270.6475\n",
      "Epoch 795: val_loss did not improve from 13634.29883\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9762.6016 - mean_absolute_error: 9762.6016 - val_loss: 13635.5010 - val_mean_absolute_error: 13635.5010\n",
      "Epoch 796/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7697.6665 - mean_absolute_error: 7697.6665\n",
      "Epoch 796: val_loss did not improve from 13634.29883\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9771.0107 - mean_absolute_error: 9771.0107 - val_loss: 13638.4307 - val_mean_absolute_error: 13638.4307\n",
      "Epoch 797/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11664.6377 - mean_absolute_error: 11664.6377\n",
      "Epoch 797: val_loss did not improve from 13634.29883\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9765.3623 - mean_absolute_error: 9765.3623 - val_loss: 13635.3457 - val_mean_absolute_error: 13635.3457\n",
      "Epoch 798/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10898.7744 - mean_absolute_error: 10898.7744\n",
      "Epoch 798: val_loss did not improve from 13634.29883\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9771.9053 - mean_absolute_error: 9771.9053 - val_loss: 13636.3926 - val_mean_absolute_error: 13636.3926\n",
      "Epoch 799/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8743.5732 - mean_absolute_error: 8743.5732\n",
      "Epoch 799: val_loss did not improve from 13634.29883\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9761.4824 - mean_absolute_error: 9761.4824 - val_loss: 13642.2109 - val_mean_absolute_error: 13642.2109\n",
      "Epoch 800/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8506.1006 - mean_absolute_error: 8506.1006\n",
      "Epoch 800: val_loss did not improve from 13634.29883\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9761.6816 - mean_absolute_error: 9761.6816 - val_loss: 13641.6494 - val_mean_absolute_error: 13641.6494\n",
      "Epoch 801/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8492.8008 - mean_absolute_error: 8492.8008\n",
      "Epoch 801: val_loss did not improve from 13634.29883\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9758.1094 - mean_absolute_error: 9758.1094 - val_loss: 13634.6348 - val_mean_absolute_error: 13634.6348\n",
      "Epoch 802/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6767.9585 - mean_absolute_error: 6767.9585\n",
      "Epoch 802: val_loss improved from 13634.29883 to 13633.14062, saving model to Weights-00802--13633.14062.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9780.7686 - mean_absolute_error: 9780.7686 - val_loss: 13633.1406 - val_mean_absolute_error: 13633.1406\n",
      "Epoch 803/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9222.4785 - mean_absolute_error: 9222.4785\n",
      "Epoch 803: val_loss did not improve from 13633.14062\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9762.7959 - mean_absolute_error: 9762.7959 - val_loss: 13635.8604 - val_mean_absolute_error: 13635.8604\n",
      "Epoch 804/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11590.9121 - mean_absolute_error: 11590.9121\n",
      "Epoch 804: val_loss did not improve from 13633.14062\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9760.3320 - mean_absolute_error: 9760.3320 - val_loss: 13633.7490 - val_mean_absolute_error: 13633.7490\n",
      "Epoch 805/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6908.6030 - mean_absolute_error: 6908.6030\n",
      "Epoch 805: val_loss did not improve from 13633.14062\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9767.7178 - mean_absolute_error: 9767.7178 - val_loss: 13634.0332 - val_mean_absolute_error: 13634.0332\n",
      "Epoch 806/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11761.8945 - mean_absolute_error: 11761.8945\n",
      "Epoch 806: val_loss did not improve from 13633.14062\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9764.1768 - mean_absolute_error: 9764.1768 - val_loss: 13636.4893 - val_mean_absolute_error: 13636.4893\n",
      "Epoch 807/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8455.5771 - mean_absolute_error: 8455.5771\n",
      "Epoch 807: val_loss did not improve from 13633.14062\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9760.6738 - mean_absolute_error: 9760.6738 - val_loss: 13635.7109 - val_mean_absolute_error: 13635.7109\n",
      "Epoch 808/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10335.3320 - mean_absolute_error: 10335.3320\n",
      "Epoch 808: val_loss did not improve from 13633.14062\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9756.1895 - mean_absolute_error: 9756.1895 - val_loss: 13633.7334 - val_mean_absolute_error: 13633.7334\n",
      "Epoch 809/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12034.4814 - mean_absolute_error: 12034.4814\n",
      "Epoch 809: val_loss did not improve from 13633.14062\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9759.6768 - mean_absolute_error: 9759.6768 - val_loss: 13633.3340 - val_mean_absolute_error: 13633.3340\n",
      "Epoch 810/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8474.7793 - mean_absolute_error: 8474.7793\n",
      "Epoch 810: val_loss did not improve from 13633.14062\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9764.2227 - mean_absolute_error: 9764.2227 - val_loss: 13646.9395 - val_mean_absolute_error: 13646.9395\n",
      "Epoch 811/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10268.7676 - mean_absolute_error: 10268.7676\n",
      "Epoch 811: val_loss did not improve from 13633.14062\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9764.2041 - mean_absolute_error: 9764.2041 - val_loss: 13634.3555 - val_mean_absolute_error: 13634.3555\n",
      "Epoch 812/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11072.8037 - mean_absolute_error: 11072.8037\n",
      "Epoch 812: val_loss improved from 13633.14062 to 13631.36035, saving model to Weights-00812--13631.36035.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9757.9775 - mean_absolute_error: 9757.9775 - val_loss: 13631.3604 - val_mean_absolute_error: 13631.3604\n",
      "Epoch 813/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10909.8281 - mean_absolute_error: 10909.8281\n",
      "Epoch 813: val_loss did not improve from 13631.36035\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9752.0391 - mean_absolute_error: 9752.0391 - val_loss: 13636.9785 - val_mean_absolute_error: 13636.9785\n",
      "Epoch 814/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13320.3203 - mean_absolute_error: 13320.3203\n",
      "Epoch 814: val_loss did not improve from 13631.36035\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9754.5557 - mean_absolute_error: 9754.5557 - val_loss: 13632.6387 - val_mean_absolute_error: 13632.6387\n",
      "Epoch 815/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11339.0723 - mean_absolute_error: 11339.0723\n",
      "Epoch 815: val_loss did not improve from 13631.36035\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9754.3350 - mean_absolute_error: 9754.3350 - val_loss: 13631.4326 - val_mean_absolute_error: 13631.4326\n",
      "Epoch 816/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8916.3594 - mean_absolute_error: 8916.3594\n",
      "Epoch 816: val_loss did not improve from 13631.36035\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9754.3174 - mean_absolute_error: 9754.3174 - val_loss: 13633.1484 - val_mean_absolute_error: 13633.1484\n",
      "Epoch 817/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7863.7871 - mean_absolute_error: 7863.7871\n",
      "Epoch 817: val_loss did not improve from 13631.36035\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9752.2256 - mean_absolute_error: 9752.2256 - val_loss: 13632.4014 - val_mean_absolute_error: 13632.4014\n",
      "Epoch 818/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10398.2314 - mean_absolute_error: 10398.2314\n",
      "Epoch 818: val_loss did not improve from 13631.36035\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9761.8164 - mean_absolute_error: 9761.8164 - val_loss: 13638.4404 - val_mean_absolute_error: 13638.4404\n",
      "Epoch 819/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13321.4697 - mean_absolute_error: 13321.4697\n",
      "Epoch 819: val_loss did not improve from 13631.36035\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9765.6445 - mean_absolute_error: 9765.6445 - val_loss: 13632.9258 - val_mean_absolute_error: 13632.9258\n",
      "Epoch 820/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8873.6680 - mean_absolute_error: 8873.6680\n",
      "Epoch 820: val_loss did not improve from 13631.36035\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9750.8428 - mean_absolute_error: 9750.8428 - val_loss: 13633.6982 - val_mean_absolute_error: 13633.6982\n",
      "Epoch 821/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6168.1782 - mean_absolute_error: 6168.1782\n",
      "Epoch 821: val_loss improved from 13631.36035 to 13630.72559, saving model to Weights-00821--13630.72559.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9763.2754 - mean_absolute_error: 9763.2754 - val_loss: 13630.7256 - val_mean_absolute_error: 13630.7256\n",
      "Epoch 822/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11742.5762 - mean_absolute_error: 11742.5762\n",
      "Epoch 822: val_loss did not improve from 13630.72559\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9750.2061 - mean_absolute_error: 9750.2061 - val_loss: 13636.1855 - val_mean_absolute_error: 13636.1855\n",
      "Epoch 823/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9106.9570 - mean_absolute_error: 9106.9570\n",
      "Epoch 823: val_loss improved from 13630.72559 to 13630.58008, saving model to Weights-00823--13630.58008.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9751.4961 - mean_absolute_error: 9751.4961 - val_loss: 13630.5801 - val_mean_absolute_error: 13630.5801\n",
      "Epoch 824/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9093.0469 - mean_absolute_error: 9093.0469\n",
      "Epoch 824: val_loss did not improve from 13630.58008\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9763.3848 - mean_absolute_error: 9763.3848 - val_loss: 13632.8066 - val_mean_absolute_error: 13632.8066\n",
      "Epoch 825/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9952.8066 - mean_absolute_error: 9952.8066\n",
      "Epoch 825: val_loss improved from 13630.58008 to 13629.99414, saving model to Weights-00825--13629.99414.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9750.3955 - mean_absolute_error: 9750.3955 - val_loss: 13629.9941 - val_mean_absolute_error: 13629.9941\n",
      "Epoch 826/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12439.9053 - mean_absolute_error: 12439.9053\n",
      "Epoch 826: val_loss did not improve from 13629.99414\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9769.7930 - mean_absolute_error: 9769.7930 - val_loss: 13638.1855 - val_mean_absolute_error: 13638.1855\n",
      "Epoch 827/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10190.8926 - mean_absolute_error: 10190.8926\n",
      "Epoch 827: val_loss did not improve from 13629.99414\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9744.4668 - mean_absolute_error: 9744.4668 - val_loss: 13631.0312 - val_mean_absolute_error: 13631.0312\n",
      "Epoch 828/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9044.5039 - mean_absolute_error: 9044.5039\n",
      "Epoch 828: val_loss improved from 13629.99414 to 13629.43652, saving model to Weights-00828--13629.43652.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9753.7764 - mean_absolute_error: 9753.7764 - val_loss: 13629.4365 - val_mean_absolute_error: 13629.4365\n",
      "Epoch 829/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13021.9141 - mean_absolute_error: 13021.9141\n",
      "Epoch 829: val_loss did not improve from 13629.43652\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9745.7051 - mean_absolute_error: 9745.7051 - val_loss: 13632.5312 - val_mean_absolute_error: 13632.5312\n",
      "Epoch 830/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9821.3037 - mean_absolute_error: 9821.3037\n",
      "Epoch 830: val_loss did not improve from 13629.43652\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9751.8613 - mean_absolute_error: 9751.8613 - val_loss: 13630.4131 - val_mean_absolute_error: 13630.4131\n",
      "Epoch 831/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10963.6475 - mean_absolute_error: 10963.6475\n",
      "Epoch 831: val_loss did not improve from 13629.43652\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9748.1631 - mean_absolute_error: 9748.1631 - val_loss: 13633.5049 - val_mean_absolute_error: 13633.5049\n",
      "Epoch 832/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10939.1543 - mean_absolute_error: 10939.1543\n",
      "Epoch 832: val_loss did not improve from 13629.43652\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9745.4443 - mean_absolute_error: 9745.4443 - val_loss: 13630.7842 - val_mean_absolute_error: 13630.7842\n",
      "Epoch 833/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5891.5161 - mean_absolute_error: 5891.5161\n",
      "Epoch 833: val_loss did not improve from 13629.43652\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9749.0723 - mean_absolute_error: 9749.0723 - val_loss: 13630.6182 - val_mean_absolute_error: 13630.6182\n",
      "Epoch 834/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9847.2461 - mean_absolute_error: 9847.2461\n",
      "Epoch 834: val_loss improved from 13629.43652 to 13627.86816, saving model to Weights-00834--13627.86816.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9754.1650 - mean_absolute_error: 9754.1650 - val_loss: 13627.8682 - val_mean_absolute_error: 13627.8682\n",
      "Epoch 835/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10145.0859 - mean_absolute_error: 10145.0859\n",
      "Epoch 835: val_loss did not improve from 13627.86816\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9744.7832 - mean_absolute_error: 9744.7832 - val_loss: 13631.4639 - val_mean_absolute_error: 13631.4639\n",
      "Epoch 836/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7458.5312 - mean_absolute_error: 7458.5312\n",
      "Epoch 836: val_loss did not improve from 13627.86816\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9753.4766 - mean_absolute_error: 9753.4766 - val_loss: 13629.5557 - val_mean_absolute_error: 13629.5557\n",
      "Epoch 837/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10525.8359 - mean_absolute_error: 10525.8359\n",
      "Epoch 837: val_loss did not improve from 13627.86816\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9760.9297 - mean_absolute_error: 9760.9297 - val_loss: 13639.7236 - val_mean_absolute_error: 13639.7236\n",
      "Epoch 838/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7166.4106 - mean_absolute_error: 7166.4106\n",
      "Epoch 838: val_loss did not improve from 13627.86816\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9747.8340 - mean_absolute_error: 9747.8340 - val_loss: 13629.4326 - val_mean_absolute_error: 13629.4326\n",
      "Epoch 839/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7979.0537 - mean_absolute_error: 7979.0537\n",
      "Epoch 839: val_loss improved from 13627.86816 to 13627.18750, saving model to Weights-00839--13627.18750.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9747.9795 - mean_absolute_error: 9747.9795 - val_loss: 13627.1875 - val_mean_absolute_error: 13627.1875\n",
      "Epoch 840/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13453.5176 - mean_absolute_error: 13453.5176\n",
      "Epoch 840: val_loss did not improve from 13627.18750\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9759.3867 - mean_absolute_error: 9759.3867 - val_loss: 13633.2539 - val_mean_absolute_error: 13633.2539\n",
      "Epoch 841/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10537.8281 - mean_absolute_error: 10537.8281\n",
      "Epoch 841: val_loss did not improve from 13627.18750\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9737.5742 - mean_absolute_error: 9737.5742 - val_loss: 13628.1855 - val_mean_absolute_error: 13628.1855\n",
      "Epoch 842/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7665.1157 - mean_absolute_error: 7665.1157\n",
      "Epoch 842: val_loss did not improve from 13627.18750\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9747.0615 - mean_absolute_error: 9747.0615 - val_loss: 13628.1279 - val_mean_absolute_error: 13628.1279\n",
      "Epoch 843/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11371.9844 - mean_absolute_error: 11371.9844\n",
      "Epoch 843: val_loss improved from 13627.18750 to 13626.72754, saving model to Weights-00843--13626.72754.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9751.6270 - mean_absolute_error: 9751.6270 - val_loss: 13626.7275 - val_mean_absolute_error: 13626.7275\n",
      "Epoch 844/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8645.5732 - mean_absolute_error: 8645.5732\n",
      "Epoch 844: val_loss did not improve from 13626.72754\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9738.6777 - mean_absolute_error: 9738.6777 - val_loss: 13628.2695 - val_mean_absolute_error: 13628.2695\n",
      "Epoch 845/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9403.7051 - mean_absolute_error: 9403.7051\n",
      "Epoch 845: val_loss did not improve from 13626.72754\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9750.1523 - mean_absolute_error: 9750.1523 - val_loss: 13631.2412 - val_mean_absolute_error: 13631.2412\n",
      "Epoch 846/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9379.7441 - mean_absolute_error: 9379.7441\n",
      "Epoch 846: val_loss did not improve from 13626.72754\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9733.9541 - mean_absolute_error: 9733.9541 - val_loss: 13627.3203 - val_mean_absolute_error: 13627.3203\n",
      "Epoch 847/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8539.1807 - mean_absolute_error: 8539.1807\n",
      "Epoch 847: val_loss did not improve from 13626.72754\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9742.7490 - mean_absolute_error: 9742.7490 - val_loss: 13628.3076 - val_mean_absolute_error: 13628.3076\n",
      "Epoch 848/3000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9881.7031 - mean_absolute_error: 9881.7031\n",
      "Epoch 848: val_loss did not improve from 13626.72754\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9739.7061 - mean_absolute_error: 9739.7061 - val_loss: 13626.8389 - val_mean_absolute_error: 13626.8389\n",
      "Epoch 849/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12266.6846 - mean_absolute_error: 12266.6846\n",
      "Epoch 849: val_loss did not improve from 13626.72754\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9737.8643 - mean_absolute_error: 9737.8643 - val_loss: 13630.9092 - val_mean_absolute_error: 13630.9092\n",
      "Epoch 850/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7028.8828 - mean_absolute_error: 7028.8828\n",
      "Epoch 850: val_loss improved from 13626.72754 to 13626.30957, saving model to Weights-00850--13626.30957.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9743.5869 - mean_absolute_error: 9743.5869 - val_loss: 13626.3096 - val_mean_absolute_error: 13626.3096\n",
      "Epoch 851/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10106.7295 - mean_absolute_error: 10106.7295\n",
      "Epoch 851: val_loss did not improve from 13626.30957\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9745.2920 - mean_absolute_error: 9745.2920 - val_loss: 13626.8750 - val_mean_absolute_error: 13626.8750\n",
      "Epoch 852/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9244.8125 - mean_absolute_error: 9244.8125\n",
      "Epoch 852: val_loss did not improve from 13626.30957\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9736.9111 - mean_absolute_error: 9736.9111 - val_loss: 13627.7246 - val_mean_absolute_error: 13627.7246\n",
      "Epoch 853/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10985.8398 - mean_absolute_error: 10985.8398\n",
      "Epoch 853: val_loss did not improve from 13626.30957\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9745.3779 - mean_absolute_error: 9745.3779 - val_loss: 13628.7188 - val_mean_absolute_error: 13628.7188\n",
      "Epoch 854/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8411.5430 - mean_absolute_error: 8411.5430\n",
      "Epoch 854: val_loss did not improve from 13626.30957\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9743.8828 - mean_absolute_error: 9743.8828 - val_loss: 13629.8740 - val_mean_absolute_error: 13629.8740\n",
      "Epoch 855/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9728.5977 - mean_absolute_error: 9728.5977\n",
      "Epoch 855: val_loss improved from 13626.30957 to 13624.65918, saving model to Weights-00855--13624.65918.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9738.3662 - mean_absolute_error: 9738.3662 - val_loss: 13624.6592 - val_mean_absolute_error: 13624.6592\n",
      "Epoch 856/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10630.3574 - mean_absolute_error: 10630.3574\n",
      "Epoch 856: val_loss did not improve from 13624.65918\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9734.7861 - mean_absolute_error: 9734.7861 - val_loss: 13630.0996 - val_mean_absolute_error: 13630.0996\n",
      "Epoch 857/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9266.9297 - mean_absolute_error: 9266.9297\n",
      "Epoch 857: val_loss did not improve from 13624.65918\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9737.8584 - mean_absolute_error: 9737.8584 - val_loss: 13627.3965 - val_mean_absolute_error: 13627.3965\n",
      "Epoch 858/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13756.4512 - mean_absolute_error: 13756.4512\n",
      "Epoch 858: val_loss did not improve from 13624.65918\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9731.1230 - mean_absolute_error: 9731.1230 - val_loss: 13625.7861 - val_mean_absolute_error: 13625.7861\n",
      "Epoch 859/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7693.5898 - mean_absolute_error: 7693.5898\n",
      "Epoch 859: val_loss did not improve from 13624.65918\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9750.6729 - mean_absolute_error: 9750.6729 - val_loss: 13627.6377 - val_mean_absolute_error: 13627.6377\n",
      "Epoch 860/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7523.5151 - mean_absolute_error: 7523.5151\n",
      "Epoch 860: val_loss did not improve from 13624.65918\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9735.2598 - mean_absolute_error: 9735.2598 - val_loss: 13626.4102 - val_mean_absolute_error: 13626.4102\n",
      "Epoch 861/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9923.5762 - mean_absolute_error: 9923.5762\n",
      "Epoch 861: val_loss improved from 13624.65918 to 13624.17188, saving model to Weights-00861--13624.17188.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9732.7900 - mean_absolute_error: 9732.7900 - val_loss: 13624.1719 - val_mean_absolute_error: 13624.1719\n",
      "Epoch 862/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10139.5098 - mean_absolute_error: 10139.5098\n",
      "Epoch 862: val_loss did not improve from 13624.17188\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9749.7002 - mean_absolute_error: 9749.7002 - val_loss: 13629.3252 - val_mean_absolute_error: 13629.3252\n",
      "Epoch 863/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11371.4297 - mean_absolute_error: 11371.4297\n",
      "Epoch 863: val_loss did not improve from 13624.17188\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9745.9932 - mean_absolute_error: 9745.9932 - val_loss: 13629.0957 - val_mean_absolute_error: 13629.0957\n",
      "Epoch 864/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12123.6904 - mean_absolute_error: 12123.6904\n",
      "Epoch 864: val_loss did not improve from 13624.17188\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9730.3721 - mean_absolute_error: 9730.3721 - val_loss: 13625.8252 - val_mean_absolute_error: 13625.8252\n",
      "Epoch 865/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10288.4355 - mean_absolute_error: 10288.4355\n",
      "Epoch 865: val_loss did not improve from 13624.17188\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9745.4951 - mean_absolute_error: 9745.4951 - val_loss: 13633.6660 - val_mean_absolute_error: 13633.6660\n",
      "Epoch 866/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12062.3428 - mean_absolute_error: 12062.3428\n",
      "Epoch 866: val_loss did not improve from 13624.17188\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9743.7812 - mean_absolute_error: 9743.7812 - val_loss: 13626.0605 - val_mean_absolute_error: 13626.0605\n",
      "Epoch 867/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10632.3867 - mean_absolute_error: 10632.3867\n",
      "Epoch 867: val_loss improved from 13624.17188 to 13623.95215, saving model to Weights-00867--13623.95215.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9731.5615 - mean_absolute_error: 9731.5615 - val_loss: 13623.9521 - val_mean_absolute_error: 13623.9521\n",
      "Epoch 868/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8602.8057 - mean_absolute_error: 8602.8057\n",
      "Epoch 868: val_loss did not improve from 13623.95215\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9730.2236 - mean_absolute_error: 9730.2236 - val_loss: 13624.8750 - val_mean_absolute_error: 13624.8750\n",
      "Epoch 869/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8300.2520 - mean_absolute_error: 8300.2520\n",
      "Epoch 869: val_loss did not improve from 13623.95215\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9724.3916 - mean_absolute_error: 9724.3916 - val_loss: 13624.4658 - val_mean_absolute_error: 13624.4658\n",
      "Epoch 870/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11570.9150 - mean_absolute_error: 11570.9150\n",
      "Epoch 870: val_loss improved from 13623.95215 to 13623.93652, saving model to Weights-00870--13623.93652.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9733.3438 - mean_absolute_error: 9733.3438 - val_loss: 13623.9365 - val_mean_absolute_error: 13623.9365\n",
      "Epoch 871/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8985.6816 - mean_absolute_error: 8985.6816\n",
      "Epoch 871: val_loss did not improve from 13623.93652\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9724.6074 - mean_absolute_error: 9724.6074 - val_loss: 13624.6123 - val_mean_absolute_error: 13624.6123\n",
      "Epoch 872/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9270.8828 - mean_absolute_error: 9270.8828\n",
      "Epoch 872: val_loss did not improve from 13623.93652\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9726.3135 - mean_absolute_error: 9726.3135 - val_loss: 13625.5576 - val_mean_absolute_error: 13625.5576\n",
      "Epoch 873/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9380.3809 - mean_absolute_error: 9380.3809\n",
      "Epoch 873: val_loss did not improve from 13623.93652\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9736.4316 - mean_absolute_error: 9736.4316 - val_loss: 13625.2666 - val_mean_absolute_error: 13625.2666\n",
      "Epoch 874/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11310.8789 - mean_absolute_error: 11310.8789\n",
      "Epoch 874: val_loss improved from 13623.93652 to 13621.64941, saving model to Weights-00874--13621.64941.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9730.4961 - mean_absolute_error: 9730.4961 - val_loss: 13621.6494 - val_mean_absolute_error: 13621.6494\n",
      "Epoch 875/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12358.6387 - mean_absolute_error: 12358.6387\n",
      "Epoch 875: val_loss did not improve from 13621.64941\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9730.0850 - mean_absolute_error: 9730.0850 - val_loss: 13626.5938 - val_mean_absolute_error: 13626.5938\n",
      "Epoch 876/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10812.3037 - mean_absolute_error: 10812.3037\n",
      "Epoch 876: val_loss did not improve from 13621.64941\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9728.6406 - mean_absolute_error: 9728.6406 - val_loss: 13622.3936 - val_mean_absolute_error: 13622.3936\n",
      "Epoch 877/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7713.3247 - mean_absolute_error: 7713.3247\n",
      "Epoch 877: val_loss did not improve from 13621.64941\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9728.4912 - mean_absolute_error: 9728.4912 - val_loss: 13626.0801 - val_mean_absolute_error: 13626.0801\n",
      "Epoch 878/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10180.2539 - mean_absolute_error: 10180.2539\n",
      "Epoch 878: val_loss did not improve from 13621.64941\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9724.9590 - mean_absolute_error: 9724.9590 - val_loss: 13622.1182 - val_mean_absolute_error: 13622.1182\n",
      "Epoch 879/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7745.6304 - mean_absolute_error: 7745.6304\n",
      "Epoch 879: val_loss did not improve from 13621.64941\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9728.3662 - mean_absolute_error: 9728.3662 - val_loss: 13624.2520 - val_mean_absolute_error: 13624.2520\n",
      "Epoch 880/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10134.2822 - mean_absolute_error: 10134.2822\n",
      "Epoch 880: val_loss did not improve from 13621.64941\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9718.7754 - mean_absolute_error: 9718.7754 - val_loss: 13621.7451 - val_mean_absolute_error: 13621.7451\n",
      "Epoch 881/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9434.9658 - mean_absolute_error: 9434.9658\n",
      "Epoch 881: val_loss did not improve from 13621.64941\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9741.4102 - mean_absolute_error: 9741.4102 - val_loss: 13624.7949 - val_mean_absolute_error: 13624.7949\n",
      "Epoch 882/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10209.7422 - mean_absolute_error: 10209.7422\n",
      "Epoch 882: val_loss did not improve from 13621.64941\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9726.3594 - mean_absolute_error: 9726.3594 - val_loss: 13626.5498 - val_mean_absolute_error: 13626.5498\n",
      "Epoch 883/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11125.4990 - mean_absolute_error: 11125.4990\n",
      "Epoch 883: val_loss improved from 13621.64941 to 13621.52637, saving model to Weights-00883--13621.52637.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9727.1621 - mean_absolute_error: 9727.1621 - val_loss: 13621.5264 - val_mean_absolute_error: 13621.5264\n",
      "Epoch 884/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11439.9268 - mean_absolute_error: 11439.9268\n",
      "Epoch 884: val_loss improved from 13621.52637 to 13620.32715, saving model to Weights-00884--13620.32715.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9720.9219 - mean_absolute_error: 9720.9219 - val_loss: 13620.3271 - val_mean_absolute_error: 13620.3271\n",
      "Epoch 885/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6753.0645 - mean_absolute_error: 6753.0645\n",
      "Epoch 885: val_loss did not improve from 13620.32715\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9730.4512 - mean_absolute_error: 9730.4512 - val_loss: 13627.9258 - val_mean_absolute_error: 13627.9258\n",
      "Epoch 886/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7840.4180 - mean_absolute_error: 7840.4180\n",
      "Epoch 886: val_loss improved from 13620.32715 to 13620.28906, saving model to Weights-00886--13620.28906.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9722.3916 - mean_absolute_error: 9722.3916 - val_loss: 13620.2891 - val_mean_absolute_error: 13620.2891\n",
      "Epoch 887/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9611.1914 - mean_absolute_error: 9611.1914\n",
      "Epoch 887: val_loss did not improve from 13620.28906\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9720.8613 - mean_absolute_error: 9720.8613 - val_loss: 13622.5283 - val_mean_absolute_error: 13622.5283\n",
      "Epoch 888/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8323.2744 - mean_absolute_error: 8323.2744\n",
      "Epoch 888: val_loss improved from 13620.28906 to 13620.06738, saving model to Weights-00888--13620.06738.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9731.6367 - mean_absolute_error: 9731.6367 - val_loss: 13620.0674 - val_mean_absolute_error: 13620.0674\n",
      "Epoch 889/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10037.9297 - mean_absolute_error: 10037.9297\n",
      "Epoch 889: val_loss improved from 13620.06738 to 13619.83301, saving model to Weights-00889--13619.83301.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9721.2607 - mean_absolute_error: 9721.2607 - val_loss: 13619.8330 - val_mean_absolute_error: 13619.8330\n",
      "Epoch 890/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8732.0273 - mean_absolute_error: 8732.0273\n",
      "Epoch 890: val_loss improved from 13619.83301 to 13619.04688, saving model to Weights-00890--13619.04688.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9728.7656 - mean_absolute_error: 9728.7656 - val_loss: 13619.0469 - val_mean_absolute_error: 13619.0469\n",
      "Epoch 891/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10682.6660 - mean_absolute_error: 10682.6660\n",
      "Epoch 891: val_loss did not improve from 13619.04688\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9720.4150 - mean_absolute_error: 9720.4150 - val_loss: 13622.7959 - val_mean_absolute_error: 13622.7959\n",
      "Epoch 892/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10206.9082 - mean_absolute_error: 10206.9082\n",
      "Epoch 892: val_loss did not improve from 13619.04688\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9717.2803 - mean_absolute_error: 9717.2803 - val_loss: 13619.0752 - val_mean_absolute_error: 13619.0752\n",
      "Epoch 893/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8297.5342 - mean_absolute_error: 8297.5342\n",
      "Epoch 893: val_loss did not improve from 13619.04688\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9716.8125 - mean_absolute_error: 9716.8125 - val_loss: 13619.6270 - val_mean_absolute_error: 13619.6270\n",
      "Epoch 894/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7271.8105 - mean_absolute_error: 7271.8105\n",
      "Epoch 894: val_loss did not improve from 13619.04688\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9751.1055 - mean_absolute_error: 9751.1055 - val_loss: 13626.5244 - val_mean_absolute_error: 13626.5244\n",
      "Epoch 895/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9144.8584 - mean_absolute_error: 9144.8584\n",
      "Epoch 895: val_loss did not improve from 13619.04688\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9729.5938 - mean_absolute_error: 9729.5938 - val_loss: 13620.0469 - val_mean_absolute_error: 13620.0469\n",
      "Epoch 896/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9481.9277 - mean_absolute_error: 9481.9277\n",
      "Epoch 896: val_loss improved from 13619.04688 to 13618.96680, saving model to Weights-00896--13618.96680.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9722.4502 - mean_absolute_error: 9722.4502 - val_loss: 13618.9668 - val_mean_absolute_error: 13618.9668\n",
      "Epoch 897/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7405.5625 - mean_absolute_error: 7405.5625\n",
      "Epoch 897: val_loss improved from 13618.96680 to 13618.36523, saving model to Weights-00897--13618.36523.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9716.3604 - mean_absolute_error: 9716.3604 - val_loss: 13618.3652 - val_mean_absolute_error: 13618.3652\n",
      "Epoch 898/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9695.3867 - mean_absolute_error: 9695.3867\n",
      "Epoch 898: val_loss did not improve from 13618.36523\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9722.7578 - mean_absolute_error: 9722.7578 - val_loss: 13622.1123 - val_mean_absolute_error: 13622.1123\n",
      "Epoch 899/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7989.1475 - mean_absolute_error: 7989.1475\n",
      "Epoch 899: val_loss did not improve from 13618.36523\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9715.0654 - mean_absolute_error: 9715.0654 - val_loss: 13618.6455 - val_mean_absolute_error: 13618.6455\n",
      "Epoch 900/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9221.3340 - mean_absolute_error: 9221.3340\n",
      "Epoch 900: val_loss did not improve from 13618.36523\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9715.6074 - mean_absolute_error: 9715.6074 - val_loss: 13623.9912 - val_mean_absolute_error: 13623.9912\n",
      "Epoch 901/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8588.2305 - mean_absolute_error: 8588.2305\n",
      "Epoch 901: val_loss improved from 13618.36523 to 13617.83398, saving model to Weights-00901--13617.83398.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9718.3486 - mean_absolute_error: 9718.3486 - val_loss: 13617.8340 - val_mean_absolute_error: 13617.8340\n",
      "Epoch 902/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8731.9375 - mean_absolute_error: 8731.9375\n",
      "Epoch 902: val_loss did not improve from 13617.83398\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9717.4199 - mean_absolute_error: 9717.4199 - val_loss: 13617.9111 - val_mean_absolute_error: 13617.9111\n",
      "Epoch 903/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9486.6416 - mean_absolute_error: 9486.6416\n",
      "Epoch 903: val_loss did not improve from 13617.83398\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9740.7783 - mean_absolute_error: 9740.7783 - val_loss: 13629.7373 - val_mean_absolute_error: 13629.7373\n",
      "Epoch 904/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10163.5586 - mean_absolute_error: 10163.5586\n",
      "Epoch 904: val_loss did not improve from 13617.83398\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9743.1602 - mean_absolute_error: 9743.1602 - val_loss: 13621.2646 - val_mean_absolute_error: 13621.2646\n",
      "Epoch 905/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8206.9473 - mean_absolute_error: 8206.9473\n",
      "Epoch 905: val_loss did not improve from 13617.83398\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9728.8379 - mean_absolute_error: 9728.8379 - val_loss: 13626.8828 - val_mean_absolute_error: 13626.8828\n",
      "Epoch 906/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10113.7607 - mean_absolute_error: 10113.7607\n",
      "Epoch 906: val_loss improved from 13617.83398 to 13616.73828, saving model to Weights-00906--13616.73828.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9719.0381 - mean_absolute_error: 9719.0381 - val_loss: 13616.7383 - val_mean_absolute_error: 13616.7383\n",
      "Epoch 907/3000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9812.3232 - mean_absolute_error: 9812.3232\n",
      "Epoch 907: val_loss did not improve from 13616.73828\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9713.9531 - mean_absolute_error: 9713.9531 - val_loss: 13618.3213 - val_mean_absolute_error: 13618.3213\n",
      "Epoch 908/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8991.7305 - mean_absolute_error: 8991.7305\n",
      "Epoch 908: val_loss did not improve from 13616.73828\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9710.8984 - mean_absolute_error: 9710.8984 - val_loss: 13617.1152 - val_mean_absolute_error: 13617.1152\n",
      "Epoch 909/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8954.0391 - mean_absolute_error: 8954.0391\n",
      "Epoch 909: val_loss did not improve from 13616.73828\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9714.7031 - mean_absolute_error: 9714.7031 - val_loss: 13616.9639 - val_mean_absolute_error: 13616.9639\n",
      "Epoch 910/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9572.5859 - mean_absolute_error: 9572.5859\n",
      "Epoch 910: val_loss did not improve from 13616.73828\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9726.0449 - mean_absolute_error: 9726.0449 - val_loss: 13626.6221 - val_mean_absolute_error: 13626.6221\n",
      "Epoch 911/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10012.5781 - mean_absolute_error: 10012.5781\n",
      "Epoch 911: val_loss improved from 13616.73828 to 13616.24414, saving model to Weights-00911--13616.24414.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9718.3721 - mean_absolute_error: 9718.3721 - val_loss: 13616.2441 - val_mean_absolute_error: 13616.2441\n",
      "Epoch 912/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8856.1094 - mean_absolute_error: 8856.1094\n",
      "Epoch 912: val_loss improved from 13616.24414 to 13615.97852, saving model to Weights-00912--13615.97852.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9719.2969 - mean_absolute_error: 9719.2969 - val_loss: 13615.9785 - val_mean_absolute_error: 13615.9785\n",
      "Epoch 913/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12018.0059 - mean_absolute_error: 12018.0059\n",
      "Epoch 913: val_loss did not improve from 13615.97852\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9708.8506 - mean_absolute_error: 9708.8506 - val_loss: 13616.5361 - val_mean_absolute_error: 13616.5361\n",
      "Epoch 914/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8593.1162 - mean_absolute_error: 8593.1162\n",
      "Epoch 914: val_loss did not improve from 13615.97852\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9714.1514 - mean_absolute_error: 9714.1514 - val_loss: 13616.1973 - val_mean_absolute_error: 13616.1973\n",
      "Epoch 915/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12952.9629 - mean_absolute_error: 12952.9629\n",
      "Epoch 915: val_loss did not improve from 13615.97852\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9706.4619 - mean_absolute_error: 9706.4619 - val_loss: 13617.9346 - val_mean_absolute_error: 13617.9346\n",
      "Epoch 916/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7028.6035 - mean_absolute_error: 7028.6035\n",
      "Epoch 916: val_loss improved from 13615.97852 to 13615.22656, saving model to Weights-00916--13615.22656.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9705.4385 - mean_absolute_error: 9705.4385 - val_loss: 13615.2266 - val_mean_absolute_error: 13615.2266\n",
      "Epoch 917/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9404.2988 - mean_absolute_error: 9404.2988\n",
      "Epoch 917: val_loss did not improve from 13615.22656\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9716.4551 - mean_absolute_error: 9716.4551 - val_loss: 13616.4932 - val_mean_absolute_error: 13616.4932\n",
      "Epoch 918/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8016.6768 - mean_absolute_error: 8016.6768\n",
      "Epoch 918: val_loss did not improve from 13615.22656\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9714.0049 - mean_absolute_error: 9714.0049 - val_loss: 13618.6670 - val_mean_absolute_error: 13618.6670\n",
      "Epoch 919/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11652.7275 - mean_absolute_error: 11652.7275\n",
      "Epoch 919: val_loss did not improve from 13615.22656\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9705.8506 - mean_absolute_error: 9705.8506 - val_loss: 13616.6885 - val_mean_absolute_error: 13616.6885\n",
      "Epoch 920/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9241.9297 - mean_absolute_error: 9241.9297\n",
      "Epoch 920: val_loss did not improve from 13615.22656\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9710.2344 - mean_absolute_error: 9710.2344 - val_loss: 13615.8320 - val_mean_absolute_error: 13615.8320\n",
      "Epoch 921/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7726.2256 - mean_absolute_error: 7726.2256\n",
      "Epoch 921: val_loss did not improve from 13615.22656\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9707.1621 - mean_absolute_error: 9707.1621 - val_loss: 13617.0723 - val_mean_absolute_error: 13617.0723\n",
      "Epoch 922/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9551.1943 - mean_absolute_error: 9551.1943\n",
      "Epoch 922: val_loss improved from 13615.22656 to 13614.16699, saving model to Weights-00922--13614.16699.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9702.9834 - mean_absolute_error: 9702.9834 - val_loss: 13614.1670 - val_mean_absolute_error: 13614.1670\n",
      "Epoch 923/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10792.9902 - mean_absolute_error: 10792.9902\n",
      "Epoch 923: val_loss did not improve from 13614.16699\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9707.6094 - mean_absolute_error: 9707.6094 - val_loss: 13614.6553 - val_mean_absolute_error: 13614.6553\n",
      "Epoch 924/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7650.0205 - mean_absolute_error: 7650.0205\n",
      "Epoch 924: val_loss did not improve from 13614.16699\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9704.6387 - mean_absolute_error: 9704.6387 - val_loss: 13617.5352 - val_mean_absolute_error: 13617.5352\n",
      "Epoch 925/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11302.3691 - mean_absolute_error: 11302.3691\n",
      "Epoch 925: val_loss improved from 13614.16699 to 13613.79785, saving model to Weights-00925--13613.79785.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9701.9678 - mean_absolute_error: 9701.9678 - val_loss: 13613.7979 - val_mean_absolute_error: 13613.7979\n",
      "Epoch 926/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11571.0566 - mean_absolute_error: 11571.0566\n",
      "Epoch 926: val_loss did not improve from 13613.79785\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9722.2861 - mean_absolute_error: 9722.2861 - val_loss: 13619.2607 - val_mean_absolute_error: 13619.2607\n",
      "Epoch 927/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7597.5229 - mean_absolute_error: 7597.5229\n",
      "Epoch 927: val_loss did not improve from 13613.79785\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9696.7402 - mean_absolute_error: 9696.7402 - val_loss: 13618.9844 - val_mean_absolute_error: 13618.9844\n",
      "Epoch 928/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9675.5449 - mean_absolute_error: 9675.5449\n",
      "Epoch 928: val_loss did not improve from 13613.79785\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9713.6387 - mean_absolute_error: 9713.6387 - val_loss: 13618.2305 - val_mean_absolute_error: 13618.2305\n",
      "Epoch 929/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7234.3066 - mean_absolute_error: 7234.3066\n",
      "Epoch 929: val_loss did not improve from 13613.79785\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9708.2051 - mean_absolute_error: 9708.2051 - val_loss: 13616.3711 - val_mean_absolute_error: 13616.3711\n",
      "Epoch 930/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10167.6543 - mean_absolute_error: 10167.6543\n",
      "Epoch 930: val_loss improved from 13613.79785 to 13612.95898, saving model to Weights-00930--13612.95898.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9702.6826 - mean_absolute_error: 9702.6826 - val_loss: 13612.9590 - val_mean_absolute_error: 13612.9590\n",
      "Epoch 931/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8085.7046 - mean_absolute_error: 8085.7046\n",
      "Epoch 931: val_loss did not improve from 13612.95898\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9711.5400 - mean_absolute_error: 9711.5400 - val_loss: 13615.3232 - val_mean_absolute_error: 13615.3232\n",
      "Epoch 932/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12774.0713 - mean_absolute_error: 12774.0713\n",
      "Epoch 932: val_loss improved from 13612.95898 to 13612.50000, saving model to Weights-00932--13612.50000.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9698.1475 - mean_absolute_error: 9698.1475 - val_loss: 13612.5000 - val_mean_absolute_error: 13612.5000\n",
      "Epoch 933/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9899.0508 - mean_absolute_error: 9899.0508\n",
      "Epoch 933: val_loss did not improve from 13612.50000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9702.0645 - mean_absolute_error: 9702.0645 - val_loss: 13616.2422 - val_mean_absolute_error: 13616.2422\n",
      "Epoch 934/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11076.5996 - mean_absolute_error: 11076.5996\n",
      "Epoch 934: val_loss did not improve from 13612.50000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9703.3994 - mean_absolute_error: 9703.3994 - val_loss: 13613.3906 - val_mean_absolute_error: 13613.3906\n",
      "Epoch 935/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8079.0547 - mean_absolute_error: 8079.0547\n",
      "Epoch 935: val_loss did not improve from 13612.50000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9706.5176 - mean_absolute_error: 9706.5176 - val_loss: 13615.5186 - val_mean_absolute_error: 13615.5186\n",
      "Epoch 936/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9172.7725 - mean_absolute_error: 9172.7725\n",
      "Epoch 936: val_loss did not improve from 13612.50000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9719.2705 - mean_absolute_error: 9719.2705 - val_loss: 13617.3770 - val_mean_absolute_error: 13617.3770\n",
      "Epoch 937/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9701.0752 - mean_absolute_error: 9701.0752\n",
      "Epoch 937: val_loss did not improve from 13612.50000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9706.3262 - mean_absolute_error: 9706.3262 - val_loss: 13613.3594 - val_mean_absolute_error: 13613.3594\n",
      "Epoch 938/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9362.2939 - mean_absolute_error: 9362.2939\n",
      "Epoch 938: val_loss improved from 13612.50000 to 13611.60938, saving model to Weights-00938--13611.60938.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9697.8496 - mean_absolute_error: 9697.8496 - val_loss: 13611.6094 - val_mean_absolute_error: 13611.6094\n",
      "Epoch 939/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8719.9941 - mean_absolute_error: 8719.9941\n",
      "Epoch 939: val_loss did not improve from 13611.60938\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9702.2656 - mean_absolute_error: 9702.2656 - val_loss: 13613.2021 - val_mean_absolute_error: 13613.2021\n",
      "Epoch 940/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6910.8154 - mean_absolute_error: 6910.8154\n",
      "Epoch 940: val_loss did not improve from 13611.60938\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9700.9033 - mean_absolute_error: 9700.9033 - val_loss: 13612.5039 - val_mean_absolute_error: 13612.5039\n",
      "Epoch 941/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12577.5830 - mean_absolute_error: 12577.5830\n",
      "Epoch 941: val_loss did not improve from 13611.60938\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9721.5195 - mean_absolute_error: 9721.5195 - val_loss: 13615.8135 - val_mean_absolute_error: 13615.8135\n",
      "Epoch 942/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8805.2734 - mean_absolute_error: 8805.2734\n",
      "Epoch 942: val_loss did not improve from 13611.60938\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9710.9873 - mean_absolute_error: 9710.9873 - val_loss: 13616.4600 - val_mean_absolute_error: 13616.4600\n",
      "Epoch 943/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8232.3857 - mean_absolute_error: 8232.3857\n",
      "Epoch 943: val_loss did not improve from 13611.60938\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9700.4551 - mean_absolute_error: 9700.4551 - val_loss: 13612.2354 - val_mean_absolute_error: 13612.2354\n",
      "Epoch 944/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7671.1274 - mean_absolute_error: 7671.1274\n",
      "Epoch 944: val_loss improved from 13611.60938 to 13610.57031, saving model to Weights-00944--13610.57031.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9699.9854 - mean_absolute_error: 9699.9854 - val_loss: 13610.5703 - val_mean_absolute_error: 13610.5703\n",
      "Epoch 945/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8416.8115 - mean_absolute_error: 8416.8115\n",
      "Epoch 945: val_loss did not improve from 13610.57031\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9693.3594 - mean_absolute_error: 9693.3594 - val_loss: 13614.6260 - val_mean_absolute_error: 13614.6260\n",
      "Epoch 946/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7876.1562 - mean_absolute_error: 7876.1562\n",
      "Epoch 946: val_loss did not improve from 13610.57031\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9702.9922 - mean_absolute_error: 9702.9922 - val_loss: 13611.4141 - val_mean_absolute_error: 13611.4141\n",
      "Epoch 947/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12745.8105 - mean_absolute_error: 12745.8105\n",
      "Epoch 947: val_loss did not improve from 13610.57031\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9703.3232 - mean_absolute_error: 9703.3232 - val_loss: 13612.8428 - val_mean_absolute_error: 13612.8428\n",
      "Epoch 948/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6906.4199 - mean_absolute_error: 6906.4199\n",
      "Epoch 948: val_loss did not improve from 13610.57031\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9701.7227 - mean_absolute_error: 9701.7227 - val_loss: 13612.9375 - val_mean_absolute_error: 13612.9375\n",
      "Epoch 949/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13425.5488 - mean_absolute_error: 13425.5488\n",
      "Epoch 949: val_loss improved from 13610.57031 to 13610.40625, saving model to Weights-00949--13610.40625.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9702.8281 - mean_absolute_error: 9702.8281 - val_loss: 13610.4062 - val_mean_absolute_error: 13610.4062\n",
      "Epoch 950/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12365.7012 - mean_absolute_error: 12365.7012\n",
      "Epoch 950: val_loss did not improve from 13610.40625\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9698.7305 - mean_absolute_error: 9698.7305 - val_loss: 13610.5410 - val_mean_absolute_error: 13610.5410\n",
      "Epoch 951/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6771.4639 - mean_absolute_error: 6771.4639\n",
      "Epoch 951: val_loss did not improve from 13610.40625\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9693.6484 - mean_absolute_error: 9693.6484 - val_loss: 13612.8594 - val_mean_absolute_error: 13612.8594\n",
      "Epoch 952/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8310.9648 - mean_absolute_error: 8310.9648\n",
      "Epoch 952: val_loss improved from 13610.40625 to 13609.34961, saving model to Weights-00952--13609.34961.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9709.5479 - mean_absolute_error: 9709.5479 - val_loss: 13609.3496 - val_mean_absolute_error: 13609.3496\n",
      "Epoch 953/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7835.2207 - mean_absolute_error: 7835.2207\n",
      "Epoch 953: val_loss did not improve from 13609.34961\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9697.7227 - mean_absolute_error: 9697.7227 - val_loss: 13609.7207 - val_mean_absolute_error: 13609.7207\n",
      "Epoch 954/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10142.9990 - mean_absolute_error: 10142.9990\n",
      "Epoch 954: val_loss did not improve from 13609.34961\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9692.5771 - mean_absolute_error: 9692.5771 - val_loss: 13611.2500 - val_mean_absolute_error: 13611.2500\n",
      "Epoch 955/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7833.1533 - mean_absolute_error: 7833.1533\n",
      "Epoch 955: val_loss did not improve from 13609.34961\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9695.8428 - mean_absolute_error: 9695.8428 - val_loss: 13610.5156 - val_mean_absolute_error: 13610.5156\n",
      "Epoch 956/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8493.7383 - mean_absolute_error: 8493.7383\n",
      "Epoch 956: val_loss did not improve from 13609.34961\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9687.6650 - mean_absolute_error: 9687.6650 - val_loss: 13610.8652 - val_mean_absolute_error: 13610.8652\n",
      "Epoch 957/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8842.5967 - mean_absolute_error: 8842.5967\n",
      "Epoch 957: val_loss did not improve from 13609.34961\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9692.1191 - mean_absolute_error: 9692.1191 - val_loss: 13611.1533 - val_mean_absolute_error: 13611.1533\n",
      "Epoch 958/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9949.4854 - mean_absolute_error: 9949.4854\n",
      "Epoch 958: val_loss improved from 13609.34961 to 13608.71973, saving model to Weights-00958--13608.71973.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9691.2100 - mean_absolute_error: 9691.2100 - val_loss: 13608.7197 - val_mean_absolute_error: 13608.7197\n",
      "Epoch 959/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8619.6582 - mean_absolute_error: 8619.6582\n",
      "Epoch 959: val_loss did not improve from 13608.71973\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9696.9268 - mean_absolute_error: 9696.9268 - val_loss: 13608.7822 - val_mean_absolute_error: 13608.7822\n",
      "Epoch 960/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7516.6133 - mean_absolute_error: 7516.6133\n",
      "Epoch 960: val_loss did not improve from 13608.71973\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9702.9424 - mean_absolute_error: 9702.9424 - val_loss: 13609.8301 - val_mean_absolute_error: 13609.8301\n",
      "Epoch 961/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9843.0420 - mean_absolute_error: 9843.0420\n",
      "Epoch 961: val_loss did not improve from 13608.71973\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9695.0371 - mean_absolute_error: 9695.0371 - val_loss: 13610.1807 - val_mean_absolute_error: 13610.1807\n",
      "Epoch 962/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11235.7656 - mean_absolute_error: 11235.7656\n",
      "Epoch 962: val_loss did not improve from 13608.71973\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9687.5059 - mean_absolute_error: 9687.5059 - val_loss: 13610.9600 - val_mean_absolute_error: 13610.9600\n",
      "Epoch 963/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10048.0869 - mean_absolute_error: 10048.0869\n",
      "Epoch 963: val_loss did not improve from 13608.71973\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9694.8223 - mean_absolute_error: 9694.8223 - val_loss: 13608.9883 - val_mean_absolute_error: 13608.9883\n",
      "Epoch 964/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7945.0625 - mean_absolute_error: 7945.0625\n",
      "Epoch 964: val_loss improved from 13608.71973 to 13607.48145, saving model to Weights-00964--13607.48145.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9691.0830 - mean_absolute_error: 9691.0830 - val_loss: 13607.4814 - val_mean_absolute_error: 13607.4814\n",
      "Epoch 965/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13036.3145 - mean_absolute_error: 13036.3145\n",
      "Epoch 965: val_loss did not improve from 13607.48145\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9690.5791 - mean_absolute_error: 9690.5791 - val_loss: 13607.6377 - val_mean_absolute_error: 13607.6377\n",
      "Epoch 966/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11206.6914 - mean_absolute_error: 11206.6914\n",
      "Epoch 966: val_loss did not improve from 13607.48145\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9697.6914 - mean_absolute_error: 9697.6914 - val_loss: 13610.1270 - val_mean_absolute_error: 13610.1270\n",
      "Epoch 967/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9736.5898 - mean_absolute_error: 9736.5898\n",
      "Epoch 967: val_loss did not improve from 13607.48145\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9693.3516 - mean_absolute_error: 9693.3516 - val_loss: 13607.8799 - val_mean_absolute_error: 13607.8799\n",
      "Epoch 968/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9493.0029 - mean_absolute_error: 9493.0029\n",
      "Epoch 968: val_loss did not improve from 13607.48145\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9688.2012 - mean_absolute_error: 9688.2012 - val_loss: 13608.1299 - val_mean_absolute_error: 13608.1299\n",
      "Epoch 969/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11951.5723 - mean_absolute_error: 11951.5723\n",
      "Epoch 969: val_loss improved from 13607.48145 to 13606.96289, saving model to Weights-00969--13606.96289.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9686.0615 - mean_absolute_error: 9686.0615 - val_loss: 13606.9629 - val_mean_absolute_error: 13606.9629\n",
      "Epoch 970/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11809.3652 - mean_absolute_error: 11809.3652\n",
      "Epoch 970: val_loss did not improve from 13606.96289\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9687.0908 - mean_absolute_error: 9687.0908 - val_loss: 13609.8066 - val_mean_absolute_error: 13609.8066\n",
      "Epoch 971/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10144.7812 - mean_absolute_error: 10144.7812\n",
      "Epoch 971: val_loss did not improve from 13606.96289\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9690.4785 - mean_absolute_error: 9690.4785 - val_loss: 13607.7188 - val_mean_absolute_error: 13607.7188\n",
      "Epoch 972/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8232.2520 - mean_absolute_error: 8232.2520\n",
      "Epoch 972: val_loss did not improve from 13606.96289\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9703.1387 - mean_absolute_error: 9703.1387 - val_loss: 13608.6250 - val_mean_absolute_error: 13608.6250\n",
      "Epoch 973/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8649.9785 - mean_absolute_error: 8649.9785\n",
      "Epoch 973: val_loss improved from 13606.96289 to 13606.14062, saving model to Weights-00973--13606.14062.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9688.4141 - mean_absolute_error: 9688.4141 - val_loss: 13606.1406 - val_mean_absolute_error: 13606.1406\n",
      "Epoch 974/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5799.1777 - mean_absolute_error: 5799.1777\n",
      "Epoch 974: val_loss did not improve from 13606.14062\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9689.1514 - mean_absolute_error: 9689.1514 - val_loss: 13609.4941 - val_mean_absolute_error: 13609.4941\n",
      "Epoch 975/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 15566.4453 - mean_absolute_error: 15566.4453\n",
      "Epoch 975: val_loss did not improve from 13606.14062\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9684.0293 - mean_absolute_error: 9684.0293 - val_loss: 13606.5000 - val_mean_absolute_error: 13606.5000\n",
      "Epoch 976/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 15032.9043 - mean_absolute_error: 15032.9043\n",
      "Epoch 976: val_loss did not improve from 13606.14062\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9694.2422 - mean_absolute_error: 9694.2422 - val_loss: 13606.5068 - val_mean_absolute_error: 13606.5068\n",
      "Epoch 977/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9655.6436 - mean_absolute_error: 9655.6436\n",
      "Epoch 977: val_loss did not improve from 13606.14062\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9685.8135 - mean_absolute_error: 9685.8135 - val_loss: 13609.7402 - val_mean_absolute_error: 13609.7402\n",
      "Epoch 978/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13369.6406 - mean_absolute_error: 13369.6406\n",
      "Epoch 978: val_loss improved from 13606.14062 to 13605.10156, saving model to Weights-00978--13605.10156.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9682.8838 - mean_absolute_error: 9682.8838 - val_loss: 13605.1016 - val_mean_absolute_error: 13605.1016\n",
      "Epoch 979/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11529.6816 - mean_absolute_error: 11529.6816\n",
      "Epoch 979: val_loss did not improve from 13605.10156\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9694.8535 - mean_absolute_error: 9694.8535 - val_loss: 13606.0674 - val_mean_absolute_error: 13606.0674\n",
      "Epoch 980/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8982.2158 - mean_absolute_error: 8982.2158\n",
      "Epoch 980: val_loss did not improve from 13605.10156\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9683.9756 - mean_absolute_error: 9683.9756 - val_loss: 13605.8496 - val_mean_absolute_error: 13605.8496\n",
      "Epoch 981/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9959.1123 - mean_absolute_error: 9959.1123\n",
      "Epoch 981: val_loss did not improve from 13605.10156\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9683.3574 - mean_absolute_error: 9683.3574 - val_loss: 13605.4658 - val_mean_absolute_error: 13605.4658\n",
      "Epoch 982/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7724.3418 - mean_absolute_error: 7724.3418\n",
      "Epoch 982: val_loss did not improve from 13605.10156\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9701.9053 - mean_absolute_error: 9701.9053 - val_loss: 13606.0820 - val_mean_absolute_error: 13606.0820\n",
      "Epoch 983/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7920.5239 - mean_absolute_error: 7920.5239\n",
      "Epoch 983: val_loss improved from 13605.10156 to 13604.91602, saving model to Weights-00983--13604.91602.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9683.4219 - mean_absolute_error: 9683.4219 - val_loss: 13604.9160 - val_mean_absolute_error: 13604.9160\n",
      "Epoch 984/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7087.7651 - mean_absolute_error: 7087.7651\n",
      "Epoch 984: val_loss did not improve from 13604.91602\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9689.9619 - mean_absolute_error: 9689.9619 - val_loss: 13605.6533 - val_mean_absolute_error: 13605.6533\n",
      "Epoch 985/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10096.1934 - mean_absolute_error: 10096.1934\n",
      "Epoch 985: val_loss improved from 13604.91602 to 13604.25879, saving model to Weights-00985--13604.25879.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9685.5889 - mean_absolute_error: 9685.5889 - val_loss: 13604.2588 - val_mean_absolute_error: 13604.2588\n",
      "Epoch 986/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5709.7329 - mean_absolute_error: 5709.7329\n",
      "Epoch 986: val_loss did not improve from 13604.25879\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9678.9238 - mean_absolute_error: 9678.9238 - val_loss: 13604.3525 - val_mean_absolute_error: 13604.3525\n",
      "Epoch 987/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5674.5391 - mean_absolute_error: 5674.5391\n",
      "Epoch 987: val_loss did not improve from 13604.25879\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9689.3311 - mean_absolute_error: 9689.3311 - val_loss: 13605.3623 - val_mean_absolute_error: 13605.3623\n",
      "Epoch 988/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8753.8867 - mean_absolute_error: 8753.8867\n",
      "Epoch 988: val_loss did not improve from 13604.25879\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9680.5664 - mean_absolute_error: 9680.5664 - val_loss: 13604.4580 - val_mean_absolute_error: 13604.4580\n",
      "Epoch 989/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11626.0996 - mean_absolute_error: 11626.0996\n",
      "Epoch 989: val_loss improved from 13604.25879 to 13603.28516, saving model to Weights-00989--13603.28516.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9679.6387 - mean_absolute_error: 9679.6387 - val_loss: 13603.2852 - val_mean_absolute_error: 13603.2852\n",
      "Epoch 990/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12849.9775 - mean_absolute_error: 12849.9775\n",
      "Epoch 990: val_loss did not improve from 13603.28516\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9683.0303 - mean_absolute_error: 9683.0303 - val_loss: 13603.6084 - val_mean_absolute_error: 13603.6084\n",
      "Epoch 991/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6841.7837 - mean_absolute_error: 6841.7837\n",
      "Epoch 991: val_loss did not improve from 13603.28516\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9681.0449 - mean_absolute_error: 9681.0449 - val_loss: 13603.9014 - val_mean_absolute_error: 13603.9014\n",
      "Epoch 992/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9777.9922 - mean_absolute_error: 9777.9922\n",
      "Epoch 992: val_loss did not improve from 13603.28516\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9679.6846 - mean_absolute_error: 9679.6846 - val_loss: 13604.7520 - val_mean_absolute_error: 13604.7520\n",
      "Epoch 993/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9600.0146 - mean_absolute_error: 9600.0146\n",
      "Epoch 993: val_loss did not improve from 13603.28516\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9677.5781 - mean_absolute_error: 9677.5781 - val_loss: 13604.9756 - val_mean_absolute_error: 13604.9756\n",
      "Epoch 994/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9555.2637 - mean_absolute_error: 9555.2637\n",
      "Epoch 994: val_loss did not improve from 13603.28516\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9685.8779 - mean_absolute_error: 9685.8779 - val_loss: 13609.5312 - val_mean_absolute_error: 13609.5312\n",
      "Epoch 995/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10462.9082 - mean_absolute_error: 10462.9082\n",
      "Epoch 995: val_loss improved from 13603.28516 to 13602.90430, saving model to Weights-00995--13602.90430.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9677.3525 - mean_absolute_error: 9677.3525 - val_loss: 13602.9043 - val_mean_absolute_error: 13602.9043\n",
      "Epoch 996/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13516.0107 - mean_absolute_error: 13516.0107\n",
      "Epoch 996: val_loss did not improve from 13602.90430\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9676.6689 - mean_absolute_error: 9676.6689 - val_loss: 13604.7578 - val_mean_absolute_error: 13604.7578\n",
      "Epoch 997/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11587.7998 - mean_absolute_error: 11587.7998\n",
      "Epoch 997: val_loss improved from 13602.90430 to 13601.98340, saving model to Weights-00997--13601.98340.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9676.8408 - mean_absolute_error: 9676.8408 - val_loss: 13601.9834 - val_mean_absolute_error: 13601.9834\n",
      "Epoch 998/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8413.0146 - mean_absolute_error: 8413.0146\n",
      "Epoch 998: val_loss improved from 13601.98340 to 13601.86914, saving model to Weights-00998--13601.86914.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9675.6377 - mean_absolute_error: 9675.6377 - val_loss: 13601.8691 - val_mean_absolute_error: 13601.8691\n",
      "Epoch 999/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9758.9854 - mean_absolute_error: 9758.9854\n",
      "Epoch 999: val_loss did not improve from 13601.86914\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9678.4580 - mean_absolute_error: 9678.4580 - val_loss: 13602.4414 - val_mean_absolute_error: 13602.4414\n",
      "Epoch 1000/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9999.8369 - mean_absolute_error: 9999.8369\n",
      "Epoch 1000: val_loss improved from 13601.86914 to 13601.60938, saving model to Weights-01000--13601.60938.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9684.6055 - mean_absolute_error: 9684.6055 - val_loss: 13601.6094 - val_mean_absolute_error: 13601.6094\n",
      "Epoch 1001/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6818.4102 - mean_absolute_error: 6818.4102\n",
      "Epoch 1001: val_loss did not improve from 13601.60938\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9683.9502 - mean_absolute_error: 9683.9502 - val_loss: 13607.0732 - val_mean_absolute_error: 13607.0742\n",
      "Epoch 1002/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10399.9131 - mean_absolute_error: 10399.9131\n",
      "Epoch 1002: val_loss improved from 13601.60938 to 13601.29688, saving model to Weights-01002--13601.29688.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9677.7178 - mean_absolute_error: 9677.7178 - val_loss: 13601.2969 - val_mean_absolute_error: 13601.2969\n",
      "Epoch 1003/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5822.4351 - mean_absolute_error: 5822.4351\n",
      "Epoch 1003: val_loss did not improve from 13601.29688\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9673.7959 - mean_absolute_error: 9673.7959 - val_loss: 13602.3525 - val_mean_absolute_error: 13602.3525\n",
      "Epoch 1004/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9575.7002 - mean_absolute_error: 9575.7002\n",
      "Epoch 1004: val_loss improved from 13601.29688 to 13600.95898, saving model to Weights-01004--13600.95898.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9679.9941 - mean_absolute_error: 9679.9941 - val_loss: 13600.9590 - val_mean_absolute_error: 13600.9590\n",
      "Epoch 1005/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8347.8770 - mean_absolute_error: 8347.8770\n",
      "Epoch 1005: val_loss improved from 13600.95898 to 13600.85156, saving model to Weights-01005--13600.85156.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9676.2842 - mean_absolute_error: 9676.2842 - val_loss: 13600.8516 - val_mean_absolute_error: 13600.8516\n",
      "Epoch 1006/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7968.4355 - mean_absolute_error: 7968.4355\n",
      "Epoch 1006: val_loss did not improve from 13600.85156\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9673.5156 - mean_absolute_error: 9673.5156 - val_loss: 13603.0049 - val_mean_absolute_error: 13603.0049\n",
      "Epoch 1007/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13449.9062 - mean_absolute_error: 13449.9062\n",
      "Epoch 1007: val_loss improved from 13600.85156 to 13600.67676, saving model to Weights-01007--13600.67676.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9674.5957 - mean_absolute_error: 9674.5957 - val_loss: 13600.6768 - val_mean_absolute_error: 13600.6768\n",
      "Epoch 1008/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13207.4502 - mean_absolute_error: 13207.4502\n",
      "Epoch 1008: val_loss improved from 13600.67676 to 13600.42969, saving model to Weights-01008--13600.42969.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9673.6748 - mean_absolute_error: 9673.6748 - val_loss: 13600.4297 - val_mean_absolute_error: 13600.4297\n",
      "Epoch 1009/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9837.8398 - mean_absolute_error: 9837.8398\n",
      "Epoch 1009: val_loss did not improve from 13600.42969\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9675.7930 - mean_absolute_error: 9675.7930 - val_loss: 13600.6191 - val_mean_absolute_error: 13600.6191\n",
      "Epoch 1010/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9619.6816 - mean_absolute_error: 9619.6816\n",
      "Epoch 1010: val_loss did not improve from 13600.42969\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9681.3340 - mean_absolute_error: 9681.3340 - val_loss: 13609.1260 - val_mean_absolute_error: 13609.1260\n",
      "Epoch 1011/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8646.8711 - mean_absolute_error: 8646.8711\n",
      "Epoch 1011: val_loss improved from 13600.42969 to 13599.67188, saving model to Weights-01011--13599.67188.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9670.7764 - mean_absolute_error: 9670.7764 - val_loss: 13599.6719 - val_mean_absolute_error: 13599.6719\n",
      "Epoch 1012/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9899.9688 - mean_absolute_error: 9899.9688\n",
      "Epoch 1012: val_loss did not improve from 13599.67188\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9677.0967 - mean_absolute_error: 9677.0967 - val_loss: 13600.4297 - val_mean_absolute_error: 13600.4297\n",
      "Epoch 1013/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12542.9395 - mean_absolute_error: 12542.9395\n",
      "Epoch 1013: val_loss improved from 13599.67188 to 13599.44141, saving model to Weights-01013--13599.44141.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9670.5137 - mean_absolute_error: 9670.5137 - val_loss: 13599.4414 - val_mean_absolute_error: 13599.4414\n",
      "Epoch 1014/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13826.2559 - mean_absolute_error: 13826.2559\n",
      "Epoch 1014: val_loss did not improve from 13599.44141\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9673.8604 - mean_absolute_error: 9673.8604 - val_loss: 13603.9004 - val_mean_absolute_error: 13603.9004\n",
      "Epoch 1015/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10415.7559 - mean_absolute_error: 10415.7559\n",
      "Epoch 1015: val_loss did not improve from 13599.44141\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9676.1562 - mean_absolute_error: 9676.1562 - val_loss: 13600.8037 - val_mean_absolute_error: 13600.8037\n",
      "Epoch 1016/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9776.4961 - mean_absolute_error: 9776.4961\n",
      "Epoch 1016: val_loss improved from 13599.44141 to 13598.91113, saving model to Weights-01016--13598.91113.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9679.8916 - mean_absolute_error: 9679.8916 - val_loss: 13598.9111 - val_mean_absolute_error: 13598.9111\n",
      "Epoch 1017/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9804.4082 - mean_absolute_error: 9804.4082\n",
      "Epoch 1017: val_loss did not improve from 13598.91113\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9670.2490 - mean_absolute_error: 9670.2490 - val_loss: 13600.2490 - val_mean_absolute_error: 13600.2490\n",
      "Epoch 1018/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7691.1245 - mean_absolute_error: 7691.1245\n",
      "Epoch 1018: val_loss did not improve from 13598.91113\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9676.2549 - mean_absolute_error: 9676.2549 - val_loss: 13599.4072 - val_mean_absolute_error: 13599.4072\n",
      "Epoch 1019/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12152.3203 - mean_absolute_error: 12152.3203\n",
      "Epoch 1019: val_loss did not improve from 13598.91113\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9665.6514 - mean_absolute_error: 9665.6514 - val_loss: 13601.8359 - val_mean_absolute_error: 13601.8359\n",
      "Epoch 1020/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7581.6255 - mean_absolute_error: 7581.6255\n",
      "Epoch 1020: val_loss improved from 13598.91113 to 13598.23047, saving model to Weights-01020--13598.23047.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9669.1709 - mean_absolute_error: 9669.1709 - val_loss: 13598.2305 - val_mean_absolute_error: 13598.2305\n",
      "Epoch 1021/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8156.6777 - mean_absolute_error: 8156.6777\n",
      "Epoch 1021: val_loss did not improve from 13598.23047\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9682.3516 - mean_absolute_error: 9682.3516 - val_loss: 13601.7764 - val_mean_absolute_error: 13601.7764\n",
      "Epoch 1022/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9895.0430 - mean_absolute_error: 9895.0430\n",
      "Epoch 1022: val_loss did not improve from 13598.23047\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9664.2363 - mean_absolute_error: 9664.2363 - val_loss: 13598.7969 - val_mean_absolute_error: 13598.7969\n",
      "Epoch 1023/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9202.1094 - mean_absolute_error: 9202.1094\n",
      "Epoch 1023: val_loss did not improve from 13598.23047\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9669.3389 - mean_absolute_error: 9669.3389 - val_loss: 13599.3467 - val_mean_absolute_error: 13599.3467\n",
      "Epoch 1024/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8648.8037 - mean_absolute_error: 8648.8037\n",
      "Epoch 1024: val_loss improved from 13598.23047 to 13597.56250, saving model to Weights-01024--13597.56250.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9682.9531 - mean_absolute_error: 9682.9531 - val_loss: 13597.5625 - val_mean_absolute_error: 13597.5625\n",
      "Epoch 1025/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7188.9165 - mean_absolute_error: 7188.9165\n",
      "Epoch 1025: val_loss did not improve from 13597.56250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9667.6592 - mean_absolute_error: 9667.6592 - val_loss: 13600.1113 - val_mean_absolute_error: 13600.1113\n",
      "Epoch 1026/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9685.9561 - mean_absolute_error: 9685.9561\n",
      "Epoch 1026: val_loss did not improve from 13597.56250\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9668.2686 - mean_absolute_error: 9668.2686 - val_loss: 13599.7451 - val_mean_absolute_error: 13599.7451\n",
      "Epoch 1027/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12563.0732 - mean_absolute_error: 12563.0732\n",
      "Epoch 1027: val_loss did not improve from 13597.56250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9663.1514 - mean_absolute_error: 9663.1514 - val_loss: 13597.9736 - val_mean_absolute_error: 13597.9736\n",
      "Epoch 1028/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6379.1470 - mean_absolute_error: 6379.1470\n",
      "Epoch 1028: val_loss improved from 13597.56250 to 13597.50488, saving model to Weights-01028--13597.50488.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9673.2998 - mean_absolute_error: 9673.2998 - val_loss: 13597.5049 - val_mean_absolute_error: 13597.5049\n",
      "Epoch 1029/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7919.8730 - mean_absolute_error: 7919.8730\n",
      "Epoch 1029: val_loss did not improve from 13597.50488\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9663.1670 - mean_absolute_error: 9663.1670 - val_loss: 13598.2441 - val_mean_absolute_error: 13598.2441\n",
      "Epoch 1030/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11442.0684 - mean_absolute_error: 11442.0684\n",
      "Epoch 1030: val_loss improved from 13597.50488 to 13596.50586, saving model to Weights-01030--13596.50586.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9670.9453 - mean_absolute_error: 9670.9453 - val_loss: 13596.5059 - val_mean_absolute_error: 13596.5059\n",
      "Epoch 1031/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10496.5742 - mean_absolute_error: 10496.5742\n",
      "Epoch 1031: val_loss improved from 13596.50586 to 13596.47559, saving model to Weights-01031--13596.47559.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9664.5381 - mean_absolute_error: 9664.5381 - val_loss: 13596.4756 - val_mean_absolute_error: 13596.4756\n",
      "Epoch 1032/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10044.5723 - mean_absolute_error: 10044.5723\n",
      "Epoch 1032: val_loss did not improve from 13596.47559\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9665.4307 - mean_absolute_error: 9665.4307 - val_loss: 13596.6553 - val_mean_absolute_error: 13596.6553\n",
      "Epoch 1033/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11678.6738 - mean_absolute_error: 11678.6738\n",
      "Epoch 1033: val_loss did not improve from 13596.47559\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9664.9688 - mean_absolute_error: 9664.9688 - val_loss: 13598.4775 - val_mean_absolute_error: 13598.4775\n",
      "Epoch 1034/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8054.1084 - mean_absolute_error: 8054.1084\n",
      "Epoch 1034: val_loss improved from 13596.47559 to 13596.11328, saving model to Weights-01034--13596.11328.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9659.6074 - mean_absolute_error: 9659.6074 - val_loss: 13596.1133 - val_mean_absolute_error: 13596.1133\n",
      "Epoch 1035/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12755.7881 - mean_absolute_error: 12755.7881\n",
      "Epoch 1035: val_loss did not improve from 13596.11328\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9662.3584 - mean_absolute_error: 9662.3584 - val_loss: 13597.3271 - val_mean_absolute_error: 13597.3271\n",
      "Epoch 1036/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7060.7788 - mean_absolute_error: 7060.7788\n",
      "Epoch 1036: val_loss improved from 13596.11328 to 13595.67871, saving model to Weights-01036--13595.67871.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9661.3164 - mean_absolute_error: 9661.3164 - val_loss: 13595.6787 - val_mean_absolute_error: 13595.6787\n",
      "Epoch 1037/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8455.1396 - mean_absolute_error: 8455.1396\n",
      "Epoch 1037: val_loss did not improve from 13595.67871\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9662.0615 - mean_absolute_error: 9662.0615 - val_loss: 13596.0449 - val_mean_absolute_error: 13596.0449\n",
      "Epoch 1038/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10830.6709 - mean_absolute_error: 10830.6709\n",
      "Epoch 1038: val_loss did not improve from 13595.67871\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9673.3398 - mean_absolute_error: 9673.3398 - val_loss: 13602.6611 - val_mean_absolute_error: 13602.6611\n",
      "Epoch 1039/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 14246.5508 - mean_absolute_error: 14246.5508\n",
      "Epoch 1039: val_loss did not improve from 13595.67871\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9675.6455 - mean_absolute_error: 9675.6455 - val_loss: 13597.3145 - val_mean_absolute_error: 13597.3145\n",
      "Epoch 1040/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 14392.0039 - mean_absolute_error: 14392.0039\n",
      "Epoch 1040: val_loss did not improve from 13595.67871\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9661.3164 - mean_absolute_error: 9661.3164 - val_loss: 13596.3750 - val_mean_absolute_error: 13596.3750\n",
      "Epoch 1041/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10380.5723 - mean_absolute_error: 10380.5723\n",
      "Epoch 1041: val_loss improved from 13595.67871 to 13594.79004, saving model to Weights-01041--13594.79004.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9661.8291 - mean_absolute_error: 9661.8291 - val_loss: 13594.7900 - val_mean_absolute_error: 13594.7900\n",
      "Epoch 1042/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8871.0176 - mean_absolute_error: 8871.0176\n",
      "Epoch 1042: val_loss improved from 13594.79004 to 13594.57031, saving model to Weights-01042--13594.57031.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9658.4092 - mean_absolute_error: 9658.4092 - val_loss: 13594.5703 - val_mean_absolute_error: 13594.5703\n",
      "Epoch 1043/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11842.6309 - mean_absolute_error: 11842.6309\n",
      "Epoch 1043: val_loss did not improve from 13594.57031\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9664.3838 - mean_absolute_error: 9664.3838 - val_loss: 13598.8496 - val_mean_absolute_error: 13598.8496\n",
      "Epoch 1044/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9415.9307 - mean_absolute_error: 9415.9307\n",
      "Epoch 1044: val_loss did not improve from 13594.57031\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9660.7959 - mean_absolute_error: 9660.7959 - val_loss: 13595.2812 - val_mean_absolute_error: 13595.2812\n",
      "Epoch 1045/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12976.6523 - mean_absolute_error: 12976.6523\n",
      "Epoch 1045: val_loss did not improve from 13594.57031\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9656.9590 - mean_absolute_error: 9656.9590 - val_loss: 13594.7520 - val_mean_absolute_error: 13594.7520\n",
      "Epoch 1046/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10380.0312 - mean_absolute_error: 10380.0312\n",
      "Epoch 1046: val_loss did not improve from 13594.57031\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9658.8467 - mean_absolute_error: 9658.8467 - val_loss: 13595.3799 - val_mean_absolute_error: 13595.3799\n",
      "Epoch 1047/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11625.0693 - mean_absolute_error: 11625.0693\n",
      "Epoch 1047: val_loss improved from 13594.57031 to 13594.26855, saving model to Weights-01047--13594.26855.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9658.5869 - mean_absolute_error: 9658.5869 - val_loss: 13594.2686 - val_mean_absolute_error: 13594.2686\n",
      "Epoch 1048/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9256.2461 - mean_absolute_error: 9256.2461\n",
      "Epoch 1048: val_loss improved from 13594.26855 to 13594.01465, saving model to Weights-01048--13594.01465.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9657.9844 - mean_absolute_error: 9657.9844 - val_loss: 13594.0146 - val_mean_absolute_error: 13594.0146\n",
      "Epoch 1049/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7859.2246 - mean_absolute_error: 7859.2246\n",
      "Epoch 1049: val_loss improved from 13594.01465 to 13593.37207, saving model to Weights-01049--13593.37207.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9668.5752 - mean_absolute_error: 9668.5752 - val_loss: 13593.3721 - val_mean_absolute_error: 13593.3721\n",
      "Epoch 1050/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7406.8750 - mean_absolute_error: 7406.8750\n",
      "Epoch 1050: val_loss did not improve from 13593.37207\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9653.7822 - mean_absolute_error: 9653.7822 - val_loss: 13596.3770 - val_mean_absolute_error: 13596.3770\n",
      "Epoch 1051/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9242.0205 - mean_absolute_error: 9242.0205\n",
      "Epoch 1051: val_loss did not improve from 13593.37207\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9659.1104 - mean_absolute_error: 9659.1104 - val_loss: 13596.9785 - val_mean_absolute_error: 13596.9785\n",
      "Epoch 1052/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8312.8652 - mean_absolute_error: 8312.8652\n",
      "Epoch 1052: val_loss did not improve from 13593.37207\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9663.1182 - mean_absolute_error: 9663.1182 - val_loss: 13593.7178 - val_mean_absolute_error: 13593.7178\n",
      "Epoch 1053/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7401.1670 - mean_absolute_error: 7401.1670\n",
      "Epoch 1053: val_loss improved from 13593.37207 to 13592.92871, saving model to Weights-01053--13592.92871.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9656.1367 - mean_absolute_error: 9656.1367 - val_loss: 13592.9287 - val_mean_absolute_error: 13592.9287\n",
      "Epoch 1054/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8073.0308 - mean_absolute_error: 8073.0308\n",
      "Epoch 1054: val_loss did not improve from 13592.92871\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9654.4336 - mean_absolute_error: 9654.4336 - val_loss: 13593.6143 - val_mean_absolute_error: 13593.6143\n",
      "Epoch 1055/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9503.7236 - mean_absolute_error: 9503.7236\n",
      "Epoch 1055: val_loss improved from 13592.92871 to 13592.34863, saving model to Weights-01055--13592.34863.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9656.3760 - mean_absolute_error: 9656.3760 - val_loss: 13592.3486 - val_mean_absolute_error: 13592.3486\n",
      "Epoch 1056/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9581.1064 - mean_absolute_error: 9581.1064\n",
      "Epoch 1056: val_loss did not improve from 13592.34863\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9655.1123 - mean_absolute_error: 9655.1123 - val_loss: 13595.5127 - val_mean_absolute_error: 13595.5127\n",
      "Epoch 1057/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11699.3516 - mean_absolute_error: 11699.3516\n",
      "Epoch 1057: val_loss did not improve from 13592.34863\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9656.5166 - mean_absolute_error: 9656.5166 - val_loss: 13592.3984 - val_mean_absolute_error: 13592.3984\n",
      "Epoch 1058/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7080.1499 - mean_absolute_error: 7080.1499\n",
      "Epoch 1058: val_loss did not improve from 13592.34863\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9656.7637 - mean_absolute_error: 9656.7637 - val_loss: 13592.6514 - val_mean_absolute_error: 13592.6514\n",
      "Epoch 1059/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8433.0479 - mean_absolute_error: 8433.0479\n",
      "Epoch 1059: val_loss improved from 13592.34863 to 13592.05371, saving model to Weights-01059--13592.05371.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9656.6348 - mean_absolute_error: 9656.6348 - val_loss: 13592.0537 - val_mean_absolute_error: 13592.0537\n",
      "Epoch 1060/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8579.7188 - mean_absolute_error: 8579.7188\n",
      "Epoch 1060: val_loss improved from 13592.05371 to 13591.47461, saving model to Weights-01060--13591.47461.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9655.1162 - mean_absolute_error: 9655.1162 - val_loss: 13591.4746 - val_mean_absolute_error: 13591.4746\n",
      "Epoch 1061/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10874.3457 - mean_absolute_error: 10874.3457\n",
      "Epoch 1061: val_loss did not improve from 13591.47461\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9653.7334 - mean_absolute_error: 9653.7334 - val_loss: 13592.2275 - val_mean_absolute_error: 13592.2275\n",
      "Epoch 1062/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11274.7051 - mean_absolute_error: 11274.7051\n",
      "Epoch 1062: val_loss did not improve from 13591.47461\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9655.4102 - mean_absolute_error: 9655.4102 - val_loss: 13591.7881 - val_mean_absolute_error: 13591.7881\n",
      "Epoch 1063/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8476.7725 - mean_absolute_error: 8476.7725\n",
      "Epoch 1063: val_loss improved from 13591.47461 to 13591.03125, saving model to Weights-01063--13591.03125.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9656.8652 - mean_absolute_error: 9656.8652 - val_loss: 13591.0312 - val_mean_absolute_error: 13591.0312\n",
      "Epoch 1064/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6863.6836 - mean_absolute_error: 6863.6836\n",
      "Epoch 1064: val_loss improved from 13591.03125 to 13590.93457, saving model to Weights-01064--13590.93457.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9653.3994 - mean_absolute_error: 9653.3994 - val_loss: 13590.9346 - val_mean_absolute_error: 13590.9346\n",
      "Epoch 1065/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8442.8193 - mean_absolute_error: 8442.8193\n",
      "Epoch 1065: val_loss improved from 13590.93457 to 13590.62012, saving model to Weights-01065--13590.62012.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9653.1338 - mean_absolute_error: 9653.1338 - val_loss: 13590.6201 - val_mean_absolute_error: 13590.6191\n",
      "Epoch 1066/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9439.6143 - mean_absolute_error: 9439.6143\n",
      "Epoch 1066: val_loss improved from 13590.62012 to 13590.55957, saving model to Weights-01066--13590.55957.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9651.6172 - mean_absolute_error: 9651.6172 - val_loss: 13590.5596 - val_mean_absolute_error: 13590.5596\n",
      "Epoch 1067/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12094.6172 - mean_absolute_error: 12094.6172\n",
      "Epoch 1067: val_loss did not improve from 13590.55957\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9668.1338 - mean_absolute_error: 9668.1338 - val_loss: 13600.1318 - val_mean_absolute_error: 13600.1318\n",
      "Epoch 1068/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9279.4912 - mean_absolute_error: 9279.4912\n",
      "Epoch 1068: val_loss did not improve from 13590.55957\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9652.6387 - mean_absolute_error: 9652.6387 - val_loss: 13592.7852 - val_mean_absolute_error: 13592.7852\n",
      "Epoch 1069/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10990.8926 - mean_absolute_error: 10990.8926\n",
      "Epoch 1069: val_loss improved from 13590.55957 to 13590.25293, saving model to Weights-01069--13590.25293.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9655.0830 - mean_absolute_error: 9655.0830 - val_loss: 13590.2529 - val_mean_absolute_error: 13590.2529\n",
      "Epoch 1070/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8120.7891 - mean_absolute_error: 8120.7891\n",
      "Epoch 1070: val_loss did not improve from 13590.25293\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9665.2734 - mean_absolute_error: 9665.2734 - val_loss: 13593.6895 - val_mean_absolute_error: 13593.6895\n",
      "Epoch 1071/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8983.7871 - mean_absolute_error: 8983.7871\n",
      "Epoch 1071: val_loss did not improve from 13590.25293\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9649.9365 - mean_absolute_error: 9649.9365 - val_loss: 13591.7236 - val_mean_absolute_error: 13591.7236\n",
      "Epoch 1072/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8316.2910 - mean_absolute_error: 8316.2910\n",
      "Epoch 1072: val_loss improved from 13590.25293 to 13589.38184, saving model to Weights-01072--13589.38184.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9652.4160 - mean_absolute_error: 9652.4160 - val_loss: 13589.3818 - val_mean_absolute_error: 13589.3818\n",
      "Epoch 1073/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11220.3105 - mean_absolute_error: 11220.3105\n",
      "Epoch 1073: val_loss did not improve from 13589.38184\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9648.4502 - mean_absolute_error: 9648.4502 - val_loss: 13590.1650 - val_mean_absolute_error: 13590.1650\n",
      "Epoch 1074/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9211.1182 - mean_absolute_error: 9211.1182\n",
      "Epoch 1074: val_loss did not improve from 13589.38184\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9651.2568 - mean_absolute_error: 9651.2568 - val_loss: 13590.7676 - val_mean_absolute_error: 13590.7676\n",
      "Epoch 1075/3000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9691.3457 - mean_absolute_error: 9691.3457\n",
      "Epoch 1075: val_loss did not improve from 13589.38184\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9649.8877 - mean_absolute_error: 9649.8877 - val_loss: 13589.7432 - val_mean_absolute_error: 13589.7432\n",
      "Epoch 1076/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9013.5576 - mean_absolute_error: 9013.5576\n",
      "Epoch 1076: val_loss improved from 13589.38184 to 13588.70215, saving model to Weights-01076--13588.70215.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9647.7422 - mean_absolute_error: 9647.7422 - val_loss: 13588.7021 - val_mean_absolute_error: 13588.7021\n",
      "Epoch 1077/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13294.1924 - mean_absolute_error: 13294.1924\n",
      "Epoch 1077: val_loss improved from 13588.70215 to 13588.65234, saving model to Weights-01077--13588.65234.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9652.2412 - mean_absolute_error: 9652.2412 - val_loss: 13588.6523 - val_mean_absolute_error: 13588.6523\n",
      "Epoch 1078/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7545.4062 - mean_absolute_error: 7545.4062\n",
      "Epoch 1078: val_loss did not improve from 13588.65234\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9648.6992 - mean_absolute_error: 9648.6992 - val_loss: 13591.5713 - val_mean_absolute_error: 13591.5713\n",
      "Epoch 1079/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8420.5127 - mean_absolute_error: 8420.5127\n",
      "Epoch 1079: val_loss did not improve from 13588.65234\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9655.6592 - mean_absolute_error: 9655.6592 - val_loss: 13589.0371 - val_mean_absolute_error: 13589.0371\n",
      "Epoch 1080/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9564.7480 - mean_absolute_error: 9564.7480\n",
      "Epoch 1080: val_loss did not improve from 13588.65234\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9644.2363 - mean_absolute_error: 9644.2363 - val_loss: 13590.7373 - val_mean_absolute_error: 13590.7373\n",
      "Epoch 1081/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8619.2305 - mean_absolute_error: 8619.2305\n",
      "Epoch 1081: val_loss improved from 13588.65234 to 13588.60645, saving model to Weights-01081--13588.60645.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9648.1289 - mean_absolute_error: 9648.1289 - val_loss: 13588.6064 - val_mean_absolute_error: 13588.6064\n",
      "Epoch 1082/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7322.9297 - mean_absolute_error: 7322.9297\n",
      "Epoch 1082: val_loss did not improve from 13588.60645\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9648.0107 - mean_absolute_error: 9648.0107 - val_loss: 13590.0244 - val_mean_absolute_error: 13590.0244\n",
      "Epoch 1083/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10539.4541 - mean_absolute_error: 10539.4541\n",
      "Epoch 1083: val_loss did not improve from 13588.60645\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9656.2979 - mean_absolute_error: 9656.2979 - val_loss: 13591.7871 - val_mean_absolute_error: 13591.7871\n",
      "Epoch 1084/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12855.6660 - mean_absolute_error: 12855.6660\n",
      "Epoch 1084: val_loss did not improve from 13588.60645\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9655.5840 - mean_absolute_error: 9655.5840 - val_loss: 13589.2627 - val_mean_absolute_error: 13589.2627\n",
      "Epoch 1085/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8873.9619 - mean_absolute_error: 8873.9619\n",
      "Epoch 1085: val_loss did not improve from 13588.60645\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9651.5049 - mean_absolute_error: 9651.5049 - val_loss: 13589.3174 - val_mean_absolute_error: 13589.3174\n",
      "Epoch 1086/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 14595.5752 - mean_absolute_error: 14595.5752\n",
      "Epoch 1086: val_loss improved from 13588.60645 to 13587.09570, saving model to Weights-01086--13587.09570.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9678.0479 - mean_absolute_error: 9678.0479 - val_loss: 13587.0957 - val_mean_absolute_error: 13587.0957\n",
      "Epoch 1087/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7150.8750 - mean_absolute_error: 7150.8750\n",
      "Epoch 1087: val_loss did not improve from 13587.09570\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9647.3125 - mean_absolute_error: 9647.3125 - val_loss: 13588.1982 - val_mean_absolute_error: 13588.1982\n",
      "Epoch 1088/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10014.5059 - mean_absolute_error: 10014.5059\n",
      "Epoch 1088: val_loss did not improve from 13587.09570\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9653.8252 - mean_absolute_error: 9653.8252 - val_loss: 13588.5869 - val_mean_absolute_error: 13588.5869\n",
      "Epoch 1089/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8880.3447 - mean_absolute_error: 8880.3447\n",
      "Epoch 1089: val_loss did not improve from 13587.09570\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9655.6562 - mean_absolute_error: 9655.6562 - val_loss: 13588.7451 - val_mean_absolute_error: 13588.7451\n",
      "Epoch 1090/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8677.4365 - mean_absolute_error: 8677.4365\n",
      "Epoch 1090: val_loss improved from 13587.09570 to 13586.32227, saving model to Weights-01090--13586.32227.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9641.8311 - mean_absolute_error: 9641.8311 - val_loss: 13586.3223 - val_mean_absolute_error: 13586.3223\n",
      "Epoch 1091/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8700.4805 - mean_absolute_error: 8700.4805\n",
      "Epoch 1091: val_loss improved from 13586.32227 to 13586.25977, saving model to Weights-01091--13586.25977.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9644.3818 - mean_absolute_error: 9644.3818 - val_loss: 13586.2598 - val_mean_absolute_error: 13586.2598\n",
      "Epoch 1092/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8286.1504 - mean_absolute_error: 8286.1504\n",
      "Epoch 1092: val_loss did not improve from 13586.25977\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9656.4189 - mean_absolute_error: 9656.4189 - val_loss: 13589.6064 - val_mean_absolute_error: 13589.6064\n",
      "Epoch 1093/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11986.5879 - mean_absolute_error: 11986.5879\n",
      "Epoch 1093: val_loss did not improve from 13586.25977\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9662.2070 - mean_absolute_error: 9662.2070 - val_loss: 13593.6172 - val_mean_absolute_error: 13593.6172\n",
      "Epoch 1094/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5890.7231 - mean_absolute_error: 5890.7231\n",
      "Epoch 1094: val_loss improved from 13586.25977 to 13585.85352, saving model to Weights-01094--13585.85352.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9639.8828 - mean_absolute_error: 9639.8828 - val_loss: 13585.8535 - val_mean_absolute_error: 13585.8535\n",
      "Epoch 1095/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10438.2891 - mean_absolute_error: 10438.2891\n",
      "Epoch 1095: val_loss did not improve from 13585.85352\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9661.4658 - mean_absolute_error: 9661.4658 - val_loss: 13591.2686 - val_mean_absolute_error: 13591.2686\n",
      "Epoch 1096/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9236.6689 - mean_absolute_error: 9236.6689\n",
      "Epoch 1096: val_loss did not improve from 13585.85352\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9660.4131 - mean_absolute_error: 9660.4131 - val_loss: 13594.0039 - val_mean_absolute_error: 13594.0039\n",
      "Epoch 1097/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10338.7451 - mean_absolute_error: 10338.7451\n",
      "Epoch 1097: val_loss did not improve from 13585.85352\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9647.3535 - mean_absolute_error: 9647.3535 - val_loss: 13587.4785 - val_mean_absolute_error: 13587.4785\n",
      "Epoch 1098/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 14190.3574 - mean_absolute_error: 14190.3574\n",
      "Epoch 1098: val_loss improved from 13585.85352 to 13585.04004, saving model to Weights-01098--13585.04004.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9638.7314 - mean_absolute_error: 9638.7314 - val_loss: 13585.0400 - val_mean_absolute_error: 13585.0400\n",
      "Epoch 1099/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12410.9590 - mean_absolute_error: 12410.9590\n",
      "Epoch 1099: val_loss did not improve from 13585.04004\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9638.8838 - mean_absolute_error: 9638.8838 - val_loss: 13586.3965 - val_mean_absolute_error: 13586.3965\n",
      "Epoch 1100/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10022.1875 - mean_absolute_error: 10022.1875\n",
      "Epoch 1100: val_loss improved from 13585.04004 to 13584.73730, saving model to Weights-01100--13584.73730.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9646.9424 - mean_absolute_error: 9646.9424 - val_loss: 13584.7373 - val_mean_absolute_error: 13584.7373\n",
      "Epoch 1101/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9393.5146 - mean_absolute_error: 9393.5146\n",
      "Epoch 1101: val_loss improved from 13584.73730 to 13584.58691, saving model to Weights-01101--13584.58691.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9641.4150 - mean_absolute_error: 9641.4150 - val_loss: 13584.5869 - val_mean_absolute_error: 13584.5869\n",
      "Epoch 1102/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7457.6426 - mean_absolute_error: 7457.6426\n",
      "Epoch 1102: val_loss did not improve from 13584.58691\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9637.6240 - mean_absolute_error: 9637.6240 - val_loss: 13585.0049 - val_mean_absolute_error: 13585.0049\n",
      "Epoch 1103/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6515.9531 - mean_absolute_error: 6515.9531\n",
      "Epoch 1103: val_loss did not improve from 13584.58691\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9644.2578 - mean_absolute_error: 9644.2578 - val_loss: 13587.7480 - val_mean_absolute_error: 13587.7480\n",
      "Epoch 1104/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8945.7363 - mean_absolute_error: 8945.7363\n",
      "Epoch 1104: val_loss improved from 13584.58691 to 13584.01953, saving model to Weights-01104--13584.01953.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9651.3613 - mean_absolute_error: 9651.3613 - val_loss: 13584.0195 - val_mean_absolute_error: 13584.0195\n",
      "Epoch 1105/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13608.4404 - mean_absolute_error: 13608.4404\n",
      "Epoch 1105: val_loss did not improve from 13584.01953\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9640.2041 - mean_absolute_error: 9640.2041 - val_loss: 13587.1846 - val_mean_absolute_error: 13587.1846\n",
      "Epoch 1106/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8386.8545 - mean_absolute_error: 8386.8545\n",
      "Epoch 1106: val_loss improved from 13584.01953 to 13583.74902, saving model to Weights-01106--13583.74902.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9639.5684 - mean_absolute_error: 9639.5684 - val_loss: 13583.7490 - val_mean_absolute_error: 13583.7490\n",
      "Epoch 1107/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8803.9512 - mean_absolute_error: 8803.9512\n",
      "Epoch 1107: val_loss did not improve from 13583.74902\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9650.2803 - mean_absolute_error: 9650.2803 - val_loss: 13584.6621 - val_mean_absolute_error: 13584.6621\n",
      "Epoch 1108/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9799.4277 - mean_absolute_error: 9799.4277\n",
      "Epoch 1108: val_loss did not improve from 13583.74902\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9643.1201 - mean_absolute_error: 9643.1201 - val_loss: 13584.2217 - val_mean_absolute_error: 13584.2217\n",
      "Epoch 1109/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8096.1865 - mean_absolute_error: 8096.1865\n",
      "Epoch 1109: val_loss did not improve from 13583.74902\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9636.1904 - mean_absolute_error: 9636.1904 - val_loss: 13587.9355 - val_mean_absolute_error: 13587.9355\n",
      "Epoch 1110/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10500.2803 - mean_absolute_error: 10500.2803\n",
      "Epoch 1110: val_loss improved from 13583.74902 to 13582.92285, saving model to Weights-01110--13582.92285.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9644.0635 - mean_absolute_error: 9644.0635 - val_loss: 13582.9229 - val_mean_absolute_error: 13582.9229\n",
      "Epoch 1111/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 14272.4473 - mean_absolute_error: 14272.4473\n",
      "Epoch 1111: val_loss did not improve from 13582.92285\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9640.0020 - mean_absolute_error: 9640.0020 - val_loss: 13583.1504 - val_mean_absolute_error: 13583.1504\n",
      "Epoch 1112/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9567.4082 - mean_absolute_error: 9567.4082\n",
      "Epoch 1112: val_loss did not improve from 13582.92285\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9645.2695 - mean_absolute_error: 9645.2695 - val_loss: 13583.1719 - val_mean_absolute_error: 13583.1719\n",
      "Epoch 1113/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8481.9863 - mean_absolute_error: 8481.9863\n",
      "Epoch 1113: val_loss did not improve from 13582.92285\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9633.7949 - mean_absolute_error: 9633.7949 - val_loss: 13583.6885 - val_mean_absolute_error: 13583.6885\n",
      "Epoch 1114/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6505.8574 - mean_absolute_error: 6505.8574\n",
      "Epoch 1114: val_loss did not improve from 13582.92285\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9648.8662 - mean_absolute_error: 9648.8662 - val_loss: 13586.9404 - val_mean_absolute_error: 13586.9404\n",
      "Epoch 1115/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9676.2383 - mean_absolute_error: 9676.2383\n",
      "Epoch 1115: val_loss did not improve from 13582.92285\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9629.9150 - mean_absolute_error: 9629.9150 - val_loss: 13583.3760 - val_mean_absolute_error: 13583.3760\n",
      "Epoch 1116/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8608.1719 - mean_absolute_error: 8608.1719\n",
      "Epoch 1116: val_loss did not improve from 13582.92285\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9644.1074 - mean_absolute_error: 9644.1074 - val_loss: 13583.3232 - val_mean_absolute_error: 13583.3232\n",
      "Epoch 1117/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7850.8574 - mean_absolute_error: 7850.8574\n",
      "Epoch 1117: val_loss did not improve from 13582.92285\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9663.6914 - mean_absolute_error: 9663.6914 - val_loss: 13585.8340 - val_mean_absolute_error: 13585.8340\n",
      "Epoch 1118/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10634.0840 - mean_absolute_error: 10634.0840\n",
      "Epoch 1118: val_loss did not improve from 13582.92285\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9649.4014 - mean_absolute_error: 9649.4014 - val_loss: 13585.2842 - val_mean_absolute_error: 13585.2842\n",
      "Epoch 1119/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11382.8125 - mean_absolute_error: 11382.8125\n",
      "Epoch 1119: val_loss improved from 13582.92285 to 13582.33984, saving model to Weights-01119--13582.33984.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9628.9912 - mean_absolute_error: 9628.9912 - val_loss: 13582.3398 - val_mean_absolute_error: 13582.3398\n",
      "Epoch 1120/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10000.6621 - mean_absolute_error: 10000.6621\n",
      "Epoch 1120: val_loss improved from 13582.33984 to 13581.62109, saving model to Weights-01120--13581.62109.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9634.4766 - mean_absolute_error: 9634.4766 - val_loss: 13581.6211 - val_mean_absolute_error: 13581.6211\n",
      "Epoch 1121/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8172.1924 - mean_absolute_error: 8172.1924\n",
      "Epoch 1121: val_loss improved from 13581.62109 to 13581.20312, saving model to Weights-01121--13581.20312.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9632.0674 - mean_absolute_error: 9632.0674 - val_loss: 13581.2031 - val_mean_absolute_error: 13581.2031\n",
      "Epoch 1122/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9918.0449 - mean_absolute_error: 9918.0449\n",
      "Epoch 1122: val_loss did not improve from 13581.20312\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9628.9844 - mean_absolute_error: 9628.9844 - val_loss: 13584.9219 - val_mean_absolute_error: 13584.9219\n",
      "Epoch 1123/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11255.7852 - mean_absolute_error: 11255.7852\n",
      "Epoch 1123: val_loss improved from 13581.20312 to 13580.90625, saving model to Weights-01123--13580.90625.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9635.3682 - mean_absolute_error: 9635.3682 - val_loss: 13580.9062 - val_mean_absolute_error: 13580.9062\n",
      "Epoch 1124/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12252.8906 - mean_absolute_error: 12252.8906\n",
      "Epoch 1124: val_loss did not improve from 13580.90625\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9631.2607 - mean_absolute_error: 9631.2607 - val_loss: 13583.6514 - val_mean_absolute_error: 13583.6514\n",
      "Epoch 1125/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9953.7100 - mean_absolute_error: 9953.7100\n",
      "Epoch 1125: val_loss did not improve from 13580.90625\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9628.9434 - mean_absolute_error: 9628.9434 - val_loss: 13581.2764 - val_mean_absolute_error: 13581.2764\n",
      "Epoch 1126/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11442.8164 - mean_absolute_error: 11442.8164\n",
      "Epoch 1126: val_loss did not improve from 13580.90625\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9640.5938 - mean_absolute_error: 9640.5938 - val_loss: 13581.4365 - val_mean_absolute_error: 13581.4365\n",
      "Epoch 1127/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10009.4609 - mean_absolute_error: 10009.4609\n",
      "Epoch 1127: val_loss improved from 13580.90625 to 13580.21973, saving model to Weights-01127--13580.21973.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9633.1523 - mean_absolute_error: 9633.1523 - val_loss: 13580.2197 - val_mean_absolute_error: 13580.2197\n",
      "Epoch 1128/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9652.0645 - mean_absolute_error: 9652.0645\n",
      "Epoch 1128: val_loss did not improve from 13580.21973\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9653.6348 - mean_absolute_error: 9653.6348 - val_loss: 13585.5342 - val_mean_absolute_error: 13585.5342\n",
      "Epoch 1129/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6427.2295 - mean_absolute_error: 6427.2295\n",
      "Epoch 1129: val_loss did not improve from 13580.21973\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9647.4209 - mean_absolute_error: 9647.4209 - val_loss: 13584.2188 - val_mean_absolute_error: 13584.2188\n",
      "Epoch 1130/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8711.8643 - mean_absolute_error: 8711.8643\n",
      "Epoch 1130: val_loss improved from 13580.21973 to 13579.74316, saving model to Weights-01130--13579.74316.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9638.2920 - mean_absolute_error: 9638.2920 - val_loss: 13579.7432 - val_mean_absolute_error: 13579.7432\n",
      "Epoch 1131/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10682.6943 - mean_absolute_error: 10682.6943\n",
      "Epoch 1131: val_loss did not improve from 13579.74316\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9648.8857 - mean_absolute_error: 9648.8857 - val_loss: 13583.1709 - val_mean_absolute_error: 13583.1709\n",
      "Epoch 1132/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7609.7163 - mean_absolute_error: 7609.7163\n",
      "Epoch 1132: val_loss did not improve from 13579.74316\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9631.7207 - mean_absolute_error: 9631.7207 - val_loss: 13581.3281 - val_mean_absolute_error: 13581.3281\n",
      "Epoch 1133/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9730.9121 - mean_absolute_error: 9730.9121\n",
      "Epoch 1133: val_loss did not improve from 13579.74316\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9635.2900 - mean_absolute_error: 9635.2900 - val_loss: 13580.8496 - val_mean_absolute_error: 13580.8496\n",
      "Epoch 1134/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9941.1367 - mean_absolute_error: 9941.1367\n",
      "Epoch 1134: val_loss did not improve from 13579.74316\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9629.0205 - mean_absolute_error: 9629.0205 - val_loss: 13581.4424 - val_mean_absolute_error: 13581.4424\n",
      "Epoch 1135/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10706.6934 - mean_absolute_error: 10706.6934\n",
      "Epoch 1135: val_loss improved from 13579.74316 to 13579.48047, saving model to Weights-01135--13579.48047.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9630.5527 - mean_absolute_error: 9630.5527 - val_loss: 13579.4805 - val_mean_absolute_error: 13579.4805\n",
      "Epoch 1136/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9762.6914 - mean_absolute_error: 9762.6914\n",
      "Epoch 1136: val_loss did not improve from 13579.48047\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9639.5283 - mean_absolute_error: 9639.5283 - val_loss: 13579.5430 - val_mean_absolute_error: 13579.5430\n",
      "Epoch 1137/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8634.4941 - mean_absolute_error: 8634.4941\n",
      "Epoch 1137: val_loss did not improve from 13579.48047\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9630.4658 - mean_absolute_error: 9630.4658 - val_loss: 13582.7441 - val_mean_absolute_error: 13582.7441\n",
      "Epoch 1138/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8624.7393 - mean_absolute_error: 8624.7393\n",
      "Epoch 1138: val_loss did not improve from 13579.48047\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9642.7812 - mean_absolute_error: 9642.7812 - val_loss: 13579.6240 - val_mean_absolute_error: 13579.6240\n",
      "Epoch 1139/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11315.8203 - mean_absolute_error: 11315.8203\n",
      "Epoch 1139: val_loss improved from 13579.48047 to 13578.81836, saving model to Weights-01139--13578.81836.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9627.4805 - mean_absolute_error: 9627.4805 - val_loss: 13578.8184 - val_mean_absolute_error: 13578.8184\n",
      "Epoch 1140/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10945.1709 - mean_absolute_error: 10945.1709\n",
      "Epoch 1140: val_loss improved from 13578.81836 to 13578.03613, saving model to Weights-01140--13578.03613.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9624.9336 - mean_absolute_error: 9624.9336 - val_loss: 13578.0361 - val_mean_absolute_error: 13578.0361\n",
      "Epoch 1141/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8664.4385 - mean_absolute_error: 8664.4385\n",
      "Epoch 1141: val_loss did not improve from 13578.03613\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9625.7314 - mean_absolute_error: 9625.7314 - val_loss: 13578.1328 - val_mean_absolute_error: 13578.1328\n",
      "Epoch 1142/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11712.7832 - mean_absolute_error: 11712.7832\n",
      "Epoch 1142: val_loss improved from 13578.03613 to 13577.66211, saving model to Weights-01142--13577.66211.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9632.8340 - mean_absolute_error: 9632.8340 - val_loss: 13577.6621 - val_mean_absolute_error: 13577.6621\n",
      "Epoch 1143/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10565.5957 - mean_absolute_error: 10565.5957\n",
      "Epoch 1143: val_loss did not improve from 13577.66211\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9624.0264 - mean_absolute_error: 9624.0264 - val_loss: 13578.3545 - val_mean_absolute_error: 13578.3545\n",
      "Epoch 1144/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 14124.0898 - mean_absolute_error: 14124.0898\n",
      "Epoch 1144: val_loss improved from 13577.66211 to 13577.28516, saving model to Weights-01144--13577.28516.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9632.4287 - mean_absolute_error: 9632.4287 - val_loss: 13577.2852 - val_mean_absolute_error: 13577.2852\n",
      "Epoch 1145/3000\n",
      "18/18 [==============================] - ETA: 0s - loss: 9626.1699 - mean_absolute_error: 9626.1699\n",
      "Epoch 1145: val_loss did not improve from 13577.28516\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9626.1699 - mean_absolute_error: 9626.1699 - val_loss: 13578.6152 - val_mean_absolute_error: 13578.6152\n",
      "Epoch 1146/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9527.7793 - mean_absolute_error: 9527.7793\n",
      "Epoch 1146: val_loss improved from 13577.28516 to 13577.02832, saving model to Weights-01146--13577.02832.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9627.9229 - mean_absolute_error: 9627.9229 - val_loss: 13577.0283 - val_mean_absolute_error: 13577.0283\n",
      "Epoch 1147/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7771.8442 - mean_absolute_error: 7771.8442\n",
      "Epoch 1147: val_loss did not improve from 13577.02832\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9621.6357 - mean_absolute_error: 9621.6357 - val_loss: 13578.0918 - val_mean_absolute_error: 13578.0918\n",
      "Epoch 1148/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9197.6797 - mean_absolute_error: 9197.6797\n",
      "Epoch 1148: val_loss did not improve from 13577.02832\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9626.2539 - mean_absolute_error: 9626.2539 - val_loss: 13579.3506 - val_mean_absolute_error: 13579.3506\n",
      "Epoch 1149/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9083.5264 - mean_absolute_error: 9083.5264\n",
      "Epoch 1149: val_loss improved from 13577.02832 to 13576.40039, saving model to Weights-01149--13576.40039.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9620.9814 - mean_absolute_error: 9620.9814 - val_loss: 13576.4004 - val_mean_absolute_error: 13576.4004\n",
      "Epoch 1150/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9626.4648 - mean_absolute_error: 9626.4648\n",
      "Epoch 1150: val_loss did not improve from 13576.40039\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9633.0049 - mean_absolute_error: 9633.0049 - val_loss: 13577.0986 - val_mean_absolute_error: 13577.0986\n",
      "Epoch 1151/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7597.1992 - mean_absolute_error: 7597.1992\n",
      "Epoch 1151: val_loss did not improve from 13576.40039\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9626.7432 - mean_absolute_error: 9626.7432 - val_loss: 13577.0205 - val_mean_absolute_error: 13577.0205\n",
      "Epoch 1152/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7405.2573 - mean_absolute_error: 7405.2573\n",
      "Epoch 1152: val_loss improved from 13576.40039 to 13576.29395, saving model to Weights-01152--13576.29395.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9622.9277 - mean_absolute_error: 9622.9277 - val_loss: 13576.2939 - val_mean_absolute_error: 13576.2939\n",
      "Epoch 1153/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12145.8408 - mean_absolute_error: 12145.8408\n",
      "Epoch 1153: val_loss improved from 13576.29395 to 13576.10059, saving model to Weights-01153--13576.10059.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9623.5068 - mean_absolute_error: 9623.5068 - val_loss: 13576.1006 - val_mean_absolute_error: 13576.1006\n",
      "Epoch 1154/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8625.5762 - mean_absolute_error: 8625.5762\n",
      "Epoch 1154: val_loss did not improve from 13576.10059\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9619.2119 - mean_absolute_error: 9619.2119 - val_loss: 13576.3750 - val_mean_absolute_error: 13576.3750\n",
      "Epoch 1155/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9103.6963 - mean_absolute_error: 9103.6963\n",
      "Epoch 1155: val_loss did not improve from 13576.10059\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9620.4492 - mean_absolute_error: 9620.4492 - val_loss: 13577.2988 - val_mean_absolute_error: 13577.2988\n",
      "Epoch 1156/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7110.9551 - mean_absolute_error: 7110.9551\n",
      "Epoch 1156: val_loss improved from 13576.10059 to 13575.22754, saving model to Weights-01156--13575.22754.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9631.1016 - mean_absolute_error: 9631.1016 - val_loss: 13575.2275 - val_mean_absolute_error: 13575.2275\n",
      "Epoch 1157/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7520.7876 - mean_absolute_error: 7520.7876\n",
      "Epoch 1157: val_loss improved from 13575.22754 to 13575.05859, saving model to Weights-01157--13575.05859.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9620.5850 - mean_absolute_error: 9620.5850 - val_loss: 13575.0586 - val_mean_absolute_error: 13575.0586\n",
      "Epoch 1158/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7568.4268 - mean_absolute_error: 7568.4268\n",
      "Epoch 1158: val_loss improved from 13575.05859 to 13574.87207, saving model to Weights-01158--13574.87207.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9625.8193 - mean_absolute_error: 9625.8193 - val_loss: 13574.8721 - val_mean_absolute_error: 13574.8721\n",
      "Epoch 1159/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10114.0283 - mean_absolute_error: 10114.0283\n",
      "Epoch 1159: val_loss improved from 13574.87207 to 13574.80176, saving model to Weights-01159--13574.80176.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9619.7773 - mean_absolute_error: 9619.7773 - val_loss: 13574.8018 - val_mean_absolute_error: 13574.8018\n",
      "Epoch 1160/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8728.8350 - mean_absolute_error: 8728.8350\n",
      "Epoch 1160: val_loss improved from 13574.80176 to 13574.59961, saving model to Weights-01160--13574.59961.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9627.2109 - mean_absolute_error: 9627.2109 - val_loss: 13574.5996 - val_mean_absolute_error: 13574.5996\n",
      "Epoch 1161/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 15952.5527 - mean_absolute_error: 15952.5527\n",
      "Epoch 1161: val_loss did not improve from 13574.59961\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9624.4229 - mean_absolute_error: 9624.4229 - val_loss: 13574.7881 - val_mean_absolute_error: 13574.7881\n",
      "Epoch 1162/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7145.3008 - mean_absolute_error: 7145.3008\n",
      "Epoch 1162: val_loss improved from 13574.59961 to 13574.30762, saving model to Weights-01162--13574.30762.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9621.5225 - mean_absolute_error: 9621.5225 - val_loss: 13574.3076 - val_mean_absolute_error: 13574.3076\n",
      "Epoch 1163/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8197.2754 - mean_absolute_error: 8197.2754\n",
      "Epoch 1163: val_loss improved from 13574.30762 to 13574.03223, saving model to Weights-01163--13574.03223.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9625.4941 - mean_absolute_error: 9625.4941 - val_loss: 13574.0322 - val_mean_absolute_error: 13574.0322\n",
      "Epoch 1164/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 14154.7598 - mean_absolute_error: 14154.7598\n",
      "Epoch 1164: val_loss did not improve from 13574.03223\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9624.7188 - mean_absolute_error: 9624.7188 - val_loss: 13575.3828 - val_mean_absolute_error: 13575.3828\n",
      "Epoch 1165/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7681.5791 - mean_absolute_error: 7681.5791\n",
      "Epoch 1165: val_loss did not improve from 13574.03223\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9620.3418 - mean_absolute_error: 9620.3418 - val_loss: 13574.4824 - val_mean_absolute_error: 13574.4824\n",
      "Epoch 1166/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9998.1377 - mean_absolute_error: 9998.1377\n",
      "Epoch 1166: val_loss did not improve from 13574.03223\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9636.5898 - mean_absolute_error: 9636.5898 - val_loss: 13574.4375 - val_mean_absolute_error: 13574.4375\n",
      "Epoch 1167/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 16610.9160 - mean_absolute_error: 16610.9160\n",
      "Epoch 1167: val_loss did not improve from 13574.03223\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9618.6924 - mean_absolute_error: 9618.6924 - val_loss: 13574.7998 - val_mean_absolute_error: 13574.7998\n",
      "Epoch 1168/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8262.1309 - mean_absolute_error: 8262.1309\n",
      "Epoch 1168: val_loss did not improve from 13574.03223\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9622.1006 - mean_absolute_error: 9622.1006 - val_loss: 13575.3135 - val_mean_absolute_error: 13575.3135\n",
      "Epoch 1169/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8757.9795 - mean_absolute_error: 8757.9795\n",
      "Epoch 1169: val_loss did not improve from 13574.03223\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9615.1748 - mean_absolute_error: 9615.1748 - val_loss: 13575.9932 - val_mean_absolute_error: 13575.9932\n",
      "Epoch 1170/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9151.1895 - mean_absolute_error: 9151.1895\n",
      "Epoch 1170: val_loss improved from 13574.03223 to 13573.18262, saving model to Weights-01170--13573.18262.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9630.6768 - mean_absolute_error: 9630.6768 - val_loss: 13573.1826 - val_mean_absolute_error: 13573.1826\n",
      "Epoch 1171/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5218.5439 - mean_absolute_error: 5218.5439\n",
      "Epoch 1171: val_loss did not improve from 13573.18262\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9618.6572 - mean_absolute_error: 9618.6572 - val_loss: 13573.7051 - val_mean_absolute_error: 13573.7051\n",
      "Epoch 1172/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10261.5352 - mean_absolute_error: 10261.5352\n",
      "Epoch 1172: val_loss did not improve from 13573.18262\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9617.4707 - mean_absolute_error: 9617.4707 - val_loss: 13575.1475 - val_mean_absolute_error: 13575.1475\n",
      "Epoch 1173/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11279.8164 - mean_absolute_error: 11279.8164\n",
      "Epoch 1173: val_loss did not improve from 13573.18262\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9617.6729 - mean_absolute_error: 9617.6729 - val_loss: 13573.7617 - val_mean_absolute_error: 13573.7617\n",
      "Epoch 1174/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10273.1211 - mean_absolute_error: 10273.1211\n",
      "Epoch 1174: val_loss improved from 13573.18262 to 13572.42578, saving model to Weights-01174--13572.42578.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9617.8623 - mean_absolute_error: 9617.8623 - val_loss: 13572.4258 - val_mean_absolute_error: 13572.4258\n",
      "Epoch 1175/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8347.2139 - mean_absolute_error: 8347.2139\n",
      "Epoch 1175: val_loss did not improve from 13572.42578\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9630.0664 - mean_absolute_error: 9630.0664 - val_loss: 13575.4365 - val_mean_absolute_error: 13575.4365\n",
      "Epoch 1176/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11620.8740 - mean_absolute_error: 11620.8740\n",
      "Epoch 1176: val_loss did not improve from 13572.42578\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9614.2197 - mean_absolute_error: 9614.2197 - val_loss: 13574.2012 - val_mean_absolute_error: 13574.2012\n",
      "Epoch 1177/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8696.9043 - mean_absolute_error: 8696.9043\n",
      "Epoch 1177: val_loss improved from 13572.42578 to 13571.85742, saving model to Weights-01177--13571.85742.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9624.6035 - mean_absolute_error: 9624.6035 - val_loss: 13571.8574 - val_mean_absolute_error: 13571.8574\n",
      "Epoch 1178/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8586.4336 - mean_absolute_error: 8586.4336\n",
      "Epoch 1178: val_loss did not improve from 13571.85742\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9613.6777 - mean_absolute_error: 9613.6777 - val_loss: 13572.4014 - val_mean_absolute_error: 13572.4014\n",
      "Epoch 1179/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5541.1719 - mean_absolute_error: 5541.1719\n",
      "Epoch 1179: val_loss improved from 13571.85742 to 13571.40820, saving model to Weights-01179--13571.40820.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9613.4443 - mean_absolute_error: 9613.4443 - val_loss: 13571.4082 - val_mean_absolute_error: 13571.4082\n",
      "Epoch 1180/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6868.9976 - mean_absolute_error: 6868.9976\n",
      "Epoch 1180: val_loss improved from 13571.40820 to 13571.31934, saving model to Weights-01180--13571.31934.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9614.4268 - mean_absolute_error: 9614.4268 - val_loss: 13571.3193 - val_mean_absolute_error: 13571.3193\n",
      "Epoch 1181/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9294.8311 - mean_absolute_error: 9294.8311\n",
      "Epoch 1181: val_loss improved from 13571.31934 to 13571.03320, saving model to Weights-01181--13571.03320.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9617.0352 - mean_absolute_error: 9617.0352 - val_loss: 13571.0332 - val_mean_absolute_error: 13571.0332\n",
      "Epoch 1182/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8863.3047 - mean_absolute_error: 8863.3047\n",
      "Epoch 1182: val_loss did not improve from 13571.03320\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9614.7861 - mean_absolute_error: 9614.7861 - val_loss: 13571.3027 - val_mean_absolute_error: 13571.3027\n",
      "Epoch 1183/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7925.8623 - mean_absolute_error: 7925.8623\n",
      "Epoch 1183: val_loss improved from 13571.03320 to 13570.77930, saving model to Weights-01183--13570.77930.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9612.3711 - mean_absolute_error: 9612.3711 - val_loss: 13570.7793 - val_mean_absolute_error: 13570.7793\n",
      "Epoch 1184/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8291.3818 - mean_absolute_error: 8291.3818\n",
      "Epoch 1184: val_loss did not improve from 13570.77930\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9630.4717 - mean_absolute_error: 9630.4717 - val_loss: 13571.2656 - val_mean_absolute_error: 13571.2656\n",
      "Epoch 1185/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9159.3184 - mean_absolute_error: 9159.3184\n",
      "Epoch 1185: val_loss improved from 13570.77930 to 13570.44922, saving model to Weights-01185--13570.44922.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9619.9971 - mean_absolute_error: 9619.9971 - val_loss: 13570.4492 - val_mean_absolute_error: 13570.4492\n",
      "Epoch 1186/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11205.8984 - mean_absolute_error: 11205.8984\n",
      "Epoch 1186: val_loss did not improve from 13570.44922\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9612.0762 - mean_absolute_error: 9612.0762 - val_loss: 13570.8691 - val_mean_absolute_error: 13570.8691\n",
      "Epoch 1187/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11717.7949 - mean_absolute_error: 11717.7949\n",
      "Epoch 1187: val_loss improved from 13570.44922 to 13570.16309, saving model to Weights-01187--13570.16309.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9613.1660 - mean_absolute_error: 9613.1660 - val_loss: 13570.1631 - val_mean_absolute_error: 13570.1631\n",
      "Epoch 1188/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10216.0186 - mean_absolute_error: 10216.0186\n",
      "Epoch 1188: val_loss improved from 13570.16309 to 13570.08789, saving model to Weights-01188--13570.08789.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9618.3779 - mean_absolute_error: 9618.3779 - val_loss: 13570.0879 - val_mean_absolute_error: 13570.0879\n",
      "Epoch 1189/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9495.5703 - mean_absolute_error: 9495.5703\n",
      "Epoch 1189: val_loss did not improve from 13570.08789\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9611.4941 - mean_absolute_error: 9611.4941 - val_loss: 13570.7891 - val_mean_absolute_error: 13570.7891\n",
      "Epoch 1190/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8011.7935 - mean_absolute_error: 8011.7935\n",
      "Epoch 1190: val_loss did not improve from 13570.08789\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9615.8594 - mean_absolute_error: 9615.8594 - val_loss: 13570.1787 - val_mean_absolute_error: 13570.1787\n",
      "Epoch 1191/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9853.7246 - mean_absolute_error: 9853.7246\n",
      "Epoch 1191: val_loss did not improve from 13570.08789\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9616.7090 - mean_absolute_error: 9616.7090 - val_loss: 13572.9912 - val_mean_absolute_error: 13572.9912\n",
      "Epoch 1192/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8978.9277 - mean_absolute_error: 8978.9277\n",
      "Epoch 1192: val_loss improved from 13570.08789 to 13569.34668, saving model to Weights-01192--13569.34668.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9613.1455 - mean_absolute_error: 9613.1455 - val_loss: 13569.3467 - val_mean_absolute_error: 13569.3467\n",
      "Epoch 1193/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5581.2129 - mean_absolute_error: 5581.2129\n",
      "Epoch 1193: val_loss improved from 13569.34668 to 13569.18750, saving model to Weights-01193--13569.18750.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9610.2285 - mean_absolute_error: 9610.2285 - val_loss: 13569.1875 - val_mean_absolute_error: 13569.1875\n",
      "Epoch 1194/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11455.7207 - mean_absolute_error: 11455.7207\n",
      "Epoch 1194: val_loss improved from 13569.18750 to 13568.95312, saving model to Weights-01194--13568.95312.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9608.5156 - mean_absolute_error: 9608.5156 - val_loss: 13568.9531 - val_mean_absolute_error: 13568.9531\n",
      "Epoch 1195/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10298.4121 - mean_absolute_error: 10298.4121\n",
      "Epoch 1195: val_loss did not improve from 13568.95312\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9612.9609 - mean_absolute_error: 9612.9609 - val_loss: 13569.8857 - val_mean_absolute_error: 13569.8857\n",
      "Epoch 1196/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12363.2832 - mean_absolute_error: 12363.2832\n",
      "Epoch 1196: val_loss did not improve from 13568.95312\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9627.7275 - mean_absolute_error: 9627.7275 - val_loss: 13572.4814 - val_mean_absolute_error: 13572.4814\n",
      "Epoch 1197/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10181.7031 - mean_absolute_error: 10181.7031\n",
      "Epoch 1197: val_loss did not improve from 13568.95312\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9615.9238 - mean_absolute_error: 9615.9238 - val_loss: 13572.2715 - val_mean_absolute_error: 13572.2715\n",
      "Epoch 1198/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5448.2056 - mean_absolute_error: 5448.2056\n",
      "Epoch 1198: val_loss did not improve from 13568.95312\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9606.2432 - mean_absolute_error: 9606.2432 - val_loss: 13569.8486 - val_mean_absolute_error: 13569.8486\n",
      "Epoch 1199/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8832.5127 - mean_absolute_error: 8832.5127\n",
      "Epoch 1199: val_loss did not improve from 13568.95312\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9613.7832 - mean_absolute_error: 9613.7832 - val_loss: 13570.7832 - val_mean_absolute_error: 13570.7832\n",
      "Epoch 1200/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9473.8340 - mean_absolute_error: 9473.8340\n",
      "Epoch 1200: val_loss did not improve from 13568.95312\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9612.7734 - mean_absolute_error: 9612.7734 - val_loss: 13569.4160 - val_mean_absolute_error: 13569.4160\n",
      "Epoch 1201/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9811.6201 - mean_absolute_error: 9811.6201\n",
      "Epoch 1201: val_loss improved from 13568.95312 to 13567.93555, saving model to Weights-01201--13567.93555.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9606.0820 - mean_absolute_error: 9606.0820 - val_loss: 13567.9355 - val_mean_absolute_error: 13567.9355\n",
      "Epoch 1202/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10253.8145 - mean_absolute_error: 10253.8145\n",
      "Epoch 1202: val_loss improved from 13567.93555 to 13567.68066, saving model to Weights-01202--13567.68066.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9609.3848 - mean_absolute_error: 9609.3848 - val_loss: 13567.6807 - val_mean_absolute_error: 13567.6807\n",
      "Epoch 1203/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7449.4219 - mean_absolute_error: 7449.4219\n",
      "Epoch 1203: val_loss improved from 13567.68066 to 13567.53418, saving model to Weights-01203--13567.53418.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9612.4307 - mean_absolute_error: 9612.4307 - val_loss: 13567.5342 - val_mean_absolute_error: 13567.5342\n",
      "Epoch 1204/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10790.3887 - mean_absolute_error: 10790.3887\n",
      "Epoch 1204: val_loss did not improve from 13567.53418\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9607.4365 - mean_absolute_error: 9607.4365 - val_loss: 13568.4443 - val_mean_absolute_error: 13568.4443\n",
      "Epoch 1205/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7384.0898 - mean_absolute_error: 7384.0898\n",
      "Epoch 1205: val_loss improved from 13567.53418 to 13567.16699, saving model to Weights-01205--13567.16699.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9609.4385 - mean_absolute_error: 9609.4385 - val_loss: 13567.1670 - val_mean_absolute_error: 13567.1670\n",
      "Epoch 1206/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10085.6162 - mean_absolute_error: 10085.6162\n",
      "Epoch 1206: val_loss did not improve from 13567.16699\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9606.0674 - mean_absolute_error: 9606.0674 - val_loss: 13569.5645 - val_mean_absolute_error: 13569.5645\n",
      "Epoch 1207/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10324.9414 - mean_absolute_error: 10324.9414\n",
      "Epoch 1207: val_loss improved from 13567.16699 to 13566.88379, saving model to Weights-01207--13566.88379.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9607.2920 - mean_absolute_error: 9607.2920 - val_loss: 13566.8838 - val_mean_absolute_error: 13566.8838\n",
      "Epoch 1208/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11219.1484 - mean_absolute_error: 11219.1484\n",
      "Epoch 1208: val_loss did not improve from 13566.88379\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9621.1562 - mean_absolute_error: 9621.1562 - val_loss: 13571.6455 - val_mean_absolute_error: 13571.6455\n",
      "Epoch 1209/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10307.7734 - mean_absolute_error: 10307.7734\n",
      "Epoch 1209: val_loss improved from 13566.88379 to 13566.69922, saving model to Weights-01209--13566.69922.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9604.3604 - mean_absolute_error: 9604.3604 - val_loss: 13566.6992 - val_mean_absolute_error: 13566.6992\n",
      "Epoch 1210/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8556.3262 - mean_absolute_error: 8556.3262\n",
      "Epoch 1210: val_loss did not improve from 13566.69922\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9604.6953 - mean_absolute_error: 9604.6953 - val_loss: 13567.1094 - val_mean_absolute_error: 13567.1094\n",
      "Epoch 1211/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11694.6592 - mean_absolute_error: 11694.6592\n",
      "Epoch 1211: val_loss did not improve from 13566.69922\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9607.7910 - mean_absolute_error: 9607.7910 - val_loss: 13566.8770 - val_mean_absolute_error: 13566.8770\n",
      "Epoch 1212/3000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9621.2480 - mean_absolute_error: 9621.2480  \n",
      "Epoch 1212: val_loss did not improve from 13566.69922\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9624.3779 - mean_absolute_error: 9624.3779 - val_loss: 13568.6377 - val_mean_absolute_error: 13568.6377\n",
      "Epoch 1213/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8243.5186 - mean_absolute_error: 8243.5186\n",
      "Epoch 1213: val_loss did not improve from 13566.69922\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9617.4219 - mean_absolute_error: 9617.4219 - val_loss: 13573.4990 - val_mean_absolute_error: 13573.4990\n",
      "Epoch 1214/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9484.1289 - mean_absolute_error: 9484.1289\n",
      "Epoch 1214: val_loss improved from 13566.69922 to 13565.72656, saving model to Weights-01214--13565.72656.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9610.7461 - mean_absolute_error: 9610.7461 - val_loss: 13565.7266 - val_mean_absolute_error: 13565.7275\n",
      "Epoch 1215/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5396.9971 - mean_absolute_error: 5396.9971\n",
      "Epoch 1215: val_loss improved from 13565.72656 to 13565.46875, saving model to Weights-01215--13565.46875.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9607.1855 - mean_absolute_error: 9607.1855 - val_loss: 13565.4688 - val_mean_absolute_error: 13565.4688\n",
      "Epoch 1216/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10468.8848 - mean_absolute_error: 10468.8848\n",
      "Epoch 1216: val_loss did not improve from 13565.46875\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9613.5029 - mean_absolute_error: 9613.5029 - val_loss: 13567.8535 - val_mean_absolute_error: 13567.8535\n",
      "Epoch 1217/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9945.5283 - mean_absolute_error: 9945.5283\n",
      "Epoch 1217: val_loss did not improve from 13565.46875\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9615.1621 - mean_absolute_error: 9615.1621 - val_loss: 13569.3838 - val_mean_absolute_error: 13569.3838\n",
      "Epoch 1218/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8797.2686 - mean_absolute_error: 8797.2686\n",
      "Epoch 1218: val_loss did not improve from 13565.46875\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9615.9375 - mean_absolute_error: 9615.9375 - val_loss: 13567.9922 - val_mean_absolute_error: 13567.9922\n",
      "Epoch 1219/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6473.5654 - mean_absolute_error: 6473.5654\n",
      "Epoch 1219: val_loss did not improve from 13565.46875\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9626.6543 - mean_absolute_error: 9626.6543 - val_loss: 13567.8896 - val_mean_absolute_error: 13567.8896\n",
      "Epoch 1220/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 15155.0352 - mean_absolute_error: 15155.0352\n",
      "Epoch 1220: val_loss improved from 13565.46875 to 13564.75098, saving model to Weights-01220--13564.75098.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9604.4111 - mean_absolute_error: 9604.4111 - val_loss: 13564.7510 - val_mean_absolute_error: 13564.7510\n",
      "Epoch 1221/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12490.5312 - mean_absolute_error: 12490.5312\n",
      "Epoch 1221: val_loss did not improve from 13564.75098\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9609.3711 - mean_absolute_error: 9609.3711 - val_loss: 13566.8301 - val_mean_absolute_error: 13566.8301\n",
      "Epoch 1222/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9060.3867 - mean_absolute_error: 9060.3867\n",
      "Epoch 1222: val_loss improved from 13564.75098 to 13564.66113, saving model to Weights-01222--13564.66113.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9616.6826 - mean_absolute_error: 9616.6826 - val_loss: 13564.6611 - val_mean_absolute_error: 13564.6611\n",
      "Epoch 1223/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10650.1172 - mean_absolute_error: 10650.1172\n",
      "Epoch 1223: val_loss did not improve from 13564.66113\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9604.7734 - mean_absolute_error: 9604.7734 - val_loss: 13568.1504 - val_mean_absolute_error: 13568.1504\n",
      "Epoch 1224/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10347.9746 - mean_absolute_error: 10347.9746\n",
      "Epoch 1224: val_loss improved from 13564.66113 to 13564.01465, saving model to Weights-01224--13564.01465.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9605.9443 - mean_absolute_error: 9605.9443 - val_loss: 13564.0146 - val_mean_absolute_error: 13564.0146\n",
      "Epoch 1225/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7308.3564 - mean_absolute_error: 7308.3564\n",
      "Epoch 1225: val_loss did not improve from 13564.01465\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9625.7959 - mean_absolute_error: 9625.7959 - val_loss: 13569.9600 - val_mean_absolute_error: 13569.9600\n",
      "Epoch 1226/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8939.6846 - mean_absolute_error: 8939.6846\n",
      "Epoch 1226: val_loss did not improve from 13564.01465\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9592.5605 - mean_absolute_error: 9592.5605 - val_loss: 13567.4844 - val_mean_absolute_error: 13567.4844\n",
      "Epoch 1227/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9370.8955 - mean_absolute_error: 9370.8955\n",
      "Epoch 1227: val_loss improved from 13564.01465 to 13563.42773, saving model to Weights-01227--13563.42773.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9615.9092 - mean_absolute_error: 9615.9092 - val_loss: 13563.4277 - val_mean_absolute_error: 13563.4277\n",
      "Epoch 1228/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9109.1816 - mean_absolute_error: 9109.1816\n",
      "Epoch 1228: val_loss did not improve from 13563.42773\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9601.8174 - mean_absolute_error: 9601.8174 - val_loss: 13563.6680 - val_mean_absolute_error: 13563.6680\n",
      "Epoch 1229/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9739.3984 - mean_absolute_error: 9739.3984\n",
      "Epoch 1229: val_loss improved from 13563.42773 to 13563.20996, saving model to Weights-01229--13563.20996.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9605.9395 - mean_absolute_error: 9605.9395 - val_loss: 13563.2100 - val_mean_absolute_error: 13563.2100\n",
      "Epoch 1230/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11522.6934 - mean_absolute_error: 11522.6934\n",
      "Epoch 1230: val_loss did not improve from 13563.20996\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9607.6270 - mean_absolute_error: 9607.6270 - val_loss: 13566.8164 - val_mean_absolute_error: 13566.8164\n",
      "Epoch 1231/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8880.7539 - mean_absolute_error: 8880.7539\n",
      "Epoch 1231: val_loss did not improve from 13563.20996\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9610.3076 - mean_absolute_error: 9610.3076 - val_loss: 13565.6641 - val_mean_absolute_error: 13565.6641\n",
      "Epoch 1232/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10893.8398 - mean_absolute_error: 10893.8398\n",
      "Epoch 1232: val_loss improved from 13563.20996 to 13562.53027, saving model to Weights-01232--13562.53027.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9602.2324 - mean_absolute_error: 9602.2324 - val_loss: 13562.5303 - val_mean_absolute_error: 13562.5303\n",
      "Epoch 1233/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8267.1533 - mean_absolute_error: 8267.1533\n",
      "Epoch 1233: val_loss improved from 13562.53027 to 13562.36914, saving model to Weights-01233--13562.36914.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9599.6631 - mean_absolute_error: 9599.6631 - val_loss: 13562.3691 - val_mean_absolute_error: 13562.3691\n",
      "Epoch 1234/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12751.7510 - mean_absolute_error: 12751.7510\n",
      "Epoch 1234: val_loss did not improve from 13562.36914\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9599.4463 - mean_absolute_error: 9599.4463 - val_loss: 13562.4023 - val_mean_absolute_error: 13562.4023\n",
      "Epoch 1235/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10044.9727 - mean_absolute_error: 10044.9727\n",
      "Epoch 1235: val_loss did not improve from 13562.36914\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9612.0205 - mean_absolute_error: 9612.0205 - val_loss: 13565.4531 - val_mean_absolute_error: 13565.4531\n",
      "Epoch 1236/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9039.2930 - mean_absolute_error: 9039.2930\n",
      "Epoch 1236: val_loss did not improve from 13562.36914\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9595.4375 - mean_absolute_error: 9595.4375 - val_loss: 13565.0957 - val_mean_absolute_error: 13565.0957\n",
      "Epoch 1237/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9798.6035 - mean_absolute_error: 9798.6035\n",
      "Epoch 1237: val_loss did not improve from 13562.36914\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9619.1143 - mean_absolute_error: 9619.1143 - val_loss: 13563.2002 - val_mean_absolute_error: 13563.2002\n",
      "Epoch 1238/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8564.6943 - mean_absolute_error: 8564.6943\n",
      "Epoch 1238: val_loss did not improve from 13562.36914\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9603.2871 - mean_absolute_error: 9603.2871 - val_loss: 13565.0303 - val_mean_absolute_error: 13565.0303\n",
      "Epoch 1239/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10194.0352 - mean_absolute_error: 10194.0352\n",
      "Epoch 1239: val_loss improved from 13562.36914 to 13561.66016, saving model to Weights-01239--13561.66016.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9599.1621 - mean_absolute_error: 9599.1621 - val_loss: 13561.6602 - val_mean_absolute_error: 13561.6602\n",
      "Epoch 1240/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8334.3643 - mean_absolute_error: 8334.3643\n",
      "Epoch 1240: val_loss improved from 13561.66016 to 13561.30664, saving model to Weights-01240--13561.30664.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9597.8496 - mean_absolute_error: 9597.8496 - val_loss: 13561.3066 - val_mean_absolute_error: 13561.3066\n",
      "Epoch 1241/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6999.1123 - mean_absolute_error: 6999.1123\n",
      "Epoch 1241: val_loss did not improve from 13561.30664\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9608.9854 - mean_absolute_error: 9608.9854 - val_loss: 13567.1816 - val_mean_absolute_error: 13567.1816\n",
      "Epoch 1242/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8497.8223 - mean_absolute_error: 8497.8223\n",
      "Epoch 1242: val_loss did not improve from 13561.30664\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9597.1631 - mean_absolute_error: 9597.1631 - val_loss: 13562.2451 - val_mean_absolute_error: 13562.2451\n",
      "Epoch 1243/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10584.5986 - mean_absolute_error: 10584.5986\n",
      "Epoch 1243: val_loss improved from 13561.30664 to 13561.03320, saving model to Weights-01243--13561.03320.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9604.4336 - mean_absolute_error: 9604.4336 - val_loss: 13561.0332 - val_mean_absolute_error: 13561.0332\n",
      "Epoch 1244/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10056.1562 - mean_absolute_error: 10056.1562\n",
      "Epoch 1244: val_loss did not improve from 13561.03320\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9600.9141 - mean_absolute_error: 9600.9141 - val_loss: 13563.1445 - val_mean_absolute_error: 13563.1445\n",
      "Epoch 1245/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10659.3555 - mean_absolute_error: 10659.3555\n",
      "Epoch 1245: val_loss improved from 13561.03320 to 13560.41699, saving model to Weights-01245--13560.41699.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9595.4619 - mean_absolute_error: 9595.4619 - val_loss: 13560.4170 - val_mean_absolute_error: 13560.4170\n",
      "Epoch 1246/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13483.0576 - mean_absolute_error: 13483.0576\n",
      "Epoch 1246: val_loss did not improve from 13560.41699\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9594.8750 - mean_absolute_error: 9594.8750 - val_loss: 13560.7510 - val_mean_absolute_error: 13560.7510\n",
      "Epoch 1247/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10411.4375 - mean_absolute_error: 10411.4375\n",
      "Epoch 1247: val_loss improved from 13560.41699 to 13560.32812, saving model to Weights-01247--13560.32812.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9604.0684 - mean_absolute_error: 9604.0684 - val_loss: 13560.3281 - val_mean_absolute_error: 13560.3281\n",
      "Epoch 1248/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11976.3369 - mean_absolute_error: 11976.3369\n",
      "Epoch 1248: val_loss did not improve from 13560.32812\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9598.4307 - mean_absolute_error: 9598.4307 - val_loss: 13562.2842 - val_mean_absolute_error: 13562.2842\n",
      "Epoch 1249/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7663.8047 - mean_absolute_error: 7663.8047\n",
      "Epoch 1249: val_loss improved from 13560.32812 to 13559.74512, saving model to Weights-01249--13559.74512.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9597.4561 - mean_absolute_error: 9597.4561 - val_loss: 13559.7451 - val_mean_absolute_error: 13559.7451\n",
      "Epoch 1250/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7101.9399 - mean_absolute_error: 7101.9399\n",
      "Epoch 1250: val_loss improved from 13559.74512 to 13559.46680, saving model to Weights-01250--13559.46680.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9598.5625 - mean_absolute_error: 9598.5625 - val_loss: 13559.4668 - val_mean_absolute_error: 13559.4668\n",
      "Epoch 1251/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10223.7676 - mean_absolute_error: 10223.7676\n",
      "Epoch 1251: val_loss did not improve from 13559.46680\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9596.6729 - mean_absolute_error: 9596.6729 - val_loss: 13563.3193 - val_mean_absolute_error: 13563.3193\n",
      "Epoch 1252/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11204.9863 - mean_absolute_error: 11204.9863\n",
      "Epoch 1252: val_loss improved from 13559.46680 to 13559.24512, saving model to Weights-01252--13559.24512.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9599.3076 - mean_absolute_error: 9599.3076 - val_loss: 13559.2451 - val_mean_absolute_error: 13559.2451\n",
      "Epoch 1253/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9845.0078 - mean_absolute_error: 9845.0078\n",
      "Epoch 1253: val_loss did not improve from 13559.24512\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9603.3574 - mean_absolute_error: 9603.3574 - val_loss: 13559.6973 - val_mean_absolute_error: 13559.6973\n",
      "Epoch 1254/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8992.4941 - mean_absolute_error: 8992.4941\n",
      "Epoch 1254: val_loss did not improve from 13559.24512\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9596.0078 - mean_absolute_error: 9596.0078 - val_loss: 13564.2285 - val_mean_absolute_error: 13564.2285\n",
      "Epoch 1255/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11132.5645 - mean_absolute_error: 11132.5645\n",
      "Epoch 1255: val_loss did not improve from 13559.24512\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9598.6123 - mean_absolute_error: 9598.6123 - val_loss: 13560.6406 - val_mean_absolute_error: 13560.6406\n",
      "Epoch 1256/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11441.1279 - mean_absolute_error: 11441.1279\n",
      "Epoch 1256: val_loss did not improve from 13559.24512\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9598.9814 - mean_absolute_error: 9598.9814 - val_loss: 13559.7061 - val_mean_absolute_error: 13559.7061\n",
      "Epoch 1257/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6525.2168 - mean_absolute_error: 6525.2168\n",
      "Epoch 1257: val_loss did not improve from 13559.24512\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9602.7910 - mean_absolute_error: 9602.7910 - val_loss: 13559.5645 - val_mean_absolute_error: 13559.5645\n",
      "Epoch 1258/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13929.8340 - mean_absolute_error: 13929.8340\n",
      "Epoch 1258: val_loss improved from 13559.24512 to 13558.19043, saving model to Weights-01258--13558.19043.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9593.2842 - mean_absolute_error: 9593.2842 - val_loss: 13558.1904 - val_mean_absolute_error: 13558.1904\n",
      "Epoch 1259/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7157.7251 - mean_absolute_error: 7157.7251\n",
      "Epoch 1259: val_loss improved from 13558.19043 to 13558.11035, saving model to Weights-01259--13558.11035.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9603.0840 - mean_absolute_error: 9603.0840 - val_loss: 13558.1104 - val_mean_absolute_error: 13558.1113\n",
      "Epoch 1260/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10639.1348 - mean_absolute_error: 10639.1348\n",
      "Epoch 1260: val_loss did not improve from 13558.11035\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9592.2051 - mean_absolute_error: 9592.2051 - val_loss: 13558.1943 - val_mean_absolute_error: 13558.1943\n",
      "Epoch 1261/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11790.0439 - mean_absolute_error: 11790.0439\n",
      "Epoch 1261: val_loss did not improve from 13558.11035\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9594.2256 - mean_absolute_error: 9594.2256 - val_loss: 13558.2139 - val_mean_absolute_error: 13558.2139\n",
      "Epoch 1262/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9901.8320 - mean_absolute_error: 9901.8320\n",
      "Epoch 1262: val_loss did not improve from 13558.11035\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9594.4854 - mean_absolute_error: 9594.4854 - val_loss: 13558.6562 - val_mean_absolute_error: 13558.6562\n",
      "Epoch 1263/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10444.0146 - mean_absolute_error: 10444.0146\n",
      "Epoch 1263: val_loss improved from 13558.11035 to 13557.22070, saving model to Weights-01263--13557.22070.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9597.5264 - mean_absolute_error: 9597.5264 - val_loss: 13557.2207 - val_mean_absolute_error: 13557.2207\n",
      "Epoch 1264/3000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9383.8135 - mean_absolute_error: 9383.8135\n",
      "Epoch 1264: val_loss did not improve from 13557.22070\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9599.8779 - mean_absolute_error: 9599.8779 - val_loss: 13558.7744 - val_mean_absolute_error: 13558.7744\n",
      "Epoch 1265/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9656.5820 - mean_absolute_error: 9656.5820\n",
      "Epoch 1265: val_loss did not improve from 13557.22070\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9594.7305 - mean_absolute_error: 9594.7305 - val_loss: 13558.8018 - val_mean_absolute_error: 13558.8018\n",
      "Epoch 1266/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11887.3125 - mean_absolute_error: 11887.3125\n",
      "Epoch 1266: val_loss did not improve from 13557.22070\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9593.3496 - mean_absolute_error: 9593.3496 - val_loss: 13557.8242 - val_mean_absolute_error: 13557.8242\n",
      "Epoch 1267/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10912.3887 - mean_absolute_error: 10912.3887\n",
      "Epoch 1267: val_loss improved from 13557.22070 to 13557.10840, saving model to Weights-01267--13557.10840.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9605.2275 - mean_absolute_error: 9605.2275 - val_loss: 13557.1084 - val_mean_absolute_error: 13557.1084\n",
      "Epoch 1268/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6667.6235 - mean_absolute_error: 6667.6235\n",
      "Epoch 1268: val_loss did not improve from 13557.10840\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9591.1348 - mean_absolute_error: 9591.1348 - val_loss: 13558.7695 - val_mean_absolute_error: 13558.7695\n",
      "Epoch 1269/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11499.1855 - mean_absolute_error: 11499.1855\n",
      "Epoch 1269: val_loss did not improve from 13557.10840\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9598.3682 - mean_absolute_error: 9598.3682 - val_loss: 13558.4502 - val_mean_absolute_error: 13558.4502\n",
      "Epoch 1270/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10795.0908 - mean_absolute_error: 10795.0908\n",
      "Epoch 1270: val_loss did not improve from 13557.10840\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9589.2158 - mean_absolute_error: 9589.2158 - val_loss: 13557.5078 - val_mean_absolute_error: 13557.5078\n",
      "Epoch 1271/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9307.2432 - mean_absolute_error: 9307.2432\n",
      "Epoch 1271: val_loss improved from 13557.10840 to 13555.82422, saving model to Weights-01271--13555.82422.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9588.2236 - mean_absolute_error: 9588.2236 - val_loss: 13555.8242 - val_mean_absolute_error: 13555.8242\n",
      "Epoch 1272/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7094.1133 - mean_absolute_error: 7094.1133\n",
      "Epoch 1272: val_loss improved from 13555.82422 to 13555.72852, saving model to Weights-01272--13555.72852.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9592.2432 - mean_absolute_error: 9592.2432 - val_loss: 13555.7285 - val_mean_absolute_error: 13555.7285\n",
      "Epoch 1273/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8053.9004 - mean_absolute_error: 8053.9004\n",
      "Epoch 1273: val_loss did not improve from 13555.72852\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9591.6895 - mean_absolute_error: 9591.6895 - val_loss: 13557.7178 - val_mean_absolute_error: 13557.7178\n",
      "Epoch 1274/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9194.4453 - mean_absolute_error: 9194.4453\n",
      "Epoch 1274: val_loss did not improve from 13555.72852\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9591.8828 - mean_absolute_error: 9591.8828 - val_loss: 13557.0469 - val_mean_absolute_error: 13557.0469\n",
      "Epoch 1275/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8711.8838 - mean_absolute_error: 8711.8838\n",
      "Epoch 1275: val_loss did not improve from 13555.72852\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9591.2461 - mean_absolute_error: 9591.2461 - val_loss: 13557.6611 - val_mean_absolute_error: 13557.6611\n",
      "Epoch 1276/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6167.9072 - mean_absolute_error: 6167.9072\n",
      "Epoch 1276: val_loss did not improve from 13555.72852\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9590.4854 - mean_absolute_error: 9590.4854 - val_loss: 13556.4072 - val_mean_absolute_error: 13556.4072\n",
      "Epoch 1277/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9407.0088 - mean_absolute_error: 9407.0088\n",
      "Epoch 1277: val_loss improved from 13555.72852 to 13554.78906, saving model to Weights-01277--13554.78906.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9588.7627 - mean_absolute_error: 9588.7627 - val_loss: 13554.7891 - val_mean_absolute_error: 13554.7891\n",
      "Epoch 1278/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9625.2510 - mean_absolute_error: 9625.2510\n",
      "Epoch 1278: val_loss did not improve from 13554.78906\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9599.6299 - mean_absolute_error: 9599.6299 - val_loss: 13558.2451 - val_mean_absolute_error: 13558.2451\n",
      "Epoch 1279/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9626.4062 - mean_absolute_error: 9626.4062\n",
      "Epoch 1279: val_loss improved from 13554.78906 to 13554.49316, saving model to Weights-01279--13554.49316.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9586.6602 - mean_absolute_error: 9586.6602 - val_loss: 13554.4932 - val_mean_absolute_error: 13554.4932\n",
      "Epoch 1280/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10501.4893 - mean_absolute_error: 10501.4893\n",
      "Epoch 1280: val_loss did not improve from 13554.49316\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9593.5820 - mean_absolute_error: 9593.5820 - val_loss: 13555.4385 - val_mean_absolute_error: 13555.4385\n",
      "Epoch 1281/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8918.3301 - mean_absolute_error: 8918.3301\n",
      "Epoch 1281: val_loss did not improve from 13554.49316\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9589.7822 - mean_absolute_error: 9589.7822 - val_loss: 13555.3076 - val_mean_absolute_error: 13555.3076\n",
      "Epoch 1282/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8890.1094 - mean_absolute_error: 8890.1094\n",
      "Epoch 1282: val_loss did not improve from 13554.49316\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9595.9688 - mean_absolute_error: 9595.9688 - val_loss: 13555.2363 - val_mean_absolute_error: 13555.2363\n",
      "Epoch 1283/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7661.5684 - mean_absolute_error: 7661.5684\n",
      "Epoch 1283: val_loss did not improve from 13554.49316\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9587.6328 - mean_absolute_error: 9587.6328 - val_loss: 13555.6963 - val_mean_absolute_error: 13555.6963\n",
      "Epoch 1284/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13243.3848 - mean_absolute_error: 13243.3848\n",
      "Epoch 1284: val_loss improved from 13554.49316 to 13553.63672, saving model to Weights-01284--13553.63672.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9592.3701 - mean_absolute_error: 9592.3701 - val_loss: 13553.6367 - val_mean_absolute_error: 13553.6367\n",
      "Epoch 1285/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8390.3242 - mean_absolute_error: 8390.3242\n",
      "Epoch 1285: val_loss did not improve from 13553.63672\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9587.2666 - mean_absolute_error: 9587.2666 - val_loss: 13555.9521 - val_mean_absolute_error: 13555.9521\n",
      "Epoch 1286/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8347.5293 - mean_absolute_error: 8347.5293\n",
      "Epoch 1286: val_loss improved from 13553.63672 to 13553.24609, saving model to Weights-01286--13553.24609.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9582.3486 - mean_absolute_error: 9582.3486 - val_loss: 13553.2461 - val_mean_absolute_error: 13553.2461\n",
      "Epoch 1287/3000\n",
      " 8/18 [============>.................] - ETA: 0s - loss: 9331.3867 - mean_absolute_error: 9331.3867\n",
      "Epoch 1287: val_loss improved from 13553.24609 to 13552.98242, saving model to Weights-01287--13552.98242.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9588.5146 - mean_absolute_error: 9588.5146 - val_loss: 13552.9824 - val_mean_absolute_error: 13552.9824\n",
      "Epoch 1288/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10043.1992 - mean_absolute_error: 10043.1992\n",
      "Epoch 1288: val_loss did not improve from 13552.98242\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9587.2617 - mean_absolute_error: 9587.2617 - val_loss: 13554.2441 - val_mean_absolute_error: 13554.2441\n",
      "Epoch 1289/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7743.8428 - mean_absolute_error: 7743.8428\n",
      "Epoch 1289: val_loss did not improve from 13552.98242\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9584.7773 - mean_absolute_error: 9584.7773 - val_loss: 13553.3555 - val_mean_absolute_error: 13553.3555\n",
      "Epoch 1290/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7607.0869 - mean_absolute_error: 7607.0869\n",
      "Epoch 1290: val_loss improved from 13552.98242 to 13552.44336, saving model to Weights-01290--13552.44336.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9587.9023 - mean_absolute_error: 9587.9023 - val_loss: 13552.4434 - val_mean_absolute_error: 13552.4434\n",
      "Epoch 1291/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10480.2617 - mean_absolute_error: 10480.2617\n",
      "Epoch 1291: val_loss did not improve from 13552.44336\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9594.3877 - mean_absolute_error: 9594.3877 - val_loss: 13558.8789 - val_mean_absolute_error: 13558.8789\n",
      "Epoch 1292/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8491.8691 - mean_absolute_error: 8491.8691\n",
      "Epoch 1292: val_loss did not improve from 13552.44336\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9599.1924 - mean_absolute_error: 9599.1924 - val_loss: 13556.3496 - val_mean_absolute_error: 13556.3496\n",
      "Epoch 1293/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11260.4297 - mean_absolute_error: 11260.4297\n",
      "Epoch 1293: val_loss did not improve from 13552.44336\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9596.0488 - mean_absolute_error: 9596.0488 - val_loss: 13555.1201 - val_mean_absolute_error: 13555.1201\n",
      "Epoch 1294/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9966.0566 - mean_absolute_error: 9966.0566\n",
      "Epoch 1294: val_loss did not improve from 13552.44336\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9589.5215 - mean_absolute_error: 9589.5215 - val_loss: 13553.1523 - val_mean_absolute_error: 13553.1523\n",
      "Epoch 1295/3000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9507.7881 - mean_absolute_error: 9507.7881  \n",
      "Epoch 1295: val_loss did not improve from 13552.44336\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9600.7373 - mean_absolute_error: 9600.7373 - val_loss: 13552.9932 - val_mean_absolute_error: 13552.9932\n",
      "Epoch 1296/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8252.7783 - mean_absolute_error: 8252.7783\n",
      "Epoch 1296: val_loss did not improve from 13552.44336\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9585.3076 - mean_absolute_error: 9585.3076 - val_loss: 13552.8447 - val_mean_absolute_error: 13552.8447\n",
      "Epoch 1297/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9373.8828 - mean_absolute_error: 9373.8828\n",
      "Epoch 1297: val_loss improved from 13552.44336 to 13551.20410, saving model to Weights-01297--13551.20410.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9585.6387 - mean_absolute_error: 9585.6387 - val_loss: 13551.2041 - val_mean_absolute_error: 13551.2041\n",
      "Epoch 1298/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7938.6831 - mean_absolute_error: 7938.6831\n",
      "Epoch 1298: val_loss did not improve from 13551.20410\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9584.9775 - mean_absolute_error: 9584.9775 - val_loss: 13551.2061 - val_mean_absolute_error: 13551.2061\n",
      "Epoch 1299/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10657.0176 - mean_absolute_error: 10657.0176\n",
      "Epoch 1299: val_loss did not improve from 13551.20410\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9581.6611 - mean_absolute_error: 9581.6611 - val_loss: 13554.5244 - val_mean_absolute_error: 13554.5244\n",
      "Epoch 1300/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11468.3828 - mean_absolute_error: 11468.3828\n",
      "Epoch 1300: val_loss improved from 13551.20410 to 13550.71582, saving model to Weights-01300--13550.71582.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9591.8965 - mean_absolute_error: 9591.8965 - val_loss: 13550.7158 - val_mean_absolute_error: 13550.7158\n",
      "Epoch 1301/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10350.9824 - mean_absolute_error: 10350.9824\n",
      "Epoch 1301: val_loss did not improve from 13550.71582\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9585.0557 - mean_absolute_error: 9585.0557 - val_loss: 13551.3594 - val_mean_absolute_error: 13551.3594\n",
      "Epoch 1302/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8398.7324 - mean_absolute_error: 8398.7324\n",
      "Epoch 1302: val_loss did not improve from 13550.71582\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9580.2646 - mean_absolute_error: 9580.2646 - val_loss: 13551.5107 - val_mean_absolute_error: 13551.5107\n",
      "Epoch 1303/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11815.4961 - mean_absolute_error: 11815.4961\n",
      "Epoch 1303: val_loss improved from 13550.71582 to 13550.62207, saving model to Weights-01303--13550.62207.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9586.5889 - mean_absolute_error: 9586.5889 - val_loss: 13550.6221 - val_mean_absolute_error: 13550.6221\n",
      "Epoch 1304/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9278.0898 - mean_absolute_error: 9278.0898\n",
      "Epoch 1304: val_loss did not improve from 13550.62207\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9579.2363 - mean_absolute_error: 9579.2363 - val_loss: 13551.5283 - val_mean_absolute_error: 13551.5283\n",
      "Epoch 1305/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12716.9102 - mean_absolute_error: 12716.9102\n",
      "Epoch 1305: val_loss did not improve from 13550.62207\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9588.1445 - mean_absolute_error: 9588.1445 - val_loss: 13553.0068 - val_mean_absolute_error: 13553.0068\n",
      "Epoch 1306/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10466.4863 - mean_absolute_error: 10466.4863\n",
      "Epoch 1306: val_loss improved from 13550.62207 to 13549.75586, saving model to Weights-01306--13549.75586.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9582.8594 - mean_absolute_error: 9582.8594 - val_loss: 13549.7559 - val_mean_absolute_error: 13549.7559\n",
      "Epoch 1307/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11245.3320 - mean_absolute_error: 11245.3320\n",
      "Epoch 1307: val_loss did not improve from 13549.75586\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9584.2529 - mean_absolute_error: 9584.2529 - val_loss: 13550.8809 - val_mean_absolute_error: 13550.8809\n",
      "Epoch 1308/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8443.2939 - mean_absolute_error: 8443.2939\n",
      "Epoch 1308: val_loss improved from 13549.75586 to 13549.34570, saving model to Weights-01308--13549.34570.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9585.9521 - mean_absolute_error: 9585.9521 - val_loss: 13549.3457 - val_mean_absolute_error: 13549.3457\n",
      "Epoch 1309/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6870.7842 - mean_absolute_error: 6870.7842\n",
      "Epoch 1309: val_loss did not improve from 13549.34570\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9583.0107 - mean_absolute_error: 9583.0107 - val_loss: 13554.7539 - val_mean_absolute_error: 13554.7539\n",
      "Epoch 1310/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10682.3467 - mean_absolute_error: 10682.3467\n",
      "Epoch 1310: val_loss did not improve from 13549.34570\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9583.9287 - mean_absolute_error: 9583.9287 - val_loss: 13549.4229 - val_mean_absolute_error: 13549.4229\n",
      "Epoch 1311/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11688.5967 - mean_absolute_error: 11688.5967\n",
      "Epoch 1311: val_loss improved from 13549.34570 to 13549.25684, saving model to Weights-01311--13549.25684.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9580.7861 - mean_absolute_error: 9580.7861 - val_loss: 13549.2568 - val_mean_absolute_error: 13549.2568\n",
      "Epoch 1312/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9782.8066 - mean_absolute_error: 9782.8066\n",
      "Epoch 1312: val_loss improved from 13549.25684 to 13548.67285, saving model to Weights-01312--13548.67285.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9580.9932 - mean_absolute_error: 9580.9932 - val_loss: 13548.6729 - val_mean_absolute_error: 13548.6729\n",
      "Epoch 1313/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9212.4502 - mean_absolute_error: 9212.4502\n",
      "Epoch 1313: val_loss improved from 13548.67285 to 13548.48047, saving model to Weights-01313--13548.48047.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9580.3633 - mean_absolute_error: 9580.3633 - val_loss: 13548.4805 - val_mean_absolute_error: 13548.4805\n",
      "Epoch 1314/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13398.7324 - mean_absolute_error: 13398.7324\n",
      "Epoch 1314: val_loss did not improve from 13548.48047\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9578.6797 - mean_absolute_error: 9578.6797 - val_loss: 13551.2969 - val_mean_absolute_error: 13551.2969\n",
      "Epoch 1315/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8911.2109 - mean_absolute_error: 8911.2109\n",
      "Epoch 1315: val_loss did not improve from 13548.48047\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9578.9561 - mean_absolute_error: 9578.9561 - val_loss: 13549.4746 - val_mean_absolute_error: 13549.4746\n",
      "Epoch 1316/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12465.8066 - mean_absolute_error: 12465.8066\n",
      "Epoch 1316: val_loss did not improve from 13548.48047\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9583.3291 - mean_absolute_error: 9583.3291 - val_loss: 13548.9229 - val_mean_absolute_error: 13548.9229\n",
      "Epoch 1317/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8815.9258 - mean_absolute_error: 8815.9258\n",
      "Epoch 1317: val_loss improved from 13548.48047 to 13548.22363, saving model to Weights-01317--13548.22363.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9583.5674 - mean_absolute_error: 9583.5674 - val_loss: 13548.2236 - val_mean_absolute_error: 13548.2236\n",
      "Epoch 1318/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8111.2358 - mean_absolute_error: 8111.2358\n",
      "Epoch 1318: val_loss improved from 13548.22363 to 13547.56445, saving model to Weights-01318--13547.56445.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9579.1436 - mean_absolute_error: 9579.1436 - val_loss: 13547.5645 - val_mean_absolute_error: 13547.5645\n",
      "Epoch 1319/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8343.4355 - mean_absolute_error: 8343.4355\n",
      "Epoch 1319: val_loss did not improve from 13547.56445\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9582.1973 - mean_absolute_error: 9582.1973 - val_loss: 13548.2861 - val_mean_absolute_error: 13548.2861\n",
      "Epoch 1320/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6988.8047 - mean_absolute_error: 6988.8047\n",
      "Epoch 1320: val_loss did not improve from 13547.56445\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9595.2881 - mean_absolute_error: 9595.2881 - val_loss: 13551.7666 - val_mean_absolute_error: 13551.7666\n",
      "Epoch 1321/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7251.0239 - mean_absolute_error: 7251.0239\n",
      "Epoch 1321: val_loss did not improve from 13547.56445\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9590.5225 - mean_absolute_error: 9590.5225 - val_loss: 13551.2578 - val_mean_absolute_error: 13551.2578\n",
      "Epoch 1322/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7838.0820 - mean_absolute_error: 7838.0820\n",
      "Epoch 1322: val_loss did not improve from 13547.56445\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9620.0645 - mean_absolute_error: 9620.0645 - val_loss: 13555.7246 - val_mean_absolute_error: 13555.7246\n",
      "Epoch 1323/3000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9591.4111 - mean_absolute_error: 9591.4111\n",
      "Epoch 1323: val_loss did not improve from 13547.56445\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9590.5850 - mean_absolute_error: 9590.5850 - val_loss: 13552.3057 - val_mean_absolute_error: 13552.3057\n",
      "Epoch 1324/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10704.8760 - mean_absolute_error: 10704.8760\n",
      "Epoch 1324: val_loss improved from 13547.56445 to 13547.02832, saving model to Weights-01324--13547.02832.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9588.0410 - mean_absolute_error: 9588.0410 - val_loss: 13547.0283 - val_mean_absolute_error: 13547.0283\n",
      "Epoch 1325/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9568.0801 - mean_absolute_error: 9568.0801\n",
      "Epoch 1325: val_loss improved from 13547.02832 to 13546.26562, saving model to Weights-01325--13546.26562.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9584.2900 - mean_absolute_error: 9584.2900 - val_loss: 13546.2656 - val_mean_absolute_error: 13546.2656\n",
      "Epoch 1326/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10688.9824 - mean_absolute_error: 10688.9824\n",
      "Epoch 1326: val_loss improved from 13546.26562 to 13546.19238, saving model to Weights-01326--13546.19238.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9578.6787 - mean_absolute_error: 9578.6787 - val_loss: 13546.1924 - val_mean_absolute_error: 13546.1924\n",
      "Epoch 1327/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11869.8896 - mean_absolute_error: 11869.8896\n",
      "Epoch 1327: val_loss improved from 13546.19238 to 13546.01172, saving model to Weights-01327--13546.01172.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9574.8486 - mean_absolute_error: 9574.8486 - val_loss: 13546.0117 - val_mean_absolute_error: 13546.0117\n",
      "Epoch 1328/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13480.8057 - mean_absolute_error: 13480.8057\n",
      "Epoch 1328: val_loss improved from 13546.01172 to 13545.80957, saving model to Weights-01328--13545.80957.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9574.8770 - mean_absolute_error: 9574.8770 - val_loss: 13545.8096 - val_mean_absolute_error: 13545.8096\n",
      "Epoch 1329/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13528.1523 - mean_absolute_error: 13528.1523\n",
      "Epoch 1329: val_loss did not improve from 13545.80957\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9577.3818 - mean_absolute_error: 9577.3818 - val_loss: 13548.4404 - val_mean_absolute_error: 13548.4404\n",
      "Epoch 1330/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10535.6904 - mean_absolute_error: 10535.6904\n",
      "Epoch 1330: val_loss improved from 13545.80957 to 13545.37402, saving model to Weights-01330--13545.37402.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9574.8555 - mean_absolute_error: 9574.8555 - val_loss: 13545.3740 - val_mean_absolute_error: 13545.3740\n",
      "Epoch 1331/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7576.2393 - mean_absolute_error: 7576.2393\n",
      "Epoch 1331: val_loss improved from 13545.37402 to 13545.08594, saving model to Weights-01331--13545.08594.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9585.7656 - mean_absolute_error: 9585.7656 - val_loss: 13545.0859 - val_mean_absolute_error: 13545.0859\n",
      "Epoch 1332/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7513.0361 - mean_absolute_error: 7513.0361\n",
      "Epoch 1332: val_loss did not improve from 13545.08594\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9568.0283 - mean_absolute_error: 9568.0283 - val_loss: 13550.1631 - val_mean_absolute_error: 13550.1631\n",
      "Epoch 1333/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10846.2363 - mean_absolute_error: 10846.2363\n",
      "Epoch 1333: val_loss improved from 13545.08594 to 13544.85547, saving model to Weights-01333--13544.85547.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9591.9717 - mean_absolute_error: 9591.9717 - val_loss: 13544.8555 - val_mean_absolute_error: 13544.8545\n",
      "Epoch 1334/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8907.6904 - mean_absolute_error: 8907.6904\n",
      "Epoch 1334: val_loss improved from 13544.85547 to 13544.55762, saving model to Weights-01334--13544.55762.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9576.8984 - mean_absolute_error: 9576.8984 - val_loss: 13544.5576 - val_mean_absolute_error: 13544.5576\n",
      "Epoch 1335/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10131.2500 - mean_absolute_error: 10131.2500\n",
      "Epoch 1335: val_loss did not improve from 13544.55762\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9590.0957 - mean_absolute_error: 9590.0957 - val_loss: 13550.8262 - val_mean_absolute_error: 13550.8262\n",
      "Epoch 1336/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7534.6196 - mean_absolute_error: 7534.6196\n",
      "Epoch 1336: val_loss did not improve from 13544.55762\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9567.8350 - mean_absolute_error: 9567.8350 - val_loss: 13544.8389 - val_mean_absolute_error: 13544.8389\n",
      "Epoch 1337/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10160.3184 - mean_absolute_error: 10160.3184\n",
      "Epoch 1337: val_loss did not improve from 13544.55762\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9586.3535 - mean_absolute_error: 9586.3535 - val_loss: 13546.0186 - val_mean_absolute_error: 13546.0186\n",
      "Epoch 1338/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8152.9912 - mean_absolute_error: 8152.9912\n",
      "Epoch 1338: val_loss did not improve from 13544.55762\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9575.9502 - mean_absolute_error: 9575.9502 - val_loss: 13545.9961 - val_mean_absolute_error: 13545.9961\n",
      "Epoch 1339/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10849.2168 - mean_absolute_error: 10849.2168\n",
      "Epoch 1339: val_loss improved from 13544.55762 to 13544.03809, saving model to Weights-01339--13544.03809.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9578.8926 - mean_absolute_error: 9578.8926 - val_loss: 13544.0381 - val_mean_absolute_error: 13544.0381\n",
      "Epoch 1340/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6130.5674 - mean_absolute_error: 6130.5674\n",
      "Epoch 1340: val_loss improved from 13544.03809 to 13544.00684, saving model to Weights-01340--13544.00684.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9571.1484 - mean_absolute_error: 9571.1484 - val_loss: 13544.0068 - val_mean_absolute_error: 13544.0068\n",
      "Epoch 1341/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10462.2402 - mean_absolute_error: 10462.2402\n",
      "Epoch 1341: val_loss improved from 13544.00684 to 13543.37012, saving model to Weights-01341--13543.37012.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9578.0000 - mean_absolute_error: 9578.0000 - val_loss: 13543.3701 - val_mean_absolute_error: 13543.3701\n",
      "Epoch 1342/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10427.6895 - mean_absolute_error: 10427.6895\n",
      "Epoch 1342: val_loss did not improve from 13543.37012\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9583.4590 - mean_absolute_error: 9583.4590 - val_loss: 13544.8047 - val_mean_absolute_error: 13544.8047\n",
      "Epoch 1343/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10882.7324 - mean_absolute_error: 10882.7324\n",
      "Epoch 1343: val_loss improved from 13543.37012 to 13542.93359, saving model to Weights-01343--13542.93359.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9568.8496 - mean_absolute_error: 9568.8496 - val_loss: 13542.9336 - val_mean_absolute_error: 13542.9336\n",
      "Epoch 1344/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7418.4580 - mean_absolute_error: 7418.4580\n",
      "Epoch 1344: val_loss improved from 13542.93359 to 13542.77148, saving model to Weights-01344--13542.77148.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9572.8594 - mean_absolute_error: 9572.8594 - val_loss: 13542.7715 - val_mean_absolute_error: 13542.7715\n",
      "Epoch 1345/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6835.0303 - mean_absolute_error: 6835.0303\n",
      "Epoch 1345: val_loss improved from 13542.77148 to 13542.51953, saving model to Weights-01345--13542.51953.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9574.6680 - mean_absolute_error: 9574.6680 - val_loss: 13542.5195 - val_mean_absolute_error: 13542.5195\n",
      "Epoch 1346/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11797.8535 - mean_absolute_error: 11797.8535\n",
      "Epoch 1346: val_loss did not improve from 13542.51953\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9572.8984 - mean_absolute_error: 9572.8984 - val_loss: 13542.9395 - val_mean_absolute_error: 13542.9395\n",
      "Epoch 1347/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9607.3340 - mean_absolute_error: 9607.3340\n",
      "Epoch 1347: val_loss improved from 13542.51953 to 13542.18164, saving model to Weights-01347--13542.18164.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9568.0557 - mean_absolute_error: 9568.0557 - val_loss: 13542.1816 - val_mean_absolute_error: 13542.1816\n",
      "Epoch 1348/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8331.3594 - mean_absolute_error: 8331.3594\n",
      "Epoch 1348: val_loss improved from 13542.18164 to 13541.88379, saving model to Weights-01348--13541.88379.hdf5\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9578.2246 - mean_absolute_error: 9578.2246 - val_loss: 13541.8838 - val_mean_absolute_error: 13541.8838\n",
      "Epoch 1349/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10516.1641 - mean_absolute_error: 10516.1641\n",
      "Epoch 1349: val_loss did not improve from 13541.88379\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9574.5703 - mean_absolute_error: 9574.5703 - val_loss: 13543.2354 - val_mean_absolute_error: 13543.2354\n",
      "Epoch 1350/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9349.5117 - mean_absolute_error: 9349.5117\n",
      "Epoch 1350: val_loss did not improve from 13541.88379\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9572.5156 - mean_absolute_error: 9572.5156 - val_loss: 13542.3721 - val_mean_absolute_error: 13542.3721\n",
      "Epoch 1351/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12190.9395 - mean_absolute_error: 12190.9395\n",
      "Epoch 1351: val_loss improved from 13541.88379 to 13541.47559, saving model to Weights-01351--13541.47559.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9572.9385 - mean_absolute_error: 9572.9385 - val_loss: 13541.4756 - val_mean_absolute_error: 13541.4756\n",
      "Epoch 1352/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9326.3086 - mean_absolute_error: 9326.3086\n",
      "Epoch 1352: val_loss did not improve from 13541.47559\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9564.7686 - mean_absolute_error: 9564.7686 - val_loss: 13543.4375 - val_mean_absolute_error: 13543.4375\n",
      "Epoch 1353/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10984.2432 - mean_absolute_error: 10984.2432\n",
      "Epoch 1353: val_loss improved from 13541.47559 to 13541.09277, saving model to Weights-01353--13541.09277.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9580.5586 - mean_absolute_error: 9580.5586 - val_loss: 13541.0928 - val_mean_absolute_error: 13541.0928\n",
      "Epoch 1354/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11266.8340 - mean_absolute_error: 11266.8340\n",
      "Epoch 1354: val_loss did not improve from 13541.09277\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9566.7500 - mean_absolute_error: 9566.7500 - val_loss: 13542.1768 - val_mean_absolute_error: 13542.1768\n",
      "Epoch 1355/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6962.2930 - mean_absolute_error: 6962.2930\n",
      "Epoch 1355: val_loss did not improve from 13541.09277\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9570.7822 - mean_absolute_error: 9570.7822 - val_loss: 13542.3994 - val_mean_absolute_error: 13542.3994\n",
      "Epoch 1356/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10533.6650 - mean_absolute_error: 10533.6650\n",
      "Epoch 1356: val_loss did not improve from 13541.09277\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9569.7305 - mean_absolute_error: 9569.7305 - val_loss: 13542.7314 - val_mean_absolute_error: 13542.7314\n",
      "Epoch 1357/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10533.0293 - mean_absolute_error: 10533.0293\n",
      "Epoch 1357: val_loss improved from 13541.09277 to 13540.31348, saving model to Weights-01357--13540.31348.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9571.3066 - mean_absolute_error: 9571.3066 - val_loss: 13540.3135 - val_mean_absolute_error: 13540.3135\n",
      "Epoch 1358/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10609.5117 - mean_absolute_error: 10609.5117\n",
      "Epoch 1358: val_loss did not improve from 13540.31348\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9570.2275 - mean_absolute_error: 9570.2275 - val_loss: 13541.7227 - val_mean_absolute_error: 13541.7227\n",
      "Epoch 1359/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10748.3857 - mean_absolute_error: 10748.3857\n",
      "Epoch 1359: val_loss improved from 13540.31348 to 13539.97461, saving model to Weights-01359--13539.97461.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9567.5098 - mean_absolute_error: 9567.5098 - val_loss: 13539.9746 - val_mean_absolute_error: 13539.9746\n",
      "Epoch 1360/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13260.6025 - mean_absolute_error: 13260.6025\n",
      "Epoch 1360: val_loss did not improve from 13539.97461\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9566.4619 - mean_absolute_error: 9566.4619 - val_loss: 13540.3359 - val_mean_absolute_error: 13540.3359\n",
      "Epoch 1361/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12324.7539 - mean_absolute_error: 12324.7539\n",
      "Epoch 1361: val_loss did not improve from 13539.97461\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9574.8906 - mean_absolute_error: 9574.8906 - val_loss: 13540.3242 - val_mean_absolute_error: 13540.3242\n",
      "Epoch 1362/3000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9648.7451 - mean_absolute_error: 9648.7451\n",
      "Epoch 1362: val_loss improved from 13539.97461 to 13539.33203, saving model to Weights-01362--13539.33203.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9568.8594 - mean_absolute_error: 9568.8594 - val_loss: 13539.3320 - val_mean_absolute_error: 13539.3320\n",
      "Epoch 1363/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8707.8770 - mean_absolute_error: 8707.8770\n",
      "Epoch 1363: val_loss did not improve from 13539.33203\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9583.6709 - mean_absolute_error: 9583.6709 - val_loss: 13542.3711 - val_mean_absolute_error: 13542.3711\n",
      "Epoch 1364/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12651.4092 - mean_absolute_error: 12651.4092\n",
      "Epoch 1364: val_loss did not improve from 13539.33203\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9566.8301 - mean_absolute_error: 9566.8301 - val_loss: 13541.4980 - val_mean_absolute_error: 13541.4980\n",
      "Epoch 1365/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7898.1279 - mean_absolute_error: 7898.1279\n",
      "Epoch 1365: val_loss improved from 13539.33203 to 13538.76855, saving model to Weights-01365--13538.76855.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9574.0850 - mean_absolute_error: 9574.0850 - val_loss: 13538.7686 - val_mean_absolute_error: 13538.7686\n",
      "Epoch 1366/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10537.0283 - mean_absolute_error: 10537.0283\n",
      "Epoch 1366: val_loss improved from 13538.76855 to 13538.70508, saving model to Weights-01366--13538.70508.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9564.3701 - mean_absolute_error: 9564.3701 - val_loss: 13538.7051 - val_mean_absolute_error: 13538.7051\n",
      "Epoch 1367/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9889.2090 - mean_absolute_error: 9889.2090\n",
      "Epoch 1367: val_loss did not improve from 13538.70508\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9574.9971 - mean_absolute_error: 9574.9971 - val_loss: 13539.5107 - val_mean_absolute_error: 13539.5107\n",
      "Epoch 1368/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10815.2617 - mean_absolute_error: 10815.2617\n",
      "Epoch 1368: val_loss did not improve from 13538.70508\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9569.6484 - mean_absolute_error: 9569.6484 - val_loss: 13539.9873 - val_mean_absolute_error: 13539.9873\n",
      "Epoch 1369/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11363.0742 - mean_absolute_error: 11363.0742\n",
      "Epoch 1369: val_loss improved from 13538.70508 to 13538.42383, saving model to Weights-01369--13538.42383.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9575.9629 - mean_absolute_error: 9575.9629 - val_loss: 13538.4238 - val_mean_absolute_error: 13538.4238\n",
      "Epoch 1370/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10450.7949 - mean_absolute_error: 10450.7949\n",
      "Epoch 1370: val_loss improved from 13538.42383 to 13537.94824, saving model to Weights-01370--13537.94824.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9562.4805 - mean_absolute_error: 9562.4805 - val_loss: 13537.9482 - val_mean_absolute_error: 13537.9482\n",
      "Epoch 1371/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11752.2773 - mean_absolute_error: 11752.2773\n",
      "Epoch 1371: val_loss did not improve from 13537.94824\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9559.8838 - mean_absolute_error: 9559.8838 - val_loss: 13541.8994 - val_mean_absolute_error: 13541.8994\n",
      "Epoch 1372/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9028.9893 - mean_absolute_error: 9028.9893\n",
      "Epoch 1372: val_loss did not improve from 13537.94824\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9570.3730 - mean_absolute_error: 9570.3730 - val_loss: 13541.1992 - val_mean_absolute_error: 13541.1992\n",
      "Epoch 1373/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10226.0430 - mean_absolute_error: 10226.0430\n",
      "Epoch 1373: val_loss improved from 13537.94824 to 13537.31250, saving model to Weights-01373--13537.31250.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9566.6572 - mean_absolute_error: 9566.6572 - val_loss: 13537.3125 - val_mean_absolute_error: 13537.3125\n",
      "Epoch 1374/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8412.2275 - mean_absolute_error: 8412.2275\n",
      "Epoch 1374: val_loss improved from 13537.31250 to 13537.07422, saving model to Weights-01374--13537.07422.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9564.2021 - mean_absolute_error: 9564.2021 - val_loss: 13537.0742 - val_mean_absolute_error: 13537.0742\n",
      "Epoch 1375/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10145.7598 - mean_absolute_error: 10145.7598\n",
      "Epoch 1375: val_loss did not improve from 13537.07422\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9566.4531 - mean_absolute_error: 9566.4531 - val_loss: 13537.8701 - val_mean_absolute_error: 13537.8701\n",
      "Epoch 1376/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6567.1250 - mean_absolute_error: 6567.1250\n",
      "Epoch 1376: val_loss did not improve from 13537.07422\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9568.7080 - mean_absolute_error: 9568.7080 - val_loss: 13539.5928 - val_mean_absolute_error: 13539.5928\n",
      "Epoch 1377/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10919.5898 - mean_absolute_error: 10919.5898\n",
      "Epoch 1377: val_loss did not improve from 13537.07422\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9567.0381 - mean_absolute_error: 9567.0381 - val_loss: 13539.3398 - val_mean_absolute_error: 13539.3398\n",
      "Epoch 1378/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8428.5684 - mean_absolute_error: 8428.5684\n",
      "Epoch 1378: val_loss did not improve from 13537.07422\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9572.4795 - mean_absolute_error: 9572.4795 - val_loss: 13539.4785 - val_mean_absolute_error: 13539.4785\n",
      "Epoch 1379/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6592.0430 - mean_absolute_error: 6592.0430\n",
      "Epoch 1379: val_loss improved from 13537.07422 to 13536.44727, saving model to Weights-01379--13536.44727.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9564.1924 - mean_absolute_error: 9564.1924 - val_loss: 13536.4473 - val_mean_absolute_error: 13536.4473\n",
      "Epoch 1380/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9752.0918 - mean_absolute_error: 9752.0918\n",
      "Epoch 1380: val_loss improved from 13536.44727 to 13535.98926, saving model to Weights-01380--13535.98926.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9566.4521 - mean_absolute_error: 9566.4521 - val_loss: 13535.9893 - val_mean_absolute_error: 13535.9893\n",
      "Epoch 1381/3000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9577.4268 - mean_absolute_error: 9577.4268\n",
      "Epoch 1381: val_loss did not improve from 13535.98926\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9566.5039 - mean_absolute_error: 9566.5039 - val_loss: 13537.1338 - val_mean_absolute_error: 13537.1338\n",
      "Epoch 1382/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9330.2012 - mean_absolute_error: 9330.2012\n",
      "Epoch 1382: val_loss did not improve from 13535.98926\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9561.9053 - mean_absolute_error: 9561.9053 - val_loss: 13538.3682 - val_mean_absolute_error: 13538.3682\n",
      "Epoch 1383/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7942.8506 - mean_absolute_error: 7942.8506\n",
      "Epoch 1383: val_loss did not improve from 13535.98926\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9571.0000 - mean_absolute_error: 9571.0000 - val_loss: 13537.8877 - val_mean_absolute_error: 13537.8877\n",
      "Epoch 1384/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11807.2979 - mean_absolute_error: 11807.2979\n",
      "Epoch 1384: val_loss improved from 13535.98926 to 13535.27051, saving model to Weights-01384--13535.27051.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9556.9639 - mean_absolute_error: 9556.9639 - val_loss: 13535.2705 - val_mean_absolute_error: 13535.2705\n",
      "Epoch 1385/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9672.3975 - mean_absolute_error: 9672.3975\n",
      "Epoch 1385: val_loss did not improve from 13535.27051\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9559.8477 - mean_absolute_error: 9559.8477 - val_loss: 13535.3604 - val_mean_absolute_error: 13535.3604\n",
      "Epoch 1386/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10055.0889 - mean_absolute_error: 10055.0889\n",
      "Epoch 1386: val_loss improved from 13535.27051 to 13534.94141, saving model to Weights-01386--13534.94141.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9562.0859 - mean_absolute_error: 9562.0859 - val_loss: 13534.9414 - val_mean_absolute_error: 13534.9414\n",
      "Epoch 1387/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8399.8516 - mean_absolute_error: 8399.8516\n",
      "Epoch 1387: val_loss did not improve from 13534.94141\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9584.9834 - mean_absolute_error: 9584.9834 - val_loss: 13539.2949 - val_mean_absolute_error: 13539.2949\n",
      "Epoch 1388/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6948.2783 - mean_absolute_error: 6948.2783\n",
      "Epoch 1388: val_loss did not improve from 13534.94141\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9563.4238 - mean_absolute_error: 9563.4238 - val_loss: 13535.7832 - val_mean_absolute_error: 13535.7832\n",
      "Epoch 1389/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11449.4268 - mean_absolute_error: 11449.4268\n",
      "Epoch 1389: val_loss improved from 13534.94141 to 13534.45312, saving model to Weights-01389--13534.45312.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9572.0312 - mean_absolute_error: 9572.0312 - val_loss: 13534.4531 - val_mean_absolute_error: 13534.4531\n",
      "Epoch 1390/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6496.3545 - mean_absolute_error: 6496.3545\n",
      "Epoch 1390: val_loss did not improve from 13534.45312\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9565.9580 - mean_absolute_error: 9565.9580 - val_loss: 13538.8164 - val_mean_absolute_error: 13538.8164\n",
      "Epoch 1391/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11258.8936 - mean_absolute_error: 11258.8936\n",
      "Epoch 1391: val_loss improved from 13534.45312 to 13534.04590, saving model to Weights-01391--13534.04590.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9561.0879 - mean_absolute_error: 9561.0879 - val_loss: 13534.0459 - val_mean_absolute_error: 13534.0459\n",
      "Epoch 1392/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7245.4424 - mean_absolute_error: 7245.4424\n",
      "Epoch 1392: val_loss improved from 13534.04590 to 13533.93848, saving model to Weights-01392--13533.93848.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9559.0596 - mean_absolute_error: 9559.0596 - val_loss: 13533.9385 - val_mean_absolute_error: 13533.9385\n",
      "Epoch 1393/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12383.1953 - mean_absolute_error: 12383.1953\n",
      "Epoch 1393: val_loss improved from 13533.93848 to 13533.75098, saving model to Weights-01393--13533.75098.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9562.2969 - mean_absolute_error: 9562.2969 - val_loss: 13533.7510 - val_mean_absolute_error: 13533.7510\n",
      "Epoch 1394/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9361.8623 - mean_absolute_error: 9361.8623\n",
      "Epoch 1394: val_loss did not improve from 13533.75098\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9567.0459 - mean_absolute_error: 9567.0459 - val_loss: 13535.5420 - val_mean_absolute_error: 13535.5420\n",
      "Epoch 1395/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12271.0830 - mean_absolute_error: 12271.0830\n",
      "Epoch 1395: val_loss did not improve from 13533.75098\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9563.8984 - mean_absolute_error: 9563.8984 - val_loss: 13536.2861 - val_mean_absolute_error: 13536.2861\n",
      "Epoch 1396/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8615.9961 - mean_absolute_error: 8615.9961\n",
      "Epoch 1396: val_loss improved from 13533.75098 to 13533.18555, saving model to Weights-01396--13533.18555.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9561.9023 - mean_absolute_error: 9561.9023 - val_loss: 13533.1855 - val_mean_absolute_error: 13533.1855\n",
      "Epoch 1397/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7474.4912 - mean_absolute_error: 7474.4912\n",
      "Epoch 1397: val_loss improved from 13533.18555 to 13532.95508, saving model to Weights-01397--13532.95508.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9561.9131 - mean_absolute_error: 9561.9131 - val_loss: 13532.9551 - val_mean_absolute_error: 13532.9551\n",
      "Epoch 1398/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6699.0679 - mean_absolute_error: 6699.0679\n",
      "Epoch 1398: val_loss did not improve from 13532.95508\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9562.4316 - mean_absolute_error: 9562.4316 - val_loss: 13534.9092 - val_mean_absolute_error: 13534.9092\n",
      "Epoch 1399/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6903.3394 - mean_absolute_error: 6903.3394\n",
      "Epoch 1399: val_loss improved from 13532.95508 to 13532.48730, saving model to Weights-01399--13532.48730.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9566.7822 - mean_absolute_error: 9566.7822 - val_loss: 13532.4873 - val_mean_absolute_error: 13532.4873\n",
      "Epoch 1400/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10923.2305 - mean_absolute_error: 10923.2305\n",
      "Epoch 1400: val_loss did not improve from 13532.48730\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9558.6973 - mean_absolute_error: 9558.6973 - val_loss: 13533.0684 - val_mean_absolute_error: 13533.0684\n",
      "Epoch 1401/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9381.6855 - mean_absolute_error: 9381.6855\n",
      "Epoch 1401: val_loss did not improve from 13532.48730\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9580.6611 - mean_absolute_error: 9580.6611 - val_loss: 13533.5088 - val_mean_absolute_error: 13533.5088\n",
      "Epoch 1402/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8874.3311 - mean_absolute_error: 8874.3311\n",
      "Epoch 1402: val_loss improved from 13532.48730 to 13532.05762, saving model to Weights-01402--13532.05762.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9561.2676 - mean_absolute_error: 9561.2676 - val_loss: 13532.0576 - val_mean_absolute_error: 13532.0576\n",
      "Epoch 1403/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11140.2246 - mean_absolute_error: 11140.2246\n",
      "Epoch 1403: val_loss did not improve from 13532.05762\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9560.5547 - mean_absolute_error: 9560.5547 - val_loss: 13535.1230 - val_mean_absolute_error: 13535.1230\n",
      "Epoch 1404/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9423.8496 - mean_absolute_error: 9423.8496\n",
      "Epoch 1404: val_loss did not improve from 13532.05762\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9559.6709 - mean_absolute_error: 9559.6709 - val_loss: 13532.5410 - val_mean_absolute_error: 13532.5410\n",
      "Epoch 1405/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11806.1621 - mean_absolute_error: 11806.1621\n",
      "Epoch 1405: val_loss did not improve from 13532.05762\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9567.3779 - mean_absolute_error: 9567.3779 - val_loss: 13535.1074 - val_mean_absolute_error: 13535.1074\n",
      "Epoch 1406/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8372.4922 - mean_absolute_error: 8372.4922\n",
      "Epoch 1406: val_loss improved from 13532.05762 to 13531.88770, saving model to Weights-01406--13531.88770.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9558.5850 - mean_absolute_error: 9558.5850 - val_loss: 13531.8877 - val_mean_absolute_error: 13531.8887\n",
      "Epoch 1407/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10653.4531 - mean_absolute_error: 10653.4531\n",
      "Epoch 1407: val_loss did not improve from 13531.88770\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9558.3506 - mean_absolute_error: 9558.3506 - val_loss: 13533.0615 - val_mean_absolute_error: 13533.0615\n",
      "Epoch 1408/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7351.8882 - mean_absolute_error: 7351.8882\n",
      "Epoch 1408: val_loss did not improve from 13531.88770\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9562.0361 - mean_absolute_error: 9562.0361 - val_loss: 13534.4473 - val_mean_absolute_error: 13534.4473\n",
      "Epoch 1409/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12635.7041 - mean_absolute_error: 12635.7041\n",
      "Epoch 1409: val_loss improved from 13531.88770 to 13530.65039, saving model to Weights-01409--13530.65039.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9556.6104 - mean_absolute_error: 9556.6104 - val_loss: 13530.6504 - val_mean_absolute_error: 13530.6504\n",
      "Epoch 1410/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9877.9434 - mean_absolute_error: 9877.9434\n",
      "Epoch 1410: val_loss improved from 13530.65039 to 13530.45801, saving model to Weights-01410--13530.45801.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9557.3389 - mean_absolute_error: 9557.3389 - val_loss: 13530.4580 - val_mean_absolute_error: 13530.4580\n",
      "Epoch 1411/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8427.8066 - mean_absolute_error: 8427.8066\n",
      "Epoch 1411: val_loss did not improve from 13530.45801\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9553.2598 - mean_absolute_error: 9553.2598 - val_loss: 13531.2686 - val_mean_absolute_error: 13531.2686\n",
      "Epoch 1412/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 15376.5645 - mean_absolute_error: 15376.5645\n",
      "Epoch 1412: val_loss improved from 13530.45801 to 13530.07715, saving model to Weights-01412--13530.07715.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9561.1260 - mean_absolute_error: 9561.1260 - val_loss: 13530.0771 - val_mean_absolute_error: 13530.0771\n",
      "Epoch 1413/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10379.5654 - mean_absolute_error: 10379.5654\n",
      "Epoch 1413: val_loss did not improve from 13530.07715\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9561.8330 - mean_absolute_error: 9561.8330 - val_loss: 13533.9111 - val_mean_absolute_error: 13533.9111\n",
      "Epoch 1414/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12533.4609 - mean_absolute_error: 12533.4609\n",
      "Epoch 1414: val_loss improved from 13530.07715 to 13529.84082, saving model to Weights-01414--13529.84082.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9568.9014 - mean_absolute_error: 9568.9014 - val_loss: 13529.8408 - val_mean_absolute_error: 13529.8408\n",
      "Epoch 1415/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9256.9160 - mean_absolute_error: 9256.9160\n",
      "Epoch 1415: val_loss did not improve from 13529.84082\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9562.1074 - mean_absolute_error: 9562.1074 - val_loss: 13531.2676 - val_mean_absolute_error: 13531.2676\n",
      "Epoch 1416/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9212.6348 - mean_absolute_error: 9212.6348\n",
      "Epoch 1416: val_loss improved from 13529.84082 to 13529.40332, saving model to Weights-01416--13529.40332.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9559.1709 - mean_absolute_error: 9559.1709 - val_loss: 13529.4033 - val_mean_absolute_error: 13529.4033\n",
      "Epoch 1417/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7069.6221 - mean_absolute_error: 7069.6221\n",
      "Epoch 1417: val_loss did not improve from 13529.40332\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9554.7021 - mean_absolute_error: 9554.7021 - val_loss: 13529.8721 - val_mean_absolute_error: 13529.8721\n",
      "Epoch 1418/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12076.0664 - mean_absolute_error: 12076.0664\n",
      "Epoch 1418: val_loss did not improve from 13529.40332\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9560.3154 - mean_absolute_error: 9560.3154 - val_loss: 13532.9814 - val_mean_absolute_error: 13532.9814\n",
      "Epoch 1419/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12528.5137 - mean_absolute_error: 12528.5137\n",
      "Epoch 1419: val_loss improved from 13529.40332 to 13528.77344, saving model to Weights-01419--13528.77344.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9557.4814 - mean_absolute_error: 9557.4814 - val_loss: 13528.7734 - val_mean_absolute_error: 13528.7734\n",
      "Epoch 1420/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8120.9277 - mean_absolute_error: 8120.9277\n",
      "Epoch 1420: val_loss did not improve from 13528.77344\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9556.2041 - mean_absolute_error: 9556.2041 - val_loss: 13528.9092 - val_mean_absolute_error: 13528.9092\n",
      "Epoch 1421/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9205.6162 - mean_absolute_error: 9205.6162\n",
      "Epoch 1421: val_loss improved from 13528.77344 to 13528.31445, saving model to Weights-01421--13528.31445.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9551.6572 - mean_absolute_error: 9551.6572 - val_loss: 13528.3145 - val_mean_absolute_error: 13528.3145\n",
      "Epoch 1422/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8685.4902 - mean_absolute_error: 8685.4902\n",
      "Epoch 1422: val_loss did not improve from 13528.31445\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9551.5889 - mean_absolute_error: 9551.5889 - val_loss: 13529.5020 - val_mean_absolute_error: 13529.5020\n",
      "Epoch 1423/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7369.3774 - mean_absolute_error: 7369.3774\n",
      "Epoch 1423: val_loss did not improve from 13528.31445\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9552.2715 - mean_absolute_error: 9552.2715 - val_loss: 13529.2549 - val_mean_absolute_error: 13529.2549\n",
      "Epoch 1424/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8395.1436 - mean_absolute_error: 8395.1436\n",
      "Epoch 1424: val_loss did not improve from 13528.31445\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9553.8408 - mean_absolute_error: 9553.8408 - val_loss: 13529.0234 - val_mean_absolute_error: 13529.0234\n",
      "Epoch 1425/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9877.6846 - mean_absolute_error: 9877.6846\n",
      "Epoch 1425: val_loss improved from 13528.31445 to 13527.57031, saving model to Weights-01425--13527.57031.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9555.8037 - mean_absolute_error: 9555.8037 - val_loss: 13527.5703 - val_mean_absolute_error: 13527.5703\n",
      "Epoch 1426/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9587.5039 - mean_absolute_error: 9587.5039\n",
      "Epoch 1426: val_loss improved from 13527.57031 to 13527.41797, saving model to Weights-01426--13527.41797.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9559.0020 - mean_absolute_error: 9559.0020 - val_loss: 13527.4180 - val_mean_absolute_error: 13527.4180\n",
      "Epoch 1427/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12264.4219 - mean_absolute_error: 12264.4219\n",
      "Epoch 1427: val_loss did not improve from 13527.41797\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9567.8018 - mean_absolute_error: 9567.8018 - val_loss: 13528.1797 - val_mean_absolute_error: 13528.1797\n",
      "Epoch 1428/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7002.6650 - mean_absolute_error: 7002.6650\n",
      "Epoch 1428: val_loss improved from 13527.41797 to 13527.08594, saving model to Weights-01428--13527.08594.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9560.1816 - mean_absolute_error: 9560.1816 - val_loss: 13527.0859 - val_mean_absolute_error: 13527.0859\n",
      "Epoch 1429/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11955.5625 - mean_absolute_error: 11955.5625\n",
      "Epoch 1429: val_loss did not improve from 13527.08594\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9561.9404 - mean_absolute_error: 9561.9404 - val_loss: 13527.7539 - val_mean_absolute_error: 13527.7539\n",
      "Epoch 1430/3000\n",
      " 8/18 [============>.................] - ETA: 0s - loss: 9874.0400 - mean_absolute_error: 9874.0400  \n",
      "Epoch 1430: val_loss improved from 13527.08594 to 13527.00781, saving model to Weights-01430--13527.00781.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9550.2803 - mean_absolute_error: 9550.2803 - val_loss: 13527.0078 - val_mean_absolute_error: 13527.0078\n",
      "Epoch 1431/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10142.6582 - mean_absolute_error: 10142.6582\n",
      "Epoch 1431: val_loss improved from 13527.00781 to 13526.61621, saving model to Weights-01431--13526.61621.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9556.6094 - mean_absolute_error: 9556.6094 - val_loss: 13526.6162 - val_mean_absolute_error: 13526.6162\n",
      "Epoch 1432/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10256.7881 - mean_absolute_error: 10256.7881\n",
      "Epoch 1432: val_loss did not improve from 13526.61621\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9555.7139 - mean_absolute_error: 9555.7139 - val_loss: 13529.1221 - val_mean_absolute_error: 13529.1221\n",
      "Epoch 1433/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9235.9697 - mean_absolute_error: 9235.9697\n",
      "Epoch 1433: val_loss improved from 13526.61621 to 13526.18164, saving model to Weights-01433--13526.18164.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9549.8037 - mean_absolute_error: 9549.8037 - val_loss: 13526.1816 - val_mean_absolute_error: 13526.1816\n",
      "Epoch 1434/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9313.8848 - mean_absolute_error: 9313.8848\n",
      "Epoch 1434: val_loss improved from 13526.18164 to 13525.96777, saving model to Weights-01434--13525.96777.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9549.7744 - mean_absolute_error: 9549.7744 - val_loss: 13525.9678 - val_mean_absolute_error: 13525.9678\n",
      "Epoch 1435/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12508.7314 - mean_absolute_error: 12508.7314\n",
      "Epoch 1435: val_loss did not improve from 13525.96777\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9552.7500 - mean_absolute_error: 9552.7500 - val_loss: 13526.6885 - val_mean_absolute_error: 13526.6885\n",
      "Epoch 1436/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9506.2832 - mean_absolute_error: 9506.2832\n",
      "Epoch 1436: val_loss improved from 13525.96777 to 13525.65820, saving model to Weights-01436--13525.65820.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9552.2568 - mean_absolute_error: 9552.2568 - val_loss: 13525.6582 - val_mean_absolute_error: 13525.6582\n",
      "Epoch 1437/3000\n",
      " 8/18 [============>.................] - ETA: 0s - loss: 9994.7490 - mean_absolute_error: 9994.7490  \n",
      "Epoch 1437: val_loss improved from 13525.65820 to 13525.39062, saving model to Weights-01437--13525.39062.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9570.1562 - mean_absolute_error: 9570.1562 - val_loss: 13525.3906 - val_mean_absolute_error: 13525.3906\n",
      "Epoch 1438/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8240.5352 - mean_absolute_error: 8240.5352\n",
      "Epoch 1438: val_loss did not improve from 13525.39062\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9552.9766 - mean_absolute_error: 9552.9766 - val_loss: 13527.9941 - val_mean_absolute_error: 13527.9941\n",
      "Epoch 1439/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8675.6055 - mean_absolute_error: 8675.6055\n",
      "Epoch 1439: val_loss did not improve from 13525.39062\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9550.7832 - mean_absolute_error: 9550.7832 - val_loss: 13526.5889 - val_mean_absolute_error: 13526.5889\n",
      "Epoch 1440/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4840.0713 - mean_absolute_error: 4840.0713\n",
      "Epoch 1440: val_loss improved from 13525.39062 to 13524.91504, saving model to Weights-01440--13524.91504.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9555.9219 - mean_absolute_error: 9555.9219 - val_loss: 13524.9150 - val_mean_absolute_error: 13524.9150\n",
      "Epoch 1441/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9659.5820 - mean_absolute_error: 9659.5820\n",
      "Epoch 1441: val_loss did not improve from 13524.91504\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9548.2324 - mean_absolute_error: 9548.2324 - val_loss: 13527.0020 - val_mean_absolute_error: 13527.0020\n",
      "Epoch 1442/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11811.1270 - mean_absolute_error: 11811.1270\n",
      "Epoch 1442: val_loss improved from 13524.91504 to 13524.54590, saving model to Weights-01442--13524.54590.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9550.1406 - mean_absolute_error: 9550.1406 - val_loss: 13524.5459 - val_mean_absolute_error: 13524.5459\n",
      "Epoch 1443/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10221.0488 - mean_absolute_error: 10221.0488\n",
      "Epoch 1443: val_loss improved from 13524.54590 to 13524.34375, saving model to Weights-01443--13524.34375.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9554.1494 - mean_absolute_error: 9554.1494 - val_loss: 13524.3438 - val_mean_absolute_error: 13524.3438\n",
      "Epoch 1444/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9247.3623 - mean_absolute_error: 9247.3623\n",
      "Epoch 1444: val_loss did not improve from 13524.34375\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9547.6328 - mean_absolute_error: 9547.6328 - val_loss: 13525.0791 - val_mean_absolute_error: 13525.0791\n",
      "Epoch 1445/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11215.5840 - mean_absolute_error: 11215.5840\n",
      "Epoch 1445: val_loss improved from 13524.34375 to 13524.31055, saving model to Weights-01445--13524.31055.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9563.4385 - mean_absolute_error: 9563.4385 - val_loss: 13524.3105 - val_mean_absolute_error: 13524.3105\n",
      "Epoch 1446/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7644.4541 - mean_absolute_error: 7644.4541\n",
      "Epoch 1446: val_loss improved from 13524.31055 to 13524.08691, saving model to Weights-01446--13524.08691.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9547.7461 - mean_absolute_error: 9547.7461 - val_loss: 13524.0869 - val_mean_absolute_error: 13524.0869\n",
      "Epoch 1447/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8875.7969 - mean_absolute_error: 8875.7969\n",
      "Epoch 1447: val_loss improved from 13524.08691 to 13523.52637, saving model to Weights-01447--13523.52637.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9545.4775 - mean_absolute_error: 9545.4775 - val_loss: 13523.5264 - val_mean_absolute_error: 13523.5264\n",
      "Epoch 1448/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10332.2812 - mean_absolute_error: 10332.2812\n",
      "Epoch 1448: val_loss did not improve from 13523.52637\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9550.3516 - mean_absolute_error: 9550.3516 - val_loss: 13525.8125 - val_mean_absolute_error: 13525.8125\n",
      "Epoch 1449/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7493.9287 - mean_absolute_error: 7493.9287\n",
      "Epoch 1449: val_loss improved from 13523.52637 to 13523.09961, saving model to Weights-01449--13523.09961.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9545.3926 - mean_absolute_error: 9545.3926 - val_loss: 13523.0996 - val_mean_absolute_error: 13523.0996\n",
      "Epoch 1450/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8111.3584 - mean_absolute_error: 8111.3584\n",
      "Epoch 1450: val_loss improved from 13523.09961 to 13522.92676, saving model to Weights-01450--13522.92676.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9548.8525 - mean_absolute_error: 9548.8525 - val_loss: 13522.9268 - val_mean_absolute_error: 13522.9268\n",
      "Epoch 1451/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8135.1777 - mean_absolute_error: 8135.1777\n",
      "Epoch 1451: val_loss improved from 13522.92676 to 13522.83887, saving model to Weights-01451--13522.83887.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9549.2344 - mean_absolute_error: 9549.2344 - val_loss: 13522.8389 - val_mean_absolute_error: 13522.8389\n",
      "Epoch 1452/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7966.4429 - mean_absolute_error: 7966.4429\n",
      "Epoch 1452: val_loss improved from 13522.83887 to 13522.65137, saving model to Weights-01452--13522.65137.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9543.0859 - mean_absolute_error: 9543.0859 - val_loss: 13522.6514 - val_mean_absolute_error: 13522.6514\n",
      "Epoch 1453/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10116.7480 - mean_absolute_error: 10116.7480\n",
      "Epoch 1453: val_loss did not improve from 13522.65137\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9549.4893 - mean_absolute_error: 9549.4893 - val_loss: 13524.4092 - val_mean_absolute_error: 13524.4092\n",
      "Epoch 1454/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8391.0742 - mean_absolute_error: 8391.0742\n",
      "Epoch 1454: val_loss improved from 13522.65137 to 13522.28223, saving model to Weights-01454--13522.28223.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9551.2988 - mean_absolute_error: 9551.2988 - val_loss: 13522.2822 - val_mean_absolute_error: 13522.2822\n",
      "Epoch 1455/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9705.0498 - mean_absolute_error: 9705.0498\n",
      "Epoch 1455: val_loss did not improve from 13522.28223\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9557.7402 - mean_absolute_error: 9557.7402 - val_loss: 13525.1152 - val_mean_absolute_error: 13525.1152\n",
      "Epoch 1456/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8866.1309 - mean_absolute_error: 8866.1309\n",
      "Epoch 1456: val_loss did not improve from 13522.28223\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9552.0117 - mean_absolute_error: 9552.0117 - val_loss: 13524.3301 - val_mean_absolute_error: 13524.3301\n",
      "Epoch 1457/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10023.3848 - mean_absolute_error: 10023.3848\n",
      "Epoch 1457: val_loss improved from 13522.28223 to 13521.58301, saving model to Weights-01457--13521.58301.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9559.7803 - mean_absolute_error: 9559.7803 - val_loss: 13521.5830 - val_mean_absolute_error: 13521.5830\n",
      "Epoch 1458/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11513.4883 - mean_absolute_error: 11513.4883\n",
      "Epoch 1458: val_loss improved from 13521.58301 to 13521.49512, saving model to Weights-01458--13521.49512.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9546.2686 - mean_absolute_error: 9546.2686 - val_loss: 13521.4951 - val_mean_absolute_error: 13521.4951\n",
      "Epoch 1459/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10721.7402 - mean_absolute_error: 10721.7402\n",
      "Epoch 1459: val_loss did not improve from 13521.49512\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9551.5674 - mean_absolute_error: 9551.5674 - val_loss: 13523.8213 - val_mean_absolute_error: 13523.8213\n",
      "Epoch 1460/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9078.7441 - mean_absolute_error: 9078.7441\n",
      "Epoch 1460: val_loss improved from 13521.49512 to 13521.14062, saving model to Weights-01460--13521.14062.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9545.7773 - mean_absolute_error: 9545.7773 - val_loss: 13521.1406 - val_mean_absolute_error: 13521.1406\n",
      "Epoch 1461/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10310.3789 - mean_absolute_error: 10310.3789\n",
      "Epoch 1461: val_loss improved from 13521.14062 to 13520.87988, saving model to Weights-01461--13520.87988.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9544.5625 - mean_absolute_error: 9544.5625 - val_loss: 13520.8799 - val_mean_absolute_error: 13520.8799\n",
      "Epoch 1462/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9072.3291 - mean_absolute_error: 9072.3291\n",
      "Epoch 1462: val_loss improved from 13520.87988 to 13520.70117, saving model to Weights-01462--13520.70117.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9543.7422 - mean_absolute_error: 9543.7422 - val_loss: 13520.7012 - val_mean_absolute_error: 13520.7012\n",
      "Epoch 1463/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11955.6016 - mean_absolute_error: 11955.6016\n",
      "Epoch 1463: val_loss did not improve from 13520.70117\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9542.8857 - mean_absolute_error: 9542.8857 - val_loss: 13524.1631 - val_mean_absolute_error: 13524.1631\n",
      "Epoch 1464/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10922.6934 - mean_absolute_error: 10922.6934\n",
      "Epoch 1464: val_loss improved from 13520.70117 to 13520.32520, saving model to Weights-01464--13520.32520.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9547.3721 - mean_absolute_error: 9547.3721 - val_loss: 13520.3252 - val_mean_absolute_error: 13520.3252\n",
      "Epoch 1465/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6174.5635 - mean_absolute_error: 6174.5635\n",
      "Epoch 1465: val_loss improved from 13520.32520 to 13520.13770, saving model to Weights-01465--13520.13770.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9546.9551 - mean_absolute_error: 9546.9551 - val_loss: 13520.1377 - val_mean_absolute_error: 13520.1377\n",
      "Epoch 1466/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8102.0059 - mean_absolute_error: 8102.0059\n",
      "Epoch 1466: val_loss improved from 13520.13770 to 13519.97070, saving model to Weights-01466--13519.97070.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9545.2559 - mean_absolute_error: 9545.2559 - val_loss: 13519.9707 - val_mean_absolute_error: 13519.9707\n",
      "Epoch 1467/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8986.5508 - mean_absolute_error: 8986.5508\n",
      "Epoch 1467: val_loss did not improve from 13519.97070\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9549.5322 - mean_absolute_error: 9549.5322 - val_loss: 13520.6904 - val_mean_absolute_error: 13520.6904\n",
      "Epoch 1468/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10467.8516 - mean_absolute_error: 10467.8516\n",
      "Epoch 1468: val_loss improved from 13519.97070 to 13519.79004, saving model to Weights-01468--13519.79004.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9543.5986 - mean_absolute_error: 9543.5986 - val_loss: 13519.7900 - val_mean_absolute_error: 13519.7900\n",
      "Epoch 1469/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12172.4570 - mean_absolute_error: 12172.4570\n",
      "Epoch 1469: val_loss improved from 13519.79004 to 13519.33203, saving model to Weights-01469--13519.33203.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9542.6455 - mean_absolute_error: 9542.6455 - val_loss: 13519.3320 - val_mean_absolute_error: 13519.3320\n",
      "Epoch 1470/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12163.6338 - mean_absolute_error: 12163.6338\n",
      "Epoch 1470: val_loss improved from 13519.33203 to 13519.22266, saving model to Weights-01470--13519.22266.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9545.2705 - mean_absolute_error: 9545.2705 - val_loss: 13519.2227 - val_mean_absolute_error: 13519.2227\n",
      "Epoch 1471/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10657.6289 - mean_absolute_error: 10657.6289\n",
      "Epoch 1471: val_loss did not improve from 13519.22266\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9543.2588 - mean_absolute_error: 9543.2588 - val_loss: 13521.1611 - val_mean_absolute_error: 13521.1611\n",
      "Epoch 1472/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11868.9443 - mean_absolute_error: 11868.9443\n",
      "Epoch 1472: val_loss improved from 13519.22266 to 13518.88184, saving model to Weights-01472--13518.88184.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9544.6553 - mean_absolute_error: 9544.6553 - val_loss: 13518.8818 - val_mean_absolute_error: 13518.8818\n",
      "Epoch 1473/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 14514.7412 - mean_absolute_error: 14514.7412\n",
      "Epoch 1473: val_loss improved from 13518.88184 to 13518.66406, saving model to Weights-01473--13518.66406.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9544.0156 - mean_absolute_error: 9544.0156 - val_loss: 13518.6641 - val_mean_absolute_error: 13518.6641\n",
      "Epoch 1474/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11798.9023 - mean_absolute_error: 11798.9023\n",
      "Epoch 1474: val_loss improved from 13518.66406 to 13518.44238, saving model to Weights-01474--13518.44238.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9545.6104 - mean_absolute_error: 9545.6104 - val_loss: 13518.4424 - val_mean_absolute_error: 13518.4424\n",
      "Epoch 1475/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10283.9688 - mean_absolute_error: 10283.9688\n",
      "Epoch 1475: val_loss improved from 13518.44238 to 13518.28418, saving model to Weights-01475--13518.28418.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9545.0830 - mean_absolute_error: 9545.0830 - val_loss: 13518.2842 - val_mean_absolute_error: 13518.2842\n",
      "Epoch 1476/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8843.2598 - mean_absolute_error: 8843.2598\n",
      "Epoch 1476: val_loss did not improve from 13518.28418\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9544.8730 - mean_absolute_error: 9544.8730 - val_loss: 13519.0742 - val_mean_absolute_error: 13519.0742\n",
      "Epoch 1477/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 14403.6377 - mean_absolute_error: 14403.6377\n",
      "Epoch 1477: val_loss improved from 13518.28418 to 13517.79785, saving model to Weights-01477--13517.79785.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9556.5234 - mean_absolute_error: 9556.5234 - val_loss: 13517.7979 - val_mean_absolute_error: 13517.7979\n",
      "Epoch 1478/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11030.1123 - mean_absolute_error: 11030.1123\n",
      "Epoch 1478: val_loss did not improve from 13517.79785\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9545.6621 - mean_absolute_error: 9545.6621 - val_loss: 13521.6279 - val_mean_absolute_error: 13521.6279\n",
      "Epoch 1479/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8169.2002 - mean_absolute_error: 8169.2002\n",
      "Epoch 1479: val_loss improved from 13517.79785 to 13517.42383, saving model to Weights-01479--13517.42383.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9549.2715 - mean_absolute_error: 9549.2715 - val_loss: 13517.4238 - val_mean_absolute_error: 13517.4238\n",
      "Epoch 1480/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10082.1152 - mean_absolute_error: 10082.1152\n",
      "Epoch 1480: val_loss did not improve from 13517.42383\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9545.4043 - mean_absolute_error: 9545.4043 - val_loss: 13518.8496 - val_mean_absolute_error: 13518.8496\n",
      "Epoch 1481/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9678.0391 - mean_absolute_error: 9678.0391\n",
      "Epoch 1481: val_loss improved from 13517.42383 to 13517.02734, saving model to Weights-01481--13517.02734.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9547.2617 - mean_absolute_error: 9547.2617 - val_loss: 13517.0273 - val_mean_absolute_error: 13517.0273\n",
      "Epoch 1482/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 14878.1895 - mean_absolute_error: 14878.1895\n",
      "Epoch 1482: val_loss improved from 13517.02734 to 13516.91309, saving model to Weights-01482--13516.91309.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9546.7480 - mean_absolute_error: 9546.7480 - val_loss: 13516.9131 - val_mean_absolute_error: 13516.9131\n",
      "Epoch 1483/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9311.4004 - mean_absolute_error: 9311.4004\n",
      "Epoch 1483: val_loss did not improve from 13516.91309\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9541.3760 - mean_absolute_error: 9541.3760 - val_loss: 13518.6875 - val_mean_absolute_error: 13518.6875\n",
      "Epoch 1484/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12635.5986 - mean_absolute_error: 12635.5986\n",
      "Epoch 1484: val_loss improved from 13516.91309 to 13516.44434, saving model to Weights-01484--13516.44434.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9543.6826 - mean_absolute_error: 9543.6826 - val_loss: 13516.4443 - val_mean_absolute_error: 13516.4443\n",
      "Epoch 1485/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8430.6484 - mean_absolute_error: 8430.6484\n",
      "Epoch 1485: val_loss did not improve from 13516.44434\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9538.2812 - mean_absolute_error: 9538.2812 - val_loss: 13517.7969 - val_mean_absolute_error: 13517.7969\n",
      "Epoch 1486/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9861.2402 - mean_absolute_error: 9861.2402\n",
      "Epoch 1486: val_loss did not improve from 13516.44434\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9539.4785 - mean_absolute_error: 9539.4785 - val_loss: 13518.1611 - val_mean_absolute_error: 13518.1611\n",
      "Epoch 1487/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8802.6748 - mean_absolute_error: 8802.6748\n",
      "Epoch 1487: val_loss did not improve from 13516.44434\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9543.8242 - mean_absolute_error: 9543.8242 - val_loss: 13517.6309 - val_mean_absolute_error: 13517.6309\n",
      "Epoch 1488/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12315.7637 - mean_absolute_error: 12315.7637\n",
      "Epoch 1488: val_loss did not improve from 13516.44434\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9551.5498 - mean_absolute_error: 9551.5498 - val_loss: 13517.0527 - val_mean_absolute_error: 13517.0527\n",
      "Epoch 1489/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9558.0322 - mean_absolute_error: 9558.0322\n",
      "Epoch 1489: val_loss did not improve from 13516.44434\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9563.2979 - mean_absolute_error: 9563.2979 - val_loss: 13524.1006 - val_mean_absolute_error: 13524.1006\n",
      "Epoch 1490/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13341.5781 - mean_absolute_error: 13341.5781\n",
      "Epoch 1490: val_loss improved from 13516.44434 to 13515.26562, saving model to Weights-01490--13515.26562.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9536.6826 - mean_absolute_error: 9536.6826 - val_loss: 13515.2656 - val_mean_absolute_error: 13515.2656\n",
      "Epoch 1491/3000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9012.3525 - mean_absolute_error: 9012.3525  \n",
      "Epoch 1491: val_loss did not improve from 13515.26562\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9540.4629 - mean_absolute_error: 9540.4629 - val_loss: 13515.6738 - val_mean_absolute_error: 13515.6738\n",
      "Epoch 1492/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9290.3398 - mean_absolute_error: 9290.3398\n",
      "Epoch 1492: val_loss did not improve from 13515.26562\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9542.4873 - mean_absolute_error: 9542.4873 - val_loss: 13517.5654 - val_mean_absolute_error: 13517.5654\n",
      "Epoch 1493/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10901.1660 - mean_absolute_error: 10901.1660\n",
      "Epoch 1493: val_loss did not improve from 13515.26562\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9544.2637 - mean_absolute_error: 9544.2637 - val_loss: 13516.8311 - val_mean_absolute_error: 13516.8311\n",
      "Epoch 1494/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12258.4102 - mean_absolute_error: 12258.4102\n",
      "Epoch 1494: val_loss improved from 13515.26562 to 13515.20215, saving model to Weights-01494--13515.20215.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9556.5557 - mean_absolute_error: 9556.5557 - val_loss: 13515.2021 - val_mean_absolute_error: 13515.2021\n",
      "Epoch 1495/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8906.2461 - mean_absolute_error: 8906.2461\n",
      "Epoch 1495: val_loss improved from 13515.20215 to 13514.40430, saving model to Weights-01495--13514.40430.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9536.0781 - mean_absolute_error: 9536.0781 - val_loss: 13514.4043 - val_mean_absolute_error: 13514.4043\n",
      "Epoch 1496/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6801.6035 - mean_absolute_error: 6801.6035\n",
      "Epoch 1496: val_loss did not improve from 13514.40430\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9540.0059 - mean_absolute_error: 9540.0059 - val_loss: 13515.5059 - val_mean_absolute_error: 13515.5059\n",
      "Epoch 1497/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9070.4004 - mean_absolute_error: 9070.4004\n",
      "Epoch 1497: val_loss improved from 13514.40430 to 13513.98047, saving model to Weights-01497--13513.98047.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9539.5049 - mean_absolute_error: 9539.5049 - val_loss: 13513.9805 - val_mean_absolute_error: 13513.9805\n",
      "Epoch 1498/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6887.0615 - mean_absolute_error: 6887.0615\n",
      "Epoch 1498: val_loss improved from 13513.98047 to 13513.83594, saving model to Weights-01498--13513.83594.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9537.6289 - mean_absolute_error: 9537.6289 - val_loss: 13513.8359 - val_mean_absolute_error: 13513.8359\n",
      "Epoch 1499/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9793.8477 - mean_absolute_error: 9793.8477\n",
      "Epoch 1499: val_loss did not improve from 13513.83594\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9533.8643 - mean_absolute_error: 9533.8643 - val_loss: 13514.8506 - val_mean_absolute_error: 13514.8506\n",
      "Epoch 1500/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9416.0391 - mean_absolute_error: 9416.0391\n",
      "Epoch 1500: val_loss did not improve from 13513.83594\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9537.9424 - mean_absolute_error: 9537.9424 - val_loss: 13516.1699 - val_mean_absolute_error: 13516.1699\n",
      "Epoch 1501/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12936.3359 - mean_absolute_error: 12936.3359\n",
      "Epoch 1501: val_loss improved from 13513.83594 to 13513.19824, saving model to Weights-01501--13513.19824.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9545.3555 - mean_absolute_error: 9545.3555 - val_loss: 13513.1982 - val_mean_absolute_error: 13513.1982\n",
      "Epoch 1502/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12196.9648 - mean_absolute_error: 12196.9648\n",
      "Epoch 1502: val_loss did not improve from 13513.19824\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9548.1211 - mean_absolute_error: 9548.1211 - val_loss: 13515.4668 - val_mean_absolute_error: 13515.4668\n",
      "Epoch 1503/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12722.1436 - mean_absolute_error: 12722.1436\n",
      "Epoch 1503: val_loss improved from 13513.19824 to 13513.15723, saving model to Weights-01503--13513.15723.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9538.7930 - mean_absolute_error: 9538.7930 - val_loss: 13513.1572 - val_mean_absolute_error: 13513.1572\n",
      "Epoch 1504/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9428.5684 - mean_absolute_error: 9428.5684\n",
      "Epoch 1504: val_loss improved from 13513.15723 to 13513.09863, saving model to Weights-01504--13513.09863.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9536.2480 - mean_absolute_error: 9536.2480 - val_loss: 13513.0986 - val_mean_absolute_error: 13513.0986\n",
      "Epoch 1505/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9242.7061 - mean_absolute_error: 9242.7061\n",
      "Epoch 1505: val_loss improved from 13513.09863 to 13512.89453, saving model to Weights-01505--13512.89453.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9536.6260 - mean_absolute_error: 9536.6260 - val_loss: 13512.8945 - val_mean_absolute_error: 13512.8945\n",
      "Epoch 1506/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8696.0391 - mean_absolute_error: 8696.0391\n",
      "Epoch 1506: val_loss did not improve from 13512.89453\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9541.6143 - mean_absolute_error: 9541.6143 - val_loss: 13515.8760 - val_mean_absolute_error: 13515.8760\n",
      "Epoch 1507/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9139.6875 - mean_absolute_error: 9139.6875\n",
      "Epoch 1507: val_loss improved from 13512.89453 to 13512.10938, saving model to Weights-01507--13512.10938.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9544.5322 - mean_absolute_error: 9544.5322 - val_loss: 13512.1094 - val_mean_absolute_error: 13512.1094\n",
      "Epoch 1508/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8390.0840 - mean_absolute_error: 8390.0840\n",
      "Epoch 1508: val_loss improved from 13512.10938 to 13511.99219, saving model to Weights-01508--13511.99219.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9549.4512 - mean_absolute_error: 9549.4512 - val_loss: 13511.9922 - val_mean_absolute_error: 13511.9922\n",
      "Epoch 1509/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6608.0166 - mean_absolute_error: 6608.0166\n",
      "Epoch 1509: val_loss did not improve from 13511.99219\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9534.2500 - mean_absolute_error: 9534.2500 - val_loss: 13513.7441 - val_mean_absolute_error: 13513.7441\n",
      "Epoch 1510/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9442.8330 - mean_absolute_error: 9442.8330\n",
      "Epoch 1510: val_loss did not improve from 13511.99219\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9535.9561 - mean_absolute_error: 9535.9561 - val_loss: 13513.4844 - val_mean_absolute_error: 13513.4844\n",
      "Epoch 1511/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10173.7461 - mean_absolute_error: 10173.7461\n",
      "Epoch 1511: val_loss improved from 13511.99219 to 13511.33984, saving model to Weights-01511--13511.33984.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9535.3975 - mean_absolute_error: 9535.3975 - val_loss: 13511.3398 - val_mean_absolute_error: 13511.3398\n",
      "Epoch 1512/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8550.0615 - mean_absolute_error: 8550.0615\n",
      "Epoch 1512: val_loss improved from 13511.33984 to 13511.19824, saving model to Weights-01512--13511.19824.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9541.0664 - mean_absolute_error: 9541.0664 - val_loss: 13511.1982 - val_mean_absolute_error: 13511.1982\n",
      "Epoch 1513/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13014.7402 - mean_absolute_error: 13014.7402\n",
      "Epoch 1513: val_loss did not improve from 13511.19824\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9532.1787 - mean_absolute_error: 9532.1787 - val_loss: 13512.2637 - val_mean_absolute_error: 13512.2637\n",
      "Epoch 1514/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11491.2871 - mean_absolute_error: 11491.2871\n",
      "Epoch 1514: val_loss improved from 13511.19824 to 13510.86719, saving model to Weights-01514--13510.86719.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9546.4004 - mean_absolute_error: 9546.4004 - val_loss: 13510.8672 - val_mean_absolute_error: 13510.8672\n",
      "Epoch 1515/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10634.2539 - mean_absolute_error: 10634.2539\n",
      "Epoch 1515: val_loss did not improve from 13510.86719\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9543.6797 - mean_absolute_error: 9543.6797 - val_loss: 13517.7480 - val_mean_absolute_error: 13517.7480\n",
      "Epoch 1516/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8274.5596 - mean_absolute_error: 8274.5596\n",
      "Epoch 1516: val_loss improved from 13510.86719 to 13510.48438, saving model to Weights-01516--13510.48438.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9531.7158 - mean_absolute_error: 9531.7158 - val_loss: 13510.4844 - val_mean_absolute_error: 13510.4844\n",
      "Epoch 1517/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11980.5332 - mean_absolute_error: 11980.5332\n",
      "Epoch 1517: val_loss improved from 13510.48438 to 13510.31250, saving model to Weights-01517--13510.31250.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9549.4238 - mean_absolute_error: 9549.4238 - val_loss: 13510.3125 - val_mean_absolute_error: 13510.3125\n",
      "Epoch 1518/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8680.3184 - mean_absolute_error: 8680.3184\n",
      "Epoch 1518: val_loss did not improve from 13510.31250\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9546.6602 - mean_absolute_error: 9546.6602 - val_loss: 13516.6396 - val_mean_absolute_error: 13516.6396\n",
      "Epoch 1519/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8535.0029 - mean_absolute_error: 8535.0029\n",
      "Epoch 1519: val_loss improved from 13510.31250 to 13510.01270, saving model to Weights-01519--13510.01270.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9539.5264 - mean_absolute_error: 9539.5264 - val_loss: 13510.0127 - val_mean_absolute_error: 13510.0127\n",
      "Epoch 1520/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9520.3750 - mean_absolute_error: 9520.3750\n",
      "Epoch 1520: val_loss did not improve from 13510.01270\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9533.1836 - mean_absolute_error: 9533.1836 - val_loss: 13511.0244 - val_mean_absolute_error: 13511.0244\n",
      "Epoch 1521/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11824.3184 - mean_absolute_error: 11824.3184\n",
      "Epoch 1521: val_loss improved from 13510.01270 to 13509.61035, saving model to Weights-01521--13509.61035.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9531.2139 - mean_absolute_error: 9531.2139 - val_loss: 13509.6104 - val_mean_absolute_error: 13509.6104\n",
      "Epoch 1522/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9358.7754 - mean_absolute_error: 9358.7754\n",
      "Epoch 1522: val_loss improved from 13509.61035 to 13509.44238, saving model to Weights-01522--13509.44238.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9537.2852 - mean_absolute_error: 9537.2852 - val_loss: 13509.4424 - val_mean_absolute_error: 13509.4424\n",
      "Epoch 1523/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13814.2158 - mean_absolute_error: 13814.2158\n",
      "Epoch 1523: val_loss did not improve from 13509.44238\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9534.0342 - mean_absolute_error: 9534.0342 - val_loss: 13510.0781 - val_mean_absolute_error: 13510.0781\n",
      "Epoch 1524/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9467.0449 - mean_absolute_error: 9467.0449\n",
      "Epoch 1524: val_loss did not improve from 13509.44238\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9542.9248 - mean_absolute_error: 9542.9248 - val_loss: 13511.6396 - val_mean_absolute_error: 13511.6396\n",
      "Epoch 1525/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9584.2227 - mean_absolute_error: 9584.2227\n",
      "Epoch 1525: val_loss improved from 13509.44238 to 13509.36035, saving model to Weights-01525--13509.36035.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9526.9854 - mean_absolute_error: 9526.9854 - val_loss: 13509.3604 - val_mean_absolute_error: 13509.3604\n",
      "Epoch 1526/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10038.6543 - mean_absolute_error: 10038.6543\n",
      "Epoch 1526: val_loss did not improve from 13509.36035\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9537.9229 - mean_absolute_error: 9537.9229 - val_loss: 13520.2910 - val_mean_absolute_error: 13520.2910\n",
      "Epoch 1527/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10460.7188 - mean_absolute_error: 10460.7188\n",
      "Epoch 1527: val_loss improved from 13509.36035 to 13509.18359, saving model to Weights-01527--13509.18359.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9554.8555 - mean_absolute_error: 9554.8555 - val_loss: 13509.1836 - val_mean_absolute_error: 13509.1836\n",
      "Epoch 1528/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8491.1592 - mean_absolute_error: 8491.1592\n",
      "Epoch 1528: val_loss improved from 13509.18359 to 13508.84570, saving model to Weights-01528--13508.84570.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9544.3594 - mean_absolute_error: 9544.3594 - val_loss: 13508.8457 - val_mean_absolute_error: 13508.8457\n",
      "Epoch 1529/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6529.8877 - mean_absolute_error: 6529.8877\n",
      "Epoch 1529: val_loss did not improve from 13508.84570\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9529.7207 - mean_absolute_error: 9529.7207 - val_loss: 13510.1846 - val_mean_absolute_error: 13510.1846\n",
      "Epoch 1530/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7369.0029 - mean_absolute_error: 7369.0029\n",
      "Epoch 1530: val_loss improved from 13508.84570 to 13508.15723, saving model to Weights-01530--13508.15723.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9531.5469 - mean_absolute_error: 9531.5469 - val_loss: 13508.1572 - val_mean_absolute_error: 13508.1572\n",
      "Epoch 1531/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8194.2051 - mean_absolute_error: 8194.2051\n",
      "Epoch 1531: val_loss improved from 13508.15723 to 13507.71387, saving model to Weights-01531--13507.71387.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9533.1836 - mean_absolute_error: 9533.1836 - val_loss: 13507.7139 - val_mean_absolute_error: 13507.7139\n",
      "Epoch 1532/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7938.6982 - mean_absolute_error: 7938.6982\n",
      "Epoch 1532: val_loss did not improve from 13507.71387\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9535.8799 - mean_absolute_error: 9535.8799 - val_loss: 13509.3584 - val_mean_absolute_error: 13509.3584\n",
      "Epoch 1533/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10017.3564 - mean_absolute_error: 10017.3564\n",
      "Epoch 1533: val_loss improved from 13507.71387 to 13507.26953, saving model to Weights-01533--13507.26953.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9527.0068 - mean_absolute_error: 9527.0068 - val_loss: 13507.2695 - val_mean_absolute_error: 13507.2695\n",
      "Epoch 1534/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7550.8457 - mean_absolute_error: 7550.8457\n",
      "Epoch 1534: val_loss improved from 13507.26953 to 13507.14062, saving model to Weights-01534--13507.14062.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9530.0371 - mean_absolute_error: 9530.0371 - val_loss: 13507.1406 - val_mean_absolute_error: 13507.1406\n",
      "Epoch 1535/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11651.8887 - mean_absolute_error: 11651.8887\n",
      "Epoch 1535: val_loss did not improve from 13507.14062\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9531.6729 - mean_absolute_error: 9531.6729 - val_loss: 13511.1445 - val_mean_absolute_error: 13511.1436\n",
      "Epoch 1536/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 16028.3398 - mean_absolute_error: 16028.3398\n",
      "Epoch 1536: val_loss did not improve from 13507.14062\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9534.2021 - mean_absolute_error: 9534.2021 - val_loss: 13512.3486 - val_mean_absolute_error: 13512.3486\n",
      "Epoch 1537/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8774.5771 - mean_absolute_error: 8774.5771\n",
      "Epoch 1537: val_loss improved from 13507.14062 to 13506.94629, saving model to Weights-01537--13506.94629.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9528.3213 - mean_absolute_error: 9528.3213 - val_loss: 13506.9463 - val_mean_absolute_error: 13506.9463\n",
      "Epoch 1538/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9374.4570 - mean_absolute_error: 9374.4570\n",
      "Epoch 1538: val_loss improved from 13506.94629 to 13506.38672, saving model to Weights-01538--13506.38672.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9534.5361 - mean_absolute_error: 9534.5361 - val_loss: 13506.3867 - val_mean_absolute_error: 13506.3867\n",
      "Epoch 1539/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8279.0781 - mean_absolute_error: 8279.0781\n",
      "Epoch 1539: val_loss improved from 13506.38672 to 13506.21289, saving model to Weights-01539--13506.21289.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9530.0576 - mean_absolute_error: 9530.0576 - val_loss: 13506.2129 - val_mean_absolute_error: 13506.2129\n",
      "Epoch 1540/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8894.5996 - mean_absolute_error: 8894.5996\n",
      "Epoch 1540: val_loss improved from 13506.21289 to 13506.04395, saving model to Weights-01540--13506.04395.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9535.1904 - mean_absolute_error: 9535.1904 - val_loss: 13506.0439 - val_mean_absolute_error: 13506.0439\n",
      "Epoch 1541/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12112.5781 - mean_absolute_error: 12112.5781\n",
      "Epoch 1541: val_loss did not improve from 13506.04395\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9529.5889 - mean_absolute_error: 9529.5889 - val_loss: 13507.2539 - val_mean_absolute_error: 13507.2539\n",
      "Epoch 1542/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8591.6582 - mean_absolute_error: 8591.6582\n",
      "Epoch 1542: val_loss did not improve from 13506.04395\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9542.5146 - mean_absolute_error: 9542.5146 - val_loss: 13508.4482 - val_mean_absolute_error: 13508.4482\n",
      "Epoch 1543/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9598.4531 - mean_absolute_error: 9598.4531\n",
      "Epoch 1543: val_loss improved from 13506.04395 to 13505.52246, saving model to Weights-01543--13505.52246.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9530.7549 - mean_absolute_error: 9530.7549 - val_loss: 13505.5225 - val_mean_absolute_error: 13505.5225\n",
      "Epoch 1544/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9471.3311 - mean_absolute_error: 9471.3311\n",
      "Epoch 1544: val_loss improved from 13505.52246 to 13505.38574, saving model to Weights-01544--13505.38574.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9531.2803 - mean_absolute_error: 9531.2803 - val_loss: 13505.3857 - val_mean_absolute_error: 13505.3857\n",
      "Epoch 1545/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7964.9512 - mean_absolute_error: 7964.9512\n",
      "Epoch 1545: val_loss did not improve from 13505.38574\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9526.9961 - mean_absolute_error: 9526.9961 - val_loss: 13508.3369 - val_mean_absolute_error: 13508.3369\n",
      "Epoch 1546/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9384.2363 - mean_absolute_error: 9384.2363\n",
      "Epoch 1546: val_loss improved from 13505.38574 to 13504.99316, saving model to Weights-01546--13504.99316.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9528.0479 - mean_absolute_error: 9528.0479 - val_loss: 13504.9932 - val_mean_absolute_error: 13504.9932\n",
      "Epoch 1547/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7153.6382 - mean_absolute_error: 7153.6382\n",
      "Epoch 1547: val_loss improved from 13504.99316 to 13504.76953, saving model to Weights-01547--13504.76953.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9527.8916 - mean_absolute_error: 9527.8916 - val_loss: 13504.7695 - val_mean_absolute_error: 13504.7695\n",
      "Epoch 1548/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8339.0088 - mean_absolute_error: 8339.0088\n",
      "Epoch 1548: val_loss improved from 13504.76953 to 13504.59473, saving model to Weights-01548--13504.59473.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9540.4111 - mean_absolute_error: 9540.4111 - val_loss: 13504.5947 - val_mean_absolute_error: 13504.5947\n",
      "Epoch 1549/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12776.0391 - mean_absolute_error: 12776.0391\n",
      "Epoch 1549: val_loss did not improve from 13504.59473\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9540.2100 - mean_absolute_error: 9540.2100 - val_loss: 13506.8867 - val_mean_absolute_error: 13506.8867\n",
      "Epoch 1550/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7283.2852 - mean_absolute_error: 7283.2852\n",
      "Epoch 1550: val_loss did not improve from 13504.59473\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9544.3662 - mean_absolute_error: 9544.3662 - val_loss: 13510.6729 - val_mean_absolute_error: 13510.6729\n",
      "Epoch 1551/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11962.6426 - mean_absolute_error: 11962.6426\n",
      "Epoch 1551: val_loss improved from 13504.59473 to 13504.46191, saving model to Weights-01551--13504.46191.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9534.0146 - mean_absolute_error: 9534.0146 - val_loss: 13504.4619 - val_mean_absolute_error: 13504.4619\n",
      "Epoch 1552/3000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9573.1533 - mean_absolute_error: 9573.1533\n",
      "Epoch 1552: val_loss did not improve from 13504.46191\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9533.9932 - mean_absolute_error: 9533.9932 - val_loss: 13507.2373 - val_mean_absolute_error: 13507.2373\n",
      "Epoch 1553/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9006.5098 - mean_absolute_error: 9006.5098\n",
      "Epoch 1553: val_loss improved from 13504.46191 to 13503.66797, saving model to Weights-01553--13503.66797.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9526.5049 - mean_absolute_error: 9526.5049 - val_loss: 13503.6680 - val_mean_absolute_error: 13503.6689\n",
      "Epoch 1554/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8401.8691 - mean_absolute_error: 8401.8691\n",
      "Epoch 1554: val_loss improved from 13503.66797 to 13503.53027, saving model to Weights-01554--13503.53027.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9530.8682 - mean_absolute_error: 9530.8682 - val_loss: 13503.5303 - val_mean_absolute_error: 13503.5303\n",
      "Epoch 1555/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8174.8589 - mean_absolute_error: 8174.8589\n",
      "Epoch 1555: val_loss did not improve from 13503.53027\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9542.5859 - mean_absolute_error: 9542.5859 - val_loss: 13507.2373 - val_mean_absolute_error: 13507.2373\n",
      "Epoch 1556/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10305.3232 - mean_absolute_error: 10305.3232\n",
      "Epoch 1556: val_loss did not improve from 13503.53027\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9540.3652 - mean_absolute_error: 9540.3652 - val_loss: 13509.1250 - val_mean_absolute_error: 13509.1250\n",
      "Epoch 1557/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8507.6250 - mean_absolute_error: 8507.6250\n",
      "Epoch 1557: val_loss improved from 13503.53027 to 13502.98145, saving model to Weights-01557--13502.98145.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9523.4844 - mean_absolute_error: 9523.4844 - val_loss: 13502.9814 - val_mean_absolute_error: 13502.9814\n",
      "Epoch 1558/3000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9339.7822 - mean_absolute_error: 9339.7822\n",
      "Epoch 1558: val_loss did not improve from 13502.98145\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9535.4307 - mean_absolute_error: 9535.4307 - val_loss: 13504.1113 - val_mean_absolute_error: 13504.1113\n",
      "Epoch 1559/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9265.1533 - mean_absolute_error: 9265.1533\n",
      "Epoch 1559: val_loss did not improve from 13502.98145\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9533.0742 - mean_absolute_error: 9533.0742 - val_loss: 13505.6172 - val_mean_absolute_error: 13505.6172\n",
      "Epoch 1560/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8203.3828 - mean_absolute_error: 8203.3828\n",
      "Epoch 1560: val_loss did not improve from 13502.98145\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9551.6758 - mean_absolute_error: 9551.6758 - val_loss: 13508.8955 - val_mean_absolute_error: 13508.8955\n",
      "Epoch 1561/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10301.7598 - mean_absolute_error: 10301.7598\n",
      "Epoch 1561: val_loss improved from 13502.98145 to 13502.72168, saving model to Weights-01561--13502.72168.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9525.8711 - mean_absolute_error: 9525.8711 - val_loss: 13502.7217 - val_mean_absolute_error: 13502.7217\n",
      "Epoch 1562/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9386.6650 - mean_absolute_error: 9386.6650\n",
      "Epoch 1562: val_loss improved from 13502.72168 to 13502.26562, saving model to Weights-01562--13502.26562.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9529.4355 - mean_absolute_error: 9529.4355 - val_loss: 13502.2656 - val_mean_absolute_error: 13502.2656\n",
      "Epoch 1563/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8592.8105 - mean_absolute_error: 8592.8105\n",
      "Epoch 1563: val_loss improved from 13502.26562 to 13501.99512, saving model to Weights-01563--13501.99512.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9525.5244 - mean_absolute_error: 9525.5244 - val_loss: 13501.9951 - val_mean_absolute_error: 13501.9951\n",
      "Epoch 1564/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9862.8398 - mean_absolute_error: 9862.8398\n",
      "Epoch 1564: val_loss did not improve from 13501.99512\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9526.6006 - mean_absolute_error: 9526.6006 - val_loss: 13504.4150 - val_mean_absolute_error: 13504.4150\n",
      "Epoch 1565/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9373.9492 - mean_absolute_error: 9373.9492\n",
      "Epoch 1565: val_loss did not improve from 13501.99512\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9525.4766 - mean_absolute_error: 9525.4766 - val_loss: 13502.9531 - val_mean_absolute_error: 13502.9531\n",
      "Epoch 1566/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8170.0410 - mean_absolute_error: 8170.0410\n",
      "Epoch 1566: val_loss did not improve from 13501.99512\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9526.0166 - mean_absolute_error: 9526.0166 - val_loss: 13504.2314 - val_mean_absolute_error: 13504.2314\n",
      "Epoch 1567/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11739.7168 - mean_absolute_error: 11739.7168\n",
      "Epoch 1567: val_loss improved from 13501.99512 to 13501.27344, saving model to Weights-01567--13501.27344.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9528.0781 - mean_absolute_error: 9528.0781 - val_loss: 13501.2734 - val_mean_absolute_error: 13501.2734\n",
      "Epoch 1568/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8475.2617 - mean_absolute_error: 8475.2617\n",
      "Epoch 1568: val_loss did not improve from 13501.27344\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9526.1299 - mean_absolute_error: 9526.1299 - val_loss: 13507.0469 - val_mean_absolute_error: 13507.0469\n",
      "Epoch 1569/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7741.7305 - mean_absolute_error: 7741.7305\n",
      "Epoch 1569: val_loss did not improve from 13501.27344\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9526.0986 - mean_absolute_error: 9526.0986 - val_loss: 13503.2666 - val_mean_absolute_error: 13503.2666\n",
      "Epoch 1570/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8395.5742 - mean_absolute_error: 8395.5742\n",
      "Epoch 1570: val_loss did not improve from 13501.27344\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9526.1904 - mean_absolute_error: 9526.1904 - val_loss: 13505.1904 - val_mean_absolute_error: 13505.1904\n",
      "Epoch 1571/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7302.7627 - mean_absolute_error: 7302.7627\n",
      "Epoch 1571: val_loss did not improve from 13501.27344\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9528.0996 - mean_absolute_error: 9528.0996 - val_loss: 13503.9521 - val_mean_absolute_error: 13503.9521\n",
      "Epoch 1572/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10042.4980 - mean_absolute_error: 10042.4980\n",
      "Epoch 1572: val_loss improved from 13501.27344 to 13500.67773, saving model to Weights-01572--13500.67773.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9528.8975 - mean_absolute_error: 9528.8975 - val_loss: 13500.6777 - val_mean_absolute_error: 13500.6777\n",
      "Epoch 1573/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13602.1523 - mean_absolute_error: 13602.1523\n",
      "Epoch 1573: val_loss did not improve from 13500.67773\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9527.0361 - mean_absolute_error: 9527.0361 - val_loss: 13501.3359 - val_mean_absolute_error: 13501.3359\n",
      "Epoch 1574/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10008.5605 - mean_absolute_error: 10008.5605\n",
      "Epoch 1574: val_loss improved from 13500.67773 to 13500.06641, saving model to Weights-01574--13500.06641.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9525.6865 - mean_absolute_error: 9525.6865 - val_loss: 13500.0664 - val_mean_absolute_error: 13500.0664\n",
      "Epoch 1575/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10226.3633 - mean_absolute_error: 10226.3633\n",
      "Epoch 1575: val_loss did not improve from 13500.06641\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9536.9111 - mean_absolute_error: 9536.9111 - val_loss: 13506.1055 - val_mean_absolute_error: 13506.1055\n",
      "Epoch 1576/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7977.6606 - mean_absolute_error: 7977.6606\n",
      "Epoch 1576: val_loss improved from 13500.06641 to 13499.90918, saving model to Weights-01576--13499.90918.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9521.6963 - mean_absolute_error: 9521.6963 - val_loss: 13499.9092 - val_mean_absolute_error: 13499.9092\n",
      "Epoch 1577/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12355.5508 - mean_absolute_error: 12355.5508\n",
      "Epoch 1577: val_loss improved from 13499.90918 to 13499.47852, saving model to Weights-01577--13499.47852.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9528.2939 - mean_absolute_error: 9528.2939 - val_loss: 13499.4785 - val_mean_absolute_error: 13499.4785\n",
      "Epoch 1578/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11948.6621 - mean_absolute_error: 11948.6621\n",
      "Epoch 1578: val_loss did not improve from 13499.47852\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9528.3799 - mean_absolute_error: 9528.3799 - val_loss: 13509.1738 - val_mean_absolute_error: 13509.1738\n",
      "Epoch 1579/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9618.4414 - mean_absolute_error: 9618.4414\n",
      "Epoch 1579: val_loss improved from 13499.47852 to 13499.09668, saving model to Weights-01579--13499.09668.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9529.1689 - mean_absolute_error: 9529.1689 - val_loss: 13499.0967 - val_mean_absolute_error: 13499.0967\n",
      "Epoch 1580/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8652.3281 - mean_absolute_error: 8652.3281\n",
      "Epoch 1580: val_loss did not improve from 13499.09668\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9525.0127 - mean_absolute_error: 9525.0127 - val_loss: 13499.8984 - val_mean_absolute_error: 13499.8984\n",
      "Epoch 1581/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9209.8691 - mean_absolute_error: 9209.8691\n",
      "Epoch 1581: val_loss did not improve from 13499.09668\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9527.5029 - mean_absolute_error: 9527.5029 - val_loss: 13514.0781 - val_mean_absolute_error: 13514.0781\n",
      "Epoch 1582/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8687.6357 - mean_absolute_error: 8687.6357\n",
      "Epoch 1582: val_loss did not improve from 13499.09668\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9525.2393 - mean_absolute_error: 9525.2393 - val_loss: 13499.8125 - val_mean_absolute_error: 13499.8125\n",
      "Epoch 1583/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9452.0508 - mean_absolute_error: 9452.0508\n",
      "Epoch 1583: val_loss did not improve from 13499.09668\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9523.8604 - mean_absolute_error: 9523.8604 - val_loss: 13503.2451 - val_mean_absolute_error: 13503.2451\n",
      "Epoch 1584/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11422.5684 - mean_absolute_error: 11422.5684\n",
      "Epoch 1584: val_loss improved from 13499.09668 to 13498.40039, saving model to Weights-01584--13498.40039.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9529.9023 - mean_absolute_error: 9529.9023 - val_loss: 13498.4004 - val_mean_absolute_error: 13498.4004\n",
      "Epoch 1585/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9762.6016 - mean_absolute_error: 9762.6016\n",
      "Epoch 1585: val_loss did not improve from 13498.40039\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9531.3789 - mean_absolute_error: 9531.3789 - val_loss: 13503.7324 - val_mean_absolute_error: 13503.7324\n",
      "Epoch 1586/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9579.2812 - mean_absolute_error: 9579.2812\n",
      "Epoch 1586: val_loss improved from 13498.40039 to 13498.29297, saving model to Weights-01586--13498.29297.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9535.2969 - mean_absolute_error: 9535.2969 - val_loss: 13498.2930 - val_mean_absolute_error: 13498.2930\n",
      "Epoch 1587/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 14963.9648 - mean_absolute_error: 14963.9648\n",
      "Epoch 1587: val_loss did not improve from 13498.29297\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9516.6211 - mean_absolute_error: 9516.6211 - val_loss: 13504.2197 - val_mean_absolute_error: 13504.2197\n",
      "Epoch 1588/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12242.1943 - mean_absolute_error: 12242.1943\n",
      "Epoch 1588: val_loss did not improve from 13498.29297\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9524.9258 - mean_absolute_error: 9524.9258 - val_loss: 13504.4609 - val_mean_absolute_error: 13504.4609\n",
      "Epoch 1589/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7797.6802 - mean_absolute_error: 7797.6802\n",
      "Epoch 1589: val_loss did not improve from 13498.29297\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9526.1768 - mean_absolute_error: 9526.1768 - val_loss: 13501.2861 - val_mean_absolute_error: 13501.2861\n",
      "Epoch 1590/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9335.4883 - mean_absolute_error: 9335.4883\n",
      "Epoch 1590: val_loss did not improve from 13498.29297\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9526.2168 - mean_absolute_error: 9526.2168 - val_loss: 13502.1396 - val_mean_absolute_error: 13502.1396\n",
      "Epoch 1591/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12065.2480 - mean_absolute_error: 12065.2480\n",
      "Epoch 1591: val_loss did not improve from 13498.29297\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9534.8389 - mean_absolute_error: 9534.8389 - val_loss: 13505.0889 - val_mean_absolute_error: 13505.0889\n",
      "Epoch 1592/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8289.9561 - mean_absolute_error: 8289.9561\n",
      "Epoch 1592: val_loss improved from 13498.29297 to 13497.85742, saving model to Weights-01592--13497.85742.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9518.1025 - mean_absolute_error: 9518.1025 - val_loss: 13497.8574 - val_mean_absolute_error: 13497.8574\n",
      "Epoch 1593/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 14778.3516 - mean_absolute_error: 14778.3516\n",
      "Epoch 1593: val_loss improved from 13497.85742 to 13497.34082, saving model to Weights-01593--13497.34082.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9524.7871 - mean_absolute_error: 9524.7871 - val_loss: 13497.3408 - val_mean_absolute_error: 13497.3408\n",
      "Epoch 1594/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11746.1855 - mean_absolute_error: 11746.1855\n",
      "Epoch 1594: val_loss did not improve from 13497.34082\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9521.3135 - mean_absolute_error: 9521.3135 - val_loss: 13497.4355 - val_mean_absolute_error: 13497.4355\n",
      "Epoch 1595/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8068.8516 - mean_absolute_error: 8068.8516\n",
      "Epoch 1595: val_loss did not improve from 13497.34082\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9524.1289 - mean_absolute_error: 9524.1289 - val_loss: 13498.1309 - val_mean_absolute_error: 13498.1309\n",
      "Epoch 1596/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7442.0273 - mean_absolute_error: 7442.0273\n",
      "Epoch 1596: val_loss improved from 13497.34082 to 13496.68848, saving model to Weights-01596--13496.68848.hdf5\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9527.6982 - mean_absolute_error: 9527.6982 - val_loss: 13496.6885 - val_mean_absolute_error: 13496.6885\n",
      "Epoch 1597/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11440.9434 - mean_absolute_error: 11440.9434\n",
      "Epoch 1597: val_loss did not improve from 13496.68848\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9530.3809 - mean_absolute_error: 9530.3809 - val_loss: 13505.9736 - val_mean_absolute_error: 13505.9736\n",
      "Epoch 1598/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11097.7197 - mean_absolute_error: 11097.7197\n",
      "Epoch 1598: val_loss did not improve from 13496.68848\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9519.7070 - mean_absolute_error: 9519.7070 - val_loss: 13502.3037 - val_mean_absolute_error: 13502.3037\n",
      "Epoch 1599/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9833.6191 - mean_absolute_error: 9833.6191\n",
      "Epoch 1599: val_loss did not improve from 13496.68848\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9521.8828 - mean_absolute_error: 9521.8828 - val_loss: 13500.5322 - val_mean_absolute_error: 13500.5322\n",
      "Epoch 1600/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12402.0293 - mean_absolute_error: 12402.0293\n",
      "Epoch 1600: val_loss did not improve from 13496.68848\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9521.3203 - mean_absolute_error: 9521.3203 - val_loss: 13501.9766 - val_mean_absolute_error: 13501.9766\n",
      "Epoch 1601/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7439.1958 - mean_absolute_error: 7439.1958\n",
      "Epoch 1601: val_loss did not improve from 13496.68848\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9520.6943 - mean_absolute_error: 9520.6943 - val_loss: 13499.5566 - val_mean_absolute_error: 13499.5566\n",
      "Epoch 1602/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10676.5059 - mean_absolute_error: 10676.5059\n",
      "Epoch 1602: val_loss did not improve from 13496.68848\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9520.9902 - mean_absolute_error: 9520.9902 - val_loss: 13500.8398 - val_mean_absolute_error: 13500.8398\n",
      "Epoch 1603/3000\n",
      " 8/18 [============>.................] - ETA: 0s - loss: 8861.7705 - mean_absolute_error: 8861.7705  \n",
      "Epoch 1603: val_loss improved from 13496.68848 to 13495.24121, saving model to Weights-01603--13495.24121.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9525.5225 - mean_absolute_error: 9525.5225 - val_loss: 13495.2412 - val_mean_absolute_error: 13495.2412\n",
      "Epoch 1604/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12475.0703 - mean_absolute_error: 12475.0703\n",
      "Epoch 1604: val_loss did not improve from 13495.24121\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9528.9014 - mean_absolute_error: 9528.9014 - val_loss: 13499.8203 - val_mean_absolute_error: 13499.8203\n",
      "Epoch 1605/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13473.3555 - mean_absolute_error: 13473.3555\n",
      "Epoch 1605: val_loss did not improve from 13495.24121\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9557.9961 - mean_absolute_error: 9557.9961 - val_loss: 13497.7471 - val_mean_absolute_error: 13497.7471\n",
      "Epoch 1606/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10951.0264 - mean_absolute_error: 10951.0264\n",
      "Epoch 1606: val_loss did not improve from 13495.24121\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9519.6133 - mean_absolute_error: 9519.6133 - val_loss: 13497.0312 - val_mean_absolute_error: 13497.0312\n",
      "Epoch 1607/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12254.6602 - mean_absolute_error: 12254.6602\n",
      "Epoch 1607: val_loss improved from 13495.24121 to 13495.22461, saving model to Weights-01607--13495.22461.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9525.2539 - mean_absolute_error: 9525.2539 - val_loss: 13495.2246 - val_mean_absolute_error: 13495.2246\n",
      "Epoch 1608/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8314.7871 - mean_absolute_error: 8314.7871\n",
      "Epoch 1608: val_loss did not improve from 13495.22461\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9520.2852 - mean_absolute_error: 9520.2852 - val_loss: 13496.1562 - val_mean_absolute_error: 13496.1562\n",
      "Epoch 1609/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6988.6992 - mean_absolute_error: 6988.6992\n",
      "Epoch 1609: val_loss did not improve from 13495.22461\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9530.9268 - mean_absolute_error: 9530.9268 - val_loss: 13505.6924 - val_mean_absolute_error: 13505.6924\n",
      "Epoch 1610/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9556.3369 - mean_absolute_error: 9556.3369\n",
      "Epoch 1610: val_loss did not improve from 13495.22461\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9523.7158 - mean_absolute_error: 9523.7158 - val_loss: 13498.3818 - val_mean_absolute_error: 13498.3818\n",
      "Epoch 1611/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8437.3340 - mean_absolute_error: 8437.3340\n",
      "Epoch 1611: val_loss did not improve from 13495.22461\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9521.0850 - mean_absolute_error: 9521.0850 - val_loss: 13501.1621 - val_mean_absolute_error: 13501.1621\n",
      "Epoch 1612/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9694.6836 - mean_absolute_error: 9694.6836\n",
      "Epoch 1612: val_loss did not improve from 13495.22461\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9519.0488 - mean_absolute_error: 9519.0488 - val_loss: 13503.2393 - val_mean_absolute_error: 13503.2393\n",
      "Epoch 1613/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9406.7080 - mean_absolute_error: 9406.7080\n",
      "Epoch 1613: val_loss did not improve from 13495.22461\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9520.1299 - mean_absolute_error: 9520.1299 - val_loss: 13501.0127 - val_mean_absolute_error: 13501.0127\n",
      "Epoch 1614/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9389.7637 - mean_absolute_error: 9389.7637\n",
      "Epoch 1614: val_loss did not improve from 13495.22461\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9521.3682 - mean_absolute_error: 9521.3682 - val_loss: 13500.9658 - val_mean_absolute_error: 13500.9648\n",
      "Epoch 1615/3000\n",
      "11/18 [=================>............] - ETA: 0s - loss: 9179.3613 - mean_absolute_error: 9179.3613\n",
      "Epoch 1615: val_loss improved from 13495.22461 to 13494.29785, saving model to Weights-01615--13494.29785.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9525.8535 - mean_absolute_error: 9525.8535 - val_loss: 13494.2979 - val_mean_absolute_error: 13494.2979\n",
      "Epoch 1616/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 15598.4580 - mean_absolute_error: 15598.4580\n",
      "Epoch 1616: val_loss did not improve from 13494.29785\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9522.9736 - mean_absolute_error: 9522.9736 - val_loss: 13495.0264 - val_mean_absolute_error: 13495.0264\n",
      "Epoch 1617/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7348.3569 - mean_absolute_error: 7348.3569\n",
      "Epoch 1617: val_loss did not improve from 13494.29785\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9523.3311 - mean_absolute_error: 9523.3311 - val_loss: 13501.5801 - val_mean_absolute_error: 13501.5801\n",
      "Epoch 1618/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9612.6523 - mean_absolute_error: 9612.6523\n",
      "Epoch 1618: val_loss did not improve from 13494.29785\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9518.5508 - mean_absolute_error: 9518.5508 - val_loss: 13502.2354 - val_mean_absolute_error: 13502.2354\n",
      "Epoch 1619/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9379.2383 - mean_absolute_error: 9379.2383\n",
      "Epoch 1619: val_loss did not improve from 13494.29785\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9524.9531 - mean_absolute_error: 9524.9531 - val_loss: 13505.1348 - val_mean_absolute_error: 13505.1348\n",
      "Epoch 1620/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12422.5312 - mean_absolute_error: 12422.5312\n",
      "Epoch 1620: val_loss did not improve from 13494.29785\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9518.8418 - mean_absolute_error: 9518.8418 - val_loss: 13497.6641 - val_mean_absolute_error: 13497.6641\n",
      "Epoch 1621/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6591.5146 - mean_absolute_error: 6591.5146\n",
      "Epoch 1621: val_loss did not improve from 13494.29785\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9526.7988 - mean_absolute_error: 9526.7988 - val_loss: 13494.7441 - val_mean_absolute_error: 13494.7441\n",
      "Epoch 1622/3000\n",
      " 8/18 [============>.................] - ETA: 0s - loss: 9278.5801 - mean_absolute_error: 9278.5801  \n",
      "Epoch 1622: val_loss did not improve from 13494.29785\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9523.1211 - mean_absolute_error: 9523.1211 - val_loss: 13499.7129 - val_mean_absolute_error: 13499.7129\n",
      "Epoch 1623/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10584.5566 - mean_absolute_error: 10584.5566\n",
      "Epoch 1623: val_loss did not improve from 13494.29785\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9516.9326 - mean_absolute_error: 9516.9326 - val_loss: 13499.9590 - val_mean_absolute_error: 13499.9590\n",
      "Epoch 1624/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8827.3574 - mean_absolute_error: 8827.3574\n",
      "Epoch 1624: val_loss did not improve from 13494.29785\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9518.2139 - mean_absolute_error: 9518.2139 - val_loss: 13499.1895 - val_mean_absolute_error: 13499.1895\n",
      "Epoch 1625/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8466.0801 - mean_absolute_error: 8466.0801\n",
      "Epoch 1625: val_loss improved from 13494.29785 to 13493.63281, saving model to Weights-01625--13493.63281.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9523.8359 - mean_absolute_error: 9523.8359 - val_loss: 13493.6328 - val_mean_absolute_error: 13493.6328\n",
      "Epoch 1626/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9866.4004 - mean_absolute_error: 9866.4004\n",
      "Epoch 1626: val_loss did not improve from 13493.63281\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9519.8672 - mean_absolute_error: 9519.8672 - val_loss: 13495.7764 - val_mean_absolute_error: 13495.7764\n",
      "Epoch 1627/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10444.1816 - mean_absolute_error: 10444.1816\n",
      "Epoch 1627: val_loss did not improve from 13493.63281\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9516.1035 - mean_absolute_error: 9516.1035 - val_loss: 13495.9521 - val_mean_absolute_error: 13495.9521\n",
      "Epoch 1628/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13949.6602 - mean_absolute_error: 13949.6602\n",
      "Epoch 1628: val_loss did not improve from 13493.63281\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9518.9639 - mean_absolute_error: 9518.9639 - val_loss: 13494.5254 - val_mean_absolute_error: 13494.5254\n",
      "Epoch 1629/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7659.6621 - mean_absolute_error: 7659.6621\n",
      "Epoch 1629: val_loss did not improve from 13493.63281\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9519.8330 - mean_absolute_error: 9519.8330 - val_loss: 13494.0557 - val_mean_absolute_error: 13494.0557\n",
      "Epoch 1630/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6448.3291 - mean_absolute_error: 6448.3291\n",
      "Epoch 1630: val_loss improved from 13493.63281 to 13491.00195, saving model to Weights-01630--13491.00195.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9535.1973 - mean_absolute_error: 9535.1973 - val_loss: 13491.0020 - val_mean_absolute_error: 13491.0020\n",
      "Epoch 1631/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7653.3032 - mean_absolute_error: 7653.3032\n",
      "Epoch 1631: val_loss did not improve from 13491.00195\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9515.5605 - mean_absolute_error: 9515.5605 - val_loss: 13501.2646 - val_mean_absolute_error: 13501.2646\n",
      "Epoch 1632/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9116.8145 - mean_absolute_error: 9116.8145\n",
      "Epoch 1632: val_loss did not improve from 13491.00195\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9521.4111 - mean_absolute_error: 9521.4111 - val_loss: 13506.3447 - val_mean_absolute_error: 13506.3447\n",
      "Epoch 1633/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7797.1743 - mean_absolute_error: 7797.1743\n",
      "Epoch 1633: val_loss did not improve from 13491.00195\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9512.5332 - mean_absolute_error: 9512.5332 - val_loss: 13493.6582 - val_mean_absolute_error: 13493.6582\n",
      "Epoch 1634/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7952.7114 - mean_absolute_error: 7952.7114\n",
      "Epoch 1634: val_loss improved from 13491.00195 to 13490.43652, saving model to Weights-01634--13490.43652.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9526.2021 - mean_absolute_error: 9526.2021 - val_loss: 13490.4365 - val_mean_absolute_error: 13490.4365\n",
      "Epoch 1635/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8652.6758 - mean_absolute_error: 8652.6758\n",
      "Epoch 1635: val_loss did not improve from 13490.43652\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9520.4277 - mean_absolute_error: 9520.4277 - val_loss: 13492.7178 - val_mean_absolute_error: 13492.7168\n",
      "Epoch 1636/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10364.1631 - mean_absolute_error: 10364.1631\n",
      "Epoch 1636: val_loss did not improve from 13490.43652\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9524.3506 - mean_absolute_error: 9524.3506 - val_loss: 13504.2822 - val_mean_absolute_error: 13504.2822\n",
      "Epoch 1637/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5591.8623 - mean_absolute_error: 5591.8623\n",
      "Epoch 1637: val_loss did not improve from 13490.43652\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9512.9902 - mean_absolute_error: 9512.9902 - val_loss: 13492.7637 - val_mean_absolute_error: 13492.7637\n",
      "Epoch 1638/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7099.6479 - mean_absolute_error: 7099.6479\n",
      "Epoch 1638: val_loss improved from 13490.43652 to 13489.99609, saving model to Weights-01638--13489.99609.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9518.5078 - mean_absolute_error: 9518.5078 - val_loss: 13489.9961 - val_mean_absolute_error: 13489.9961\n",
      "Epoch 1639/3000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9733.4082 - mean_absolute_error: 9733.4082  \n",
      "Epoch 1639: val_loss did not improve from 13489.99609\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9527.1553 - mean_absolute_error: 9527.1553 - val_loss: 13497.9062 - val_mean_absolute_error: 13497.9062\n",
      "Epoch 1640/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9385.3320 - mean_absolute_error: 9385.3320\n",
      "Epoch 1640: val_loss improved from 13489.99609 to 13489.67285, saving model to Weights-01640--13489.67285.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9523.9121 - mean_absolute_error: 9523.9121 - val_loss: 13489.6729 - val_mean_absolute_error: 13489.6729\n",
      "Epoch 1641/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8430.6816 - mean_absolute_error: 8430.6816\n",
      "Epoch 1641: val_loss did not improve from 13489.67285\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9522.4531 - mean_absolute_error: 9522.4531 - val_loss: 13490.8213 - val_mean_absolute_error: 13490.8213\n",
      "Epoch 1642/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12349.1426 - mean_absolute_error: 12349.1426\n",
      "Epoch 1642: val_loss did not improve from 13489.67285\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9509.2725 - mean_absolute_error: 9509.2725 - val_loss: 13502.8975 - val_mean_absolute_error: 13502.8975\n",
      "Epoch 1643/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8318.6992 - mean_absolute_error: 8318.6992\n",
      "Epoch 1643: val_loss did not improve from 13489.67285\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9517.5732 - mean_absolute_error: 9517.5732 - val_loss: 13497.9463 - val_mean_absolute_error: 13497.9463\n",
      "Epoch 1644/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9989.4258 - mean_absolute_error: 9989.4258\n",
      "Epoch 1644: val_loss did not improve from 13489.67285\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9533.6533 - mean_absolute_error: 9533.6533 - val_loss: 13489.9561 - val_mean_absolute_error: 13489.9561\n",
      "Epoch 1645/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9364.6387 - mean_absolute_error: 9364.6387\n",
      "Epoch 1645: val_loss did not improve from 13489.67285\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9517.4531 - mean_absolute_error: 9517.4531 - val_loss: 13495.2627 - val_mean_absolute_error: 13495.2627\n",
      "Epoch 1646/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8729.9463 - mean_absolute_error: 8729.9463\n",
      "Epoch 1646: val_loss did not improve from 13489.67285\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9533.3926 - mean_absolute_error: 9533.3926 - val_loss: 13507.3369 - val_mean_absolute_error: 13507.3369\n",
      "Epoch 1647/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8172.7324 - mean_absolute_error: 8172.7324\n",
      "Epoch 1647: val_loss improved from 13489.67285 to 13488.90918, saving model to Weights-01647--13488.90918.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9526.5986 - mean_absolute_error: 9526.5986 - val_loss: 13488.9092 - val_mean_absolute_error: 13488.9092\n",
      "Epoch 1648/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12755.0410 - mean_absolute_error: 12755.0410\n",
      "Epoch 1648: val_loss did not improve from 13488.90918\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9526.2939 - mean_absolute_error: 9526.2939 - val_loss: 13491.1016 - val_mean_absolute_error: 13491.1016\n",
      "Epoch 1649/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8775.9492 - mean_absolute_error: 8775.9492\n",
      "Epoch 1649: val_loss did not improve from 13488.90918\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9521.1201 - mean_absolute_error: 9521.1201 - val_loss: 13492.0195 - val_mean_absolute_error: 13492.0195\n",
      "Epoch 1650/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11227.6113 - mean_absolute_error: 11227.6113\n",
      "Epoch 1650: val_loss did not improve from 13488.90918\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9519.2910 - mean_absolute_error: 9519.2910 - val_loss: 13501.0225 - val_mean_absolute_error: 13501.0225\n",
      "Epoch 1651/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11728.2461 - mean_absolute_error: 11728.2461\n",
      "Epoch 1651: val_loss did not improve from 13488.90918\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9521.0723 - mean_absolute_error: 9521.0723 - val_loss: 13490.0752 - val_mean_absolute_error: 13490.0752\n",
      "Epoch 1652/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6267.3555 - mean_absolute_error: 6267.3555\n",
      "Epoch 1652: val_loss did not improve from 13488.90918\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9513.7139 - mean_absolute_error: 9513.7139 - val_loss: 13496.2607 - val_mean_absolute_error: 13496.2607\n",
      "Epoch 1653/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13147.2363 - mean_absolute_error: 13147.2363\n",
      "Epoch 1653: val_loss did not improve from 13488.90918\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9532.6562 - mean_absolute_error: 9532.6562 - val_loss: 13488.9424 - val_mean_absolute_error: 13488.9424\n",
      "Epoch 1654/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8786.2773 - mean_absolute_error: 8786.2773\n",
      "Epoch 1654: val_loss did not improve from 13488.90918\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9514.1152 - mean_absolute_error: 9514.1152 - val_loss: 13500.2529 - val_mean_absolute_error: 13500.2529\n",
      "Epoch 1655/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8917.1953 - mean_absolute_error: 8917.1953\n",
      "Epoch 1655: val_loss did not improve from 13488.90918\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9514.3281 - mean_absolute_error: 9514.3281 - val_loss: 13495.9268 - val_mean_absolute_error: 13495.9268\n",
      "Epoch 1656/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9358.6328 - mean_absolute_error: 9358.6328\n",
      "Epoch 1656: val_loss did not improve from 13488.90918\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9512.2686 - mean_absolute_error: 9512.2686 - val_loss: 13495.0615 - val_mean_absolute_error: 13495.0615\n",
      "Epoch 1657/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7723.8491 - mean_absolute_error: 7723.8491\n",
      "Epoch 1657: val_loss improved from 13488.90918 to 13488.51270, saving model to Weights-01657--13488.51270.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9535.5078 - mean_absolute_error: 9535.5078 - val_loss: 13488.5127 - val_mean_absolute_error: 13488.5127\n",
      "Epoch 1658/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7601.4536 - mean_absolute_error: 7601.4536\n",
      "Epoch 1658: val_loss did not improve from 13488.51270\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9507.5820 - mean_absolute_error: 9507.5820 - val_loss: 13496.1094 - val_mean_absolute_error: 13496.1094\n",
      "Epoch 1659/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10008.3662 - mean_absolute_error: 10008.3662\n",
      "Epoch 1659: val_loss did not improve from 13488.51270\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9519.2969 - mean_absolute_error: 9519.2969 - val_loss: 13493.4648 - val_mean_absolute_error: 13493.4648\n",
      "Epoch 1660/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7501.0205 - mean_absolute_error: 7501.0205\n",
      "Epoch 1660: val_loss did not improve from 13488.51270\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9512.9844 - mean_absolute_error: 9512.9844 - val_loss: 13498.1719 - val_mean_absolute_error: 13498.1719\n",
      "Epoch 1661/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 14664.0879 - mean_absolute_error: 14664.0879\n",
      "Epoch 1661: val_loss did not improve from 13488.51270\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9512.3750 - mean_absolute_error: 9512.3750 - val_loss: 13489.6406 - val_mean_absolute_error: 13489.6406\n",
      "Epoch 1662/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8789.4707 - mean_absolute_error: 8789.4707\n",
      "Epoch 1662: val_loss did not improve from 13488.51270\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9513.2246 - mean_absolute_error: 9513.2246 - val_loss: 13491.9326 - val_mean_absolute_error: 13491.9326\n",
      "Epoch 1663/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9492.4541 - mean_absolute_error: 9492.4541\n",
      "Epoch 1663: val_loss improved from 13488.51270 to 13487.95508, saving model to Weights-01663--13487.95508.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9531.5713 - mean_absolute_error: 9531.5713 - val_loss: 13487.9551 - val_mean_absolute_error: 13487.9551\n",
      "Epoch 1664/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7682.9419 - mean_absolute_error: 7682.9419\n",
      "Epoch 1664: val_loss did not improve from 13487.95508\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9516.6943 - mean_absolute_error: 9516.6943 - val_loss: 13488.6064 - val_mean_absolute_error: 13488.6064\n",
      "Epoch 1665/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10642.5254 - mean_absolute_error: 10642.5254\n",
      "Epoch 1665: val_loss did not improve from 13487.95508\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9514.6484 - mean_absolute_error: 9514.6484 - val_loss: 13502.6768 - val_mean_absolute_error: 13502.6768\n",
      "Epoch 1666/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6850.9443 - mean_absolute_error: 6850.9443\n",
      "Epoch 1666: val_loss did not improve from 13487.95508\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9518.9336 - mean_absolute_error: 9518.9336 - val_loss: 13496.6768 - val_mean_absolute_error: 13496.6768\n",
      "Epoch 1667/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10091.7363 - mean_absolute_error: 10091.7363\n",
      "Epoch 1667: val_loss improved from 13487.95508 to 13486.52051, saving model to Weights-01667--13486.52051.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9511.0303 - mean_absolute_error: 9511.0303 - val_loss: 13486.5205 - val_mean_absolute_error: 13486.5205\n",
      "Epoch 1668/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11695.7764 - mean_absolute_error: 11695.7764\n",
      "Epoch 1668: val_loss did not improve from 13486.52051\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9512.8975 - mean_absolute_error: 9512.8975 - val_loss: 13487.3379 - val_mean_absolute_error: 13487.3379\n",
      "Epoch 1669/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9764.2031 - mean_absolute_error: 9764.2031\n",
      "Epoch 1669: val_loss did not improve from 13486.52051\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9539.7695 - mean_absolute_error: 9539.7695 - val_loss: 13495.7646 - val_mean_absolute_error: 13495.7646\n",
      "Epoch 1670/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9402.9473 - mean_absolute_error: 9402.9473\n",
      "Epoch 1670: val_loss did not improve from 13486.52051\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9509.4893 - mean_absolute_error: 9509.4893 - val_loss: 13487.5508 - val_mean_absolute_error: 13487.5508\n",
      "Epoch 1671/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9429.9463 - mean_absolute_error: 9429.9463\n",
      "Epoch 1671: val_loss improved from 13486.52051 to 13485.94434, saving model to Weights-01671--13485.94434.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9510.7354 - mean_absolute_error: 9510.7354 - val_loss: 13485.9443 - val_mean_absolute_error: 13485.9443\n",
      "Epoch 1672/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9730.5098 - mean_absolute_error: 9730.5098\n",
      "Epoch 1672: val_loss did not improve from 13485.94434\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9512.8701 - mean_absolute_error: 9512.8701 - val_loss: 13492.3838 - val_mean_absolute_error: 13492.3828\n",
      "Epoch 1673/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7522.3086 - mean_absolute_error: 7522.3086\n",
      "Epoch 1673: val_loss did not improve from 13485.94434\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9509.6816 - mean_absolute_error: 9509.6816 - val_loss: 13490.9951 - val_mean_absolute_error: 13490.9951\n",
      "Epoch 1674/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13233.5977 - mean_absolute_error: 13233.5977\n",
      "Epoch 1674: val_loss did not improve from 13485.94434\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9517.2324 - mean_absolute_error: 9517.2324 - val_loss: 13486.5410 - val_mean_absolute_error: 13486.5410\n",
      "Epoch 1675/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11621.9199 - mean_absolute_error: 11621.9199\n",
      "Epoch 1675: val_loss did not improve from 13485.94434\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9513.7344 - mean_absolute_error: 9513.7344 - val_loss: 13496.3486 - val_mean_absolute_error: 13496.3486\n",
      "Epoch 1676/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8249.1875 - mean_absolute_error: 8249.1875\n",
      "Epoch 1676: val_loss did not improve from 13485.94434\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9515.6865 - mean_absolute_error: 9515.6865 - val_loss: 13488.6406 - val_mean_absolute_error: 13488.6406\n",
      "Epoch 1677/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11312.0879 - mean_absolute_error: 11312.0879\n",
      "Epoch 1677: val_loss did not improve from 13485.94434\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9510.6230 - mean_absolute_error: 9510.6230 - val_loss: 13496.3682 - val_mean_absolute_error: 13496.3682\n",
      "Epoch 1678/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10508.4551 - mean_absolute_error: 10508.4551\n",
      "Epoch 1678: val_loss did not improve from 13485.94434\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9513.8408 - mean_absolute_error: 9513.8408 - val_loss: 13486.5264 - val_mean_absolute_error: 13486.5264\n",
      "Epoch 1679/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10731.2314 - mean_absolute_error: 10731.2314\n",
      "Epoch 1679: val_loss did not improve from 13485.94434\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9512.1807 - mean_absolute_error: 9512.1807 - val_loss: 13489.2969 - val_mean_absolute_error: 13489.2969\n",
      "Epoch 1680/3000\n",
      " 8/18 [============>.................] - ETA: 0s - loss: 9535.9180 - mean_absolute_error: 9535.9180\n",
      "Epoch 1680: val_loss did not improve from 13485.94434\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9509.5742 - mean_absolute_error: 9509.5742 - val_loss: 13487.6240 - val_mean_absolute_error: 13487.6240\n",
      "Epoch 1681/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11062.7402 - mean_absolute_error: 11062.7402\n",
      "Epoch 1681: val_loss did not improve from 13485.94434\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9509.8701 - mean_absolute_error: 9509.8701 - val_loss: 13489.3496 - val_mean_absolute_error: 13489.3496\n",
      "Epoch 1682/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9554.5088 - mean_absolute_error: 9554.5088\n",
      "Epoch 1682: val_loss improved from 13485.94434 to 13485.57520, saving model to Weights-01682--13485.57520.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9523.4160 - mean_absolute_error: 9523.4160 - val_loss: 13485.5752 - val_mean_absolute_error: 13485.5752\n",
      "Epoch 1683/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7441.3955 - mean_absolute_error: 7441.3955\n",
      "Epoch 1683: val_loss did not improve from 13485.57520\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9514.2920 - mean_absolute_error: 9514.2920 - val_loss: 13496.8623 - val_mean_absolute_error: 13496.8623\n",
      "Epoch 1684/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8024.8105 - mean_absolute_error: 8024.8105\n",
      "Epoch 1684: val_loss did not improve from 13485.57520\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9514.1572 - mean_absolute_error: 9514.1572 - val_loss: 13487.3281 - val_mean_absolute_error: 13487.3281\n",
      "Epoch 1685/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10675.4805 - mean_absolute_error: 10675.4805\n",
      "Epoch 1685: val_loss did not improve from 13485.57520\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9529.0000 - mean_absolute_error: 9529.0000 - val_loss: 13495.1475 - val_mean_absolute_error: 13495.1475\n",
      "Epoch 1686/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7216.6729 - mean_absolute_error: 7216.6729\n",
      "Epoch 1686: val_loss improved from 13485.57520 to 13484.02246, saving model to Weights-01686--13484.02246.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9517.0977 - mean_absolute_error: 9517.0977 - val_loss: 13484.0225 - val_mean_absolute_error: 13484.0225\n",
      "Epoch 1687/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7821.6143 - mean_absolute_error: 7821.6143\n",
      "Epoch 1687: val_loss did not improve from 13484.02246\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9516.0273 - mean_absolute_error: 9516.0273 - val_loss: 13486.1250 - val_mean_absolute_error: 13486.1260\n",
      "Epoch 1688/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12631.6387 - mean_absolute_error: 12631.6387\n",
      "Epoch 1688: val_loss improved from 13484.02246 to 13483.65723, saving model to Weights-01688--13483.65723.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9509.3926 - mean_absolute_error: 9509.3926 - val_loss: 13483.6572 - val_mean_absolute_error: 13483.6572\n",
      "Epoch 1689/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7890.0547 - mean_absolute_error: 7890.0547\n",
      "Epoch 1689: val_loss improved from 13483.65723 to 13483.35645, saving model to Weights-01689--13483.35645.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9514.7881 - mean_absolute_error: 9514.7881 - val_loss: 13483.3564 - val_mean_absolute_error: 13483.3564\n",
      "Epoch 1690/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9284.3887 - mean_absolute_error: 9284.3887\n",
      "Epoch 1690: val_loss did not improve from 13483.35645\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9508.8223 - mean_absolute_error: 9508.8223 - val_loss: 13494.8848 - val_mean_absolute_error: 13494.8848\n",
      "Epoch 1691/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12377.0664 - mean_absolute_error: 12377.0664\n",
      "Epoch 1691: val_loss did not improve from 13483.35645\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9535.4121 - mean_absolute_error: 9535.4121 - val_loss: 13485.2373 - val_mean_absolute_error: 13485.2373\n",
      "Epoch 1692/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7917.0845 - mean_absolute_error: 7917.0845\n",
      "Epoch 1692: val_loss did not improve from 13483.35645\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9505.6230 - mean_absolute_error: 9505.6230 - val_loss: 13496.6455 - val_mean_absolute_error: 13496.6455\n",
      "Epoch 1693/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8032.7212 - mean_absolute_error: 8032.7212\n",
      "Epoch 1693: val_loss did not improve from 13483.35645\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9518.4961 - mean_absolute_error: 9518.4961 - val_loss: 13497.0137 - val_mean_absolute_error: 13497.0137\n",
      "Epoch 1694/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8620.1348 - mean_absolute_error: 8620.1348\n",
      "Epoch 1694: val_loss did not improve from 13483.35645\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9504.8574 - mean_absolute_error: 9504.8574 - val_loss: 13485.3252 - val_mean_absolute_error: 13485.3252\n",
      "Epoch 1695/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9495.5840 - mean_absolute_error: 9495.5840\n",
      "Epoch 1695: val_loss improved from 13483.35645 to 13482.52930, saving model to Weights-01695--13482.52930.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9509.4326 - mean_absolute_error: 9509.4326 - val_loss: 13482.5293 - val_mean_absolute_error: 13482.5293\n",
      "Epoch 1696/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7973.0928 - mean_absolute_error: 7973.0928\n",
      "Epoch 1696: val_loss did not improve from 13482.52930\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9511.6201 - mean_absolute_error: 9511.6201 - val_loss: 13484.8340 - val_mean_absolute_error: 13484.8340\n",
      "Epoch 1697/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9838.6152 - mean_absolute_error: 9838.6152\n",
      "Epoch 1697: val_loss did not improve from 13482.52930\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9512.3457 - mean_absolute_error: 9512.3457 - val_loss: 13488.7061 - val_mean_absolute_error: 13488.7061\n",
      "Epoch 1698/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9708.0645 - mean_absolute_error: 9708.0645\n",
      "Epoch 1698: val_loss did not improve from 13482.52930\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9511.5127 - mean_absolute_error: 9511.5127 - val_loss: 13495.5381 - val_mean_absolute_error: 13495.5381\n",
      "Epoch 1699/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13235.9570 - mean_absolute_error: 13235.9570\n",
      "Epoch 1699: val_loss did not improve from 13482.52930\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9510.8936 - mean_absolute_error: 9510.8936 - val_loss: 13492.5674 - val_mean_absolute_error: 13492.5674\n",
      "Epoch 1700/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10646.0742 - mean_absolute_error: 10646.0742\n",
      "Epoch 1700: val_loss did not improve from 13482.52930\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9512.6074 - mean_absolute_error: 9512.6074 - val_loss: 13482.5850 - val_mean_absolute_error: 13482.5850\n",
      "Epoch 1701/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8844.9219 - mean_absolute_error: 8844.9219\n",
      "Epoch 1701: val_loss improved from 13482.52930 to 13482.51465, saving model to Weights-01701--13482.51465.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9511.6719 - mean_absolute_error: 9511.6719 - val_loss: 13482.5146 - val_mean_absolute_error: 13482.5146\n",
      "Epoch 1702/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8894.8291 - mean_absolute_error: 8894.8291\n",
      "Epoch 1702: val_loss did not improve from 13482.51465\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9511.8604 - mean_absolute_error: 9511.8604 - val_loss: 13491.5928 - val_mean_absolute_error: 13491.5928\n",
      "Epoch 1703/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8038.0947 - mean_absolute_error: 8038.0947\n",
      "Epoch 1703: val_loss did not improve from 13482.51465\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9512.7676 - mean_absolute_error: 9512.7676 - val_loss: 13483.7197 - val_mean_absolute_error: 13483.7197\n",
      "Epoch 1704/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7119.7676 - mean_absolute_error: 7119.7676\n",
      "Epoch 1704: val_loss did not improve from 13482.51465\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9510.9941 - mean_absolute_error: 9510.9941 - val_loss: 13488.9355 - val_mean_absolute_error: 13488.9355\n",
      "Epoch 1705/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7501.5869 - mean_absolute_error: 7501.5869\n",
      "Epoch 1705: val_loss did not improve from 13482.51465\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9507.0674 - mean_absolute_error: 9507.0674 - val_loss: 13487.1279 - val_mean_absolute_error: 13487.1279\n",
      "Epoch 1706/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9865.7109 - mean_absolute_error: 9865.7109\n",
      "Epoch 1706: val_loss improved from 13482.51465 to 13482.43262, saving model to Weights-01706--13482.43262.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9510.8125 - mean_absolute_error: 9510.8125 - val_loss: 13482.4326 - val_mean_absolute_error: 13482.4326\n",
      "Epoch 1707/3000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9069.5098 - mean_absolute_error: 9069.5098  \n",
      "Epoch 1707: val_loss did not improve from 13482.43262\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9506.5488 - mean_absolute_error: 9506.5488 - val_loss: 13488.3623 - val_mean_absolute_error: 13488.3623\n",
      "Epoch 1708/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11000.6914 - mean_absolute_error: 11000.6914\n",
      "Epoch 1708: val_loss did not improve from 13482.43262\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9508.1279 - mean_absolute_error: 9508.1279 - val_loss: 13492.8320 - val_mean_absolute_error: 13492.8320\n",
      "Epoch 1709/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8621.7998 - mean_absolute_error: 8621.7998\n",
      "Epoch 1709: val_loss did not improve from 13482.43262\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9507.5371 - mean_absolute_error: 9507.5371 - val_loss: 13485.0146 - val_mean_absolute_error: 13485.0146\n",
      "Epoch 1710/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6180.4854 - mean_absolute_error: 6180.4854\n",
      "Epoch 1710: val_loss improved from 13482.43262 to 13480.59570, saving model to Weights-01710--13480.59570.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9512.3496 - mean_absolute_error: 9512.3496 - val_loss: 13480.5957 - val_mean_absolute_error: 13480.5957\n",
      "Epoch 1711/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8345.9033 - mean_absolute_error: 8345.9033\n",
      "Epoch 1711: val_loss did not improve from 13480.59570\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9521.1465 - mean_absolute_error: 9521.1465 - val_loss: 13488.2129 - val_mean_absolute_error: 13488.2129\n",
      "Epoch 1712/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10386.4814 - mean_absolute_error: 10386.4814\n",
      "Epoch 1712: val_loss did not improve from 13480.59570\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9517.9844 - mean_absolute_error: 9517.9844 - val_loss: 13485.8906 - val_mean_absolute_error: 13485.8906\n",
      "Epoch 1713/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10470.2246 - mean_absolute_error: 10470.2246\n",
      "Epoch 1713: val_loss did not improve from 13480.59570\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9505.7266 - mean_absolute_error: 9505.7266 - val_loss: 13486.0195 - val_mean_absolute_error: 13486.0195\n",
      "Epoch 1714/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11027.7461 - mean_absolute_error: 11027.7461\n",
      "Epoch 1714: val_loss did not improve from 13480.59570\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9505.6670 - mean_absolute_error: 9505.6670 - val_loss: 13483.4395 - val_mean_absolute_error: 13483.4395\n",
      "Epoch 1715/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10039.6621 - mean_absolute_error: 10039.6621\n",
      "Epoch 1715: val_loss did not improve from 13480.59570\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9510.0781 - mean_absolute_error: 9510.0781 - val_loss: 13482.2480 - val_mean_absolute_error: 13482.2480\n",
      "Epoch 1716/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10091.7412 - mean_absolute_error: 10091.7412\n",
      "Epoch 1716: val_loss did not improve from 13480.59570\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9506.2676 - mean_absolute_error: 9506.2676 - val_loss: 13482.9824 - val_mean_absolute_error: 13482.9824\n",
      "Epoch 1717/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10333.3965 - mean_absolute_error: 10333.3965\n",
      "Epoch 1717: val_loss did not improve from 13480.59570\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9509.2344 - mean_absolute_error: 9509.2344 - val_loss: 13485.7744 - val_mean_absolute_error: 13485.7744\n",
      "Epoch 1718/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9665.9375 - mean_absolute_error: 9665.9375\n",
      "Epoch 1718: val_loss did not improve from 13480.59570\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9506.3750 - mean_absolute_error: 9506.3750 - val_loss: 13483.4082 - val_mean_absolute_error: 13483.4082\n",
      "Epoch 1719/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8598.1299 - mean_absolute_error: 8598.1299\n",
      "Epoch 1719: val_loss did not improve from 13480.59570\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9507.9561 - mean_absolute_error: 9507.9561 - val_loss: 13481.4160 - val_mean_absolute_error: 13481.4160\n",
      "Epoch 1720/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8230.2188 - mean_absolute_error: 8230.2188\n",
      "Epoch 1720: val_loss did not improve from 13480.59570\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9507.3428 - mean_absolute_error: 9507.3428 - val_loss: 13485.1904 - val_mean_absolute_error: 13485.1904\n",
      "Epoch 1721/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11309.0303 - mean_absolute_error: 11309.0303\n",
      "Epoch 1721: val_loss did not improve from 13480.59570\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9517.1309 - mean_absolute_error: 9517.1309 - val_loss: 13490.6982 - val_mean_absolute_error: 13490.6982\n",
      "Epoch 1722/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7721.9722 - mean_absolute_error: 7721.9722\n",
      "Epoch 1722: val_loss improved from 13480.59570 to 13479.65723, saving model to Weights-01722--13479.65723.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9508.0889 - mean_absolute_error: 9508.0889 - val_loss: 13479.6572 - val_mean_absolute_error: 13479.6572\n",
      "Epoch 1723/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8758.9561 - mean_absolute_error: 8758.9561\n",
      "Epoch 1723: val_loss did not improve from 13479.65723\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9506.4795 - mean_absolute_error: 9506.4795 - val_loss: 13483.4395 - val_mean_absolute_error: 13483.4395\n",
      "Epoch 1724/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5781.8613 - mean_absolute_error: 5781.8613\n",
      "Epoch 1724: val_loss did not improve from 13479.65723\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9508.2500 - mean_absolute_error: 9508.2500 - val_loss: 13483.9834 - val_mean_absolute_error: 13483.9834\n",
      "Epoch 1725/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12063.8887 - mean_absolute_error: 12063.8887\n",
      "Epoch 1725: val_loss improved from 13479.65723 to 13479.21973, saving model to Weights-01725--13479.21973.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9522.2178 - mean_absolute_error: 9522.2178 - val_loss: 13479.2197 - val_mean_absolute_error: 13479.2197\n",
      "Epoch 1726/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7178.1782 - mean_absolute_error: 7178.1782\n",
      "Epoch 1726: val_loss did not improve from 13479.21973\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9519.2773 - mean_absolute_error: 9519.2773 - val_loss: 13493.2197 - val_mean_absolute_error: 13493.2197\n",
      "Epoch 1727/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10160.0400 - mean_absolute_error: 10160.0400\n",
      "Epoch 1727: val_loss did not improve from 13479.21973\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9498.3770 - mean_absolute_error: 9498.3770 - val_loss: 13479.9189 - val_mean_absolute_error: 13479.9189\n",
      "Epoch 1728/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11671.0957 - mean_absolute_error: 11671.0957\n",
      "Epoch 1728: val_loss did not improve from 13479.21973\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9550.5146 - mean_absolute_error: 9550.5146 - val_loss: 13480.5859 - val_mean_absolute_error: 13480.5859\n",
      "Epoch 1729/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9571.6123 - mean_absolute_error: 9571.6123\n",
      "Epoch 1729: val_loss did not improve from 13479.21973\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9510.2920 - mean_absolute_error: 9510.2920 - val_loss: 13491.8145 - val_mean_absolute_error: 13491.8145\n",
      "Epoch 1730/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6966.4155 - mean_absolute_error: 6966.4155\n",
      "Epoch 1730: val_loss did not improve from 13479.21973\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9510.1807 - mean_absolute_error: 9510.1807 - val_loss: 13479.9199 - val_mean_absolute_error: 13479.9199\n",
      "Epoch 1731/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9507.1436 - mean_absolute_error: 9507.1436\n",
      "Epoch 1731: val_loss did not improve from 13479.21973\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9510.3232 - mean_absolute_error: 9510.3232 - val_loss: 13479.3359 - val_mean_absolute_error: 13479.3359\n",
      "Epoch 1732/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11030.4414 - mean_absolute_error: 11030.4414\n",
      "Epoch 1732: val_loss did not improve from 13479.21973\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9506.8320 - mean_absolute_error: 9506.8320 - val_loss: 13482.9277 - val_mean_absolute_error: 13482.9277\n",
      "Epoch 1733/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11850.3281 - mean_absolute_error: 11850.3281\n",
      "Epoch 1733: val_loss did not improve from 13479.21973\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9502.7861 - mean_absolute_error: 9502.7861 - val_loss: 13481.9795 - val_mean_absolute_error: 13481.9795\n",
      "Epoch 1734/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9991.7598 - mean_absolute_error: 9991.7598\n",
      "Epoch 1734: val_loss did not improve from 13479.21973\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9505.4600 - mean_absolute_error: 9505.4600 - val_loss: 13482.6416 - val_mean_absolute_error: 13482.6416\n",
      "Epoch 1735/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6709.9727 - mean_absolute_error: 6709.9727\n",
      "Epoch 1735: val_loss improved from 13479.21973 to 13477.82129, saving model to Weights-01735--13477.82129.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9511.7051 - mean_absolute_error: 9511.7051 - val_loss: 13477.8213 - val_mean_absolute_error: 13477.8213\n",
      "Epoch 1736/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7722.1401 - mean_absolute_error: 7722.1401\n",
      "Epoch 1736: val_loss did not improve from 13477.82129\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9505.1006 - mean_absolute_error: 9505.1006 - val_loss: 13478.9082 - val_mean_absolute_error: 13478.9082\n",
      "Epoch 1737/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10815.2080 - mean_absolute_error: 10815.2080\n",
      "Epoch 1737: val_loss did not improve from 13477.82129\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9510.4736 - mean_absolute_error: 9510.4736 - val_loss: 13491.6885 - val_mean_absolute_error: 13491.6885\n",
      "Epoch 1738/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 14771.7188 - mean_absolute_error: 14771.7188\n",
      "Epoch 1738: val_loss did not improve from 13477.82129\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9506.2344 - mean_absolute_error: 9506.2344 - val_loss: 13479.4014 - val_mean_absolute_error: 13479.4014\n",
      "Epoch 1739/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7508.2891 - mean_absolute_error: 7508.2891\n",
      "Epoch 1739: val_loss did not improve from 13477.82129\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9513.0518 - mean_absolute_error: 9513.0518 - val_loss: 13484.1191 - val_mean_absolute_error: 13484.1191\n",
      "Epoch 1740/3000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9610.5645 - mean_absolute_error: 9610.5645\n",
      "Epoch 1740: val_loss did not improve from 13477.82129\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9505.7100 - mean_absolute_error: 9505.7100 - val_loss: 13481.9648 - val_mean_absolute_error: 13481.9648\n",
      "Epoch 1741/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7379.6460 - mean_absolute_error: 7379.6460\n",
      "Epoch 1741: val_loss improved from 13477.82129 to 13476.66602, saving model to Weights-01741--13476.66602.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9514.0283 - mean_absolute_error: 9514.0283 - val_loss: 13476.6660 - val_mean_absolute_error: 13476.6660\n",
      "Epoch 1742/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8530.8975 - mean_absolute_error: 8530.8975\n",
      "Epoch 1742: val_loss did not improve from 13476.66602\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9500.7607 - mean_absolute_error: 9500.7607 - val_loss: 13486.6113 - val_mean_absolute_error: 13486.6113\n",
      "Epoch 1743/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11253.9385 - mean_absolute_error: 11253.9385\n",
      "Epoch 1743: val_loss did not improve from 13476.66602\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9512.0596 - mean_absolute_error: 9512.0596 - val_loss: 13490.8379 - val_mean_absolute_error: 13490.8379\n",
      "Epoch 1744/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9681.5703 - mean_absolute_error: 9681.5703\n",
      "Epoch 1744: val_loss improved from 13476.66602 to 13476.41992, saving model to Weights-01744--13476.41992.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9510.1797 - mean_absolute_error: 9510.1797 - val_loss: 13476.4199 - val_mean_absolute_error: 13476.4199\n",
      "Epoch 1745/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11529.8027 - mean_absolute_error: 11529.8027\n",
      "Epoch 1745: val_loss did not improve from 13476.41992\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9501.8525 - mean_absolute_error: 9501.8525 - val_loss: 13478.6055 - val_mean_absolute_error: 13478.6055\n",
      "Epoch 1746/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10491.7422 - mean_absolute_error: 10491.7422\n",
      "Epoch 1746: val_loss did not improve from 13476.41992\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9502.2900 - mean_absolute_error: 9502.2900 - val_loss: 13483.7646 - val_mean_absolute_error: 13483.7646\n",
      "Epoch 1747/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8497.2891 - mean_absolute_error: 8497.2891\n",
      "Epoch 1747: val_loss did not improve from 13476.41992\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9507.2236 - mean_absolute_error: 9507.2236 - val_loss: 13482.4648 - val_mean_absolute_error: 13482.4648\n",
      "Epoch 1748/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5845.6924 - mean_absolute_error: 5845.6924\n",
      "Epoch 1748: val_loss did not improve from 13476.41992\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9503.8164 - mean_absolute_error: 9503.8164 - val_loss: 13483.6748 - val_mean_absolute_error: 13483.6748\n",
      "Epoch 1749/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9216.1738 - mean_absolute_error: 9216.1738\n",
      "Epoch 1749: val_loss did not improve from 13476.41992\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9507.6885 - mean_absolute_error: 9507.6885 - val_loss: 13476.8398 - val_mean_absolute_error: 13476.8398\n",
      "Epoch 1750/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11765.1396 - mean_absolute_error: 11765.1396\n",
      "Epoch 1750: val_loss did not improve from 13476.41992\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9502.9072 - mean_absolute_error: 9502.9072 - val_loss: 13479.8408 - val_mean_absolute_error: 13479.8408\n",
      "Epoch 1751/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8146.7993 - mean_absolute_error: 8146.7993\n",
      "Epoch 1751: val_loss did not improve from 13476.41992\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9505.5801 - mean_absolute_error: 9505.5801 - val_loss: 13477.1572 - val_mean_absolute_error: 13477.1572\n",
      "Epoch 1752/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10725.9590 - mean_absolute_error: 10725.9590\n",
      "Epoch 1752: val_loss did not improve from 13476.41992\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9510.5332 - mean_absolute_error: 9510.5332 - val_loss: 13483.8232 - val_mean_absolute_error: 13483.8232\n",
      "Epoch 1753/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8036.3408 - mean_absolute_error: 8036.3408\n",
      "Epoch 1753: val_loss did not improve from 13476.41992\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9505.0234 - mean_absolute_error: 9505.0234 - val_loss: 13476.4873 - val_mean_absolute_error: 13476.4873\n",
      "Epoch 1754/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7582.6162 - mean_absolute_error: 7582.6162\n",
      "Epoch 1754: val_loss did not improve from 13476.41992\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9501.3770 - mean_absolute_error: 9501.3770 - val_loss: 13477.8184 - val_mean_absolute_error: 13477.8184\n",
      "Epoch 1755/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9801.0703 - mean_absolute_error: 9801.0703\n",
      "Epoch 1755: val_loss did not improve from 13476.41992\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9504.6709 - mean_absolute_error: 9504.6709 - val_loss: 13481.6846 - val_mean_absolute_error: 13481.6846\n",
      "Epoch 1756/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8763.5684 - mean_absolute_error: 8763.5684\n",
      "Epoch 1756: val_loss improved from 13476.41992 to 13474.69531, saving model to Weights-01756--13474.69531.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9502.2139 - mean_absolute_error: 9502.2139 - val_loss: 13474.6953 - val_mean_absolute_error: 13474.6953\n",
      "Epoch 1757/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9290.5283 - mean_absolute_error: 9290.5283\n",
      "Epoch 1757: val_loss did not improve from 13474.69531\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9506.9219 - mean_absolute_error: 9506.9219 - val_loss: 13475.4873 - val_mean_absolute_error: 13475.4873\n",
      "Epoch 1758/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10253.0742 - mean_absolute_error: 10253.0742\n",
      "Epoch 1758: val_loss did not improve from 13474.69531\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9502.6963 - mean_absolute_error: 9502.6963 - val_loss: 13479.1973 - val_mean_absolute_error: 13479.1973\n",
      "Epoch 1759/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7898.6123 - mean_absolute_error: 7898.6123\n",
      "Epoch 1759: val_loss did not improve from 13474.69531\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9507.6562 - mean_absolute_error: 9507.6562 - val_loss: 13487.0664 - val_mean_absolute_error: 13487.0664\n",
      "Epoch 1760/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9502.1426 - mean_absolute_error: 9502.1426\n",
      "Epoch 1760: val_loss did not improve from 13474.69531\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9520.3779 - mean_absolute_error: 9520.3779 - val_loss: 13478.1572 - val_mean_absolute_error: 13478.1572\n",
      "Epoch 1761/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10580.9355 - mean_absolute_error: 10580.9355\n",
      "Epoch 1761: val_loss did not improve from 13474.69531\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9504.7266 - mean_absolute_error: 9504.7266 - val_loss: 13486.3555 - val_mean_absolute_error: 13486.3555\n",
      "Epoch 1762/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8974.6123 - mean_absolute_error: 8974.6123\n",
      "Epoch 1762: val_loss did not improve from 13474.69531\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9500.9863 - mean_absolute_error: 9500.9863 - val_loss: 13476.4033 - val_mean_absolute_error: 13476.4033\n",
      "Epoch 1763/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8649.5264 - mean_absolute_error: 8649.5264\n",
      "Epoch 1763: val_loss improved from 13474.69531 to 13474.29688, saving model to Weights-01763--13474.29688.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9500.3574 - mean_absolute_error: 9500.3574 - val_loss: 13474.2969 - val_mean_absolute_error: 13474.2969\n",
      "Epoch 1764/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10844.7012 - mean_absolute_error: 10844.7012\n",
      "Epoch 1764: val_loss did not improve from 13474.29688\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9505.6865 - mean_absolute_error: 9505.6865 - val_loss: 13476.1318 - val_mean_absolute_error: 13476.1318\n",
      "Epoch 1765/3000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9598.4404 - mean_absolute_error: 9598.4404  \n",
      "Epoch 1765: val_loss did not improve from 13474.29688\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9502.9707 - mean_absolute_error: 9502.9707 - val_loss: 13485.7246 - val_mean_absolute_error: 13485.7246\n",
      "Epoch 1766/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10385.0361 - mean_absolute_error: 10385.0361\n",
      "Epoch 1766: val_loss did not improve from 13474.29688\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9508.6592 - mean_absolute_error: 9508.6592 - val_loss: 13483.8291 - val_mean_absolute_error: 13483.8291\n",
      "Epoch 1767/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12483.0781 - mean_absolute_error: 12483.0781\n",
      "Epoch 1767: val_loss did not improve from 13474.29688\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9497.9492 - mean_absolute_error: 9497.9492 - val_loss: 13477.1396 - val_mean_absolute_error: 13477.1396\n",
      "Epoch 1768/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9241.2080 - mean_absolute_error: 9241.2080\n",
      "Epoch 1768: val_loss did not improve from 13474.29688\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9504.3867 - mean_absolute_error: 9504.3867 - val_loss: 13474.7793 - val_mean_absolute_error: 13474.7793\n",
      "Epoch 1769/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9010.6660 - mean_absolute_error: 9010.6660\n",
      "Epoch 1769: val_loss did not improve from 13474.29688\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9501.4922 - mean_absolute_error: 9501.4922 - val_loss: 13476.6865 - val_mean_absolute_error: 13476.6865\n",
      "Epoch 1770/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12838.1426 - mean_absolute_error: 12838.1426\n",
      "Epoch 1770: val_loss did not improve from 13474.29688\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9500.0986 - mean_absolute_error: 9500.0986 - val_loss: 13474.3613 - val_mean_absolute_error: 13474.3613\n",
      "Epoch 1771/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6563.4707 - mean_absolute_error: 6563.4707\n",
      "Epoch 1771: val_loss improved from 13474.29688 to 13472.62109, saving model to Weights-01771--13472.62109.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9505.2344 - mean_absolute_error: 9505.2344 - val_loss: 13472.6211 - val_mean_absolute_error: 13472.6211\n",
      "Epoch 1772/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8972.5156 - mean_absolute_error: 8972.5156\n",
      "Epoch 1772: val_loss did not improve from 13472.62109\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9504.9111 - mean_absolute_error: 9504.9111 - val_loss: 13479.9521 - val_mean_absolute_error: 13479.9521\n",
      "Epoch 1773/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12682.1660 - mean_absolute_error: 12682.1660\n",
      "Epoch 1773: val_loss improved from 13472.62109 to 13472.47656, saving model to Weights-01773--13472.47656.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9502.5947 - mean_absolute_error: 9502.5947 - val_loss: 13472.4766 - val_mean_absolute_error: 13472.4766\n",
      "Epoch 1774/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9638.4600 - mean_absolute_error: 9638.4600\n",
      "Epoch 1774: val_loss did not improve from 13472.47656\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9501.2158 - mean_absolute_error: 9501.2158 - val_loss: 13476.9287 - val_mean_absolute_error: 13476.9287\n",
      "Epoch 1775/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8721.4150 - mean_absolute_error: 8721.4150\n",
      "Epoch 1775: val_loss did not improve from 13472.47656\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9499.4443 - mean_absolute_error: 9499.4443 - val_loss: 13482.1914 - val_mean_absolute_error: 13482.1914\n",
      "Epoch 1776/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10909.4375 - mean_absolute_error: 10909.4375\n",
      "Epoch 1776: val_loss did not improve from 13472.47656\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9502.3232 - mean_absolute_error: 9502.3232 - val_loss: 13475.0078 - val_mean_absolute_error: 13475.0078\n",
      "Epoch 1777/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9919.2236 - mean_absolute_error: 9919.2236\n",
      "Epoch 1777: val_loss did not improve from 13472.47656\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9500.1338 - mean_absolute_error: 9500.1338 - val_loss: 13473.0117 - val_mean_absolute_error: 13473.0117\n",
      "Epoch 1778/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8313.0430 - mean_absolute_error: 8313.0430\n",
      "Epoch 1778: val_loss did not improve from 13472.47656\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9504.1602 - mean_absolute_error: 9504.1602 - val_loss: 13474.7480 - val_mean_absolute_error: 13474.7480\n",
      "Epoch 1779/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11002.8174 - mean_absolute_error: 11002.8174\n",
      "Epoch 1779: val_loss did not improve from 13472.47656\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9500.3311 - mean_absolute_error: 9500.3311 - val_loss: 13480.2090 - val_mean_absolute_error: 13480.2090\n",
      "Epoch 1780/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7765.5312 - mean_absolute_error: 7765.5312\n",
      "Epoch 1780: val_loss did not improve from 13472.47656\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9501.3418 - mean_absolute_error: 9501.3418 - val_loss: 13480.6943 - val_mean_absolute_error: 13480.6943\n",
      "Epoch 1781/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8950.0762 - mean_absolute_error: 8950.0762\n",
      "Epoch 1781: val_loss did not improve from 13472.47656\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9504.9531 - mean_absolute_error: 9504.9531 - val_loss: 13472.7432 - val_mean_absolute_error: 13472.7432\n",
      "Epoch 1782/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9951.5020 - mean_absolute_error: 9951.5020\n",
      "Epoch 1782: val_loss did not improve from 13472.47656\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9511.1709 - mean_absolute_error: 9511.1709 - val_loss: 13483.8613 - val_mean_absolute_error: 13483.8613\n",
      "Epoch 1783/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9447.9492 - mean_absolute_error: 9447.9492\n",
      "Epoch 1783: val_loss improved from 13472.47656 to 13471.43945, saving model to Weights-01783--13471.43945.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9502.7266 - mean_absolute_error: 9502.7266 - val_loss: 13471.4395 - val_mean_absolute_error: 13471.4395\n",
      "Epoch 1784/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8896.8496 - mean_absolute_error: 8896.8496\n",
      "Epoch 1784: val_loss did not improve from 13471.43945\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9504.0811 - mean_absolute_error: 9504.0811 - val_loss: 13472.4307 - val_mean_absolute_error: 13472.4307\n",
      "Epoch 1785/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7862.5698 - mean_absolute_error: 7862.5698\n",
      "Epoch 1785: val_loss did not improve from 13471.43945\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9502.2285 - mean_absolute_error: 9502.2285 - val_loss: 13473.4668 - val_mean_absolute_error: 13473.4668\n",
      "Epoch 1786/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9444.4883 - mean_absolute_error: 9444.4883\n",
      "Epoch 1786: val_loss improved from 13471.43945 to 13470.37012, saving model to Weights-01786--13470.37012.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9503.1602 - mean_absolute_error: 9503.1602 - val_loss: 13470.3701 - val_mean_absolute_error: 13470.3701\n",
      "Epoch 1787/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9772.6211 - mean_absolute_error: 9772.6211\n",
      "Epoch 1787: val_loss did not improve from 13470.37012\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9500.7051 - mean_absolute_error: 9500.7051 - val_loss: 13480.6504 - val_mean_absolute_error: 13480.6504\n",
      "Epoch 1788/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7251.4502 - mean_absolute_error: 7251.4502\n",
      "Epoch 1788: val_loss did not improve from 13470.37012\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9501.7402 - mean_absolute_error: 9501.7402 - val_loss: 13482.8203 - val_mean_absolute_error: 13482.8203\n",
      "Epoch 1789/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9565.9521 - mean_absolute_error: 9565.9521\n",
      "Epoch 1789: val_loss did not improve from 13470.37012\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9496.3145 - mean_absolute_error: 9496.3145 - val_loss: 13473.6826 - val_mean_absolute_error: 13473.6826\n",
      "Epoch 1790/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9574.3906 - mean_absolute_error: 9574.3906\n",
      "Epoch 1790: val_loss improved from 13470.37012 to 13469.95508, saving model to Weights-01790--13469.95508.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9496.2930 - mean_absolute_error: 9496.2930 - val_loss: 13469.9551 - val_mean_absolute_error: 13469.9551\n",
      "Epoch 1791/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9599.3535 - mean_absolute_error: 9599.3535\n",
      "Epoch 1791: val_loss did not improve from 13469.95508\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9498.4688 - mean_absolute_error: 9498.4688 - val_loss: 13471.0088 - val_mean_absolute_error: 13471.0088\n",
      "Epoch 1792/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7759.4023 - mean_absolute_error: 7759.4023\n",
      "Epoch 1792: val_loss did not improve from 13469.95508\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9497.5068 - mean_absolute_error: 9497.5068 - val_loss: 13469.9609 - val_mean_absolute_error: 13469.9609\n",
      "Epoch 1793/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11801.8379 - mean_absolute_error: 11801.8379\n",
      "Epoch 1793: val_loss did not improve from 13469.95508\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9507.2217 - mean_absolute_error: 9507.2217 - val_loss: 13476.8135 - val_mean_absolute_error: 13476.8135\n",
      "Epoch 1794/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11625.9893 - mean_absolute_error: 11625.9893\n",
      "Epoch 1794: val_loss did not improve from 13469.95508\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9503.2803 - mean_absolute_error: 9503.2803 - val_loss: 13479.4180 - val_mean_absolute_error: 13479.4180\n",
      "Epoch 1795/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9157.6240 - mean_absolute_error: 9157.6240\n",
      "Epoch 1795: val_loss improved from 13469.95508 to 13469.22168, saving model to Weights-01795--13469.22168.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9499.4248 - mean_absolute_error: 9499.4248 - val_loss: 13469.2217 - val_mean_absolute_error: 13469.2217\n",
      "Epoch 1796/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6538.0859 - mean_absolute_error: 6538.0859\n",
      "Epoch 1796: val_loss did not improve from 13469.22168\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9506.2480 - mean_absolute_error: 9506.2480 - val_loss: 13474.1748 - val_mean_absolute_error: 13474.1748\n",
      "Epoch 1797/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6973.5352 - mean_absolute_error: 6973.5352\n",
      "Epoch 1797: val_loss did not improve from 13469.22168\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9498.1514 - mean_absolute_error: 9498.1514 - val_loss: 13471.7402 - val_mean_absolute_error: 13471.7402\n",
      "Epoch 1798/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9157.3662 - mean_absolute_error: 9157.3662\n",
      "Epoch 1798: val_loss did not improve from 13469.22168\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9497.0469 - mean_absolute_error: 9497.0469 - val_loss: 13470.8887 - val_mean_absolute_error: 13470.8887\n",
      "Epoch 1799/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7247.1528 - mean_absolute_error: 7247.1528\n",
      "Epoch 1799: val_loss did not improve from 13469.22168\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9496.3457 - mean_absolute_error: 9496.3457 - val_loss: 13471.2002 - val_mean_absolute_error: 13471.2002\n",
      "Epoch 1800/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11380.5234 - mean_absolute_error: 11380.5234\n",
      "Epoch 1800: val_loss did not improve from 13469.22168\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9509.9316 - mean_absolute_error: 9509.9316 - val_loss: 13479.5674 - val_mean_absolute_error: 13479.5674\n",
      "Epoch 1801/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6301.5728 - mean_absolute_error: 6301.5728\n",
      "Epoch 1801: val_loss improved from 13469.22168 to 13468.58105, saving model to Weights-01801--13468.58105.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9503.2109 - mean_absolute_error: 9503.2109 - val_loss: 13468.5811 - val_mean_absolute_error: 13468.5811\n",
      "Epoch 1802/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10758.3770 - mean_absolute_error: 10758.3770\n",
      "Epoch 1802: val_loss did not improve from 13468.58105\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9509.6367 - mean_absolute_error: 9509.6367 - val_loss: 13473.9395 - val_mean_absolute_error: 13473.9395\n",
      "Epoch 1803/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7375.5195 - mean_absolute_error: 7375.5195\n",
      "Epoch 1803: val_loss did not improve from 13468.58105\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9502.2285 - mean_absolute_error: 9502.2285 - val_loss: 13478.0020 - val_mean_absolute_error: 13478.0020\n",
      "Epoch 1804/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6856.3574 - mean_absolute_error: 6856.3574\n",
      "Epoch 1804: val_loss improved from 13468.58105 to 13468.36328, saving model to Weights-01804--13468.36328.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9498.2607 - mean_absolute_error: 9498.2607 - val_loss: 13468.3633 - val_mean_absolute_error: 13468.3633\n",
      "Epoch 1805/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9271.0449 - mean_absolute_error: 9271.0449\n",
      "Epoch 1805: val_loss did not improve from 13468.36328\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9505.1777 - mean_absolute_error: 9505.1777 - val_loss: 13470.1807 - val_mean_absolute_error: 13470.1807\n",
      "Epoch 1806/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12724.8574 - mean_absolute_error: 12724.8574\n",
      "Epoch 1806: val_loss did not improve from 13468.36328\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9502.1162 - mean_absolute_error: 9502.1162 - val_loss: 13474.5049 - val_mean_absolute_error: 13474.5049\n",
      "Epoch 1807/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10355.9082 - mean_absolute_error: 10355.9082\n",
      "Epoch 1807: val_loss did not improve from 13468.36328\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9500.1494 - mean_absolute_error: 9500.1494 - val_loss: 13477.6270 - val_mean_absolute_error: 13477.6270\n",
      "Epoch 1808/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9573.4951 - mean_absolute_error: 9573.4951\n",
      "Epoch 1808: val_loss did not improve from 13468.36328\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9493.1387 - mean_absolute_error: 9493.1387 - val_loss: 13469.1963 - val_mean_absolute_error: 13469.1963\n",
      "Epoch 1809/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8514.1143 - mean_absolute_error: 8514.1143\n",
      "Epoch 1809: val_loss did not improve from 13468.36328\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9495.1406 - mean_absolute_error: 9495.1406 - val_loss: 13468.6689 - val_mean_absolute_error: 13468.6689\n",
      "Epoch 1810/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9563.7090 - mean_absolute_error: 9563.7090\n",
      "Epoch 1810: val_loss improved from 13468.36328 to 13468.00488, saving model to Weights-01810--13468.00488.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9495.8408 - mean_absolute_error: 9495.8408 - val_loss: 13468.0049 - val_mean_absolute_error: 13468.0049\n",
      "Epoch 1811/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12361.9121 - mean_absolute_error: 12361.9121\n",
      "Epoch 1811: val_loss did not improve from 13468.00488\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9497.2939 - mean_absolute_error: 9497.2939 - val_loss: 13472.8701 - val_mean_absolute_error: 13472.8701\n",
      "Epoch 1812/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7654.6348 - mean_absolute_error: 7654.6348\n",
      "Epoch 1812: val_loss did not improve from 13468.00488\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9500.6729 - mean_absolute_error: 9500.6729 - val_loss: 13475.0859 - val_mean_absolute_error: 13475.0859\n",
      "Epoch 1813/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10975.8555 - mean_absolute_error: 10975.8555\n",
      "Epoch 1813: val_loss did not improve from 13468.00488\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9498.1943 - mean_absolute_error: 9498.1943 - val_loss: 13472.9736 - val_mean_absolute_error: 13472.9736\n",
      "Epoch 1814/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12315.2461 - mean_absolute_error: 12315.2461\n",
      "Epoch 1814: val_loss improved from 13468.00488 to 13467.21484, saving model to Weights-01814--13467.21484.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9502.3389 - mean_absolute_error: 9502.3389 - val_loss: 13467.2148 - val_mean_absolute_error: 13467.2148\n",
      "Epoch 1815/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11170.7480 - mean_absolute_error: 11170.7480\n",
      "Epoch 1815: val_loss did not improve from 13467.21484\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9500.9209 - mean_absolute_error: 9500.9209 - val_loss: 13474.4326 - val_mean_absolute_error: 13474.4326\n",
      "Epoch 1816/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10222.0859 - mean_absolute_error: 10222.0859\n",
      "Epoch 1816: val_loss did not improve from 13467.21484\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9499.2256 - mean_absolute_error: 9499.2256 - val_loss: 13468.7451 - val_mean_absolute_error: 13468.7451\n",
      "Epoch 1817/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8732.2930 - mean_absolute_error: 8732.2930\n",
      "Epoch 1817: val_loss did not improve from 13467.21484\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9498.6152 - mean_absolute_error: 9498.6152 - val_loss: 13477.1992 - val_mean_absolute_error: 13477.1992\n",
      "Epoch 1818/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9750.0107 - mean_absolute_error: 9750.0107\n",
      "Epoch 1818: val_loss did not improve from 13467.21484\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9495.9219 - mean_absolute_error: 9495.9219 - val_loss: 13470.8125 - val_mean_absolute_error: 13470.8125\n",
      "Epoch 1819/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8983.0059 - mean_absolute_error: 8983.0059\n",
      "Epoch 1819: val_loss did not improve from 13467.21484\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9496.5576 - mean_absolute_error: 9496.5576 - val_loss: 13475.3672 - val_mean_absolute_error: 13475.3672\n",
      "Epoch 1820/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9968.8486 - mean_absolute_error: 9968.8486\n",
      "Epoch 1820: val_loss did not improve from 13467.21484\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9498.0469 - mean_absolute_error: 9498.0469 - val_loss: 13467.8682 - val_mean_absolute_error: 13467.8682\n",
      "Epoch 1821/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10637.3789 - mean_absolute_error: 10637.3789\n",
      "Epoch 1821: val_loss did not improve from 13467.21484\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9494.7500 - mean_absolute_error: 9494.7500 - val_loss: 13467.3193 - val_mean_absolute_error: 13467.3193\n",
      "Epoch 1822/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9804.6836 - mean_absolute_error: 9804.6836\n",
      "Epoch 1822: val_loss did not improve from 13467.21484\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9500.1055 - mean_absolute_error: 9500.1055 - val_loss: 13468.2930 - val_mean_absolute_error: 13468.2930\n",
      "Epoch 1823/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8848.2910 - mean_absolute_error: 8848.2910\n",
      "Epoch 1823: val_loss improved from 13467.21484 to 13466.24316, saving model to Weights-01823--13466.24316.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9496.1084 - mean_absolute_error: 9496.1084 - val_loss: 13466.2432 - val_mean_absolute_error: 13466.2432\n",
      "Epoch 1824/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8710.2646 - mean_absolute_error: 8710.2646\n",
      "Epoch 1824: val_loss did not improve from 13466.24316\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9493.8164 - mean_absolute_error: 9493.8164 - val_loss: 13466.8906 - val_mean_absolute_error: 13466.8906\n",
      "Epoch 1825/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7082.0850 - mean_absolute_error: 7082.0850\n",
      "Epoch 1825: val_loss did not improve from 13466.24316\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9496.9141 - mean_absolute_error: 9496.9141 - val_loss: 13469.1982 - val_mean_absolute_error: 13469.1982\n",
      "Epoch 1826/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9357.2617 - mean_absolute_error: 9357.2617\n",
      "Epoch 1826: val_loss did not improve from 13466.24316\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9495.1709 - mean_absolute_error: 9495.1709 - val_loss: 13466.5469 - val_mean_absolute_error: 13466.5469\n",
      "Epoch 1827/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8544.2871 - mean_absolute_error: 8544.2871\n",
      "Epoch 1827: val_loss did not improve from 13466.24316\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9493.3633 - mean_absolute_error: 9493.3633 - val_loss: 13469.1133 - val_mean_absolute_error: 13469.1133\n",
      "Epoch 1828/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6899.0918 - mean_absolute_error: 6899.0918\n",
      "Epoch 1828: val_loss did not improve from 13466.24316\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9493.5898 - mean_absolute_error: 9493.5898 - val_loss: 13469.4922 - val_mean_absolute_error: 13469.4922\n",
      "Epoch 1829/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8807.8145 - mean_absolute_error: 8807.8145\n",
      "Epoch 1829: val_loss did not improve from 13466.24316\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9501.9824 - mean_absolute_error: 9501.9824 - val_loss: 13468.0986 - val_mean_absolute_error: 13468.0986\n",
      "Epoch 1830/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10679.0098 - mean_absolute_error: 10679.0098\n",
      "Epoch 1830: val_loss did not improve from 13466.24316\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9493.5938 - mean_absolute_error: 9493.5938 - val_loss: 13470.1973 - val_mean_absolute_error: 13470.1973\n",
      "Epoch 1831/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6987.6582 - mean_absolute_error: 6987.6582\n",
      "Epoch 1831: val_loss did not improve from 13466.24316\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9494.8350 - mean_absolute_error: 9494.8350 - val_loss: 13474.4697 - val_mean_absolute_error: 13474.4697\n",
      "Epoch 1832/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11225.6406 - mean_absolute_error: 11225.6406\n",
      "Epoch 1832: val_loss improved from 13466.24316 to 13465.42188, saving model to Weights-01832--13465.42188.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9500.9326 - mean_absolute_error: 9500.9326 - val_loss: 13465.4219 - val_mean_absolute_error: 13465.4219\n",
      "Epoch 1833/3000\n",
      "18/18 [==============================] - ETA: 0s - loss: 9497.8389 - mean_absolute_error: 9497.8389\n",
      "Epoch 1833: val_loss did not improve from 13465.42188\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9497.8389 - mean_absolute_error: 9497.8389 - val_loss: 13472.0879 - val_mean_absolute_error: 13472.0879\n",
      "Epoch 1834/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7399.5322 - mean_absolute_error: 7399.5322\n",
      "Epoch 1834: val_loss did not improve from 13465.42188\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9496.5029 - mean_absolute_error: 9496.5029 - val_loss: 13469.8027 - val_mean_absolute_error: 13469.8027\n",
      "Epoch 1835/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8266.5508 - mean_absolute_error: 8266.5508\n",
      "Epoch 1835: val_loss did not improve from 13465.42188\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9494.3184 - mean_absolute_error: 9494.3184 - val_loss: 13466.7061 - val_mean_absolute_error: 13466.7061\n",
      "Epoch 1836/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12682.8223 - mean_absolute_error: 12682.8223\n",
      "Epoch 1836: val_loss improved from 13465.42188 to 13463.99316, saving model to Weights-01836--13463.99316.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9492.9219 - mean_absolute_error: 9492.9219 - val_loss: 13463.9932 - val_mean_absolute_error: 13463.9932\n",
      "Epoch 1837/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9937.7822 - mean_absolute_error: 9937.7822\n",
      "Epoch 1837: val_loss did not improve from 13463.99316\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9496.0781 - mean_absolute_error: 9496.0781 - val_loss: 13465.0586 - val_mean_absolute_error: 13465.0586\n",
      "Epoch 1838/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 15110.3037 - mean_absolute_error: 15110.3037\n",
      "Epoch 1838: val_loss did not improve from 13463.99316\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9490.9482 - mean_absolute_error: 9490.9482 - val_loss: 13476.4219 - val_mean_absolute_error: 13476.4219\n",
      "Epoch 1839/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7638.1035 - mean_absolute_error: 7638.1035\n",
      "Epoch 1839: val_loss did not improve from 13463.99316\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9504.8330 - mean_absolute_error: 9504.8330 - val_loss: 13465.7910 - val_mean_absolute_error: 13465.7910\n",
      "Epoch 1840/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9022.4277 - mean_absolute_error: 9022.4277\n",
      "Epoch 1840: val_loss did not improve from 13463.99316\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9494.3770 - mean_absolute_error: 9494.3770 - val_loss: 13469.7549 - val_mean_absolute_error: 13469.7549\n",
      "Epoch 1841/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7888.9653 - mean_absolute_error: 7888.9653\n",
      "Epoch 1841: val_loss did not improve from 13463.99316\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9501.0244 - mean_absolute_error: 9501.0244 - val_loss: 13473.8389 - val_mean_absolute_error: 13473.8389\n",
      "Epoch 1842/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10015.0908 - mean_absolute_error: 10015.0908\n",
      "Epoch 1842: val_loss improved from 13463.99316 to 13463.07520, saving model to Weights-01842--13463.07520.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9495.7109 - mean_absolute_error: 9495.7109 - val_loss: 13463.0752 - val_mean_absolute_error: 13463.0752\n",
      "Epoch 1843/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7217.8506 - mean_absolute_error: 7217.8506\n",
      "Epoch 1843: val_loss did not improve from 13463.07520\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9491.4014 - mean_absolute_error: 9491.4014 - val_loss: 13466.8203 - val_mean_absolute_error: 13466.8203\n",
      "Epoch 1844/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9215.6904 - mean_absolute_error: 9215.6904\n",
      "Epoch 1844: val_loss did not improve from 13463.07520\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9506.4111 - mean_absolute_error: 9506.4111 - val_loss: 13477.9248 - val_mean_absolute_error: 13477.9248\n",
      "Epoch 1845/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11889.8926 - mean_absolute_error: 11889.8926\n",
      "Epoch 1845: val_loss improved from 13463.07520 to 13462.18066, saving model to Weights-01845--13462.18066.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9495.4746 - mean_absolute_error: 9495.4746 - val_loss: 13462.1807 - val_mean_absolute_error: 13462.1807\n",
      "Epoch 1846/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11542.7100 - mean_absolute_error: 11542.7100\n",
      "Epoch 1846: val_loss did not improve from 13462.18066\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9494.8027 - mean_absolute_error: 9494.8027 - val_loss: 13464.4531 - val_mean_absolute_error: 13464.4531\n",
      "Epoch 1847/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10178.6367 - mean_absolute_error: 10178.6367\n",
      "Epoch 1847: val_loss did not improve from 13462.18066\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9493.6768 - mean_absolute_error: 9493.6768 - val_loss: 13464.2588 - val_mean_absolute_error: 13464.2588\n",
      "Epoch 1848/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11055.1523 - mean_absolute_error: 11055.1523\n",
      "Epoch 1848: val_loss did not improve from 13462.18066\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9496.7764 - mean_absolute_error: 9496.7764 - val_loss: 13469.4492 - val_mean_absolute_error: 13469.4492\n",
      "Epoch 1849/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7780.3994 - mean_absolute_error: 7780.3994\n",
      "Epoch 1849: val_loss did not improve from 13462.18066\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9491.1797 - mean_absolute_error: 9491.1797 - val_loss: 13466.1836 - val_mean_absolute_error: 13466.1836\n",
      "Epoch 1850/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8273.6279 - mean_absolute_error: 8273.6279\n",
      "Epoch 1850: val_loss did not improve from 13462.18066\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9491.5146 - mean_absolute_error: 9491.5146 - val_loss: 13463.6123 - val_mean_absolute_error: 13463.6133\n",
      "Epoch 1851/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6959.6938 - mean_absolute_error: 6959.6938\n",
      "Epoch 1851: val_loss did not improve from 13462.18066\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9494.2969 - mean_absolute_error: 9494.2969 - val_loss: 13463.4482 - val_mean_absolute_error: 13463.4482\n",
      "Epoch 1852/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9762.5547 - mean_absolute_error: 9762.5547\n",
      "Epoch 1852: val_loss did not improve from 13462.18066\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9493.4873 - mean_absolute_error: 9493.4873 - val_loss: 13468.5947 - val_mean_absolute_error: 13468.5947\n",
      "Epoch 1853/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10228.2969 - mean_absolute_error: 10228.2969\n",
      "Epoch 1853: val_loss did not improve from 13462.18066\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9493.9355 - mean_absolute_error: 9493.9355 - val_loss: 13465.6826 - val_mean_absolute_error: 13465.6826\n",
      "Epoch 1854/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9428.5879 - mean_absolute_error: 9428.5879\n",
      "Epoch 1854: val_loss did not improve from 13462.18066\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9521.8301 - mean_absolute_error: 9521.8301 - val_loss: 13465.9951 - val_mean_absolute_error: 13465.9951\n",
      "Epoch 1855/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10441.2129 - mean_absolute_error: 10441.2129\n",
      "Epoch 1855: val_loss did not improve from 13462.18066\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9498.2275 - mean_absolute_error: 9498.2275 - val_loss: 13474.1631 - val_mean_absolute_error: 13474.1631\n",
      "Epoch 1856/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9829.5195 - mean_absolute_error: 9829.5195\n",
      "Epoch 1856: val_loss did not improve from 13462.18066\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9503.2393 - mean_absolute_error: 9503.2393 - val_loss: 13475.7656 - val_mean_absolute_error: 13475.7656\n",
      "Epoch 1857/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11063.7852 - mean_absolute_error: 11063.7852\n",
      "Epoch 1857: val_loss did not improve from 13462.18066\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9487.5293 - mean_absolute_error: 9487.5293 - val_loss: 13463.4639 - val_mean_absolute_error: 13463.4639\n",
      "Epoch 1858/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9325.3740 - mean_absolute_error: 9325.3740\n",
      "Epoch 1858: val_loss improved from 13462.18066 to 13462.11523, saving model to Weights-01858--13462.11523.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9490.6016 - mean_absolute_error: 9490.6016 - val_loss: 13462.1152 - val_mean_absolute_error: 13462.1152\n",
      "Epoch 1859/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12242.1719 - mean_absolute_error: 12242.1719\n",
      "Epoch 1859: val_loss improved from 13462.11523 to 13460.24902, saving model to Weights-01859--13460.24902.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9493.3525 - mean_absolute_error: 9493.3525 - val_loss: 13460.2490 - val_mean_absolute_error: 13460.2490\n",
      "Epoch 1860/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10013.4844 - mean_absolute_error: 10013.4844\n",
      "Epoch 1860: val_loss did not improve from 13460.24902\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9494.7949 - mean_absolute_error: 9494.7949 - val_loss: 13460.5312 - val_mean_absolute_error: 13460.5312\n",
      "Epoch 1861/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7638.0586 - mean_absolute_error: 7638.0586\n",
      "Epoch 1861: val_loss did not improve from 13460.24902\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9490.3418 - mean_absolute_error: 9490.3418 - val_loss: 13462.1699 - val_mean_absolute_error: 13462.1699\n",
      "Epoch 1862/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11734.3457 - mean_absolute_error: 11734.3457\n",
      "Epoch 1862: val_loss did not improve from 13460.24902\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9489.5195 - mean_absolute_error: 9489.5195 - val_loss: 13467.3438 - val_mean_absolute_error: 13467.3438\n",
      "Epoch 1863/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8629.3848 - mean_absolute_error: 8629.3848\n",
      "Epoch 1863: val_loss did not improve from 13460.24902\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9495.6611 - mean_absolute_error: 9495.6611 - val_loss: 13464.5586 - val_mean_absolute_error: 13464.5586\n",
      "Epoch 1864/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8904.9023 - mean_absolute_error: 8904.9023\n",
      "Epoch 1864: val_loss did not improve from 13460.24902\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9492.4990 - mean_absolute_error: 9492.4990 - val_loss: 13466.7979 - val_mean_absolute_error: 13466.7979\n",
      "Epoch 1865/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10304.0117 - mean_absolute_error: 10304.0117\n",
      "Epoch 1865: val_loss did not improve from 13460.24902\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9496.7891 - mean_absolute_error: 9496.7891 - val_loss: 13474.7988 - val_mean_absolute_error: 13474.7988\n",
      "Epoch 1866/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8871.0312 - mean_absolute_error: 8871.0312\n",
      "Epoch 1866: val_loss did not improve from 13460.24902\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9492.1426 - mean_absolute_error: 9492.1426 - val_loss: 13460.5156 - val_mean_absolute_error: 13460.5156\n",
      "Epoch 1867/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8142.1924 - mean_absolute_error: 8142.1924\n",
      "Epoch 1867: val_loss improved from 13460.24902 to 13459.16406, saving model to Weights-01867--13459.16406.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9497.4180 - mean_absolute_error: 9497.4180 - val_loss: 13459.1641 - val_mean_absolute_error: 13459.1641\n",
      "Epoch 1868/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12739.2129 - mean_absolute_error: 12739.2129\n",
      "Epoch 1868: val_loss did not improve from 13459.16406\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9487.1143 - mean_absolute_error: 9487.1143 - val_loss: 13461.1094 - val_mean_absolute_error: 13461.1094\n",
      "Epoch 1869/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6542.5000 - mean_absolute_error: 6542.5000\n",
      "Epoch 1869: val_loss did not improve from 13459.16406\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9492.0459 - mean_absolute_error: 9492.0459 - val_loss: 13462.9248 - val_mean_absolute_error: 13462.9248\n",
      "Epoch 1870/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7641.0498 - mean_absolute_error: 7641.0498\n",
      "Epoch 1870: val_loss did not improve from 13459.16406\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9492.8340 - mean_absolute_error: 9492.8340 - val_loss: 13461.1611 - val_mean_absolute_error: 13461.1611\n",
      "Epoch 1871/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6784.5640 - mean_absolute_error: 6784.5640\n",
      "Epoch 1871: val_loss did not improve from 13459.16406\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9486.9863 - mean_absolute_error: 9486.9863 - val_loss: 13467.8496 - val_mean_absolute_error: 13467.8496\n",
      "Epoch 1872/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10231.9141 - mean_absolute_error: 10231.9141\n",
      "Epoch 1872: val_loss did not improve from 13459.16406\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9489.1650 - mean_absolute_error: 9489.1650 - val_loss: 13471.5977 - val_mean_absolute_error: 13471.5977\n",
      "Epoch 1873/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9303.8027 - mean_absolute_error: 9303.8027\n",
      "Epoch 1873: val_loss did not improve from 13459.16406\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9491.3486 - mean_absolute_error: 9491.3486 - val_loss: 13462.1572 - val_mean_absolute_error: 13462.1572\n",
      "Epoch 1874/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7266.2383 - mean_absolute_error: 7266.2383\n",
      "Epoch 1874: val_loss did not improve from 13459.16406\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9494.8584 - mean_absolute_error: 9494.8584 - val_loss: 13464.0781 - val_mean_absolute_error: 13464.0781\n",
      "Epoch 1875/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10699.8672 - mean_absolute_error: 10699.8672\n",
      "Epoch 1875: val_loss improved from 13459.16406 to 13458.00488, saving model to Weights-01875--13458.00488.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9492.0508 - mean_absolute_error: 9492.0508 - val_loss: 13458.0049 - val_mean_absolute_error: 13458.0049\n",
      "Epoch 1876/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10242.2578 - mean_absolute_error: 10242.2578\n",
      "Epoch 1876: val_loss improved from 13458.00488 to 13457.83984, saving model to Weights-01876--13457.83984.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9492.0928 - mean_absolute_error: 9492.0928 - val_loss: 13457.8398 - val_mean_absolute_error: 13457.8398\n",
      "Epoch 1877/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7762.0459 - mean_absolute_error: 7762.0459\n",
      "Epoch 1877: val_loss did not improve from 13457.83984\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9496.5674 - mean_absolute_error: 9496.5674 - val_loss: 13468.1299 - val_mean_absolute_error: 13468.1299\n",
      "Epoch 1878/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12304.9248 - mean_absolute_error: 12304.9248\n",
      "Epoch 1878: val_loss did not improve from 13457.83984\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9487.6514 - mean_absolute_error: 9487.6514 - val_loss: 13467.0244 - val_mean_absolute_error: 13467.0244\n",
      "Epoch 1879/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11834.3789 - mean_absolute_error: 11834.3789\n",
      "Epoch 1879: val_loss did not improve from 13457.83984\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9488.0107 - mean_absolute_error: 9488.0107 - val_loss: 13459.7275 - val_mean_absolute_error: 13459.7275\n",
      "Epoch 1880/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8873.6016 - mean_absolute_error: 8873.6016\n",
      "Epoch 1880: val_loss did not improve from 13457.83984\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9487.2939 - mean_absolute_error: 9487.2939 - val_loss: 13459.8750 - val_mean_absolute_error: 13459.8750\n",
      "Epoch 1881/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7188.2158 - mean_absolute_error: 7188.2158\n",
      "Epoch 1881: val_loss improved from 13457.83984 to 13457.62695, saving model to Weights-01881--13457.62695.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9490.5576 - mean_absolute_error: 9490.5576 - val_loss: 13457.6270 - val_mean_absolute_error: 13457.6270\n",
      "Epoch 1882/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9578.6787 - mean_absolute_error: 9578.6787\n",
      "Epoch 1882: val_loss improved from 13457.62695 to 13456.95703, saving model to Weights-01882--13456.95703.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9488.8467 - mean_absolute_error: 9488.8467 - val_loss: 13456.9570 - val_mean_absolute_error: 13456.9570\n",
      "Epoch 1883/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8382.2559 - mean_absolute_error: 8382.2559\n",
      "Epoch 1883: val_loss did not improve from 13456.95703\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9505.0215 - mean_absolute_error: 9505.0215 - val_loss: 13458.2676 - val_mean_absolute_error: 13458.2676\n",
      "Epoch 1884/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13585.4043 - mean_absolute_error: 13585.4043\n",
      "Epoch 1884: val_loss did not improve from 13456.95703\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9497.6592 - mean_absolute_error: 9497.6592 - val_loss: 13470.4512 - val_mean_absolute_error: 13470.4512\n",
      "Epoch 1885/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10137.5059 - mean_absolute_error: 10137.5059\n",
      "Epoch 1885: val_loss did not improve from 13456.95703\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9493.5303 - mean_absolute_error: 9493.5303 - val_loss: 13464.7051 - val_mean_absolute_error: 13464.7051\n",
      "Epoch 1886/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9778.6299 - mean_absolute_error: 9778.6299\n",
      "Epoch 1886: val_loss improved from 13456.95703 to 13456.70410, saving model to Weights-01886--13456.70410.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9492.5352 - mean_absolute_error: 9492.5352 - val_loss: 13456.7041 - val_mean_absolute_error: 13456.7041\n",
      "Epoch 1887/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9052.5254 - mean_absolute_error: 9052.5254\n",
      "Epoch 1887: val_loss improved from 13456.70410 to 13456.51172, saving model to Weights-01887--13456.51172.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9495.5039 - mean_absolute_error: 9495.5039 - val_loss: 13456.5117 - val_mean_absolute_error: 13456.5117\n",
      "Epoch 1888/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10897.2676 - mean_absolute_error: 10897.2676\n",
      "Epoch 1888: val_loss did not improve from 13456.51172\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9487.2656 - mean_absolute_error: 9487.2656 - val_loss: 13464.8535 - val_mean_absolute_error: 13464.8535\n",
      "Epoch 1889/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9310.0332 - mean_absolute_error: 9310.0332\n",
      "Epoch 1889: val_loss did not improve from 13456.51172\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9489.5723 - mean_absolute_error: 9489.5723 - val_loss: 13464.6123 - val_mean_absolute_error: 13464.6123\n",
      "Epoch 1890/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7477.2349 - mean_absolute_error: 7477.2349\n",
      "Epoch 1890: val_loss did not improve from 13456.51172\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9497.6084 - mean_absolute_error: 9497.6084 - val_loss: 13465.0996 - val_mean_absolute_error: 13465.0996\n",
      "Epoch 1891/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8850.2441 - mean_absolute_error: 8850.2441\n",
      "Epoch 1891: val_loss did not improve from 13456.51172\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9503.0781 - mean_absolute_error: 9503.0781 - val_loss: 13460.3916 - val_mean_absolute_error: 13460.3916\n",
      "Epoch 1892/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11591.6270 - mean_absolute_error: 11591.6270\n",
      "Epoch 1892: val_loss did not improve from 13456.51172\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9502.0703 - mean_absolute_error: 9502.0703 - val_loss: 13466.7500 - val_mean_absolute_error: 13466.7500\n",
      "Epoch 1893/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9636.5547 - mean_absolute_error: 9636.5547\n",
      "Epoch 1893: val_loss did not improve from 13456.51172\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9507.6055 - mean_absolute_error: 9507.6055 - val_loss: 13456.8701 - val_mean_absolute_error: 13456.8701\n",
      "Epoch 1894/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10998.4961 - mean_absolute_error: 10998.4961\n",
      "Epoch 1894: val_loss did not improve from 13456.51172\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9486.0186 - mean_absolute_error: 9486.0186 - val_loss: 13457.3125 - val_mean_absolute_error: 13457.3125\n",
      "Epoch 1895/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10913.1094 - mean_absolute_error: 10913.1094\n",
      "Epoch 1895: val_loss did not improve from 13456.51172\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9487.6348 - mean_absolute_error: 9487.6348 - val_loss: 13462.6035 - val_mean_absolute_error: 13462.6035\n",
      "Epoch 1896/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13781.6836 - mean_absolute_error: 13781.6836\n",
      "Epoch 1896: val_loss did not improve from 13456.51172\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9484.9209 - mean_absolute_error: 9484.9209 - val_loss: 13459.7891 - val_mean_absolute_error: 13459.7891\n",
      "Epoch 1897/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8862.0400 - mean_absolute_error: 8862.0400\n",
      "Epoch 1897: val_loss improved from 13456.51172 to 13455.85742, saving model to Weights-01897--13455.85742.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9486.0850 - mean_absolute_error: 9486.0850 - val_loss: 13455.8574 - val_mean_absolute_error: 13455.8574\n",
      "Epoch 1898/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7647.3086 - mean_absolute_error: 7647.3086\n",
      "Epoch 1898: val_loss did not improve from 13455.85742\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9489.7441 - mean_absolute_error: 9489.7441 - val_loss: 13457.9922 - val_mean_absolute_error: 13457.9922\n",
      "Epoch 1899/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9316.1797 - mean_absolute_error: 9316.1797\n",
      "Epoch 1899: val_loss improved from 13455.85742 to 13455.25391, saving model to Weights-01899--13455.25391.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9491.7568 - mean_absolute_error: 9491.7568 - val_loss: 13455.2539 - val_mean_absolute_error: 13455.2539\n",
      "Epoch 1900/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10268.6582 - mean_absolute_error: 10268.6582\n",
      "Epoch 1900: val_loss improved from 13455.25391 to 13454.39648, saving model to Weights-01900--13454.39648.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9498.5068 - mean_absolute_error: 9498.5068 - val_loss: 13454.3965 - val_mean_absolute_error: 13454.3965\n",
      "Epoch 1901/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8494.0273 - mean_absolute_error: 8494.0273\n",
      "Epoch 1901: val_loss did not improve from 13454.39648\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9492.6992 - mean_absolute_error: 9492.6992 - val_loss: 13465.6572 - val_mean_absolute_error: 13465.6572\n",
      "Epoch 1902/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6641.4238 - mean_absolute_error: 6641.4238\n",
      "Epoch 1902: val_loss did not improve from 13454.39648\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9495.5322 - mean_absolute_error: 9495.5322 - val_loss: 13466.2207 - val_mean_absolute_error: 13466.2207\n",
      "Epoch 1903/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7061.6655 - mean_absolute_error: 7061.6655\n",
      "Epoch 1903: val_loss did not improve from 13454.39648\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9483.6895 - mean_absolute_error: 9483.6895 - val_loss: 13455.1396 - val_mean_absolute_error: 13455.1396\n",
      "Epoch 1904/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8585.6055 - mean_absolute_error: 8585.6055\n",
      "Epoch 1904: val_loss did not improve from 13454.39648\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9485.5225 - mean_absolute_error: 9485.5225 - val_loss: 13454.7998 - val_mean_absolute_error: 13454.7998\n",
      "Epoch 1905/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8467.6787 - mean_absolute_error: 8467.6787\n",
      "Epoch 1905: val_loss improved from 13454.39648 to 13454.11133, saving model to Weights-01905--13454.11133.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9484.8984 - mean_absolute_error: 9484.8984 - val_loss: 13454.1113 - val_mean_absolute_error: 13454.1113\n",
      "Epoch 1906/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8880.4258 - mean_absolute_error: 8880.4258\n",
      "Epoch 1906: val_loss did not improve from 13454.11133\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9487.3486 - mean_absolute_error: 9487.3486 - val_loss: 13456.2285 - val_mean_absolute_error: 13456.2285\n",
      "Epoch 1907/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13177.0635 - mean_absolute_error: 13177.0635\n",
      "Epoch 1907: val_loss improved from 13454.11133 to 13453.67090, saving model to Weights-01907--13453.67090.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9488.4619 - mean_absolute_error: 9488.4619 - val_loss: 13453.6709 - val_mean_absolute_error: 13453.6709\n",
      "Epoch 1908/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9991.6270 - mean_absolute_error: 9991.6270\n",
      "Epoch 1908: val_loss did not improve from 13453.67090\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9489.8359 - mean_absolute_error: 9489.8359 - val_loss: 13458.5654 - val_mean_absolute_error: 13458.5654\n",
      "Epoch 1909/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9558.0625 - mean_absolute_error: 9558.0625\n",
      "Epoch 1909: val_loss did not improve from 13453.67090\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9490.9551 - mean_absolute_error: 9490.9551 - val_loss: 13466.1182 - val_mean_absolute_error: 13466.1182\n",
      "Epoch 1910/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7819.4365 - mean_absolute_error: 7819.4365\n",
      "Epoch 1910: val_loss did not improve from 13453.67090\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9485.5566 - mean_absolute_error: 9485.5566 - val_loss: 13460.8398 - val_mean_absolute_error: 13460.8398\n",
      "Epoch 1911/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10120.7295 - mean_absolute_error: 10120.7295\n",
      "Epoch 1911: val_loss improved from 13453.67090 to 13452.80566, saving model to Weights-01911--13452.80566.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9483.7998 - mean_absolute_error: 9483.7998 - val_loss: 13452.8057 - val_mean_absolute_error: 13452.8057\n",
      "Epoch 1912/3000\n",
      "11/18 [=================>............] - ETA: 0s - loss: 10101.2959 - mean_absolute_error: 10101.2959\n",
      "Epoch 1912: val_loss did not improve from 13452.80566\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9485.2549 - mean_absolute_error: 9485.2549 - val_loss: 13452.8809 - val_mean_absolute_error: 13452.8809\n",
      "Epoch 1913/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11530.7734 - mean_absolute_error: 11530.7734\n",
      "Epoch 1913: val_loss did not improve from 13452.80566\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9486.8096 - mean_absolute_error: 9486.8096 - val_loss: 13453.3594 - val_mean_absolute_error: 13453.3594\n",
      "Epoch 1914/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8879.5947 - mean_absolute_error: 8879.5947\n",
      "Epoch 1914: val_loss did not improve from 13452.80566\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9488.7021 - mean_absolute_error: 9488.7021 - val_loss: 13454.6875 - val_mean_absolute_error: 13454.6875\n",
      "Epoch 1915/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11366.4277 - mean_absolute_error: 11366.4277\n",
      "Epoch 1915: val_loss did not improve from 13452.80566\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9487.5869 - mean_absolute_error: 9487.5869 - val_loss: 13454.2998 - val_mean_absolute_error: 13454.2998\n",
      "Epoch 1916/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8998.1973 - mean_absolute_error: 8998.1973\n",
      "Epoch 1916: val_loss did not improve from 13452.80566\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9484.8730 - mean_absolute_error: 9484.8730 - val_loss: 13460.6074 - val_mean_absolute_error: 13460.6074\n",
      "Epoch 1917/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10812.6660 - mean_absolute_error: 10812.6660\n",
      "Epoch 1917: val_loss did not improve from 13452.80566\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9499.1621 - mean_absolute_error: 9499.1621 - val_loss: 13454.0840 - val_mean_absolute_error: 13454.0840\n",
      "Epoch 1918/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8478.7666 - mean_absolute_error: 8478.7666\n",
      "Epoch 1918: val_loss did not improve from 13452.80566\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9492.0986 - mean_absolute_error: 9492.0986 - val_loss: 13462.2520 - val_mean_absolute_error: 13462.2520\n",
      "Epoch 1919/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9457.3779 - mean_absolute_error: 9457.3779\n",
      "Epoch 1919: val_loss did not improve from 13452.80566\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9485.4482 - mean_absolute_error: 9485.4482 - val_loss: 13455.3389 - val_mean_absolute_error: 13455.3389\n",
      "Epoch 1920/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7931.5986 - mean_absolute_error: 7931.5986\n",
      "Epoch 1920: val_loss improved from 13452.80566 to 13452.40527, saving model to Weights-01920--13452.40527.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9483.0947 - mean_absolute_error: 9483.0947 - val_loss: 13452.4053 - val_mean_absolute_error: 13452.4053\n",
      "Epoch 1921/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8003.6958 - mean_absolute_error: 8003.6958\n",
      "Epoch 1921: val_loss did not improve from 13452.40527\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9489.2959 - mean_absolute_error: 9489.2959 - val_loss: 13460.0371 - val_mean_absolute_error: 13460.0371\n",
      "Epoch 1922/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9425.2852 - mean_absolute_error: 9425.2852\n",
      "Epoch 1922: val_loss improved from 13452.40527 to 13451.40039, saving model to Weights-01922--13451.40039.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9491.8164 - mean_absolute_error: 9491.8164 - val_loss: 13451.4004 - val_mean_absolute_error: 13451.4004\n",
      "Epoch 1923/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10551.3799 - mean_absolute_error: 10551.3799\n",
      "Epoch 1923: val_loss improved from 13451.40039 to 13451.06250, saving model to Weights-01923--13451.06250.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9486.6543 - mean_absolute_error: 9486.6543 - val_loss: 13451.0625 - val_mean_absolute_error: 13451.0625\n",
      "Epoch 1924/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10761.6201 - mean_absolute_error: 10761.6201\n",
      "Epoch 1924: val_loss did not improve from 13451.06250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9481.9785 - mean_absolute_error: 9481.9785 - val_loss: 13452.6396 - val_mean_absolute_error: 13452.6396\n",
      "Epoch 1925/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7735.9219 - mean_absolute_error: 7735.9219\n",
      "Epoch 1925: val_loss did not improve from 13451.06250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9509.1914 - mean_absolute_error: 9509.1914 - val_loss: 13465.3389 - val_mean_absolute_error: 13465.3389\n",
      "Epoch 1926/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8340.5293 - mean_absolute_error: 8340.5293\n",
      "Epoch 1926: val_loss did not improve from 13451.06250\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9492.9541 - mean_absolute_error: 9492.9541 - val_loss: 13452.9482 - val_mean_absolute_error: 13452.9482\n",
      "Epoch 1927/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9926.8906 - mean_absolute_error: 9926.8906\n",
      "Epoch 1927: val_loss improved from 13451.06250 to 13450.47559, saving model to Weights-01927--13450.47559.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9488.0088 - mean_absolute_error: 9488.0088 - val_loss: 13450.4756 - val_mean_absolute_error: 13450.4756\n",
      "Epoch 1928/3000\n",
      "18/18 [==============================] - ETA: 0s - loss: 9497.7861 - mean_absolute_error: 9497.7861\n",
      "Epoch 1928: val_loss did not improve from 13450.47559\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9497.7861 - mean_absolute_error: 9497.7861 - val_loss: 13451.1719 - val_mean_absolute_error: 13451.1719\n",
      "Epoch 1929/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12489.1191 - mean_absolute_error: 12489.1191\n",
      "Epoch 1929: val_loss did not improve from 13450.47559\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9493.5410 - mean_absolute_error: 9493.5410 - val_loss: 13470.9961 - val_mean_absolute_error: 13470.9961\n",
      "Epoch 1930/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6724.5049 - mean_absolute_error: 6724.5049\n",
      "Epoch 1930: val_loss did not improve from 13450.47559\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9496.7432 - mean_absolute_error: 9496.7432 - val_loss: 13464.2939 - val_mean_absolute_error: 13464.2939\n",
      "Epoch 1931/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9833.7637 - mean_absolute_error: 9833.7637\n",
      "Epoch 1931: val_loss did not improve from 13450.47559\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9485.7461 - mean_absolute_error: 9485.7461 - val_loss: 13451.3281 - val_mean_absolute_error: 13451.3281\n",
      "Epoch 1932/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9781.3682 - mean_absolute_error: 9781.3682\n",
      "Epoch 1932: val_loss did not improve from 13450.47559\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9486.6924 - mean_absolute_error: 9486.6924 - val_loss: 13450.7969 - val_mean_absolute_error: 13450.7969\n",
      "Epoch 1933/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9955.3262 - mean_absolute_error: 9955.3262\n",
      "Epoch 1933: val_loss did not improve from 13450.47559\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9482.7373 - mean_absolute_error: 9482.7373 - val_loss: 13451.7568 - val_mean_absolute_error: 13451.7568\n",
      "Epoch 1934/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8768.5117 - mean_absolute_error: 8768.5117\n",
      "Epoch 1934: val_loss did not improve from 13450.47559\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9482.7061 - mean_absolute_error: 9482.7061 - val_loss: 13454.8301 - val_mean_absolute_error: 13454.8301\n",
      "Epoch 1935/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6851.7251 - mean_absolute_error: 6851.7251\n",
      "Epoch 1935: val_loss did not improve from 13450.47559\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9485.7178 - mean_absolute_error: 9485.7178 - val_loss: 13450.5674 - val_mean_absolute_error: 13450.5674\n",
      "Epoch 1936/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8806.3281 - mean_absolute_error: 8806.3281\n",
      "Epoch 1936: val_loss did not improve from 13450.47559\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9480.6211 - mean_absolute_error: 9480.6211 - val_loss: 13454.7236 - val_mean_absolute_error: 13454.7236\n",
      "Epoch 1937/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7749.2559 - mean_absolute_error: 7749.2559\n",
      "Epoch 1937: val_loss did not improve from 13450.47559\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9485.8486 - mean_absolute_error: 9485.8486 - val_loss: 13456.2275 - val_mean_absolute_error: 13456.2275\n",
      "Epoch 1938/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13209.0693 - mean_absolute_error: 13209.0693\n",
      "Epoch 1938: val_loss did not improve from 13450.47559\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9479.9658 - mean_absolute_error: 9479.9658 - val_loss: 13451.4932 - val_mean_absolute_error: 13451.4932\n",
      "Epoch 1939/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9030.4160 - mean_absolute_error: 9030.4160\n",
      "Epoch 1939: val_loss did not improve from 13450.47559\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9480.8105 - mean_absolute_error: 9480.8105 - val_loss: 13451.1641 - val_mean_absolute_error: 13451.1641\n",
      "Epoch 1940/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9610.1299 - mean_absolute_error: 9610.1299\n",
      "Epoch 1940: val_loss improved from 13450.47559 to 13450.40527, saving model to Weights-01940--13450.40527.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9481.7021 - mean_absolute_error: 9481.7021 - val_loss: 13450.4053 - val_mean_absolute_error: 13450.4053\n",
      "Epoch 1941/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13186.1826 - mean_absolute_error: 13186.1826\n",
      "Epoch 1941: val_loss improved from 13450.40527 to 13449.70020, saving model to Weights-01941--13449.70020.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9484.5771 - mean_absolute_error: 9484.5771 - val_loss: 13449.7002 - val_mean_absolute_error: 13449.7002\n",
      "Epoch 1942/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10413.7441 - mean_absolute_error: 10413.7441\n",
      "Epoch 1942: val_loss improved from 13449.70020 to 13448.30859, saving model to Weights-01942--13448.30859.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9482.7217 - mean_absolute_error: 9482.7217 - val_loss: 13448.3086 - val_mean_absolute_error: 13448.3086\n",
      "Epoch 1943/3000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9246.8359 - mean_absolute_error: 9246.8359\n",
      "Epoch 1943: val_loss did not improve from 13448.30859\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9501.3350 - mean_absolute_error: 9501.3350 - val_loss: 13449.6602 - val_mean_absolute_error: 13449.6602\n",
      "Epoch 1944/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8322.7979 - mean_absolute_error: 8322.7979\n",
      "Epoch 1944: val_loss did not improve from 13448.30859\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9489.5527 - mean_absolute_error: 9489.5527 - val_loss: 13452.9736 - val_mean_absolute_error: 13452.9736\n",
      "Epoch 1945/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7589.5542 - mean_absolute_error: 7589.5542\n",
      "Epoch 1945: val_loss did not improve from 13448.30859\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9484.1621 - mean_absolute_error: 9484.1621 - val_loss: 13457.0566 - val_mean_absolute_error: 13457.0566\n",
      "Epoch 1946/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10474.6924 - mean_absolute_error: 10474.6924\n",
      "Epoch 1946: val_loss did not improve from 13448.30859\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9490.2139 - mean_absolute_error: 9490.2139 - val_loss: 13455.7158 - val_mean_absolute_error: 13455.7158\n",
      "Epoch 1947/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11324.6035 - mean_absolute_error: 11324.6035\n",
      "Epoch 1947: val_loss improved from 13448.30859 to 13447.96973, saving model to Weights-01947--13447.96973.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9479.6797 - mean_absolute_error: 9479.6797 - val_loss: 13447.9697 - val_mean_absolute_error: 13447.9697\n",
      "Epoch 1948/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9715.7549 - mean_absolute_error: 9715.7549\n",
      "Epoch 1948: val_loss did not improve from 13447.96973\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9493.7783 - mean_absolute_error: 9493.7783 - val_loss: 13449.3652 - val_mean_absolute_error: 13449.3652\n",
      "Epoch 1949/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11871.2529 - mean_absolute_error: 11871.2529\n",
      "Epoch 1949: val_loss did not improve from 13447.96973\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9490.6924 - mean_absolute_error: 9490.6924 - val_loss: 13448.1768 - val_mean_absolute_error: 13448.1768\n",
      "Epoch 1950/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7786.8213 - mean_absolute_error: 7786.8213\n",
      "Epoch 1950: val_loss did not improve from 13447.96973\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9478.9951 - mean_absolute_error: 9478.9951 - val_loss: 13451.0664 - val_mean_absolute_error: 13451.0664\n",
      "Epoch 1951/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7587.9795 - mean_absolute_error: 7587.9795\n",
      "Epoch 1951: val_loss did not improve from 13447.96973\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9484.9863 - mean_absolute_error: 9484.9863 - val_loss: 13457.4678 - val_mean_absolute_error: 13457.4678\n",
      "Epoch 1952/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9019.8066 - mean_absolute_error: 9019.8066\n",
      "Epoch 1952: val_loss improved from 13447.96973 to 13447.75195, saving model to Weights-01952--13447.75195.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9483.2939 - mean_absolute_error: 9483.2939 - val_loss: 13447.7520 - val_mean_absolute_error: 13447.7520\n",
      "Epoch 1953/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11281.5254 - mean_absolute_error: 11281.5254\n",
      "Epoch 1953: val_loss did not improve from 13447.75195\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9481.3545 - mean_absolute_error: 9481.3545 - val_loss: 13448.2910 - val_mean_absolute_error: 13448.2910\n",
      "Epoch 1954/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6429.3286 - mean_absolute_error: 6429.3286\n",
      "Epoch 1954: val_loss improved from 13447.75195 to 13447.53223, saving model to Weights-01954--13447.53223.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9484.4512 - mean_absolute_error: 9484.4512 - val_loss: 13447.5322 - val_mean_absolute_error: 13447.5312\n",
      "Epoch 1955/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10138.5098 - mean_absolute_error: 10138.5098\n",
      "Epoch 1955: val_loss did not improve from 13447.53223\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9484.8525 - mean_absolute_error: 9484.8525 - val_loss: 13452.2002 - val_mean_absolute_error: 13452.2002\n",
      "Epoch 1956/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9052.1006 - mean_absolute_error: 9052.1006\n",
      "Epoch 1956: val_loss did not improve from 13447.53223\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9482.6758 - mean_absolute_error: 9482.6758 - val_loss: 13451.3926 - val_mean_absolute_error: 13451.3926\n",
      "Epoch 1957/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8549.5449 - mean_absolute_error: 8549.5449\n",
      "Epoch 1957: val_loss improved from 13447.53223 to 13446.43066, saving model to Weights-01957--13446.43066.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9480.8457 - mean_absolute_error: 9480.8457 - val_loss: 13446.4307 - val_mean_absolute_error: 13446.4307\n",
      "Epoch 1958/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9589.2764 - mean_absolute_error: 9589.2764\n",
      "Epoch 1958: val_loss did not improve from 13446.43066\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9483.2324 - mean_absolute_error: 9483.2324 - val_loss: 13447.6299 - val_mean_absolute_error: 13447.6299\n",
      "Epoch 1959/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10901.2412 - mean_absolute_error: 10901.2412\n",
      "Epoch 1959: val_loss did not improve from 13446.43066\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9481.7012 - mean_absolute_error: 9481.7012 - val_loss: 13453.6943 - val_mean_absolute_error: 13453.6943\n",
      "Epoch 1960/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11087.4824 - mean_absolute_error: 11087.4824\n",
      "Epoch 1960: val_loss did not improve from 13446.43066\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9485.4766 - mean_absolute_error: 9485.4766 - val_loss: 13448.9424 - val_mean_absolute_error: 13448.9424\n",
      "Epoch 1961/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9651.4414 - mean_absolute_error: 9651.4414\n",
      "Epoch 1961: val_loss did not improve from 13446.43066\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9479.9326 - mean_absolute_error: 9479.9326 - val_loss: 13448.9424 - val_mean_absolute_error: 13448.9424\n",
      "Epoch 1962/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13773.9541 - mean_absolute_error: 13773.9541\n",
      "Epoch 1962: val_loss did not improve from 13446.43066\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9479.7275 - mean_absolute_error: 9479.7275 - val_loss: 13451.5049 - val_mean_absolute_error: 13451.5049\n",
      "Epoch 1963/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8342.1875 - mean_absolute_error: 8342.1875\n",
      "Epoch 1963: val_loss did not improve from 13446.43066\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9478.7422 - mean_absolute_error: 9478.7422 - val_loss: 13447.6689 - val_mean_absolute_error: 13447.6689\n",
      "Epoch 1964/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10528.9141 - mean_absolute_error: 10528.9141\n",
      "Epoch 1964: val_loss did not improve from 13446.43066\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9483.8438 - mean_absolute_error: 9483.8438 - val_loss: 13451.2451 - val_mean_absolute_error: 13451.2451\n",
      "Epoch 1965/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7599.4053 - mean_absolute_error: 7599.4053\n",
      "Epoch 1965: val_loss did not improve from 13446.43066\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9483.4121 - mean_absolute_error: 9483.4121 - val_loss: 13447.0264 - val_mean_absolute_error: 13447.0264\n",
      "Epoch 1966/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8758.3613 - mean_absolute_error: 8758.3613\n",
      "Epoch 1966: val_loss did not improve from 13446.43066\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9476.5234 - mean_absolute_error: 9476.5234 - val_loss: 13450.8594 - val_mean_absolute_error: 13450.8594\n",
      "Epoch 1967/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9858.1934 - mean_absolute_error: 9858.1934\n",
      "Epoch 1967: val_loss did not improve from 13446.43066\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9491.6641 - mean_absolute_error: 9491.6641 - val_loss: 13452.5322 - val_mean_absolute_error: 13452.5322\n",
      "Epoch 1968/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12474.2041 - mean_absolute_error: 12474.2041\n",
      "Epoch 1968: val_loss improved from 13446.43066 to 13445.24414, saving model to Weights-01968--13445.24414.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9487.5723 - mean_absolute_error: 9487.5723 - val_loss: 13445.2441 - val_mean_absolute_error: 13445.2441\n",
      "Epoch 1969/3000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 8959.2666 - mean_absolute_error: 8959.2666\n",
      "Epoch 1969: val_loss did not improve from 13445.24414\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9490.1660 - mean_absolute_error: 9490.1660 - val_loss: 13449.7627 - val_mean_absolute_error: 13449.7627\n",
      "Epoch 1970/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10487.2754 - mean_absolute_error: 10487.2754\n",
      "Epoch 1970: val_loss improved from 13445.24414 to 13444.94238, saving model to Weights-01970--13444.94238.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9484.0566 - mean_absolute_error: 9484.0566 - val_loss: 13444.9424 - val_mean_absolute_error: 13444.9424\n",
      "Epoch 1971/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7772.7441 - mean_absolute_error: 7772.7441\n",
      "Epoch 1971: val_loss did not improve from 13444.94238\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9480.7920 - mean_absolute_error: 9480.7920 - val_loss: 13454.6719 - val_mean_absolute_error: 13454.6719\n",
      "Epoch 1972/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11568.3154 - mean_absolute_error: 11568.3154\n",
      "Epoch 1972: val_loss did not improve from 13444.94238\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9486.2725 - mean_absolute_error: 9486.2725 - val_loss: 13455.1143 - val_mean_absolute_error: 13455.1143\n",
      "Epoch 1973/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7229.0444 - mean_absolute_error: 7229.0444\n",
      "Epoch 1973: val_loss did not improve from 13444.94238\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9480.8232 - mean_absolute_error: 9480.8232 - val_loss: 13446.0010 - val_mean_absolute_error: 13446.0010\n",
      "Epoch 1974/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8686.2646 - mean_absolute_error: 8686.2646\n",
      "Epoch 1974: val_loss did not improve from 13444.94238\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9515.7246 - mean_absolute_error: 9515.7246 - val_loss: 13460.5830 - val_mean_absolute_error: 13460.5830\n",
      "Epoch 1975/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8009.7505 - mean_absolute_error: 8009.7505\n",
      "Epoch 1975: val_loss did not improve from 13444.94238\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9478.7139 - mean_absolute_error: 9478.7139 - val_loss: 13449.8604 - val_mean_absolute_error: 13449.8604\n",
      "Epoch 1976/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10612.5254 - mean_absolute_error: 10612.5254\n",
      "Epoch 1976: val_loss did not improve from 13444.94238\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9477.2383 - mean_absolute_error: 9477.2383 - val_loss: 13448.5781 - val_mean_absolute_error: 13448.5781\n",
      "Epoch 1977/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11650.8682 - mean_absolute_error: 11650.8682\n",
      "Epoch 1977: val_loss did not improve from 13444.94238\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9481.2891 - mean_absolute_error: 9481.2891 - val_loss: 13449.1865 - val_mean_absolute_error: 13449.1865\n",
      "Epoch 1978/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10615.9795 - mean_absolute_error: 10615.9795\n",
      "Epoch 1978: val_loss did not improve from 13444.94238\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9477.2627 - mean_absolute_error: 9477.2627 - val_loss: 13445.2764 - val_mean_absolute_error: 13445.2764\n",
      "Epoch 1979/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7195.2041 - mean_absolute_error: 7195.2041\n",
      "Epoch 1979: val_loss did not improve from 13444.94238\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9488.6016 - mean_absolute_error: 9488.6016 - val_loss: 13453.2178 - val_mean_absolute_error: 13453.2178\n",
      "Epoch 1980/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8164.9883 - mean_absolute_error: 8164.9883\n",
      "Epoch 1980: val_loss improved from 13444.94238 to 13444.50195, saving model to Weights-01980--13444.50195.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9495.1514 - mean_absolute_error: 9495.1514 - val_loss: 13444.5020 - val_mean_absolute_error: 13444.5020\n",
      "Epoch 1981/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10923.0752 - mean_absolute_error: 10923.0752\n",
      "Epoch 1981: val_loss did not improve from 13444.50195\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9476.8105 - mean_absolute_error: 9476.8105 - val_loss: 13449.2588 - val_mean_absolute_error: 13449.2588\n",
      "Epoch 1982/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6447.5991 - mean_absolute_error: 6447.5991\n",
      "Epoch 1982: val_loss did not improve from 13444.50195\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9481.0254 - mean_absolute_error: 9481.0254 - val_loss: 13444.8525 - val_mean_absolute_error: 13444.8525\n",
      "Epoch 1983/3000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9699.1816 - mean_absolute_error: 9699.1816\n",
      "Epoch 1983: val_loss did not improve from 13444.50195\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9479.1650 - mean_absolute_error: 9479.1650 - val_loss: 13444.7275 - val_mean_absolute_error: 13444.7275\n",
      "Epoch 1984/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9967.8506 - mean_absolute_error: 9967.8506\n",
      "Epoch 1984: val_loss did not improve from 13444.50195\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9480.2148 - mean_absolute_error: 9480.2148 - val_loss: 13451.3965 - val_mean_absolute_error: 13451.3965\n",
      "Epoch 1985/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8174.7905 - mean_absolute_error: 8174.7905\n",
      "Epoch 1985: val_loss improved from 13444.50195 to 13443.09766, saving model to Weights-01985--13443.09766.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9475.2021 - mean_absolute_error: 9475.2021 - val_loss: 13443.0977 - val_mean_absolute_error: 13443.0977\n",
      "Epoch 1986/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7280.6689 - mean_absolute_error: 7280.6689\n",
      "Epoch 1986: val_loss did not improve from 13443.09766\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9476.3926 - mean_absolute_error: 9476.3926 - val_loss: 13445.6602 - val_mean_absolute_error: 13445.6602\n",
      "Epoch 1987/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7568.2227 - mean_absolute_error: 7568.2227\n",
      "Epoch 1987: val_loss did not improve from 13443.09766\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9474.0342 - mean_absolute_error: 9474.0342 - val_loss: 13447.7666 - val_mean_absolute_error: 13447.7666\n",
      "Epoch 1988/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7475.1182 - mean_absolute_error: 7475.1182\n",
      "Epoch 1988: val_loss did not improve from 13443.09766\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9477.8486 - mean_absolute_error: 9477.8486 - val_loss: 13457.0684 - val_mean_absolute_error: 13457.0684\n",
      "Epoch 1989/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10447.7900 - mean_absolute_error: 10447.7900\n",
      "Epoch 1989: val_loss did not improve from 13443.09766\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9476.8750 - mean_absolute_error: 9476.8750 - val_loss: 13445.2490 - val_mean_absolute_error: 13445.2490\n",
      "Epoch 1990/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13530.4551 - mean_absolute_error: 13530.4551\n",
      "Epoch 1990: val_loss did not improve from 13443.09766\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9482.7910 - mean_absolute_error: 9482.7910 - val_loss: 13446.0586 - val_mean_absolute_error: 13446.0586\n",
      "Epoch 1991/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6919.1147 - mean_absolute_error: 6919.1147\n",
      "Epoch 1991: val_loss did not improve from 13443.09766\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9501.7607 - mean_absolute_error: 9501.7607 - val_loss: 13448.5967 - val_mean_absolute_error: 13448.5967\n",
      "Epoch 1992/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6933.0713 - mean_absolute_error: 6933.0713\n",
      "Epoch 1992: val_loss did not improve from 13443.09766\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9483.4697 - mean_absolute_error: 9483.4697 - val_loss: 13453.3896 - val_mean_absolute_error: 13453.3896\n",
      "Epoch 1993/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8617.6445 - mean_absolute_error: 8617.6445\n",
      "Epoch 1993: val_loss improved from 13443.09766 to 13441.79883, saving model to Weights-01993--13441.79883.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9483.4473 - mean_absolute_error: 9483.4473 - val_loss: 13441.7988 - val_mean_absolute_error: 13441.7988\n",
      "Epoch 1994/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5807.8779 - mean_absolute_error: 5807.8779\n",
      "Epoch 1994: val_loss did not improve from 13441.79883\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9475.4736 - mean_absolute_error: 9475.4736 - val_loss: 13452.1094 - val_mean_absolute_error: 13452.1094\n",
      "Epoch 1995/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11584.0098 - mean_absolute_error: 11584.0098\n",
      "Epoch 1995: val_loss did not improve from 13441.79883\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9477.3594 - mean_absolute_error: 9477.3594 - val_loss: 13449.4219 - val_mean_absolute_error: 13449.4219\n",
      "Epoch 1996/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8802.9707 - mean_absolute_error: 8802.9707\n",
      "Epoch 1996: val_loss did not improve from 13441.79883\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9481.6807 - mean_absolute_error: 9481.6807 - val_loss: 13444.1572 - val_mean_absolute_error: 13444.1572\n",
      "Epoch 1997/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 14643.9004 - mean_absolute_error: 14643.9004\n",
      "Epoch 1997: val_loss did not improve from 13441.79883\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9485.7822 - mean_absolute_error: 9485.7822 - val_loss: 13451.3623 - val_mean_absolute_error: 13451.3623\n",
      "Epoch 1998/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9435.1094 - mean_absolute_error: 9435.1094\n",
      "Epoch 1998: val_loss did not improve from 13441.79883\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9480.6973 - mean_absolute_error: 9480.6973 - val_loss: 13445.7129 - val_mean_absolute_error: 13445.7129\n",
      "Epoch 1999/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9694.8418 - mean_absolute_error: 9694.8418\n",
      "Epoch 1999: val_loss did not improve from 13441.79883\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9473.8232 - mean_absolute_error: 9473.8232 - val_loss: 13446.6973 - val_mean_absolute_error: 13446.6973\n",
      "Epoch 2000/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7481.4082 - mean_absolute_error: 7481.4082\n",
      "Epoch 2000: val_loss did not improve from 13441.79883\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9474.8418 - mean_absolute_error: 9474.8418 - val_loss: 13446.2900 - val_mean_absolute_error: 13446.2900\n",
      "Epoch 2001/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8970.0596 - mean_absolute_error: 8970.0596\n",
      "Epoch 2001: val_loss did not improve from 13441.79883\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9477.8379 - mean_absolute_error: 9477.8379 - val_loss: 13441.9570 - val_mean_absolute_error: 13441.9570\n",
      "Epoch 2002/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8948.1367 - mean_absolute_error: 8948.1367\n",
      "Epoch 2002: val_loss did not improve from 13441.79883\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9475.6045 - mean_absolute_error: 9475.6045 - val_loss: 13444.6914 - val_mean_absolute_error: 13444.6914\n",
      "Epoch 2003/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11539.1621 - mean_absolute_error: 11539.1621\n",
      "Epoch 2003: val_loss improved from 13441.79883 to 13440.65527, saving model to Weights-02003--13440.65527.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9475.9131 - mean_absolute_error: 9475.9131 - val_loss: 13440.6553 - val_mean_absolute_error: 13440.6562\n",
      "Epoch 2004/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11944.2422 - mean_absolute_error: 11944.2422\n",
      "Epoch 2004: val_loss improved from 13440.65527 to 13440.42969, saving model to Weights-02004--13440.42969.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9476.5908 - mean_absolute_error: 9476.5908 - val_loss: 13440.4297 - val_mean_absolute_error: 13440.4297\n",
      "Epoch 2005/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8347.7285 - mean_absolute_error: 8347.7285\n",
      "Epoch 2005: val_loss did not improve from 13440.42969\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9475.7070 - mean_absolute_error: 9475.7070 - val_loss: 13440.5391 - val_mean_absolute_error: 13440.5391\n",
      "Epoch 2006/3000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 9381.5439 - mean_absolute_error: 9381.5439\n",
      "Epoch 2006: val_loss did not improve from 13440.42969\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9476.7695 - mean_absolute_error: 9476.7695 - val_loss: 13449.3584 - val_mean_absolute_error: 13449.3584\n",
      "Epoch 2007/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12089.4561 - mean_absolute_error: 12089.4561\n",
      "Epoch 2007: val_loss did not improve from 13440.42969\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9472.9619 - mean_absolute_error: 9472.9619 - val_loss: 13442.7969 - val_mean_absolute_error: 13442.7969\n",
      "Epoch 2008/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7844.9531 - mean_absolute_error: 7844.9531\n",
      "Epoch 2008: val_loss did not improve from 13440.42969\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9483.7861 - mean_absolute_error: 9483.7861 - val_loss: 13446.6279 - val_mean_absolute_error: 13446.6279\n",
      "Epoch 2009/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9546.9463 - mean_absolute_error: 9546.9463\n",
      "Epoch 2009: val_loss improved from 13440.42969 to 13439.71582, saving model to Weights-02009--13439.71582.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9475.4424 - mean_absolute_error: 9475.4424 - val_loss: 13439.7158 - val_mean_absolute_error: 13439.7158\n",
      "Epoch 2010/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10307.0918 - mean_absolute_error: 10307.0918\n",
      "Epoch 2010: val_loss improved from 13439.71582 to 13439.67480, saving model to Weights-02010--13439.67480.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9474.6025 - mean_absolute_error: 9474.6025 - val_loss: 13439.6748 - val_mean_absolute_error: 13439.6748\n",
      "Epoch 2011/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8196.6582 - mean_absolute_error: 8196.6582\n",
      "Epoch 2011: val_loss did not improve from 13439.67480\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9493.1816 - mean_absolute_error: 9493.1816 - val_loss: 13455.9844 - val_mean_absolute_error: 13455.9844\n",
      "Epoch 2012/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5987.2886 - mean_absolute_error: 5987.2886\n",
      "Epoch 2012: val_loss did not improve from 13439.67480\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9474.2812 - mean_absolute_error: 9474.2812 - val_loss: 13440.2236 - val_mean_absolute_error: 13440.2236\n",
      "Epoch 2013/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9388.1973 - mean_absolute_error: 9388.1973\n",
      "Epoch 2013: val_loss improved from 13439.67480 to 13439.09473, saving model to Weights-02013--13439.09473.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9476.2803 - mean_absolute_error: 9476.2803 - val_loss: 13439.0947 - val_mean_absolute_error: 13439.0947\n",
      "Epoch 2014/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8769.0449 - mean_absolute_error: 8769.0449\n",
      "Epoch 2014: val_loss did not improve from 13439.09473\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9473.0039 - mean_absolute_error: 9473.0039 - val_loss: 13442.6611 - val_mean_absolute_error: 13442.6611\n",
      "Epoch 2015/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6906.5127 - mean_absolute_error: 6906.5127\n",
      "Epoch 2015: val_loss did not improve from 13439.09473\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9477.0889 - mean_absolute_error: 9477.0889 - val_loss: 13445.7998 - val_mean_absolute_error: 13445.7998\n",
      "Epoch 2016/3000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9637.6465 - mean_absolute_error: 9637.6465  \n",
      "Epoch 2016: val_loss did not improve from 13439.09473\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9473.3389 - mean_absolute_error: 9473.3389 - val_loss: 13440.5264 - val_mean_absolute_error: 13440.5264\n",
      "Epoch 2017/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11800.6865 - mean_absolute_error: 11800.6865\n",
      "Epoch 2017: val_loss did not improve from 13439.09473\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9478.4004 - mean_absolute_error: 9478.4004 - val_loss: 13443.8447 - val_mean_absolute_error: 13443.8447\n",
      "Epoch 2018/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10341.2275 - mean_absolute_error: 10341.2275\n",
      "Epoch 2018: val_loss improved from 13439.09473 to 13438.45020, saving model to Weights-02018--13438.45020.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9474.2158 - mean_absolute_error: 9474.2158 - val_loss: 13438.4502 - val_mean_absolute_error: 13438.4502\n",
      "Epoch 2019/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6350.5410 - mean_absolute_error: 6350.5410\n",
      "Epoch 2019: val_loss did not improve from 13438.45020\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9472.6885 - mean_absolute_error: 9472.6885 - val_loss: 13442.7109 - val_mean_absolute_error: 13442.7109\n",
      "Epoch 2020/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11003.3135 - mean_absolute_error: 11003.3135\n",
      "Epoch 2020: val_loss improved from 13438.45020 to 13438.20215, saving model to Weights-02020--13438.20215.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9481.7617 - mean_absolute_error: 9481.7617 - val_loss: 13438.2021 - val_mean_absolute_error: 13438.2021\n",
      "Epoch 2021/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13156.5488 - mean_absolute_error: 13156.5488\n",
      "Epoch 2021: val_loss did not improve from 13438.20215\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9474.2295 - mean_absolute_error: 9474.2295 - val_loss: 13439.5967 - val_mean_absolute_error: 13439.5967\n",
      "Epoch 2022/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10567.5713 - mean_absolute_error: 10567.5713\n",
      "Epoch 2022: val_loss did not improve from 13438.20215\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9478.9082 - mean_absolute_error: 9478.9082 - val_loss: 13445.1543 - val_mean_absolute_error: 13445.1543\n",
      "Epoch 2023/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8979.7891 - mean_absolute_error: 8979.7891\n",
      "Epoch 2023: val_loss did not improve from 13438.20215\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9480.0469 - mean_absolute_error: 9480.0469 - val_loss: 13445.4912 - val_mean_absolute_error: 13445.4912\n",
      "Epoch 2024/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10490.4150 - mean_absolute_error: 10490.4150\n",
      "Epoch 2024: val_loss did not improve from 13438.20215\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9482.1768 - mean_absolute_error: 9482.1768 - val_loss: 13454.5957 - val_mean_absolute_error: 13454.5957\n",
      "Epoch 2025/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9995.8223 - mean_absolute_error: 9995.8223\n",
      "Epoch 2025: val_loss did not improve from 13438.20215\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9484.7764 - mean_absolute_error: 9484.7764 - val_loss: 13441.3896 - val_mean_absolute_error: 13441.3896\n",
      "Epoch 2026/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8144.7202 - mean_absolute_error: 8144.7202\n",
      "Epoch 2026: val_loss did not improve from 13438.20215\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9473.4736 - mean_absolute_error: 9473.4736 - val_loss: 13442.2529 - val_mean_absolute_error: 13442.2529\n",
      "Epoch 2027/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9596.1367 - mean_absolute_error: 9596.1367\n",
      "Epoch 2027: val_loss did not improve from 13438.20215\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9472.1465 - mean_absolute_error: 9472.1465 - val_loss: 13440.4775 - val_mean_absolute_error: 13440.4775\n",
      "Epoch 2028/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10450.9434 - mean_absolute_error: 10450.9434\n",
      "Epoch 2028: val_loss improved from 13438.20215 to 13437.36230, saving model to Weights-02028--13437.36230.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9473.6729 - mean_absolute_error: 9473.6729 - val_loss: 13437.3623 - val_mean_absolute_error: 13437.3623\n",
      "Epoch 2029/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9218.1152 - mean_absolute_error: 9218.1152\n",
      "Epoch 2029: val_loss did not improve from 13437.36230\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9475.6357 - mean_absolute_error: 9475.6357 - val_loss: 13437.8438 - val_mean_absolute_error: 13437.8438\n",
      "Epoch 2030/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9951.5088 - mean_absolute_error: 9951.5088\n",
      "Epoch 2030: val_loss improved from 13437.36230 to 13437.23438, saving model to Weights-02030--13437.23438.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9471.1270 - mean_absolute_error: 9471.1270 - val_loss: 13437.2344 - val_mean_absolute_error: 13437.2344\n",
      "Epoch 2031/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7798.4590 - mean_absolute_error: 7798.4590\n",
      "Epoch 2031: val_loss improved from 13437.23438 to 13436.68359, saving model to Weights-02031--13436.68359.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9473.4570 - mean_absolute_error: 9473.4570 - val_loss: 13436.6836 - val_mean_absolute_error: 13436.6836\n",
      "Epoch 2032/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12029.8008 - mean_absolute_error: 12029.8008\n",
      "Epoch 2032: val_loss did not improve from 13436.68359\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9476.1250 - mean_absolute_error: 9476.1250 - val_loss: 13437.4326 - val_mean_absolute_error: 13437.4326\n",
      "Epoch 2033/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10210.5156 - mean_absolute_error: 10210.5156\n",
      "Epoch 2033: val_loss did not improve from 13436.68359\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9472.0986 - mean_absolute_error: 9472.0986 - val_loss: 13437.1836 - val_mean_absolute_error: 13437.1836\n",
      "Epoch 2034/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8568.1465 - mean_absolute_error: 8568.1465\n",
      "Epoch 2034: val_loss did not improve from 13436.68359\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9499.3701 - mean_absolute_error: 9499.3701 - val_loss: 13446.7031 - val_mean_absolute_error: 13446.7031\n",
      "Epoch 2035/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8367.4941 - mean_absolute_error: 8367.4941\n",
      "Epoch 2035: val_loss improved from 13436.68359 to 13436.56738, saving model to Weights-02035--13436.56738.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9475.7607 - mean_absolute_error: 9475.7607 - val_loss: 13436.5674 - val_mean_absolute_error: 13436.5674\n",
      "Epoch 2036/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8128.7324 - mean_absolute_error: 8128.7324\n",
      "Epoch 2036: val_loss improved from 13436.56738 to 13435.99414, saving model to Weights-02036--13435.99414.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9471.5020 - mean_absolute_error: 9471.5020 - val_loss: 13435.9941 - val_mean_absolute_error: 13435.9941\n",
      "Epoch 2037/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12472.6846 - mean_absolute_error: 12472.6846\n",
      "Epoch 2037: val_loss did not improve from 13435.99414\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9471.6094 - mean_absolute_error: 9471.6094 - val_loss: 13436.7256 - val_mean_absolute_error: 13436.7256\n",
      "Epoch 2038/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8831.2363 - mean_absolute_error: 8831.2363\n",
      "Epoch 2038: val_loss did not improve from 13435.99414\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9478.0869 - mean_absolute_error: 9478.0869 - val_loss: 13441.2334 - val_mean_absolute_error: 13441.2334\n",
      "Epoch 2039/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10134.7695 - mean_absolute_error: 10134.7695\n",
      "Epoch 2039: val_loss did not improve from 13435.99414\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9474.1387 - mean_absolute_error: 9474.1387 - val_loss: 13438.8057 - val_mean_absolute_error: 13438.8057\n",
      "Epoch 2040/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11823.0654 - mean_absolute_error: 11823.0654\n",
      "Epoch 2040: val_loss did not improve from 13435.99414\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9472.6406 - mean_absolute_error: 9472.6406 - val_loss: 13448.8232 - val_mean_absolute_error: 13448.8232\n",
      "Epoch 2041/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9896.1377 - mean_absolute_error: 9896.1377\n",
      "Epoch 2041: val_loss improved from 13435.99414 to 13435.43262, saving model to Weights-02041--13435.43262.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9493.6025 - mean_absolute_error: 9493.6025 - val_loss: 13435.4326 - val_mean_absolute_error: 13435.4326\n",
      "Epoch 2042/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12755.2402 - mean_absolute_error: 12755.2402\n",
      "Epoch 2042: val_loss did not improve from 13435.43262\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9470.0762 - mean_absolute_error: 9470.0762 - val_loss: 13442.9141 - val_mean_absolute_error: 13442.9141\n",
      "Epoch 2043/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7708.7563 - mean_absolute_error: 7708.7563\n",
      "Epoch 2043: val_loss did not improve from 13435.43262\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9470.7197 - mean_absolute_error: 9470.7197 - val_loss: 13437.8604 - val_mean_absolute_error: 13437.8604\n",
      "Epoch 2044/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11078.7910 - mean_absolute_error: 11078.7910\n",
      "Epoch 2044: val_loss improved from 13435.43262 to 13435.28711, saving model to Weights-02044--13435.28711.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9473.3232 - mean_absolute_error: 9473.3232 - val_loss: 13435.2871 - val_mean_absolute_error: 13435.2871\n",
      "Epoch 2045/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12843.1055 - mean_absolute_error: 12843.1055\n",
      "Epoch 2045: val_loss did not improve from 13435.28711\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9470.2637 - mean_absolute_error: 9470.2637 - val_loss: 13437.1094 - val_mean_absolute_error: 13437.1094\n",
      "Epoch 2046/3000\n",
      "10/18 [===============>..............] - ETA: 0s - loss: 9322.2373 - mean_absolute_error: 9322.2373\n",
      "Epoch 2046: val_loss improved from 13435.28711 to 13434.87695, saving model to Weights-02046--13434.87695.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9471.4062 - mean_absolute_error: 9471.4062 - val_loss: 13434.8770 - val_mean_absolute_error: 13434.8770\n",
      "Epoch 2047/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6896.5498 - mean_absolute_error: 6896.5498\n",
      "Epoch 2047: val_loss did not improve from 13434.87695\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9478.6426 - mean_absolute_error: 9478.6426 - val_loss: 13439.6074 - val_mean_absolute_error: 13439.6074\n",
      "Epoch 2048/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11508.8740 - mean_absolute_error: 11508.8740\n",
      "Epoch 2048: val_loss did not improve from 13434.87695\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9469.5078 - mean_absolute_error: 9469.5078 - val_loss: 13437.4893 - val_mean_absolute_error: 13437.4893\n",
      "Epoch 2049/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7215.3442 - mean_absolute_error: 7215.3442\n",
      "Epoch 2049: val_loss improved from 13434.87695 to 13434.34863, saving model to Weights-02049--13434.34863.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9470.0938 - mean_absolute_error: 9470.0938 - val_loss: 13434.3486 - val_mean_absolute_error: 13434.3486\n",
      "Epoch 2050/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8607.4102 - mean_absolute_error: 8607.4102\n",
      "Epoch 2050: val_loss improved from 13434.34863 to 13434.33984, saving model to Weights-02050--13434.33984.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9476.7344 - mean_absolute_error: 9476.7344 - val_loss: 13434.3398 - val_mean_absolute_error: 13434.3398\n",
      "Epoch 2051/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8528.9717 - mean_absolute_error: 8528.9717\n",
      "Epoch 2051: val_loss did not improve from 13434.33984\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9471.5674 - mean_absolute_error: 9471.5674 - val_loss: 13437.6807 - val_mean_absolute_error: 13437.6807\n",
      "Epoch 2052/3000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9565.9639 - mean_absolute_error: 9565.9639  \n",
      "Epoch 2052: val_loss improved from 13434.33984 to 13434.22461, saving model to Weights-02052--13434.22461.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9477.4424 - mean_absolute_error: 9477.4424 - val_loss: 13434.2246 - val_mean_absolute_error: 13434.2246\n",
      "Epoch 2053/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9196.6904 - mean_absolute_error: 9196.6904\n",
      "Epoch 2053: val_loss improved from 13434.22461 to 13433.84863, saving model to Weights-02053--13433.84863.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9469.2334 - mean_absolute_error: 9469.2334 - val_loss: 13433.8486 - val_mean_absolute_error: 13433.8486\n",
      "Epoch 2054/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12316.2461 - mean_absolute_error: 12316.2461\n",
      "Epoch 2054: val_loss improved from 13433.84863 to 13433.62695, saving model to Weights-02054--13433.62695.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9479.6963 - mean_absolute_error: 9479.6963 - val_loss: 13433.6270 - val_mean_absolute_error: 13433.6270\n",
      "Epoch 2055/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10115.0312 - mean_absolute_error: 10115.0312\n",
      "Epoch 2055: val_loss did not improve from 13433.62695\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9473.8359 - mean_absolute_error: 9473.8359 - val_loss: 13438.8896 - val_mean_absolute_error: 13438.8896\n",
      "Epoch 2056/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10858.1445 - mean_absolute_error: 10858.1445\n",
      "Epoch 2056: val_loss improved from 13433.62695 to 13433.33105, saving model to Weights-02056--13433.33105.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9469.7314 - mean_absolute_error: 9469.7314 - val_loss: 13433.3311 - val_mean_absolute_error: 13433.3311\n",
      "Epoch 2057/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8796.2188 - mean_absolute_error: 8796.2188\n",
      "Epoch 2057: val_loss improved from 13433.33105 to 13433.23242, saving model to Weights-02057--13433.23242.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9470.8076 - mean_absolute_error: 9470.8076 - val_loss: 13433.2324 - val_mean_absolute_error: 13433.2324\n",
      "Epoch 2058/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7711.2979 - mean_absolute_error: 7711.2979\n",
      "Epoch 2058: val_loss did not improve from 13433.23242\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9482.1035 - mean_absolute_error: 9482.1035 - val_loss: 13435.6826 - val_mean_absolute_error: 13435.6826\n",
      "Epoch 2059/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9096.1455 - mean_absolute_error: 9096.1455\n",
      "Epoch 2059: val_loss did not improve from 13433.23242\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9464.7461 - mean_absolute_error: 9464.7461 - val_loss: 13440.9512 - val_mean_absolute_error: 13440.9512\n",
      "Epoch 2060/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12209.5605 - mean_absolute_error: 12209.5605\n",
      "Epoch 2060: val_loss did not improve from 13433.23242\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9470.4277 - mean_absolute_error: 9470.4277 - val_loss: 13440.2197 - val_mean_absolute_error: 13440.2197\n",
      "Epoch 2061/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11909.2598 - mean_absolute_error: 11909.2598\n",
      "Epoch 2061: val_loss did not improve from 13433.23242\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9467.9951 - mean_absolute_error: 9467.9951 - val_loss: 13436.3877 - val_mean_absolute_error: 13436.3877\n",
      "Epoch 2062/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8933.0205 - mean_absolute_error: 8933.0205\n",
      "Epoch 2062: val_loss improved from 13433.23242 to 13432.58691, saving model to Weights-02062--13432.58691.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9474.9951 - mean_absolute_error: 9474.9951 - val_loss: 13432.5869 - val_mean_absolute_error: 13432.5869\n",
      "Epoch 2063/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7801.3623 - mean_absolute_error: 7801.3623\n",
      "Epoch 2063: val_loss did not improve from 13432.58691\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9483.2900 - mean_absolute_error: 9483.2900 - val_loss: 13445.8574 - val_mean_absolute_error: 13445.8574\n",
      "Epoch 2064/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7748.3330 - mean_absolute_error: 7748.3330\n",
      "Epoch 2064: val_loss improved from 13432.58691 to 13432.28223, saving model to Weights-02064--13432.28223.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9475.2549 - mean_absolute_error: 9475.2549 - val_loss: 13432.2822 - val_mean_absolute_error: 13432.2822\n",
      "Epoch 2065/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 14429.2188 - mean_absolute_error: 14429.2188\n",
      "Epoch 2065: val_loss did not improve from 13432.28223\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9472.0957 - mean_absolute_error: 9472.0957 - val_loss: 13434.4482 - val_mean_absolute_error: 13434.4482\n",
      "Epoch 2066/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8221.7061 - mean_absolute_error: 8221.7061\n",
      "Epoch 2066: val_loss improved from 13432.28223 to 13432.09473, saving model to Weights-02066--13432.09473.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9469.3594 - mean_absolute_error: 9469.3594 - val_loss: 13432.0947 - val_mean_absolute_error: 13432.0947\n",
      "Epoch 2067/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8591.0879 - mean_absolute_error: 8591.0879\n",
      "Epoch 2067: val_loss did not improve from 13432.09473\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9469.1006 - mean_absolute_error: 9469.1006 - val_loss: 13434.6055 - val_mean_absolute_error: 13434.6055\n",
      "Epoch 2068/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9456.6484 - mean_absolute_error: 9456.6484\n",
      "Epoch 2068: val_loss improved from 13432.09473 to 13431.70508, saving model to Weights-02068--13431.70508.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9470.7217 - mean_absolute_error: 9470.7217 - val_loss: 13431.7051 - val_mean_absolute_error: 13431.7051\n",
      "Epoch 2069/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11813.9639 - mean_absolute_error: 11813.9639\n",
      "Epoch 2069: val_loss did not improve from 13431.70508\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9487.2148 - mean_absolute_error: 9487.2148 - val_loss: 13459.9219 - val_mean_absolute_error: 13459.9219\n",
      "Epoch 2070/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6288.5273 - mean_absolute_error: 6288.5273\n",
      "Epoch 2070: val_loss did not improve from 13431.70508\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9466.5352 - mean_absolute_error: 9466.5352 - val_loss: 13433.5576 - val_mean_absolute_error: 13433.5576\n",
      "Epoch 2071/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10977.0703 - mean_absolute_error: 10977.0703\n",
      "Epoch 2071: val_loss did not improve from 13431.70508\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9476.1924 - mean_absolute_error: 9476.1924 - val_loss: 13437.0879 - val_mean_absolute_error: 13437.0879\n",
      "Epoch 2072/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10266.9688 - mean_absolute_error: 10266.9688\n",
      "Epoch 2072: val_loss did not improve from 13431.70508\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9468.1465 - mean_absolute_error: 9468.1465 - val_loss: 13436.0215 - val_mean_absolute_error: 13436.0215\n",
      "Epoch 2073/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8472.4307 - mean_absolute_error: 8472.4307\n",
      "Epoch 2073: val_loss improved from 13431.70508 to 13431.67871, saving model to Weights-02073--13431.67871.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9479.1475 - mean_absolute_error: 9479.1475 - val_loss: 13431.6787 - val_mean_absolute_error: 13431.6787\n",
      "Epoch 2074/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10119.8916 - mean_absolute_error: 10119.8916\n",
      "Epoch 2074: val_loss did not improve from 13431.67871\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9462.9805 - mean_absolute_error: 9462.9805 - val_loss: 13446.9941 - val_mean_absolute_error: 13446.9941\n",
      "Epoch 2075/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7958.7305 - mean_absolute_error: 7958.7305\n",
      "Epoch 2075: val_loss did not improve from 13431.67871\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9481.9102 - mean_absolute_error: 9481.9102 - val_loss: 13450.5264 - val_mean_absolute_error: 13450.5264\n",
      "Epoch 2076/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9227.3535 - mean_absolute_error: 9227.3535\n",
      "Epoch 2076: val_loss did not improve from 13431.67871\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9461.1094 - mean_absolute_error: 9461.1094 - val_loss: 13432.5605 - val_mean_absolute_error: 13432.5605\n",
      "Epoch 2077/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8158.0151 - mean_absolute_error: 8158.0151\n",
      "Epoch 2077: val_loss improved from 13431.67871 to 13430.58105, saving model to Weights-02077--13430.58105.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9468.7432 - mean_absolute_error: 9468.7432 - val_loss: 13430.5811 - val_mean_absolute_error: 13430.5811\n",
      "Epoch 2078/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12449.7686 - mean_absolute_error: 12449.7686\n",
      "Epoch 2078: val_loss did not improve from 13430.58105\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9474.9209 - mean_absolute_error: 9474.9209 - val_loss: 13435.8242 - val_mean_absolute_error: 13435.8242\n",
      "Epoch 2079/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7917.3955 - mean_absolute_error: 7917.3955\n",
      "Epoch 2079: val_loss did not improve from 13430.58105\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9473.5811 - mean_absolute_error: 9473.5811 - val_loss: 13430.9248 - val_mean_absolute_error: 13430.9248\n",
      "Epoch 2080/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9288.9844 - mean_absolute_error: 9288.9844\n",
      "Epoch 2080: val_loss improved from 13430.58105 to 13430.13281, saving model to Weights-02080--13430.13281.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9466.3350 - mean_absolute_error: 9466.3350 - val_loss: 13430.1328 - val_mean_absolute_error: 13430.1328\n",
      "Epoch 2081/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9112.1660 - mean_absolute_error: 9112.1660\n",
      "Epoch 2081: val_loss did not improve from 13430.13281\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9464.8857 - mean_absolute_error: 9464.8857 - val_loss: 13434.8770 - val_mean_absolute_error: 13434.8770\n",
      "Epoch 2082/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7141.0918 - mean_absolute_error: 7141.0918\n",
      "Epoch 2082: val_loss improved from 13430.13281 to 13430.01562, saving model to Weights-02082--13430.01562.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9476.3242 - mean_absolute_error: 9476.3242 - val_loss: 13430.0156 - val_mean_absolute_error: 13430.0156\n",
      "Epoch 2083/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11189.1270 - mean_absolute_error: 11189.1270\n",
      "Epoch 2083: val_loss did not improve from 13430.01562\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9466.6348 - mean_absolute_error: 9466.6348 - val_loss: 13430.0811 - val_mean_absolute_error: 13430.0811\n",
      "Epoch 2084/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9078.6855 - mean_absolute_error: 9078.6855\n",
      "Epoch 2084: val_loss did not improve from 13430.01562\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9471.6357 - mean_absolute_error: 9471.6357 - val_loss: 13433.8887 - val_mean_absolute_error: 13433.8887\n",
      "Epoch 2085/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10744.6406 - mean_absolute_error: 10744.6406\n",
      "Epoch 2085: val_loss improved from 13430.01562 to 13429.46191, saving model to Weights-02085--13429.46191.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9477.3867 - mean_absolute_error: 9477.3867 - val_loss: 13429.4619 - val_mean_absolute_error: 13429.4619\n",
      "Epoch 2086/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8338.0918 - mean_absolute_error: 8338.0918\n",
      "Epoch 2086: val_loss did not improve from 13429.46191\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9470.2051 - mean_absolute_error: 9470.2051 - val_loss: 13441.9922 - val_mean_absolute_error: 13441.9922\n",
      "Epoch 2087/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11142.5068 - mean_absolute_error: 11142.5068\n",
      "Epoch 2087: val_loss did not improve from 13429.46191\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9468.4014 - mean_absolute_error: 9468.4014 - val_loss: 13430.1660 - val_mean_absolute_error: 13430.1660\n",
      "Epoch 2088/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6920.4668 - mean_absolute_error: 6920.4668\n",
      "Epoch 2088: val_loss improved from 13429.46191 to 13429.18262, saving model to Weights-02088--13429.18262.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9465.4248 - mean_absolute_error: 9465.4248 - val_loss: 13429.1826 - val_mean_absolute_error: 13429.1826\n",
      "Epoch 2089/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8527.2539 - mean_absolute_error: 8527.2539\n",
      "Epoch 2089: val_loss did not improve from 13429.18262\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9465.9873 - mean_absolute_error: 9465.9873 - val_loss: 13429.1943 - val_mean_absolute_error: 13429.1943\n",
      "Epoch 2090/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9731.2822 - mean_absolute_error: 9731.2822\n",
      "Epoch 2090: val_loss did not improve from 13429.18262\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9470.7402 - mean_absolute_error: 9470.7402 - val_loss: 13448.3203 - val_mean_absolute_error: 13448.3203\n",
      "Epoch 2091/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8988.8613 - mean_absolute_error: 8988.8613\n",
      "Epoch 2091: val_loss did not improve from 13429.18262\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9470.8496 - mean_absolute_error: 9470.8496 - val_loss: 13435.5303 - val_mean_absolute_error: 13435.5303\n",
      "Epoch 2092/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8186.5693 - mean_absolute_error: 8186.5693\n",
      "Epoch 2092: val_loss did not improve from 13429.18262\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9465.9629 - mean_absolute_error: 9465.9629 - val_loss: 13429.9639 - val_mean_absolute_error: 13429.9648\n",
      "Epoch 2093/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9567.5059 - mean_absolute_error: 9567.5059\n",
      "Epoch 2093: val_loss improved from 13429.18262 to 13428.55566, saving model to Weights-02093--13428.55566.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9467.5352 - mean_absolute_error: 9467.5352 - val_loss: 13428.5557 - val_mean_absolute_error: 13428.5557\n",
      "Epoch 2094/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9127.3916 - mean_absolute_error: 9127.3916\n",
      "Epoch 2094: val_loss did not improve from 13428.55566\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9470.0859 - mean_absolute_error: 9470.0859 - val_loss: 13429.6445 - val_mean_absolute_error: 13429.6445\n",
      "Epoch 2095/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9225.0371 - mean_absolute_error: 9225.0371\n",
      "Epoch 2095: val_loss did not improve from 13428.55566\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9466.3164 - mean_absolute_error: 9466.3164 - val_loss: 13437.7949 - val_mean_absolute_error: 13437.7949\n",
      "Epoch 2096/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8509.2793 - mean_absolute_error: 8509.2793\n",
      "Epoch 2096: val_loss did not improve from 13428.55566\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9466.5049 - mean_absolute_error: 9466.5049 - val_loss: 13428.9932 - val_mean_absolute_error: 13428.9932\n",
      "Epoch 2097/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9658.4473 - mean_absolute_error: 9658.4473\n",
      "Epoch 2097: val_loss did not improve from 13428.55566\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9463.4258 - mean_absolute_error: 9463.4258 - val_loss: 13434.8965 - val_mean_absolute_error: 13434.8965\n",
      "Epoch 2098/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9861.5547 - mean_absolute_error: 9861.5547\n",
      "Epoch 2098: val_loss did not improve from 13428.55566\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9465.3691 - mean_absolute_error: 9465.3691 - val_loss: 13437.0869 - val_mean_absolute_error: 13437.0869\n",
      "Epoch 2099/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 15617.3486 - mean_absolute_error: 15617.3486\n",
      "Epoch 2099: val_loss did not improve from 13428.55566\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9464.6514 - mean_absolute_error: 9464.6514 - val_loss: 13435.6494 - val_mean_absolute_error: 13435.6494\n",
      "Epoch 2100/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6739.3291 - mean_absolute_error: 6739.3291\n",
      "Epoch 2100: val_loss did not improve from 13428.55566\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9462.9502 - mean_absolute_error: 9462.9502 - val_loss: 13430.1885 - val_mean_absolute_error: 13430.1885\n",
      "Epoch 2101/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8153.8398 - mean_absolute_error: 8153.8398\n",
      "Epoch 2101: val_loss improved from 13428.55566 to 13428.05176, saving model to Weights-02101--13428.05176.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9465.6592 - mean_absolute_error: 9465.6592 - val_loss: 13428.0518 - val_mean_absolute_error: 13428.0518\n",
      "Epoch 2102/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9267.3027 - mean_absolute_error: 9267.3027\n",
      "Epoch 2102: val_loss did not improve from 13428.05176\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9473.3174 - mean_absolute_error: 9473.3174 - val_loss: 13428.2969 - val_mean_absolute_error: 13428.2969\n",
      "Epoch 2103/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8295.5791 - mean_absolute_error: 8295.5791\n",
      "Epoch 2103: val_loss did not improve from 13428.05176\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9475.1973 - mean_absolute_error: 9475.1973 - val_loss: 13428.1865 - val_mean_absolute_error: 13428.1865\n",
      "Epoch 2104/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8327.6377 - mean_absolute_error: 8327.6377\n",
      "Epoch 2104: val_loss did not improve from 13428.05176\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9470.6406 - mean_absolute_error: 9470.6406 - val_loss: 13446.9746 - val_mean_absolute_error: 13446.9746\n",
      "Epoch 2105/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7732.8892 - mean_absolute_error: 7732.8892\n",
      "Epoch 2105: val_loss improved from 13428.05176 to 13426.94531, saving model to Weights-02105--13426.94531.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9466.9424 - mean_absolute_error: 9466.9424 - val_loss: 13426.9453 - val_mean_absolute_error: 13426.9453\n",
      "Epoch 2106/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7633.7100 - mean_absolute_error: 7633.7100\n",
      "Epoch 2106: val_loss did not improve from 13426.94531\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9461.7783 - mean_absolute_error: 9461.7783 - val_loss: 13432.6035 - val_mean_absolute_error: 13432.6035\n",
      "Epoch 2107/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11355.7148 - mean_absolute_error: 11355.7148\n",
      "Epoch 2107: val_loss did not improve from 13426.94531\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9464.0986 - mean_absolute_error: 9464.0986 - val_loss: 13427.6357 - val_mean_absolute_error: 13427.6357\n",
      "Epoch 2108/3000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9329.8906 - mean_absolute_error: 9329.8906  \n",
      "Epoch 2108: val_loss improved from 13426.94531 to 13426.37207, saving model to Weights-02108--13426.37207.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9474.1699 - mean_absolute_error: 9474.1699 - val_loss: 13426.3721 - val_mean_absolute_error: 13426.3721\n",
      "Epoch 2109/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6472.7061 - mean_absolute_error: 6472.7061\n",
      "Epoch 2109: val_loss did not improve from 13426.37207\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9467.9453 - mean_absolute_error: 9467.9453 - val_loss: 13434.8848 - val_mean_absolute_error: 13434.8848\n",
      "Epoch 2110/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9841.4209 - mean_absolute_error: 9841.4209\n",
      "Epoch 2110: val_loss did not improve from 13426.37207\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9462.9561 - mean_absolute_error: 9462.9561 - val_loss: 13430.8584 - val_mean_absolute_error: 13430.8584\n",
      "Epoch 2111/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7630.2246 - mean_absolute_error: 7630.2246\n",
      "Epoch 2111: val_loss improved from 13426.37207 to 13425.92480, saving model to Weights-02111--13425.92480.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9463.0352 - mean_absolute_error: 9463.0352 - val_loss: 13425.9248 - val_mean_absolute_error: 13425.9248\n",
      "Epoch 2112/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9372.6152 - mean_absolute_error: 9372.6152\n",
      "Epoch 2112: val_loss did not improve from 13425.92480\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9465.6826 - mean_absolute_error: 9465.6826 - val_loss: 13431.6680 - val_mean_absolute_error: 13431.6680\n",
      "Epoch 2113/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11539.0488 - mean_absolute_error: 11539.0488\n",
      "Epoch 2113: val_loss did not improve from 13425.92480\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9463.1191 - mean_absolute_error: 9463.1191 - val_loss: 13434.5693 - val_mean_absolute_error: 13434.5693\n",
      "Epoch 2114/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8006.5264 - mean_absolute_error: 8006.5264\n",
      "Epoch 2114: val_loss did not improve from 13425.92480\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9467.0693 - mean_absolute_error: 9467.0693 - val_loss: 13425.9346 - val_mean_absolute_error: 13425.9346\n",
      "Epoch 2115/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8273.1602 - mean_absolute_error: 8273.1602\n",
      "Epoch 2115: val_loss did not improve from 13425.92480\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9476.0527 - mean_absolute_error: 9476.0527 - val_loss: 13426.0342 - val_mean_absolute_error: 13426.0342\n",
      "Epoch 2116/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10424.8311 - mean_absolute_error: 10424.8311\n",
      "Epoch 2116: val_loss improved from 13425.92480 to 13425.28809, saving model to Weights-02116--13425.28809.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9462.7402 - mean_absolute_error: 9462.7402 - val_loss: 13425.2881 - val_mean_absolute_error: 13425.2881\n",
      "Epoch 2117/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11197.6133 - mean_absolute_error: 11197.6133\n",
      "Epoch 2117: val_loss did not improve from 13425.28809\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9463.0928 - mean_absolute_error: 9463.0928 - val_loss: 13425.3369 - val_mean_absolute_error: 13425.3369\n",
      "Epoch 2118/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11498.4326 - mean_absolute_error: 11498.4326\n",
      "Epoch 2118: val_loss did not improve from 13425.28809\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9480.2725 - mean_absolute_error: 9480.2725 - val_loss: 13446.6318 - val_mean_absolute_error: 13446.6318\n",
      "Epoch 2119/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9704.2461 - mean_absolute_error: 9704.2461\n",
      "Epoch 2119: val_loss did not improve from 13425.28809\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9460.9414 - mean_absolute_error: 9460.9414 - val_loss: 13425.4873 - val_mean_absolute_error: 13425.4873\n",
      "Epoch 2120/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12705.0195 - mean_absolute_error: 12705.0195\n",
      "Epoch 2120: val_loss did not improve from 13425.28809\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9467.6670 - mean_absolute_error: 9467.6670 - val_loss: 13425.3799 - val_mean_absolute_error: 13425.3799\n",
      "Epoch 2121/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7006.4746 - mean_absolute_error: 7006.4746\n",
      "Epoch 2121: val_loss did not improve from 13425.28809\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9459.7969 - mean_absolute_error: 9459.7969 - val_loss: 13443.3398 - val_mean_absolute_error: 13443.3398\n",
      "Epoch 2122/3000\n",
      "18/18 [==============================] - ETA: 0s - loss: 9464.1846 - mean_absolute_error: 9464.1846  \n",
      "Epoch 2122: val_loss did not improve from 13425.28809\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9464.1846 - mean_absolute_error: 9464.1846 - val_loss: 13433.2119 - val_mean_absolute_error: 13433.2119\n",
      "Epoch 2123/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7452.3945 - mean_absolute_error: 7452.3945\n",
      "Epoch 2123: val_loss did not improve from 13425.28809\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9473.7383 - mean_absolute_error: 9473.7383 - val_loss: 13427.0283 - val_mean_absolute_error: 13427.0283\n",
      "Epoch 2124/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8399.5479 - mean_absolute_error: 8399.5479\n",
      "Epoch 2124: val_loss did not improve from 13425.28809\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9466.2129 - mean_absolute_error: 9466.2129 - val_loss: 13436.2715 - val_mean_absolute_error: 13436.2715\n",
      "Epoch 2125/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10547.7520 - mean_absolute_error: 10547.7520\n",
      "Epoch 2125: val_loss did not improve from 13425.28809\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9476.9111 - mean_absolute_error: 9476.9111 - val_loss: 13431.1924 - val_mean_absolute_error: 13431.1924\n",
      "Epoch 2126/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9560.8311 - mean_absolute_error: 9560.8311\n",
      "Epoch 2126: val_loss did not improve from 13425.28809\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9464.1768 - mean_absolute_error: 9464.1768 - val_loss: 13433.0332 - val_mean_absolute_error: 13433.0332\n",
      "Epoch 2127/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11346.3760 - mean_absolute_error: 11346.3760\n",
      "Epoch 2127: val_loss did not improve from 13425.28809\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9462.4736 - mean_absolute_error: 9462.4736 - val_loss: 13431.9219 - val_mean_absolute_error: 13431.9219\n",
      "Epoch 2128/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8235.6504 - mean_absolute_error: 8235.6504\n",
      "Epoch 2128: val_loss improved from 13425.28809 to 13424.95703, saving model to Weights-02128--13424.95703.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9463.6279 - mean_absolute_error: 9463.6279 - val_loss: 13424.9570 - val_mean_absolute_error: 13424.9570\n",
      "Epoch 2129/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9148.6055 - mean_absolute_error: 9148.6055\n",
      "Epoch 2129: val_loss improved from 13424.95703 to 13423.59180, saving model to Weights-02129--13423.59180.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9461.6201 - mean_absolute_error: 9461.6201 - val_loss: 13423.5918 - val_mean_absolute_error: 13423.5918\n",
      "Epoch 2130/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6891.6504 - mean_absolute_error: 6891.6504\n",
      "Epoch 2130: val_loss improved from 13423.59180 to 13423.46484, saving model to Weights-02130--13423.46484.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9475.9043 - mean_absolute_error: 9475.9043 - val_loss: 13423.4648 - val_mean_absolute_error: 13423.4648\n",
      "Epoch 2131/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8571.5449 - mean_absolute_error: 8571.5449\n",
      "Epoch 2131: val_loss did not improve from 13423.46484\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9464.6221 - mean_absolute_error: 9464.6221 - val_loss: 13439.4229 - val_mean_absolute_error: 13439.4229\n",
      "Epoch 2132/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12796.0723 - mean_absolute_error: 12796.0723\n",
      "Epoch 2132: val_loss did not improve from 13423.46484\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9464.6807 - mean_absolute_error: 9464.6807 - val_loss: 13438.9795 - val_mean_absolute_error: 13438.9795\n",
      "Epoch 2133/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11556.2998 - mean_absolute_error: 11556.2998\n",
      "Epoch 2133: val_loss did not improve from 13423.46484\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9467.7510 - mean_absolute_error: 9467.7510 - val_loss: 13423.6387 - val_mean_absolute_error: 13423.6387\n",
      "Epoch 2134/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9968.8369 - mean_absolute_error: 9968.8369\n",
      "Epoch 2134: val_loss improved from 13423.46484 to 13423.37988, saving model to Weights-02134--13423.37988.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9463.3135 - mean_absolute_error: 9463.3135 - val_loss: 13423.3799 - val_mean_absolute_error: 13423.3809\n",
      "Epoch 2135/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9547.4121 - mean_absolute_error: 9547.4121\n",
      "Epoch 2135: val_loss did not improve from 13423.37988\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9463.1465 - mean_absolute_error: 9463.1465 - val_loss: 13439.3799 - val_mean_absolute_error: 13439.3799\n",
      "Epoch 2136/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7143.1841 - mean_absolute_error: 7143.1841\n",
      "Epoch 2136: val_loss did not improve from 13423.37988\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9461.4150 - mean_absolute_error: 9461.4150 - val_loss: 13425.1680 - val_mean_absolute_error: 13425.1680\n",
      "Epoch 2137/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9705.9629 - mean_absolute_error: 9705.9629\n",
      "Epoch 2137: val_loss improved from 13423.37988 to 13422.67871, saving model to Weights-02137--13422.67871.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9464.4404 - mean_absolute_error: 9464.4404 - val_loss: 13422.6787 - val_mean_absolute_error: 13422.6787\n",
      "Epoch 2138/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9720.4980 - mean_absolute_error: 9720.4980\n",
      "Epoch 2138: val_loss did not improve from 13422.67871\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9463.9395 - mean_absolute_error: 9463.9395 - val_loss: 13427.8984 - val_mean_absolute_error: 13427.8984\n",
      "Epoch 2139/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13805.1582 - mean_absolute_error: 13805.1582\n",
      "Epoch 2139: val_loss did not improve from 13422.67871\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9468.5088 - mean_absolute_error: 9468.5088 - val_loss: 13433.0264 - val_mean_absolute_error: 13433.0264\n",
      "Epoch 2140/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11625.9824 - mean_absolute_error: 11625.9824\n",
      "Epoch 2140: val_loss improved from 13422.67871 to 13422.13672, saving model to Weights-02140--13422.13672.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9464.3076 - mean_absolute_error: 9464.3076 - val_loss: 13422.1367 - val_mean_absolute_error: 13422.1367\n",
      "Epoch 2141/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12591.8340 - mean_absolute_error: 12591.8340\n",
      "Epoch 2141: val_loss improved from 13422.13672 to 13422.10645, saving model to Weights-02141--13422.10645.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9461.0928 - mean_absolute_error: 9461.0928 - val_loss: 13422.1064 - val_mean_absolute_error: 13422.1064\n",
      "Epoch 2142/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8141.6772 - mean_absolute_error: 8141.6772\n",
      "Epoch 2142: val_loss did not improve from 13422.10645\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9463.7344 - mean_absolute_error: 9463.7344 - val_loss: 13427.9180 - val_mean_absolute_error: 13427.9180\n",
      "Epoch 2143/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7560.2188 - mean_absolute_error: 7560.2188\n",
      "Epoch 2143: val_loss did not improve from 13422.10645\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9461.0781 - mean_absolute_error: 9461.0781 - val_loss: 13423.4961 - val_mean_absolute_error: 13423.4961\n",
      "Epoch 2144/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10817.8945 - mean_absolute_error: 10817.8945\n",
      "Epoch 2144: val_loss did not improve from 13422.10645\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9470.9307 - mean_absolute_error: 9470.9307 - val_loss: 13442.2012 - val_mean_absolute_error: 13442.2012\n",
      "Epoch 2145/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7287.5952 - mean_absolute_error: 7287.5952\n",
      "Epoch 2145: val_loss did not improve from 13422.10645\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9479.9229 - mean_absolute_error: 9479.9229 - val_loss: 13423.4355 - val_mean_absolute_error: 13423.4365\n",
      "Epoch 2146/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9501.0859 - mean_absolute_error: 9501.0859\n",
      "Epoch 2146: val_loss did not improve from 13422.10645\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9459.5820 - mean_absolute_error: 9459.5820 - val_loss: 13428.5156 - val_mean_absolute_error: 13428.5156\n",
      "Epoch 2147/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9335.5273 - mean_absolute_error: 9335.5273\n",
      "Epoch 2147: val_loss did not improve from 13422.10645\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9459.7930 - mean_absolute_error: 9459.7930 - val_loss: 13430.3535 - val_mean_absolute_error: 13430.3535\n",
      "Epoch 2148/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8756.8174 - mean_absolute_error: 8756.8174\n",
      "Epoch 2148: val_loss did not improve from 13422.10645\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9462.3271 - mean_absolute_error: 9462.3271 - val_loss: 13430.4854 - val_mean_absolute_error: 13430.4854\n",
      "Epoch 2149/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6606.7300 - mean_absolute_error: 6606.7300\n",
      "Epoch 2149: val_loss did not improve from 13422.10645\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9464.1914 - mean_absolute_error: 9464.1914 - val_loss: 13425.6943 - val_mean_absolute_error: 13425.6943\n",
      "Epoch 2150/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11136.3311 - mean_absolute_error: 11136.3311\n",
      "Epoch 2150: val_loss did not improve from 13422.10645\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9461.0449 - mean_absolute_error: 9461.0449 - val_loss: 13430.3057 - val_mean_absolute_error: 13430.3057\n",
      "Epoch 2151/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7987.3633 - mean_absolute_error: 7987.3633\n",
      "Epoch 2151: val_loss improved from 13422.10645 to 13421.73535, saving model to Weights-02151--13421.73535.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9458.0225 - mean_absolute_error: 9458.0225 - val_loss: 13421.7354 - val_mean_absolute_error: 13421.7354\n",
      "Epoch 2152/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11563.7480 - mean_absolute_error: 11563.7480\n",
      "Epoch 2152: val_loss improved from 13421.73535 to 13420.81934, saving model to Weights-02152--13420.81934.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9464.4062 - mean_absolute_error: 9464.4062 - val_loss: 13420.8193 - val_mean_absolute_error: 13420.8193\n",
      "Epoch 2153/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10319.1895 - mean_absolute_error: 10319.1895\n",
      "Epoch 2153: val_loss did not improve from 13420.81934\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9490.0049 - mean_absolute_error: 9490.0049 - val_loss: 13450.8984 - val_mean_absolute_error: 13450.8984\n",
      "Epoch 2154/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10270.3584 - mean_absolute_error: 10270.3584\n",
      "Epoch 2154: val_loss improved from 13420.81934 to 13420.68359, saving model to Weights-02154--13420.68359.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9471.8848 - mean_absolute_error: 9471.8848 - val_loss: 13420.6836 - val_mean_absolute_error: 13420.6836\n",
      "Epoch 2155/3000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 9873.9365 - mean_absolute_error: 9873.9365  \n",
      "Epoch 2155: val_loss did not improve from 13420.68359\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9460.0469 - mean_absolute_error: 9460.0469 - val_loss: 13428.7842 - val_mean_absolute_error: 13428.7842\n",
      "Epoch 2156/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9405.7402 - mean_absolute_error: 9405.7402\n",
      "Epoch 2156: val_loss did not improve from 13420.68359\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9465.3574 - mean_absolute_error: 9465.3574 - val_loss: 13436.7471 - val_mean_absolute_error: 13436.7471\n",
      "Epoch 2157/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8077.9307 - mean_absolute_error: 8077.9307\n",
      "Epoch 2157: val_loss improved from 13420.68359 to 13419.95703, saving model to Weights-02157--13419.95703.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9461.3750 - mean_absolute_error: 9461.3750 - val_loss: 13419.9570 - val_mean_absolute_error: 13419.9570\n",
      "Epoch 2158/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12860.6963 - mean_absolute_error: 12860.6963\n",
      "Epoch 2158: val_loss did not improve from 13419.95703\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9464.6172 - mean_absolute_error: 9464.6172 - val_loss: 13434.2764 - val_mean_absolute_error: 13434.2764\n",
      "Epoch 2159/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10173.3398 - mean_absolute_error: 10173.3398\n",
      "Epoch 2159: val_loss did not improve from 13419.95703\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9462.3643 - mean_absolute_error: 9462.3643 - val_loss: 13429.1562 - val_mean_absolute_error: 13429.1562\n",
      "Epoch 2160/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12349.1943 - mean_absolute_error: 12349.1943\n",
      "Epoch 2160: val_loss improved from 13419.95703 to 13419.62598, saving model to Weights-02160--13419.62598.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9461.2090 - mean_absolute_error: 9461.2090 - val_loss: 13419.6260 - val_mean_absolute_error: 13419.6260\n",
      "Epoch 2161/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10220.4619 - mean_absolute_error: 10220.4619\n",
      "Epoch 2161: val_loss did not improve from 13419.62598\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9457.3135 - mean_absolute_error: 9457.3135 - val_loss: 13425.7324 - val_mean_absolute_error: 13425.7324\n",
      "Epoch 2162/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7423.0469 - mean_absolute_error: 7423.0469\n",
      "Epoch 2162: val_loss did not improve from 13419.62598\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9461.2539 - mean_absolute_error: 9461.2539 - val_loss: 13436.5000 - val_mean_absolute_error: 13436.5000\n",
      "Epoch 2163/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11551.7266 - mean_absolute_error: 11551.7266\n",
      "Epoch 2163: val_loss did not improve from 13419.62598\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9464.4131 - mean_absolute_error: 9464.4131 - val_loss: 13420.1553 - val_mean_absolute_error: 13420.1553\n",
      "Epoch 2164/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10630.7090 - mean_absolute_error: 10630.7090\n",
      "Epoch 2164: val_loss did not improve from 13419.62598\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9462.7930 - mean_absolute_error: 9462.7930 - val_loss: 13438.3281 - val_mean_absolute_error: 13438.3281\n",
      "Epoch 2165/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8945.2480 - mean_absolute_error: 8945.2480\n",
      "Epoch 2165: val_loss improved from 13419.62598 to 13419.25586, saving model to Weights-02165--13419.25586.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9462.8965 - mean_absolute_error: 9462.8965 - val_loss: 13419.2559 - val_mean_absolute_error: 13419.2559\n",
      "Epoch 2166/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7919.1797 - mean_absolute_error: 7919.1797\n",
      "Epoch 2166: val_loss did not improve from 13419.25586\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9460.2246 - mean_absolute_error: 9460.2246 - val_loss: 13422.4766 - val_mean_absolute_error: 13422.4775\n",
      "Epoch 2167/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9348.5479 - mean_absolute_error: 9348.5479\n",
      "Epoch 2167: val_loss did not improve from 13419.25586\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9462.2480 - mean_absolute_error: 9462.2480 - val_loss: 13432.1074 - val_mean_absolute_error: 13432.1074\n",
      "Epoch 2168/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9636.6133 - mean_absolute_error: 9636.6133\n",
      "Epoch 2168: val_loss did not improve from 13419.25586\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9465.8809 - mean_absolute_error: 9465.8809 - val_loss: 13420.9424 - val_mean_absolute_error: 13420.9424\n",
      "Epoch 2169/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7863.3564 - mean_absolute_error: 7863.3564\n",
      "Epoch 2169: val_loss did not improve from 13419.25586\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9464.3174 - mean_absolute_error: 9464.3174 - val_loss: 13430.2930 - val_mean_absolute_error: 13430.2930\n",
      "Epoch 2170/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6035.3491 - mean_absolute_error: 6035.3491\n",
      "Epoch 2170: val_loss improved from 13419.25586 to 13418.25684, saving model to Weights-02170--13418.25684.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9465.6963 - mean_absolute_error: 9465.6963 - val_loss: 13418.2568 - val_mean_absolute_error: 13418.2568\n",
      "Epoch 2171/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9260.7041 - mean_absolute_error: 9260.7041\n",
      "Epoch 2171: val_loss did not improve from 13418.25684\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9456.3398 - mean_absolute_error: 9456.3398 - val_loss: 13423.5068 - val_mean_absolute_error: 13423.5068\n",
      "Epoch 2172/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11722.6992 - mean_absolute_error: 11722.6992\n",
      "Epoch 2172: val_loss did not improve from 13418.25684\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9464.7158 - mean_absolute_error: 9464.7158 - val_loss: 13440.1611 - val_mean_absolute_error: 13440.1611\n",
      "Epoch 2173/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6102.6992 - mean_absolute_error: 6102.6992\n",
      "Epoch 2173: val_loss did not improve from 13418.25684\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9458.4766 - mean_absolute_error: 9458.4766 - val_loss: 13423.6025 - val_mean_absolute_error: 13423.6025\n",
      "Epoch 2174/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8342.5244 - mean_absolute_error: 8342.5244\n",
      "Epoch 2174: val_loss did not improve from 13418.25684\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9458.9551 - mean_absolute_error: 9458.9551 - val_loss: 13432.2148 - val_mean_absolute_error: 13432.2148\n",
      "Epoch 2175/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9263.8291 - mean_absolute_error: 9263.8291\n",
      "Epoch 2175: val_loss did not improve from 13418.25684\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9458.2402 - mean_absolute_error: 9458.2402 - val_loss: 13427.3096 - val_mean_absolute_error: 13427.3096\n",
      "Epoch 2176/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13141.8545 - mean_absolute_error: 13141.8545\n",
      "Epoch 2176: val_loss improved from 13418.25684 to 13417.68555, saving model to Weights-02176--13417.68555.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9458.8145 - mean_absolute_error: 9458.8145 - val_loss: 13417.6855 - val_mean_absolute_error: 13417.6855\n",
      "Epoch 2177/3000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9311.1240 - mean_absolute_error: 9311.1240\n",
      "Epoch 2177: val_loss improved from 13417.68555 to 13417.45508, saving model to Weights-02177--13417.45508.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9459.5186 - mean_absolute_error: 9459.5186 - val_loss: 13417.4551 - val_mean_absolute_error: 13417.4551\n",
      "Epoch 2178/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7274.1943 - mean_absolute_error: 7274.1943\n",
      "Epoch 2178: val_loss did not improve from 13417.45508\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9466.7021 - mean_absolute_error: 9466.7021 - val_loss: 13437.9111 - val_mean_absolute_error: 13437.9111\n",
      "Epoch 2179/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7233.9014 - mean_absolute_error: 7233.9014\n",
      "Epoch 2179: val_loss improved from 13417.45508 to 13416.97070, saving model to Weights-02179--13416.97070.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9460.0693 - mean_absolute_error: 9460.0693 - val_loss: 13416.9707 - val_mean_absolute_error: 13416.9707\n",
      "Epoch 2180/3000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 8993.9971 - mean_absolute_error: 8993.9971\n",
      "Epoch 2180: val_loss did not improve from 13416.97070\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9465.9932 - mean_absolute_error: 9465.9932 - val_loss: 13422.5176 - val_mean_absolute_error: 13422.5176\n",
      "Epoch 2181/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6775.0303 - mean_absolute_error: 6775.0303\n",
      "Epoch 2181: val_loss did not improve from 13416.97070\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9466.0107 - mean_absolute_error: 9466.0107 - val_loss: 13438.5439 - val_mean_absolute_error: 13438.5439\n",
      "Epoch 2182/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7761.0391 - mean_absolute_error: 7761.0391\n",
      "Epoch 2182: val_loss did not improve from 13416.97070\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9457.7881 - mean_absolute_error: 9457.7881 - val_loss: 13426.9824 - val_mean_absolute_error: 13426.9824\n",
      "Epoch 2183/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7248.6880 - mean_absolute_error: 7248.6880\n",
      "Epoch 2183: val_loss did not improve from 13416.97070\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9463.0059 - mean_absolute_error: 9463.0059 - val_loss: 13421.6064 - val_mean_absolute_error: 13421.6064\n",
      "Epoch 2184/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8641.0947 - mean_absolute_error: 8641.0947\n",
      "Epoch 2184: val_loss improved from 13416.97070 to 13416.43359, saving model to Weights-02184--13416.43359.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9465.1299 - mean_absolute_error: 9465.1299 - val_loss: 13416.4336 - val_mean_absolute_error: 13416.4336\n",
      "Epoch 2185/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10476.1094 - mean_absolute_error: 10476.1094\n",
      "Epoch 2185: val_loss did not improve from 13416.43359\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9455.6084 - mean_absolute_error: 9455.6084 - val_loss: 13426.5371 - val_mean_absolute_error: 13426.5371\n",
      "Epoch 2186/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9712.1826 - mean_absolute_error: 9712.1826\n",
      "Epoch 2186: val_loss did not improve from 13416.43359\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9461.6436 - mean_absolute_error: 9461.6436 - val_loss: 13422.0859 - val_mean_absolute_error: 13422.0859\n",
      "Epoch 2187/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13249.5547 - mean_absolute_error: 13249.5547\n",
      "Epoch 2187: val_loss improved from 13416.43359 to 13415.95898, saving model to Weights-02187--13415.95898.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9463.2891 - mean_absolute_error: 9463.2891 - val_loss: 13415.9590 - val_mean_absolute_error: 13415.9590\n",
      "Epoch 2188/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9708.1777 - mean_absolute_error: 9708.1777\n",
      "Epoch 2188: val_loss did not improve from 13415.95898\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9457.4775 - mean_absolute_error: 9457.4775 - val_loss: 13420.0986 - val_mean_absolute_error: 13420.0986\n",
      "Epoch 2189/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10187.6133 - mean_absolute_error: 10187.6133\n",
      "Epoch 2189: val_loss did not improve from 13415.95898\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9455.6709 - mean_absolute_error: 9455.6709 - val_loss: 13439.9277 - val_mean_absolute_error: 13439.9277\n",
      "Epoch 2190/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8168.9248 - mean_absolute_error: 8168.9248\n",
      "Epoch 2190: val_loss did not improve from 13415.95898\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9458.2559 - mean_absolute_error: 9458.2559 - val_loss: 13421.9785 - val_mean_absolute_error: 13421.9785\n",
      "Epoch 2191/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9136.5312 - mean_absolute_error: 9136.5312\n",
      "Epoch 2191: val_loss did not improve from 13415.95898\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9467.4326 - mean_absolute_error: 9467.4326 - val_loss: 13423.5674 - val_mean_absolute_error: 13423.5674\n",
      "Epoch 2192/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7600.5615 - mean_absolute_error: 7600.5615\n",
      "Epoch 2192: val_loss did not improve from 13415.95898\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9457.3486 - mean_absolute_error: 9457.3486 - val_loss: 13419.9873 - val_mean_absolute_error: 13419.9873\n",
      "Epoch 2193/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10618.5605 - mean_absolute_error: 10618.5605\n",
      "Epoch 2193: val_loss did not improve from 13415.95898\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9456.8486 - mean_absolute_error: 9456.8486 - val_loss: 13426.5693 - val_mean_absolute_error: 13426.5693\n",
      "Epoch 2194/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9769.3193 - mean_absolute_error: 9769.3193\n",
      "Epoch 2194: val_loss did not improve from 13415.95898\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9459.9619 - mean_absolute_error: 9459.9619 - val_loss: 13418.5381 - val_mean_absolute_error: 13418.5381\n",
      "Epoch 2195/3000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9437.5410 - mean_absolute_error: 9437.5410\n",
      "Epoch 2195: val_loss improved from 13415.95898 to 13415.23242, saving model to Weights-02195--13415.23242.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9461.4521 - mean_absolute_error: 9461.4521 - val_loss: 13415.2324 - val_mean_absolute_error: 13415.2324\n",
      "Epoch 2196/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9131.0000 - mean_absolute_error: 9131.0000\n",
      "Epoch 2196: val_loss did not improve from 13415.23242\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9454.8486 - mean_absolute_error: 9454.8486 - val_loss: 13418.0928 - val_mean_absolute_error: 13418.0928\n",
      "Epoch 2197/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11884.9316 - mean_absolute_error: 11884.9316\n",
      "Epoch 2197: val_loss did not improve from 13415.23242\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9456.6426 - mean_absolute_error: 9456.6426 - val_loss: 13421.5156 - val_mean_absolute_error: 13421.5156\n",
      "Epoch 2198/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13078.6670 - mean_absolute_error: 13078.6670\n",
      "Epoch 2198: val_loss did not improve from 13415.23242\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9454.3701 - mean_absolute_error: 9454.3701 - val_loss: 13422.7412 - val_mean_absolute_error: 13422.7412\n",
      "Epoch 2199/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8047.1240 - mean_absolute_error: 8047.1240\n",
      "Epoch 2199: val_loss did not improve from 13415.23242\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9456.7197 - mean_absolute_error: 9456.7197 - val_loss: 13428.5312 - val_mean_absolute_error: 13428.5312\n",
      "Epoch 2200/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10596.1387 - mean_absolute_error: 10596.1387\n",
      "Epoch 2200: val_loss did not improve from 13415.23242\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9458.5107 - mean_absolute_error: 9458.5107 - val_loss: 13415.3115 - val_mean_absolute_error: 13415.3115\n",
      "Epoch 2201/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7857.9463 - mean_absolute_error: 7857.9463\n",
      "Epoch 2201: val_loss did not improve from 13415.23242\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9467.6582 - mean_absolute_error: 9467.6582 - val_loss: 13423.2734 - val_mean_absolute_error: 13423.2734\n",
      "Epoch 2202/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7300.6167 - mean_absolute_error: 7300.6167\n",
      "Epoch 2202: val_loss did not improve from 13415.23242\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9453.4893 - mean_absolute_error: 9453.4893 - val_loss: 13416.8965 - val_mean_absolute_error: 13416.8965\n",
      "Epoch 2203/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8666.5840 - mean_absolute_error: 8666.5840\n",
      "Epoch 2203: val_loss improved from 13415.23242 to 13413.78125, saving model to Weights-02203--13413.78125.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9462.4434 - mean_absolute_error: 9462.4434 - val_loss: 13413.7812 - val_mean_absolute_error: 13413.7812\n",
      "Epoch 2204/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12843.6748 - mean_absolute_error: 12843.6748\n",
      "Epoch 2204: val_loss did not improve from 13413.78125\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9455.1299 - mean_absolute_error: 9455.1299 - val_loss: 13419.9502 - val_mean_absolute_error: 13419.9502\n",
      "Epoch 2205/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5447.2407 - mean_absolute_error: 5447.2407\n",
      "Epoch 2205: val_loss did not improve from 13413.78125\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9454.0498 - mean_absolute_error: 9454.0498 - val_loss: 13422.6572 - val_mean_absolute_error: 13422.6572\n",
      "Epoch 2206/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10076.8535 - mean_absolute_error: 10076.8535\n",
      "Epoch 2206: val_loss did not improve from 13413.78125\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9456.4814 - mean_absolute_error: 9456.4814 - val_loss: 13431.1729 - val_mean_absolute_error: 13431.1729\n",
      "Epoch 2207/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12572.9990 - mean_absolute_error: 12572.9990\n",
      "Epoch 2207: val_loss did not improve from 13413.78125\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9461.3555 - mean_absolute_error: 9461.3555 - val_loss: 13417.6514 - val_mean_absolute_error: 13417.6514\n",
      "Epoch 2208/3000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9280.8145 - mean_absolute_error: 9280.8145\n",
      "Epoch 2208: val_loss did not improve from 13413.78125\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9453.3848 - mean_absolute_error: 9453.3848 - val_loss: 13420.9346 - val_mean_absolute_error: 13420.9346\n",
      "Epoch 2209/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7466.8340 - mean_absolute_error: 7466.8340\n",
      "Epoch 2209: val_loss did not improve from 13413.78125\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9457.2793 - mean_absolute_error: 9457.2793 - val_loss: 13422.2891 - val_mean_absolute_error: 13422.2891\n",
      "Epoch 2210/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7893.5513 - mean_absolute_error: 7893.5513\n",
      "Epoch 2210: val_loss did not improve from 13413.78125\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9454.4336 - mean_absolute_error: 9454.4336 - val_loss: 13428.5986 - val_mean_absolute_error: 13428.5986\n",
      "Epoch 2211/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12784.3369 - mean_absolute_error: 12784.3369\n",
      "Epoch 2211: val_loss did not improve from 13413.78125\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9463.9336 - mean_absolute_error: 9463.9336 - val_loss: 13418.4434 - val_mean_absolute_error: 13418.4434\n",
      "Epoch 2212/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7722.2910 - mean_absolute_error: 7722.2910\n",
      "Epoch 2212: val_loss improved from 13413.78125 to 13413.17188, saving model to Weights-02212--13413.17188.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9489.1699 - mean_absolute_error: 9489.1699 - val_loss: 13413.1719 - val_mean_absolute_error: 13413.1719\n",
      "Epoch 2213/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9063.1934 - mean_absolute_error: 9063.1934\n",
      "Epoch 2213: val_loss did not improve from 13413.17188\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9449.1162 - mean_absolute_error: 9449.1162 - val_loss: 13430.9111 - val_mean_absolute_error: 13430.9111\n",
      "Epoch 2214/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9559.0059 - mean_absolute_error: 9559.0059\n",
      "Epoch 2214: val_loss did not improve from 13413.17188\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9472.7861 - mean_absolute_error: 9472.7861 - val_loss: 13438.9014 - val_mean_absolute_error: 13438.9014\n",
      "Epoch 2215/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8785.0107 - mean_absolute_error: 8785.0107\n",
      "Epoch 2215: val_loss did not improve from 13413.17188\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9455.9756 - mean_absolute_error: 9455.9756 - val_loss: 13425.7588 - val_mean_absolute_error: 13425.7588\n",
      "Epoch 2216/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10052.3701 - mean_absolute_error: 10052.3701\n",
      "Epoch 2216: val_loss did not improve from 13413.17188\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9456.0820 - mean_absolute_error: 9456.0820 - val_loss: 13421.8057 - val_mean_absolute_error: 13421.8057\n",
      "Epoch 2217/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12197.3594 - mean_absolute_error: 12197.3594\n",
      "Epoch 2217: val_loss did not improve from 13413.17188\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9458.5361 - mean_absolute_error: 9458.5361 - val_loss: 13427.5781 - val_mean_absolute_error: 13427.5781\n",
      "Epoch 2218/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11459.7764 - mean_absolute_error: 11459.7764\n",
      "Epoch 2218: val_loss did not improve from 13413.17188\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9455.0488 - mean_absolute_error: 9455.0488 - val_loss: 13421.1895 - val_mean_absolute_error: 13421.1895\n",
      "Epoch 2219/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10524.6133 - mean_absolute_error: 10524.6133\n",
      "Epoch 2219: val_loss improved from 13413.17188 to 13411.82715, saving model to Weights-02219--13411.82715.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9454.0742 - mean_absolute_error: 9454.0742 - val_loss: 13411.8271 - val_mean_absolute_error: 13411.8271\n",
      "Epoch 2220/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8134.7476 - mean_absolute_error: 8134.7476\n",
      "Epoch 2220: val_loss did not improve from 13411.82715\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9462.2881 - mean_absolute_error: 9462.2881 - val_loss: 13420.0322 - val_mean_absolute_error: 13420.0332\n",
      "Epoch 2221/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8458.9180 - mean_absolute_error: 8458.9180\n",
      "Epoch 2221: val_loss did not improve from 13411.82715\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9453.8398 - mean_absolute_error: 9453.8398 - val_loss: 13424.4023 - val_mean_absolute_error: 13424.4023\n",
      "Epoch 2222/3000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9301.6816 - mean_absolute_error: 9301.6816\n",
      "Epoch 2222: val_loss did not improve from 13411.82715\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9456.9209 - mean_absolute_error: 9456.9209 - val_loss: 13412.3711 - val_mean_absolute_error: 13412.3711\n",
      "Epoch 2223/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8055.4375 - mean_absolute_error: 8055.4375\n",
      "Epoch 2223: val_loss did not improve from 13411.82715\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9459.0303 - mean_absolute_error: 9459.0303 - val_loss: 13414.9453 - val_mean_absolute_error: 13414.9453\n",
      "Epoch 2224/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5374.5078 - mean_absolute_error: 5374.5078\n",
      "Epoch 2224: val_loss improved from 13411.82715 to 13411.51953, saving model to Weights-02224--13411.51953.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9456.2383 - mean_absolute_error: 9456.2383 - val_loss: 13411.5195 - val_mean_absolute_error: 13411.5195\n",
      "Epoch 2225/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8982.6465 - mean_absolute_error: 8982.6465\n",
      "Epoch 2225: val_loss did not improve from 13411.51953\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9459.8984 - mean_absolute_error: 9459.8984 - val_loss: 13429.9688 - val_mean_absolute_error: 13429.9688\n",
      "Epoch 2226/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6715.6538 - mean_absolute_error: 6715.6538\n",
      "Epoch 2226: val_loss improved from 13411.51953 to 13410.78223, saving model to Weights-02226--13410.78223.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9452.0479 - mean_absolute_error: 9452.0479 - val_loss: 13410.7822 - val_mean_absolute_error: 13410.7822\n",
      "Epoch 2227/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12953.1914 - mean_absolute_error: 12953.1914\n",
      "Epoch 2227: val_loss improved from 13410.78223 to 13410.26367, saving model to Weights-02227--13410.26367.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9454.7520 - mean_absolute_error: 9454.7520 - val_loss: 13410.2637 - val_mean_absolute_error: 13410.2637\n",
      "Epoch 2228/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9641.7041 - mean_absolute_error: 9641.7041\n",
      "Epoch 2228: val_loss did not improve from 13410.26367\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9477.3525 - mean_absolute_error: 9477.3525 - val_loss: 13439.9053 - val_mean_absolute_error: 13439.9062\n",
      "Epoch 2229/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9516.8613 - mean_absolute_error: 9516.8613\n",
      "Epoch 2229: val_loss did not improve from 13410.26367\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9472.7773 - mean_absolute_error: 9472.7773 - val_loss: 13413.3291 - val_mean_absolute_error: 13413.3291\n",
      "Epoch 2230/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5216.7686 - mean_absolute_error: 5216.7686\n",
      "Epoch 2230: val_loss did not improve from 13410.26367\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9455.5498 - mean_absolute_error: 9455.5498 - val_loss: 13424.6318 - val_mean_absolute_error: 13424.6318\n",
      "Epoch 2231/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7778.5552 - mean_absolute_error: 7778.5552\n",
      "Epoch 2231: val_loss did not improve from 13410.26367\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9460.1328 - mean_absolute_error: 9460.1328 - val_loss: 13432.4004 - val_mean_absolute_error: 13432.4004\n",
      "Epoch 2232/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11442.4688 - mean_absolute_error: 11442.4688\n",
      "Epoch 2232: val_loss did not improve from 13410.26367\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9459.0361 - mean_absolute_error: 9459.0361 - val_loss: 13410.9766 - val_mean_absolute_error: 13410.9766\n",
      "Epoch 2233/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9676.0566 - mean_absolute_error: 9676.0566\n",
      "Epoch 2233: val_loss did not improve from 13410.26367\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9458.2432 - mean_absolute_error: 9458.2432 - val_loss: 13421.4209 - val_mean_absolute_error: 13421.4209\n",
      "Epoch 2234/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10313.5508 - mean_absolute_error: 10313.5508\n",
      "Epoch 2234: val_loss did not improve from 13410.26367\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9455.9082 - mean_absolute_error: 9455.9082 - val_loss: 13425.8740 - val_mean_absolute_error: 13425.8740\n",
      "Epoch 2235/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6081.5464 - mean_absolute_error: 6081.5464\n",
      "Epoch 2235: val_loss did not improve from 13410.26367\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9459.3018 - mean_absolute_error: 9459.3018 - val_loss: 13411.3281 - val_mean_absolute_error: 13411.3281\n",
      "Epoch 2236/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8116.6553 - mean_absolute_error: 8116.6553\n",
      "Epoch 2236: val_loss did not improve from 13410.26367\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9458.8389 - mean_absolute_error: 9458.8389 - val_loss: 13418.5176 - val_mean_absolute_error: 13418.5176\n",
      "Epoch 2237/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11052.6270 - mean_absolute_error: 11052.6270\n",
      "Epoch 2237: val_loss improved from 13410.26367 to 13410.00195, saving model to Weights-02237--13410.00195.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9450.8613 - mean_absolute_error: 9450.8613 - val_loss: 13410.0020 - val_mean_absolute_error: 13410.0020\n",
      "Epoch 2238/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7744.5488 - mean_absolute_error: 7744.5488\n",
      "Epoch 2238: val_loss did not improve from 13410.00195\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9456.6680 - mean_absolute_error: 9456.6680 - val_loss: 13412.3789 - val_mean_absolute_error: 13412.3789\n",
      "Epoch 2239/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9197.3311 - mean_absolute_error: 9197.3311\n",
      "Epoch 2239: val_loss did not improve from 13410.00195\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9451.0322 - mean_absolute_error: 9451.0322 - val_loss: 13423.7080 - val_mean_absolute_error: 13423.7080\n",
      "Epoch 2240/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9205.5195 - mean_absolute_error: 9205.5195\n",
      "Epoch 2240: val_loss did not improve from 13410.00195\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9463.0361 - mean_absolute_error: 9463.0361 - val_loss: 13417.9785 - val_mean_absolute_error: 13417.9785\n",
      "Epoch 2241/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8323.9297 - mean_absolute_error: 8323.9297\n",
      "Epoch 2241: val_loss did not improve from 13410.00195\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9452.6162 - mean_absolute_error: 9452.6162 - val_loss: 13422.6895 - val_mean_absolute_error: 13422.6895\n",
      "Epoch 2242/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9047.1875 - mean_absolute_error: 9047.1875\n",
      "Epoch 2242: val_loss did not improve from 13410.00195\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9455.1611 - mean_absolute_error: 9455.1611 - val_loss: 13420.7148 - val_mean_absolute_error: 13420.7148\n",
      "Epoch 2243/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7845.0381 - mean_absolute_error: 7845.0381\n",
      "Epoch 2243: val_loss improved from 13410.00195 to 13409.67676, saving model to Weights-02243--13409.67676.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9456.4570 - mean_absolute_error: 9456.4570 - val_loss: 13409.6768 - val_mean_absolute_error: 13409.6768\n",
      "Epoch 2244/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9486.5527 - mean_absolute_error: 9486.5527\n",
      "Epoch 2244: val_loss did not improve from 13409.67676\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9451.9053 - mean_absolute_error: 9451.9053 - val_loss: 13410.9746 - val_mean_absolute_error: 13410.9746\n",
      "Epoch 2245/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12091.8848 - mean_absolute_error: 12091.8848\n",
      "Epoch 2245: val_loss did not improve from 13409.67676\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9459.4033 - mean_absolute_error: 9459.4033 - val_loss: 13412.7812 - val_mean_absolute_error: 13412.7812\n",
      "Epoch 2246/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10588.0215 - mean_absolute_error: 10588.0215\n",
      "Epoch 2246: val_loss did not improve from 13409.67676\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9449.7344 - mean_absolute_error: 9449.7344 - val_loss: 13420.6553 - val_mean_absolute_error: 13420.6553\n",
      "Epoch 2247/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8269.4102 - mean_absolute_error: 8269.4102\n",
      "Epoch 2247: val_loss did not improve from 13409.67676\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9454.7754 - mean_absolute_error: 9454.7754 - val_loss: 13421.4922 - val_mean_absolute_error: 13421.4922\n",
      "Epoch 2248/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8602.0449 - mean_absolute_error: 8602.0449\n",
      "Epoch 2248: val_loss did not improve from 13409.67676\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9455.6875 - mean_absolute_error: 9455.6875 - val_loss: 13428.9023 - val_mean_absolute_error: 13428.9023\n",
      "Epoch 2249/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9848.5537 - mean_absolute_error: 9848.5537\n",
      "Epoch 2249: val_loss improved from 13409.67676 to 13408.54688, saving model to Weights-02249--13408.54688.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9462.6826 - mean_absolute_error: 9462.6826 - val_loss: 13408.5469 - val_mean_absolute_error: 13408.5469\n",
      "Epoch 2250/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10229.4395 - mean_absolute_error: 10229.4395\n",
      "Epoch 2250: val_loss did not improve from 13408.54688\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9450.6660 - mean_absolute_error: 9450.6660 - val_loss: 13412.0498 - val_mean_absolute_error: 13412.0498\n",
      "Epoch 2251/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8104.5483 - mean_absolute_error: 8104.5483\n",
      "Epoch 2251: val_loss did not improve from 13408.54688\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9454.3096 - mean_absolute_error: 9454.3096 - val_loss: 13414.2871 - val_mean_absolute_error: 13414.2871\n",
      "Epoch 2252/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7732.8687 - mean_absolute_error: 7732.8687\n",
      "Epoch 2252: val_loss did not improve from 13408.54688\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9461.9346 - mean_absolute_error: 9461.9346 - val_loss: 13432.4229 - val_mean_absolute_error: 13432.4229\n",
      "Epoch 2253/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10042.8008 - mean_absolute_error: 10042.8008\n",
      "Epoch 2253: val_loss did not improve from 13408.54688\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9457.4600 - mean_absolute_error: 9457.4600 - val_loss: 13408.8086 - val_mean_absolute_error: 13408.8086\n",
      "Epoch 2254/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9937.0918 - mean_absolute_error: 9937.0918\n",
      "Epoch 2254: val_loss did not improve from 13408.54688\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9453.3633 - mean_absolute_error: 9453.3633 - val_loss: 13409.7607 - val_mean_absolute_error: 13409.7607\n",
      "Epoch 2255/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9459.4287 - mean_absolute_error: 9459.4287\n",
      "Epoch 2255: val_loss did not improve from 13408.54688\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9451.7500 - mean_absolute_error: 9451.7500 - val_loss: 13414.7529 - val_mean_absolute_error: 13414.7529\n",
      "Epoch 2256/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11474.6094 - mean_absolute_error: 11474.6094\n",
      "Epoch 2256: val_loss did not improve from 13408.54688\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9449.9482 - mean_absolute_error: 9449.9482 - val_loss: 13417.6943 - val_mean_absolute_error: 13417.6943\n",
      "Epoch 2257/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7978.5322 - mean_absolute_error: 7978.5322\n",
      "Epoch 2257: val_loss did not improve from 13408.54688\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9453.7676 - mean_absolute_error: 9453.7676 - val_loss: 13422.6504 - val_mean_absolute_error: 13422.6504\n",
      "Epoch 2258/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9384.1895 - mean_absolute_error: 9384.1895\n",
      "Epoch 2258: val_loss did not improve from 13408.54688\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9454.2998 - mean_absolute_error: 9454.2998 - val_loss: 13409.9736 - val_mean_absolute_error: 13409.9736\n",
      "Epoch 2259/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11068.3096 - mean_absolute_error: 11068.3096\n",
      "Epoch 2259: val_loss did not improve from 13408.54688\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9453.4834 - mean_absolute_error: 9453.4834 - val_loss: 13422.5400 - val_mean_absolute_error: 13422.5400\n",
      "Epoch 2260/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11834.4629 - mean_absolute_error: 11834.4629\n",
      "Epoch 2260: val_loss did not improve from 13408.54688\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9449.8760 - mean_absolute_error: 9449.8760 - val_loss: 13411.8271 - val_mean_absolute_error: 13411.8271\n",
      "Epoch 2261/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8009.6655 - mean_absolute_error: 8009.6655\n",
      "Epoch 2261: val_loss improved from 13408.54688 to 13406.84766, saving model to Weights-02261--13406.84766.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9455.0820 - mean_absolute_error: 9455.0820 - val_loss: 13406.8477 - val_mean_absolute_error: 13406.8477\n",
      "Epoch 2262/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13799.5898 - mean_absolute_error: 13799.5898\n",
      "Epoch 2262: val_loss did not improve from 13406.84766\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9463.9199 - mean_absolute_error: 9463.9199 - val_loss: 13422.8418 - val_mean_absolute_error: 13422.8418\n",
      "Epoch 2263/3000\n",
      "18/18 [==============================] - ETA: 0s - loss: 9478.3809 - mean_absolute_error: 9478.3809\n",
      "Epoch 2263: val_loss did not improve from 13406.84766\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9478.3809 - mean_absolute_error: 9478.3809 - val_loss: 13415.0195 - val_mean_absolute_error: 13415.0195\n",
      "Epoch 2264/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9195.4688 - mean_absolute_error: 9195.4688\n",
      "Epoch 2264: val_loss did not improve from 13406.84766\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9462.1777 - mean_absolute_error: 9462.1777 - val_loss: 13428.9385 - val_mean_absolute_error: 13428.9385\n",
      "Epoch 2265/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8113.7300 - mean_absolute_error: 8113.7300\n",
      "Epoch 2265: val_loss did not improve from 13406.84766\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9451.4189 - mean_absolute_error: 9451.4189 - val_loss: 13412.7969 - val_mean_absolute_error: 13412.7969\n",
      "Epoch 2266/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8588.9766 - mean_absolute_error: 8588.9766\n",
      "Epoch 2266: val_loss did not improve from 13406.84766\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9449.9180 - mean_absolute_error: 9449.9180 - val_loss: 13412.7949 - val_mean_absolute_error: 13412.7949\n",
      "Epoch 2267/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 14090.0449 - mean_absolute_error: 14090.0449\n",
      "Epoch 2267: val_loss did not improve from 13406.84766\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9454.2148 - mean_absolute_error: 9454.2148 - val_loss: 13407.1133 - val_mean_absolute_error: 13407.1133\n",
      "Epoch 2268/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8487.8477 - mean_absolute_error: 8487.8477\n",
      "Epoch 2268: val_loss did not improve from 13406.84766\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9450.9951 - mean_absolute_error: 9450.9951 - val_loss: 13422.9521 - val_mean_absolute_error: 13422.9521\n",
      "Epoch 2269/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11428.9775 - mean_absolute_error: 11428.9775\n",
      "Epoch 2269: val_loss improved from 13406.84766 to 13406.81641, saving model to Weights-02269--13406.81641.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9460.7324 - mean_absolute_error: 9460.7324 - val_loss: 13406.8164 - val_mean_absolute_error: 13406.8164\n",
      "Epoch 2270/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11227.8242 - mean_absolute_error: 11227.8242\n",
      "Epoch 2270: val_loss did not improve from 13406.81641\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9449.2842 - mean_absolute_error: 9449.2842 - val_loss: 13426.8213 - val_mean_absolute_error: 13426.8213\n",
      "Epoch 2271/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12844.8506 - mean_absolute_error: 12844.8506\n",
      "Epoch 2271: val_loss did not improve from 13406.81641\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9453.0225 - mean_absolute_error: 9453.0225 - val_loss: 13415.5742 - val_mean_absolute_error: 13415.5742\n",
      "Epoch 2272/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9099.4707 - mean_absolute_error: 9099.4707\n",
      "Epoch 2272: val_loss did not improve from 13406.81641\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9449.2646 - mean_absolute_error: 9449.2646 - val_loss: 13408.3604 - val_mean_absolute_error: 13408.3604\n",
      "Epoch 2273/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11342.5273 - mean_absolute_error: 11342.5273\n",
      "Epoch 2273: val_loss did not improve from 13406.81641\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9468.6475 - mean_absolute_error: 9468.6475 - val_loss: 13406.9053 - val_mean_absolute_error: 13406.9053\n",
      "Epoch 2274/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12063.2480 - mean_absolute_error: 12063.2480\n",
      "Epoch 2274: val_loss did not improve from 13406.81641\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9450.8945 - mean_absolute_error: 9450.8945 - val_loss: 13407.7803 - val_mean_absolute_error: 13407.7803\n",
      "Epoch 2275/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8891.1621 - mean_absolute_error: 8891.1621\n",
      "Epoch 2275: val_loss did not improve from 13406.81641\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9453.4961 - mean_absolute_error: 9453.4961 - val_loss: 13408.0576 - val_mean_absolute_error: 13408.0576\n",
      "Epoch 2276/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7768.1953 - mean_absolute_error: 7768.1953\n",
      "Epoch 2276: val_loss did not improve from 13406.81641\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9466.1758 - mean_absolute_error: 9466.1758 - val_loss: 13427.6318 - val_mean_absolute_error: 13427.6318\n",
      "Epoch 2277/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10371.1006 - mean_absolute_error: 10371.1006\n",
      "Epoch 2277: val_loss did not improve from 13406.81641\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9452.3887 - mean_absolute_error: 9452.3887 - val_loss: 13415.0361 - val_mean_absolute_error: 13415.0361\n",
      "Epoch 2278/3000\n",
      "18/18 [==============================] - ETA: 0s - loss: 9447.6299 - mean_absolute_error: 9447.6299\n",
      "Epoch 2278: val_loss did not improve from 13406.81641\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9447.6299 - mean_absolute_error: 9447.6299 - val_loss: 13409.9980 - val_mean_absolute_error: 13409.9980\n",
      "Epoch 2279/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12633.6699 - mean_absolute_error: 12633.6699\n",
      "Epoch 2279: val_loss did not improve from 13406.81641\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9451.4268 - mean_absolute_error: 9451.4268 - val_loss: 13407.1523 - val_mean_absolute_error: 13407.1523\n",
      "Epoch 2280/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7405.9883 - mean_absolute_error: 7405.9883\n",
      "Epoch 2280: val_loss did not improve from 13406.81641\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9447.3740 - mean_absolute_error: 9447.3740 - val_loss: 13416.3027 - val_mean_absolute_error: 13416.3027\n",
      "Epoch 2281/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11235.7148 - mean_absolute_error: 11235.7148\n",
      "Epoch 2281: val_loss did not improve from 13406.81641\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9453.9648 - mean_absolute_error: 9453.9648 - val_loss: 13418.5557 - val_mean_absolute_error: 13418.5557\n",
      "Epoch 2282/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7683.2959 - mean_absolute_error: 7683.2959\n",
      "Epoch 2282: val_loss did not improve from 13406.81641\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9447.7002 - mean_absolute_error: 9447.7002 - val_loss: 13412.0654 - val_mean_absolute_error: 13412.0654\n",
      "Epoch 2283/3000\n",
      "18/18 [==============================] - ETA: 0s - loss: 9467.1934 - mean_absolute_error: 9467.1934\n",
      "Epoch 2283: val_loss improved from 13406.81641 to 13406.64844, saving model to Weights-02283--13406.64844.hdf5\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 9467.1934 - mean_absolute_error: 9467.1934 - val_loss: 13406.6484 - val_mean_absolute_error: 13406.6484\n",
      "Epoch 2284/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10073.3486 - mean_absolute_error: 10073.3486\n",
      "Epoch 2284: val_loss did not improve from 13406.64844\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9462.6025 - mean_absolute_error: 9462.6025 - val_loss: 13418.9688 - val_mean_absolute_error: 13418.9688\n",
      "Epoch 2285/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10203.2480 - mean_absolute_error: 10203.2480\n",
      "Epoch 2285: val_loss did not improve from 13406.64844\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9477.5225 - mean_absolute_error: 9477.5225 - val_loss: 13410.4424 - val_mean_absolute_error: 13410.4424\n",
      "Epoch 2286/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9683.6836 - mean_absolute_error: 9683.6836\n",
      "Epoch 2286: val_loss did not improve from 13406.64844\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9438.3936 - mean_absolute_error: 9438.3936 - val_loss: 13421.8535 - val_mean_absolute_error: 13421.8535\n",
      "Epoch 2287/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 14848.7715 - mean_absolute_error: 14848.7715\n",
      "Epoch 2287: val_loss did not improve from 13406.64844\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9452.3457 - mean_absolute_error: 9452.3457 - val_loss: 13428.2285 - val_mean_absolute_error: 13428.2285\n",
      "Epoch 2288/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9836.7070 - mean_absolute_error: 9836.7070\n",
      "Epoch 2288: val_loss did not improve from 13406.64844\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9448.2988 - mean_absolute_error: 9448.2988 - val_loss: 13415.7354 - val_mean_absolute_error: 13415.7354\n",
      "Epoch 2289/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7510.7109 - mean_absolute_error: 7510.7109\n",
      "Epoch 2289: val_loss did not improve from 13406.64844\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9448.5723 - mean_absolute_error: 9448.5723 - val_loss: 13408.6826 - val_mean_absolute_error: 13408.6826\n",
      "Epoch 2290/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10211.5352 - mean_absolute_error: 10211.5352\n",
      "Epoch 2290: val_loss improved from 13406.64844 to 13405.46289, saving model to Weights-02290--13405.46289.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9449.2549 - mean_absolute_error: 9449.2549 - val_loss: 13405.4629 - val_mean_absolute_error: 13405.4629\n",
      "Epoch 2291/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8620.7012 - mean_absolute_error: 8620.7012\n",
      "Epoch 2291: val_loss did not improve from 13405.46289\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9458.9561 - mean_absolute_error: 9458.9561 - val_loss: 13413.5684 - val_mean_absolute_error: 13413.5684\n",
      "Epoch 2292/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8335.4453 - mean_absolute_error: 8335.4453\n",
      "Epoch 2292: val_loss did not improve from 13405.46289\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9447.3281 - mean_absolute_error: 9447.3281 - val_loss: 13409.2773 - val_mean_absolute_error: 13409.2773\n",
      "Epoch 2293/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8519.1650 - mean_absolute_error: 8519.1650\n",
      "Epoch 2293: val_loss improved from 13405.46289 to 13402.84668, saving model to Weights-02293--13402.84668.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9447.1855 - mean_absolute_error: 9447.1855 - val_loss: 13402.8467 - val_mean_absolute_error: 13402.8467\n",
      "Epoch 2294/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9982.5400 - mean_absolute_error: 9982.5400\n",
      "Epoch 2294: val_loss did not improve from 13402.84668\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9448.1582 - mean_absolute_error: 9448.1582 - val_loss: 13407.5215 - val_mean_absolute_error: 13407.5205\n",
      "Epoch 2295/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7724.1963 - mean_absolute_error: 7724.1963\n",
      "Epoch 2295: val_loss did not improve from 13402.84668\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9447.6152 - mean_absolute_error: 9447.6152 - val_loss: 13410.0254 - val_mean_absolute_error: 13410.0254\n",
      "Epoch 2296/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7071.9023 - mean_absolute_error: 7071.9023\n",
      "Epoch 2296: val_loss did not improve from 13402.84668\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9455.3672 - mean_absolute_error: 9455.3672 - val_loss: 13423.9951 - val_mean_absolute_error: 13423.9951\n",
      "Epoch 2297/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9270.9531 - mean_absolute_error: 9270.9531\n",
      "Epoch 2297: val_loss improved from 13402.84668 to 13402.46094, saving model to Weights-02297--13402.46094.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9450.0957 - mean_absolute_error: 9450.0957 - val_loss: 13402.4609 - val_mean_absolute_error: 13402.4609\n",
      "Epoch 2298/3000\n",
      "10/18 [===============>..............] - ETA: 0s - loss: 9008.6357 - mean_absolute_error: 9008.6357  \n",
      "Epoch 2298: val_loss did not improve from 13402.46094\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 9456.4219 - mean_absolute_error: 9456.4219 - val_loss: 13408.8975 - val_mean_absolute_error: 13408.8975\n",
      "Epoch 2299/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7488.0396 - mean_absolute_error: 7488.0396\n",
      "Epoch 2299: val_loss did not improve from 13402.46094\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9447.3252 - mean_absolute_error: 9447.3252 - val_loss: 13409.9834 - val_mean_absolute_error: 13409.9834\n",
      "Epoch 2300/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6682.8447 - mean_absolute_error: 6682.8447\n",
      "Epoch 2300: val_loss did not improve from 13402.46094\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9448.4395 - mean_absolute_error: 9448.4395 - val_loss: 13413.5674 - val_mean_absolute_error: 13413.5674\n",
      "Epoch 2301/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11310.0127 - mean_absolute_error: 11310.0127\n",
      "Epoch 2301: val_loss did not improve from 13402.46094\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9448.0742 - mean_absolute_error: 9448.0742 - val_loss: 13413.2793 - val_mean_absolute_error: 13413.2793\n",
      "Epoch 2302/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11560.3320 - mean_absolute_error: 11560.3320\n",
      "Epoch 2302: val_loss did not improve from 13402.46094\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9453.1523 - mean_absolute_error: 9453.1523 - val_loss: 13402.6641 - val_mean_absolute_error: 13402.6641\n",
      "Epoch 2303/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11731.9277 - mean_absolute_error: 11731.9277\n",
      "Epoch 2303: val_loss did not improve from 13402.46094\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9449.8916 - mean_absolute_error: 9449.8916 - val_loss: 13416.1650 - val_mean_absolute_error: 13416.1650\n",
      "Epoch 2304/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9969.0332 - mean_absolute_error: 9969.0332\n",
      "Epoch 2304: val_loss did not improve from 13402.46094\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9447.4531 - mean_absolute_error: 9447.4531 - val_loss: 13416.2627 - val_mean_absolute_error: 13416.2627\n",
      "Epoch 2305/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9537.0645 - mean_absolute_error: 9537.0645\n",
      "Epoch 2305: val_loss did not improve from 13402.46094\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9448.1191 - mean_absolute_error: 9448.1191 - val_loss: 13406.5938 - val_mean_absolute_error: 13406.5938\n",
      "Epoch 2306/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9448.5117 - mean_absolute_error: 9448.5117\n",
      "Epoch 2306: val_loss did not improve from 13402.46094\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9444.0254 - mean_absolute_error: 9444.0254 - val_loss: 13417.0742 - val_mean_absolute_error: 13417.0742\n",
      "Epoch 2307/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10315.3564 - mean_absolute_error: 10315.3564\n",
      "Epoch 2307: val_loss did not improve from 13402.46094\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9446.6523 - mean_absolute_error: 9446.6523 - val_loss: 13413.3320 - val_mean_absolute_error: 13413.3320\n",
      "Epoch 2308/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8369.2744 - mean_absolute_error: 8369.2744\n",
      "Epoch 2308: val_loss improved from 13402.46094 to 13401.75195, saving model to Weights-02308--13401.75195.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9456.2461 - mean_absolute_error: 9456.2461 - val_loss: 13401.7520 - val_mean_absolute_error: 13401.7520\n",
      "Epoch 2309/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6435.9956 - mean_absolute_error: 6435.9956\n",
      "Epoch 2309: val_loss did not improve from 13401.75195\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9450.6045 - mean_absolute_error: 9450.6045 - val_loss: 13418.5244 - val_mean_absolute_error: 13418.5244\n",
      "Epoch 2310/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9479.7480 - mean_absolute_error: 9479.7480\n",
      "Epoch 2310: val_loss did not improve from 13401.75195\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9453.5713 - mean_absolute_error: 9453.5713 - val_loss: 13402.3594 - val_mean_absolute_error: 13402.3594\n",
      "Epoch 2311/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10030.3115 - mean_absolute_error: 10030.3115\n",
      "Epoch 2311: val_loss did not improve from 13401.75195\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9454.9053 - mean_absolute_error: 9454.9053 - val_loss: 13406.2930 - val_mean_absolute_error: 13406.2930\n",
      "Epoch 2312/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8818.3291 - mean_absolute_error: 8818.3291\n",
      "Epoch 2312: val_loss did not improve from 13401.75195\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9447.9258 - mean_absolute_error: 9447.9258 - val_loss: 13408.6533 - val_mean_absolute_error: 13408.6533\n",
      "Epoch 2313/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13739.7383 - mean_absolute_error: 13739.7383\n",
      "Epoch 2313: val_loss did not improve from 13401.75195\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9446.3330 - mean_absolute_error: 9446.3330 - val_loss: 13419.3271 - val_mean_absolute_error: 13419.3271\n",
      "Epoch 2314/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8462.0664 - mean_absolute_error: 8462.0664\n",
      "Epoch 2314: val_loss did not improve from 13401.75195\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9446.0127 - mean_absolute_error: 9446.0127 - val_loss: 13410.3027 - val_mean_absolute_error: 13410.3027\n",
      "Epoch 2315/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13017.3047 - mean_absolute_error: 13017.3047\n",
      "Epoch 2315: val_loss did not improve from 13401.75195\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9445.2959 - mean_absolute_error: 9445.2959 - val_loss: 13409.3799 - val_mean_absolute_error: 13409.3799\n",
      "Epoch 2316/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8764.4355 - mean_absolute_error: 8764.4355\n",
      "Epoch 2316: val_loss improved from 13401.75195 to 13401.63672, saving model to Weights-02316--13401.63672.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9443.8428 - mean_absolute_error: 9443.8428 - val_loss: 13401.6367 - val_mean_absolute_error: 13401.6367\n",
      "Epoch 2317/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9438.4395 - mean_absolute_error: 9438.4395\n",
      "Epoch 2317: val_loss did not improve from 13401.63672\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9447.1191 - mean_absolute_error: 9447.1191 - val_loss: 13402.1191 - val_mean_absolute_error: 13402.1191\n",
      "Epoch 2318/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11683.2344 - mean_absolute_error: 11683.2344\n",
      "Epoch 2318: val_loss did not improve from 13401.63672\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9454.2578 - mean_absolute_error: 9454.2578 - val_loss: 13408.8877 - val_mean_absolute_error: 13408.8877\n",
      "Epoch 2319/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8797.8398 - mean_absolute_error: 8797.8398\n",
      "Epoch 2319: val_loss did not improve from 13401.63672\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9447.5342 - mean_absolute_error: 9447.5342 - val_loss: 13403.9609 - val_mean_absolute_error: 13403.9609\n",
      "Epoch 2320/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9723.3643 - mean_absolute_error: 9723.3643\n",
      "Epoch 2320: val_loss improved from 13401.63672 to 13401.00586, saving model to Weights-02320--13401.00586.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9450.8008 - mean_absolute_error: 9450.8008 - val_loss: 13401.0059 - val_mean_absolute_error: 13401.0059\n",
      "Epoch 2321/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10311.3398 - mean_absolute_error: 10311.3398\n",
      "Epoch 2321: val_loss did not improve from 13401.00586\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9448.7803 - mean_absolute_error: 9448.7803 - val_loss: 13406.9492 - val_mean_absolute_error: 13406.9492\n",
      "Epoch 2322/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8736.1729 - mean_absolute_error: 8736.1729\n",
      "Epoch 2322: val_loss did not improve from 13401.00586\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9462.3389 - mean_absolute_error: 9462.3389 - val_loss: 13406.9639 - val_mean_absolute_error: 13406.9639\n",
      "Epoch 2323/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9575.1133 - mean_absolute_error: 9575.1133\n",
      "Epoch 2323: val_loss did not improve from 13401.00586\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9448.1514 - mean_absolute_error: 9448.1514 - val_loss: 13408.6152 - val_mean_absolute_error: 13408.6152\n",
      "Epoch 2324/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8072.6934 - mean_absolute_error: 8072.6934\n",
      "Epoch 2324: val_loss did not improve from 13401.00586\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9457.6992 - mean_absolute_error: 9457.6992 - val_loss: 13418.1299 - val_mean_absolute_error: 13418.1299\n",
      "Epoch 2325/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9094.0850 - mean_absolute_error: 9094.0850\n",
      "Epoch 2325: val_loss did not improve from 13401.00586\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9445.8418 - mean_absolute_error: 9445.8418 - val_loss: 13401.5693 - val_mean_absolute_error: 13401.5693\n",
      "Epoch 2326/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9963.8574 - mean_absolute_error: 9963.8574\n",
      "Epoch 2326: val_loss did not improve from 13401.00586\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9450.7646 - mean_absolute_error: 9450.7646 - val_loss: 13404.2656 - val_mean_absolute_error: 13404.2656\n",
      "Epoch 2327/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6819.2031 - mean_absolute_error: 6819.2031\n",
      "Epoch 2327: val_loss did not improve from 13401.00586\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9452.8535 - mean_absolute_error: 9452.8535 - val_loss: 13404.6416 - val_mean_absolute_error: 13404.6416\n",
      "Epoch 2328/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10330.6660 - mean_absolute_error: 10330.6660\n",
      "Epoch 2328: val_loss did not improve from 13401.00586\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9447.6602 - mean_absolute_error: 9447.6602 - val_loss: 13411.1592 - val_mean_absolute_error: 13411.1592\n",
      "Epoch 2329/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11711.4854 - mean_absolute_error: 11711.4854\n",
      "Epoch 2329: val_loss did not improve from 13401.00586\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9445.1270 - mean_absolute_error: 9445.1270 - val_loss: 13412.4727 - val_mean_absolute_error: 13412.4727\n",
      "Epoch 2330/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9510.5820 - mean_absolute_error: 9510.5820\n",
      "Epoch 2330: val_loss did not improve from 13401.00586\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9443.1436 - mean_absolute_error: 9443.1436 - val_loss: 13402.5479 - val_mean_absolute_error: 13402.5479\n",
      "Epoch 2331/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10949.2422 - mean_absolute_error: 10949.2422\n",
      "Epoch 2331: val_loss did not improve from 13401.00586\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9446.8496 - mean_absolute_error: 9446.8496 - val_loss: 13401.4990 - val_mean_absolute_error: 13401.4990\n",
      "Epoch 2332/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8896.3184 - mean_absolute_error: 8896.3184\n",
      "Epoch 2332: val_loss did not improve from 13401.00586\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9457.5312 - mean_absolute_error: 9457.5312 - val_loss: 13408.5752 - val_mean_absolute_error: 13408.5752\n",
      "Epoch 2333/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8426.7852 - mean_absolute_error: 8426.7852\n",
      "Epoch 2333: val_loss did not improve from 13401.00586\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9448.9092 - mean_absolute_error: 9448.9092 - val_loss: 13401.3164 - val_mean_absolute_error: 13401.3164\n",
      "Epoch 2334/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7477.2207 - mean_absolute_error: 7477.2207\n",
      "Epoch 2334: val_loss improved from 13401.00586 to 13400.02832, saving model to Weights-02334--13400.02832.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9444.7510 - mean_absolute_error: 9444.7510 - val_loss: 13400.0283 - val_mean_absolute_error: 13400.0283\n",
      "Epoch 2335/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9852.7246 - mean_absolute_error: 9852.7246\n",
      "Epoch 2335: val_loss did not improve from 13400.02832\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9446.5918 - mean_absolute_error: 9446.5918 - val_loss: 13400.4902 - val_mean_absolute_error: 13400.4902\n",
      "Epoch 2336/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10115.6855 - mean_absolute_error: 10115.6855\n",
      "Epoch 2336: val_loss improved from 13400.02832 to 13399.04883, saving model to Weights-02336--13399.04883.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9443.9727 - mean_absolute_error: 9443.9727 - val_loss: 13399.0488 - val_mean_absolute_error: 13399.0488\n",
      "Epoch 2337/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8787.4160 - mean_absolute_error: 8787.4160\n",
      "Epoch 2337: val_loss did not improve from 13399.04883\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9446.1865 - mean_absolute_error: 9446.1865 - val_loss: 13399.6562 - val_mean_absolute_error: 13399.6562\n",
      "Epoch 2338/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10891.8682 - mean_absolute_error: 10891.8682\n",
      "Epoch 2338: val_loss did not improve from 13399.04883\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9442.3623 - mean_absolute_error: 9442.3623 - val_loss: 13414.7803 - val_mean_absolute_error: 13414.7803\n",
      "Epoch 2339/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 14571.6738 - mean_absolute_error: 14571.6738\n",
      "Epoch 2339: val_loss did not improve from 13399.04883\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9452.3613 - mean_absolute_error: 9452.3613 - val_loss: 13413.9258 - val_mean_absolute_error: 13413.9258\n",
      "Epoch 2340/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8974.4199 - mean_absolute_error: 8974.4199\n",
      "Epoch 2340: val_loss improved from 13399.04883 to 13398.51562, saving model to Weights-02340--13398.51562.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9477.4004 - mean_absolute_error: 9477.4004 - val_loss: 13398.5156 - val_mean_absolute_error: 13398.5156\n",
      "Epoch 2341/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8504.2031 - mean_absolute_error: 8504.2031\n",
      "Epoch 2341: val_loss did not improve from 13398.51562\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9461.8486 - mean_absolute_error: 9461.8486 - val_loss: 13431.1094 - val_mean_absolute_error: 13431.1094\n",
      "Epoch 2342/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8380.4395 - mean_absolute_error: 8380.4395\n",
      "Epoch 2342: val_loss did not improve from 13398.51562\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9447.7461 - mean_absolute_error: 9447.7461 - val_loss: 13412.9873 - val_mean_absolute_error: 13412.9873\n",
      "Epoch 2343/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10343.3779 - mean_absolute_error: 10343.3779\n",
      "Epoch 2343: val_loss did not improve from 13398.51562\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9452.5557 - mean_absolute_error: 9452.5557 - val_loss: 13416.5801 - val_mean_absolute_error: 13416.5801\n",
      "Epoch 2344/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8784.8447 - mean_absolute_error: 8784.8447\n",
      "Epoch 2344: val_loss did not improve from 13398.51562\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9446.9658 - mean_absolute_error: 9446.9658 - val_loss: 13412.6416 - val_mean_absolute_error: 13412.6416\n",
      "Epoch 2345/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6335.2041 - mean_absolute_error: 6335.2041\n",
      "Epoch 2345: val_loss did not improve from 13398.51562\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9456.0723 - mean_absolute_error: 9456.0723 - val_loss: 13401.3789 - val_mean_absolute_error: 13401.3789\n",
      "Epoch 2346/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7265.9580 - mean_absolute_error: 7265.9580\n",
      "Epoch 2346: val_loss did not improve from 13398.51562\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9446.7227 - mean_absolute_error: 9446.7227 - val_loss: 13398.8789 - val_mean_absolute_error: 13398.8789\n",
      "Epoch 2347/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12299.6250 - mean_absolute_error: 12299.6250\n",
      "Epoch 2347: val_loss did not improve from 13398.51562\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9443.6201 - mean_absolute_error: 9443.6201 - val_loss: 13399.3906 - val_mean_absolute_error: 13399.3906\n",
      "Epoch 2348/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10475.3105 - mean_absolute_error: 10475.3105\n",
      "Epoch 2348: val_loss did not improve from 13398.51562\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9449.8818 - mean_absolute_error: 9449.8818 - val_loss: 13412.4180 - val_mean_absolute_error: 13412.4180\n",
      "Epoch 2349/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9923.8965 - mean_absolute_error: 9923.8965\n",
      "Epoch 2349: val_loss improved from 13398.51562 to 13397.70117, saving model to Weights-02349--13397.70117.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9446.5723 - mean_absolute_error: 9446.5723 - val_loss: 13397.7012 - val_mean_absolute_error: 13397.7012\n",
      "Epoch 2350/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9634.2383 - mean_absolute_error: 9634.2383\n",
      "Epoch 2350: val_loss did not improve from 13397.70117\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9450.7490 - mean_absolute_error: 9450.7490 - val_loss: 13409.2998 - val_mean_absolute_error: 13409.2998\n",
      "Epoch 2351/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9089.5576 - mean_absolute_error: 9089.5576\n",
      "Epoch 2351: val_loss did not improve from 13397.70117\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9443.9326 - mean_absolute_error: 9443.9326 - val_loss: 13404.1836 - val_mean_absolute_error: 13404.1836\n",
      "Epoch 2352/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4884.4370 - mean_absolute_error: 4884.4370\n",
      "Epoch 2352: val_loss did not improve from 13397.70117\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9444.2598 - mean_absolute_error: 9444.2598 - val_loss: 13406.0586 - val_mean_absolute_error: 13406.0586\n",
      "Epoch 2353/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9419.6934 - mean_absolute_error: 9419.6934\n",
      "Epoch 2353: val_loss did not improve from 13397.70117\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9442.2812 - mean_absolute_error: 9442.2812 - val_loss: 13404.3203 - val_mean_absolute_error: 13404.3203\n",
      "Epoch 2354/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9416.4600 - mean_absolute_error: 9416.4600\n",
      "Epoch 2354: val_loss did not improve from 13397.70117\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9445.0049 - mean_absolute_error: 9445.0049 - val_loss: 13407.2969 - val_mean_absolute_error: 13407.2969\n",
      "Epoch 2355/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11178.8057 - mean_absolute_error: 11178.8057\n",
      "Epoch 2355: val_loss did not improve from 13397.70117\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9443.3486 - mean_absolute_error: 9443.3486 - val_loss: 13403.3193 - val_mean_absolute_error: 13403.3193\n",
      "Epoch 2356/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8066.1172 - mean_absolute_error: 8066.1172\n",
      "Epoch 2356: val_loss did not improve from 13397.70117\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9447.3867 - mean_absolute_error: 9447.3867 - val_loss: 13409.1719 - val_mean_absolute_error: 13409.1719\n",
      "Epoch 2357/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9170.2051 - mean_absolute_error: 9170.2051\n",
      "Epoch 2357: val_loss did not improve from 13397.70117\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9442.1465 - mean_absolute_error: 9442.1465 - val_loss: 13410.3350 - val_mean_absolute_error: 13410.3350\n",
      "Epoch 2358/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13001.8057 - mean_absolute_error: 13001.8057\n",
      "Epoch 2358: val_loss improved from 13397.70117 to 13397.49512, saving model to Weights-02358--13397.49512.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9444.3203 - mean_absolute_error: 9444.3203 - val_loss: 13397.4951 - val_mean_absolute_error: 13397.4951\n",
      "Epoch 2359/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5300.4932 - mean_absolute_error: 5300.4932\n",
      "Epoch 2359: val_loss did not improve from 13397.49512\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9444.0566 - mean_absolute_error: 9444.0566 - val_loss: 13401.7715 - val_mean_absolute_error: 13401.7715\n",
      "Epoch 2360/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8869.7266 - mean_absolute_error: 8869.7266\n",
      "Epoch 2360: val_loss did not improve from 13397.49512\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9442.5049 - mean_absolute_error: 9442.5049 - val_loss: 13406.6719 - val_mean_absolute_error: 13406.6719\n",
      "Epoch 2361/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10096.3369 - mean_absolute_error: 10096.3369\n",
      "Epoch 2361: val_loss did not improve from 13397.49512\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9441.4082 - mean_absolute_error: 9441.4082 - val_loss: 13403.9453 - val_mean_absolute_error: 13403.9453\n",
      "Epoch 2362/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11511.8711 - mean_absolute_error: 11511.8711\n",
      "Epoch 2362: val_loss did not improve from 13397.49512\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9444.1348 - mean_absolute_error: 9444.1348 - val_loss: 13406.6719 - val_mean_absolute_error: 13406.6719\n",
      "Epoch 2363/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11784.6289 - mean_absolute_error: 11784.6289\n",
      "Epoch 2363: val_loss did not improve from 13397.49512\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9444.2266 - mean_absolute_error: 9444.2266 - val_loss: 13403.4180 - val_mean_absolute_error: 13403.4180\n",
      "Epoch 2364/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5032.0850 - mean_absolute_error: 5032.0850\n",
      "Epoch 2364: val_loss did not improve from 13397.49512\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9441.7969 - mean_absolute_error: 9441.7969 - val_loss: 13407.9805 - val_mean_absolute_error: 13407.9805\n",
      "Epoch 2365/3000\n",
      "18/18 [==============================] - ETA: 0s - loss: 9441.8711 - mean_absolute_error: 9441.8711\n",
      "Epoch 2365: val_loss did not improve from 13397.49512\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9441.8711 - mean_absolute_error: 9441.8711 - val_loss: 13410.3818 - val_mean_absolute_error: 13410.3818\n",
      "Epoch 2366/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9859.1230 - mean_absolute_error: 9859.1230\n",
      "Epoch 2366: val_loss did not improve from 13397.49512\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9442.5469 - mean_absolute_error: 9442.5469 - val_loss: 13406.2676 - val_mean_absolute_error: 13406.2676\n",
      "Epoch 2367/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7654.1968 - mean_absolute_error: 7654.1968\n",
      "Epoch 2367: val_loss did not improve from 13397.49512\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9440.4736 - mean_absolute_error: 9440.4736 - val_loss: 13405.8193 - val_mean_absolute_error: 13405.8193\n",
      "Epoch 2368/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9759.5625 - mean_absolute_error: 9759.5625\n",
      "Epoch 2368: val_loss did not improve from 13397.49512\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9452.8906 - mean_absolute_error: 9452.8906 - val_loss: 13421.5469 - val_mean_absolute_error: 13421.5469\n",
      "Epoch 2369/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10717.7676 - mean_absolute_error: 10717.7676\n",
      "Epoch 2369: val_loss did not improve from 13397.49512\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9438.3311 - mean_absolute_error: 9438.3311 - val_loss: 13402.1416 - val_mean_absolute_error: 13402.1416\n",
      "Epoch 2370/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8624.9668 - mean_absolute_error: 8624.9668\n",
      "Epoch 2370: val_loss improved from 13397.49512 to 13397.21582, saving model to Weights-02370--13397.21582.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9439.6211 - mean_absolute_error: 9439.6211 - val_loss: 13397.2158 - val_mean_absolute_error: 13397.2158\n",
      "Epoch 2371/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9333.4551 - mean_absolute_error: 9333.4551\n",
      "Epoch 2371: val_loss improved from 13397.21582 to 13395.65137, saving model to Weights-02371--13395.65137.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9455.8086 - mean_absolute_error: 9455.8086 - val_loss: 13395.6514 - val_mean_absolute_error: 13395.6514\n",
      "Epoch 2372/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7998.9790 - mean_absolute_error: 7998.9790\n",
      "Epoch 2372: val_loss did not improve from 13395.65137\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9443.5264 - mean_absolute_error: 9443.5264 - val_loss: 13415.0146 - val_mean_absolute_error: 13415.0146\n",
      "Epoch 2373/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12405.9980 - mean_absolute_error: 12405.9980\n",
      "Epoch 2373: val_loss did not improve from 13395.65137\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9442.0762 - mean_absolute_error: 9442.0762 - val_loss: 13404.8984 - val_mean_absolute_error: 13404.8984\n",
      "Epoch 2374/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12855.6592 - mean_absolute_error: 12855.6592\n",
      "Epoch 2374: val_loss did not improve from 13395.65137\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9444.2324 - mean_absolute_error: 9444.2324 - val_loss: 13403.7480 - val_mean_absolute_error: 13403.7480\n",
      "Epoch 2375/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7038.9624 - mean_absolute_error: 7038.9624\n",
      "Epoch 2375: val_loss did not improve from 13395.65137\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9442.2715 - mean_absolute_error: 9442.2715 - val_loss: 13404.5127 - val_mean_absolute_error: 13404.5127\n",
      "Epoch 2376/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7483.1133 - mean_absolute_error: 7483.1133\n",
      "Epoch 2376: val_loss did not improve from 13395.65137\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9442.1924 - mean_absolute_error: 9442.1924 - val_loss: 13414.4863 - val_mean_absolute_error: 13414.4863\n",
      "Epoch 2377/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8656.4756 - mean_absolute_error: 8656.4756\n",
      "Epoch 2377: val_loss did not improve from 13395.65137\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9442.9502 - mean_absolute_error: 9442.9502 - val_loss: 13411.7393 - val_mean_absolute_error: 13411.7393\n",
      "Epoch 2378/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9720.8379 - mean_absolute_error: 9720.8379\n",
      "Epoch 2378: val_loss improved from 13395.65137 to 13395.27539, saving model to Weights-02378--13395.27539.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9443.4053 - mean_absolute_error: 9443.4053 - val_loss: 13395.2754 - val_mean_absolute_error: 13395.2754\n",
      "Epoch 2379/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7121.3242 - mean_absolute_error: 7121.3242\n",
      "Epoch 2379: val_loss did not improve from 13395.27539\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9439.4746 - mean_absolute_error: 9439.4746 - val_loss: 13399.3213 - val_mean_absolute_error: 13399.3213\n",
      "Epoch 2380/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9528.0205 - mean_absolute_error: 9528.0205\n",
      "Epoch 2380: val_loss did not improve from 13395.27539\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9440.6943 - mean_absolute_error: 9440.6943 - val_loss: 13402.3857 - val_mean_absolute_error: 13402.3867\n",
      "Epoch 2381/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6239.9141 - mean_absolute_error: 6239.9141\n",
      "Epoch 2381: val_loss did not improve from 13395.27539\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9444.4785 - mean_absolute_error: 9444.4785 - val_loss: 13395.8213 - val_mean_absolute_error: 13395.8213\n",
      "Epoch 2382/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9579.9961 - mean_absolute_error: 9579.9961\n",
      "Epoch 2382: val_loss did not improve from 13395.27539\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9458.8799 - mean_absolute_error: 9458.8799 - val_loss: 13416.7061 - val_mean_absolute_error: 13416.7061\n",
      "Epoch 2383/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11101.4229 - mean_absolute_error: 11101.4229\n",
      "Epoch 2383: val_loss improved from 13395.27539 to 13394.81445, saving model to Weights-02383--13394.81445.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9455.0850 - mean_absolute_error: 9455.0850 - val_loss: 13394.8145 - val_mean_absolute_error: 13394.8145\n",
      "Epoch 2384/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8511.3262 - mean_absolute_error: 8511.3262\n",
      "Epoch 2384: val_loss did not improve from 13394.81445\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9442.4014 - mean_absolute_error: 9442.4014 - val_loss: 13411.7656 - val_mean_absolute_error: 13411.7656\n",
      "Epoch 2385/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11075.2861 - mean_absolute_error: 11075.2861\n",
      "Epoch 2385: val_loss did not improve from 13394.81445\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9445.4785 - mean_absolute_error: 9445.4785 - val_loss: 13401.0713 - val_mean_absolute_error: 13401.0713\n",
      "Epoch 2386/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9534.9785 - mean_absolute_error: 9534.9785\n",
      "Epoch 2386: val_loss did not improve from 13394.81445\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9442.4199 - mean_absolute_error: 9442.4199 - val_loss: 13402.3281 - val_mean_absolute_error: 13402.3281\n",
      "Epoch 2387/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8591.2354 - mean_absolute_error: 8591.2354\n",
      "Epoch 2387: val_loss improved from 13394.81445 to 13394.15625, saving model to Weights-02387--13394.15625.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9443.3760 - mean_absolute_error: 9443.3760 - val_loss: 13394.1562 - val_mean_absolute_error: 13394.1562\n",
      "Epoch 2388/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11532.4785 - mean_absolute_error: 11532.4785\n",
      "Epoch 2388: val_loss did not improve from 13394.15625\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9457.4385 - mean_absolute_error: 9457.4385 - val_loss: 13415.3164 - val_mean_absolute_error: 13415.3164\n",
      "Epoch 2389/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8773.0869 - mean_absolute_error: 8773.0869\n",
      "Epoch 2389: val_loss did not improve from 13394.15625\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9440.5469 - mean_absolute_error: 9440.5469 - val_loss: 13400.1279 - val_mean_absolute_error: 13400.1279\n",
      "Epoch 2390/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8188.2510 - mean_absolute_error: 8188.2510\n",
      "Epoch 2390: val_loss did not improve from 13394.15625\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9442.7324 - mean_absolute_error: 9442.7324 - val_loss: 13394.5215 - val_mean_absolute_error: 13394.5215\n",
      "Epoch 2391/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9727.7168 - mean_absolute_error: 9727.7168\n",
      "Epoch 2391: val_loss did not improve from 13394.15625\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9438.0781 - mean_absolute_error: 9438.0781 - val_loss: 13413.4863 - val_mean_absolute_error: 13413.4863\n",
      "Epoch 2392/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6025.0557 - mean_absolute_error: 6025.0557\n",
      "Epoch 2392: val_loss did not improve from 13394.15625\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9439.2910 - mean_absolute_error: 9439.2910 - val_loss: 13402.0361 - val_mean_absolute_error: 13402.0361\n",
      "Epoch 2393/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9404.1680 - mean_absolute_error: 9404.1680\n",
      "Epoch 2393: val_loss did not improve from 13394.15625\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9439.6494 - mean_absolute_error: 9439.6494 - val_loss: 13394.4785 - val_mean_absolute_error: 13394.4785\n",
      "Epoch 2394/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8564.9316 - mean_absolute_error: 8564.9316\n",
      "Epoch 2394: val_loss did not improve from 13394.15625\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9439.1475 - mean_absolute_error: 9439.1475 - val_loss: 13396.7080 - val_mean_absolute_error: 13396.7080\n",
      "Epoch 2395/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9001.4785 - mean_absolute_error: 9001.4785\n",
      "Epoch 2395: val_loss improved from 13394.15625 to 13393.41992, saving model to Weights-02395--13393.41992.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9439.1699 - mean_absolute_error: 9439.1699 - val_loss: 13393.4199 - val_mean_absolute_error: 13393.4199\n",
      "Epoch 2396/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9169.8457 - mean_absolute_error: 9169.8457\n",
      "Epoch 2396: val_loss did not improve from 13393.41992\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9447.0664 - mean_absolute_error: 9447.0664 - val_loss: 13401.9131 - val_mean_absolute_error: 13401.9131\n",
      "Epoch 2397/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11105.0020 - mean_absolute_error: 11105.0020\n",
      "Epoch 2397: val_loss did not improve from 13393.41992\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9439.8691 - mean_absolute_error: 9439.8691 - val_loss: 13394.0059 - val_mean_absolute_error: 13394.0059\n",
      "Epoch 2398/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9010.3945 - mean_absolute_error: 9010.3945\n",
      "Epoch 2398: val_loss did not improve from 13393.41992\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9444.5986 - mean_absolute_error: 9444.5986 - val_loss: 13396.1875 - val_mean_absolute_error: 13396.1875\n",
      "Epoch 2399/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8035.9121 - mean_absolute_error: 8035.9121\n",
      "Epoch 2399: val_loss did not improve from 13393.41992\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9438.0811 - mean_absolute_error: 9438.0811 - val_loss: 13406.4404 - val_mean_absolute_error: 13406.4404\n",
      "Epoch 2400/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8854.3203 - mean_absolute_error: 8854.3203\n",
      "Epoch 2400: val_loss did not improve from 13393.41992\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9448.4297 - mean_absolute_error: 9448.4297 - val_loss: 13404.6582 - val_mean_absolute_error: 13404.6582\n",
      "Epoch 2401/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10975.0625 - mean_absolute_error: 10975.0625\n",
      "Epoch 2401: val_loss improved from 13393.41992 to 13393.09277, saving model to Weights-02401--13393.09277.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9447.6318 - mean_absolute_error: 9447.6318 - val_loss: 13393.0928 - val_mean_absolute_error: 13393.0928\n",
      "Epoch 2402/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10991.0488 - mean_absolute_error: 10991.0488\n",
      "Epoch 2402: val_loss did not improve from 13393.09277\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9454.4111 - mean_absolute_error: 9454.4111 - val_loss: 13420.3105 - val_mean_absolute_error: 13420.3105\n",
      "Epoch 2403/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8903.4707 - mean_absolute_error: 8903.4707\n",
      "Epoch 2403: val_loss did not improve from 13393.09277\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9437.9775 - mean_absolute_error: 9437.9775 - val_loss: 13400.5938 - val_mean_absolute_error: 13400.5938\n",
      "Epoch 2404/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11583.4316 - mean_absolute_error: 11583.4316\n",
      "Epoch 2404: val_loss did not improve from 13393.09277\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9454.9492 - mean_absolute_error: 9454.9492 - val_loss: 13393.5186 - val_mean_absolute_error: 13393.5186\n",
      "Epoch 2405/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8190.1089 - mean_absolute_error: 8190.1089\n",
      "Epoch 2405: val_loss did not improve from 13393.09277\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9437.4961 - mean_absolute_error: 9437.4961 - val_loss: 13399.4189 - val_mean_absolute_error: 13399.4189\n",
      "Epoch 2406/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8491.6816 - mean_absolute_error: 8491.6816\n",
      "Epoch 2406: val_loss did not improve from 13393.09277\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9445.9668 - mean_absolute_error: 9445.9668 - val_loss: 13402.5977 - val_mean_absolute_error: 13402.5977\n",
      "Epoch 2407/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10817.0078 - mean_absolute_error: 10817.0078\n",
      "Epoch 2407: val_loss did not improve from 13393.09277\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9447.1289 - mean_absolute_error: 9447.1289 - val_loss: 13407.4375 - val_mean_absolute_error: 13407.4375\n",
      "Epoch 2408/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11423.5449 - mean_absolute_error: 11423.5449\n",
      "Epoch 2408: val_loss did not improve from 13393.09277\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9446.3623 - mean_absolute_error: 9446.3623 - val_loss: 13397.3516 - val_mean_absolute_error: 13397.3516\n",
      "Epoch 2409/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7424.3521 - mean_absolute_error: 7424.3521\n",
      "Epoch 2409: val_loss did not improve from 13393.09277\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9440.2881 - mean_absolute_error: 9440.2881 - val_loss: 13395.7676 - val_mean_absolute_error: 13395.7676\n",
      "Epoch 2410/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9510.0859 - mean_absolute_error: 9510.0859\n",
      "Epoch 2410: val_loss did not improve from 13393.09277\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9439.5576 - mean_absolute_error: 9439.5576 - val_loss: 13402.8848 - val_mean_absolute_error: 13402.8848\n",
      "Epoch 2411/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13465.7734 - mean_absolute_error: 13465.7734\n",
      "Epoch 2411: val_loss improved from 13393.09277 to 13392.57422, saving model to Weights-02411--13392.57422.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9445.6602 - mean_absolute_error: 9445.6602 - val_loss: 13392.5742 - val_mean_absolute_error: 13392.5742\n",
      "Epoch 2412/3000\n",
      "10/18 [===============>..............] - ETA: 0s - loss: 9142.4053 - mean_absolute_error: 9142.4053\n",
      "Epoch 2412: val_loss did not improve from 13392.57422\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9438.9395 - mean_absolute_error: 9438.9395 - val_loss: 13403.9775 - val_mean_absolute_error: 13403.9775\n",
      "Epoch 2413/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8880.0801 - mean_absolute_error: 8880.0801\n",
      "Epoch 2413: val_loss improved from 13392.57422 to 13391.76855, saving model to Weights-02413--13391.76855.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9436.7793 - mean_absolute_error: 9436.7793 - val_loss: 13391.7686 - val_mean_absolute_error: 13391.7686\n",
      "Epoch 2414/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6405.7466 - mean_absolute_error: 6405.7466\n",
      "Epoch 2414: val_loss did not improve from 13391.76855\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9444.4072 - mean_absolute_error: 9444.4072 - val_loss: 13400.5732 - val_mean_absolute_error: 13400.5732\n",
      "Epoch 2415/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10664.1094 - mean_absolute_error: 10664.1094\n",
      "Epoch 2415: val_loss did not improve from 13391.76855\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9439.6670 - mean_absolute_error: 9439.6670 - val_loss: 13405.2197 - val_mean_absolute_error: 13405.2197\n",
      "Epoch 2416/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9614.5605 - mean_absolute_error: 9614.5605\n",
      "Epoch 2416: val_loss did not improve from 13391.76855\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9437.3857 - mean_absolute_error: 9437.3857 - val_loss: 13398.6787 - val_mean_absolute_error: 13398.6787\n",
      "Epoch 2417/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9204.1602 - mean_absolute_error: 9204.1602\n",
      "Epoch 2417: val_loss did not improve from 13391.76855\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9439.6953 - mean_absolute_error: 9439.6953 - val_loss: 13395.1992 - val_mean_absolute_error: 13395.1992\n",
      "Epoch 2418/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9516.3506 - mean_absolute_error: 9516.3506\n",
      "Epoch 2418: val_loss improved from 13391.76855 to 13390.88770, saving model to Weights-02418--13390.88770.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9438.8389 - mean_absolute_error: 9438.8389 - val_loss: 13390.8877 - val_mean_absolute_error: 13390.8877\n",
      "Epoch 2419/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7104.5527 - mean_absolute_error: 7104.5527\n",
      "Epoch 2419: val_loss did not improve from 13390.88770\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9443.6084 - mean_absolute_error: 9443.6084 - val_loss: 13404.3857 - val_mean_absolute_error: 13404.3857\n",
      "Epoch 2420/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9815.4580 - mean_absolute_error: 9815.4580\n",
      "Epoch 2420: val_loss did not improve from 13390.88770\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9446.5957 - mean_absolute_error: 9446.5957 - val_loss: 13394.1797 - val_mean_absolute_error: 13394.1797\n",
      "Epoch 2421/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8451.2119 - mean_absolute_error: 8451.2119\n",
      "Epoch 2421: val_loss did not improve from 13390.88770\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9441.5898 - mean_absolute_error: 9441.5898 - val_loss: 13404.4863 - val_mean_absolute_error: 13404.4863\n",
      "Epoch 2422/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9080.2227 - mean_absolute_error: 9080.2227\n",
      "Epoch 2422: val_loss did not improve from 13390.88770\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9449.4561 - mean_absolute_error: 9449.4561 - val_loss: 13398.8496 - val_mean_absolute_error: 13398.8496\n",
      "Epoch 2423/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9706.3242 - mean_absolute_error: 9706.3242\n",
      "Epoch 2423: val_loss did not improve from 13390.88770\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9442.0088 - mean_absolute_error: 9442.0088 - val_loss: 13405.9062 - val_mean_absolute_error: 13405.9062\n",
      "Epoch 2424/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10161.0234 - mean_absolute_error: 10161.0234\n",
      "Epoch 2424: val_loss did not improve from 13390.88770\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9444.5518 - mean_absolute_error: 9444.5518 - val_loss: 13398.0039 - val_mean_absolute_error: 13398.0039\n",
      "Epoch 2425/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12436.7051 - mean_absolute_error: 12436.7051\n",
      "Epoch 2425: val_loss did not improve from 13390.88770\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9457.6357 - mean_absolute_error: 9457.6357 - val_loss: 13396.7422 - val_mean_absolute_error: 13396.7422\n",
      "Epoch 2426/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11053.3643 - mean_absolute_error: 11053.3643\n",
      "Epoch 2426: val_loss improved from 13390.88770 to 13390.34180, saving model to Weights-02426--13390.34180.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9435.8564 - mean_absolute_error: 9435.8564 - val_loss: 13390.3418 - val_mean_absolute_error: 13390.3418\n",
      "Epoch 2427/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10317.0693 - mean_absolute_error: 10317.0693\n",
      "Epoch 2427: val_loss improved from 13390.34180 to 13390.27148, saving model to Weights-02427--13390.27148.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9440.3838 - mean_absolute_error: 9440.3838 - val_loss: 13390.2715 - val_mean_absolute_error: 13390.2715\n",
      "Epoch 2428/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9010.8535 - mean_absolute_error: 9010.8535\n",
      "Epoch 2428: val_loss did not improve from 13390.27148\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9445.0859 - mean_absolute_error: 9445.0859 - val_loss: 13408.2910 - val_mean_absolute_error: 13408.2910\n",
      "Epoch 2429/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8984.1953 - mean_absolute_error: 8984.1953\n",
      "Epoch 2429: val_loss did not improve from 13390.27148\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9458.6182 - mean_absolute_error: 9458.6182 - val_loss: 13390.4336 - val_mean_absolute_error: 13390.4336\n",
      "Epoch 2430/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6498.5771 - mean_absolute_error: 6498.5771\n",
      "Epoch 2430: val_loss did not improve from 13390.27148\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9436.5049 - mean_absolute_error: 9436.5049 - val_loss: 13408.4443 - val_mean_absolute_error: 13408.4443\n",
      "Epoch 2431/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10942.6494 - mean_absolute_error: 10942.6494\n",
      "Epoch 2431: val_loss did not improve from 13390.27148\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9440.1289 - mean_absolute_error: 9440.1289 - val_loss: 13403.5000 - val_mean_absolute_error: 13403.5000\n",
      "Epoch 2432/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9274.7627 - mean_absolute_error: 9274.7627\n",
      "Epoch 2432: val_loss did not improve from 13390.27148\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9438.5225 - mean_absolute_error: 9438.5225 - val_loss: 13398.0156 - val_mean_absolute_error: 13398.0156\n",
      "Epoch 2433/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7259.1230 - mean_absolute_error: 7259.1230\n",
      "Epoch 2433: val_loss did not improve from 13390.27148\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9443.7529 - mean_absolute_error: 9443.7529 - val_loss: 13401.8301 - val_mean_absolute_error: 13401.8311\n",
      "Epoch 2434/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8823.8145 - mean_absolute_error: 8823.8145\n",
      "Epoch 2434: val_loss did not improve from 13390.27148\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9437.6084 - mean_absolute_error: 9437.6084 - val_loss: 13392.2188 - val_mean_absolute_error: 13392.2188\n",
      "Epoch 2435/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6083.3384 - mean_absolute_error: 6083.3384\n",
      "Epoch 2435: val_loss did not improve from 13390.27148\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9441.1904 - mean_absolute_error: 9441.1904 - val_loss: 13399.5234 - val_mean_absolute_error: 13399.5234\n",
      "Epoch 2436/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10177.9199 - mean_absolute_error: 10177.9199\n",
      "Epoch 2436: val_loss did not improve from 13390.27148\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9438.1650 - mean_absolute_error: 9438.1650 - val_loss: 13396.2188 - val_mean_absolute_error: 13396.2188\n",
      "Epoch 2437/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9155.0195 - mean_absolute_error: 9155.0195\n",
      "Epoch 2437: val_loss improved from 13390.27148 to 13390.06934, saving model to Weights-02437--13390.06934.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9440.1299 - mean_absolute_error: 9440.1299 - val_loss: 13390.0693 - val_mean_absolute_error: 13390.0693\n",
      "Epoch 2438/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10857.4717 - mean_absolute_error: 10857.4717\n",
      "Epoch 2438: val_loss did not improve from 13390.06934\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9444.4316 - mean_absolute_error: 9444.4316 - val_loss: 13396.0410 - val_mean_absolute_error: 13396.0410\n",
      "Epoch 2439/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7713.5835 - mean_absolute_error: 7713.5835\n",
      "Epoch 2439: val_loss did not improve from 13390.06934\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9435.4502 - mean_absolute_error: 9435.4502 - val_loss: 13391.7197 - val_mean_absolute_error: 13391.7197\n",
      "Epoch 2440/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8142.2305 - mean_absolute_error: 8142.2305\n",
      "Epoch 2440: val_loss improved from 13390.06934 to 13389.01465, saving model to Weights-02440--13389.01465.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9446.5654 - mean_absolute_error: 9446.5654 - val_loss: 13389.0146 - val_mean_absolute_error: 13389.0146\n",
      "Epoch 2441/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9111.5488 - mean_absolute_error: 9111.5488\n",
      "Epoch 2441: val_loss did not improve from 13389.01465\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9449.4912 - mean_absolute_error: 9449.4912 - val_loss: 13407.4434 - val_mean_absolute_error: 13407.4434\n",
      "Epoch 2442/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9267.4180 - mean_absolute_error: 9267.4180\n",
      "Epoch 2442: val_loss improved from 13389.01465 to 13388.78418, saving model to Weights-02442--13388.78418.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9436.5293 - mean_absolute_error: 9436.5293 - val_loss: 13388.7842 - val_mean_absolute_error: 13388.7842\n",
      "Epoch 2443/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8604.3008 - mean_absolute_error: 8604.3008\n",
      "Epoch 2443: val_loss did not improve from 13388.78418\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9437.2471 - mean_absolute_error: 9437.2471 - val_loss: 13390.9678 - val_mean_absolute_error: 13390.9678\n",
      "Epoch 2444/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11037.5635 - mean_absolute_error: 11037.5635\n",
      "Epoch 2444: val_loss did not improve from 13388.78418\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9444.6514 - mean_absolute_error: 9444.6514 - val_loss: 13408.7842 - val_mean_absolute_error: 13408.7842\n",
      "Epoch 2445/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10679.9463 - mean_absolute_error: 10679.9463\n",
      "Epoch 2445: val_loss did not improve from 13388.78418\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9439.4570 - mean_absolute_error: 9439.4570 - val_loss: 13390.3730 - val_mean_absolute_error: 13390.3730\n",
      "Epoch 2446/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6657.7388 - mean_absolute_error: 6657.7388\n",
      "Epoch 2446: val_loss did not improve from 13388.78418\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9432.1836 - mean_absolute_error: 9432.1836 - val_loss: 13401.7812 - val_mean_absolute_error: 13401.7812\n",
      "Epoch 2447/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8065.0703 - mean_absolute_error: 8065.0703\n",
      "Epoch 2447: val_loss did not improve from 13388.78418\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9439.1914 - mean_absolute_error: 9439.1914 - val_loss: 13400.0361 - val_mean_absolute_error: 13400.0361\n",
      "Epoch 2448/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9462.7744 - mean_absolute_error: 9462.7744\n",
      "Epoch 2448: val_loss did not improve from 13388.78418\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9453.7256 - mean_absolute_error: 9453.7256 - val_loss: 13390.9395 - val_mean_absolute_error: 13390.9395\n",
      "Epoch 2449/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9439.1230 - mean_absolute_error: 9439.1230\n",
      "Epoch 2449: val_loss did not improve from 13388.78418\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9437.5088 - mean_absolute_error: 9437.5088 - val_loss: 13401.6074 - val_mean_absolute_error: 13401.6074\n",
      "Epoch 2450/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11227.6445 - mean_absolute_error: 11227.6445\n",
      "Epoch 2450: val_loss did not improve from 13388.78418\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9438.3350 - mean_absolute_error: 9438.3350 - val_loss: 13398.6016 - val_mean_absolute_error: 13398.6016\n",
      "Epoch 2451/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8292.3828 - mean_absolute_error: 8292.3828\n",
      "Epoch 2451: val_loss did not improve from 13388.78418\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9434.4551 - mean_absolute_error: 9434.4551 - val_loss: 13394.6504 - val_mean_absolute_error: 13394.6504\n",
      "Epoch 2452/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7350.2856 - mean_absolute_error: 7350.2856\n",
      "Epoch 2452: val_loss did not improve from 13388.78418\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9433.9961 - mean_absolute_error: 9433.9961 - val_loss: 13399.4971 - val_mean_absolute_error: 13399.4971\n",
      "Epoch 2453/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7937.1704 - mean_absolute_error: 7937.1704\n",
      "Epoch 2453: val_loss did not improve from 13388.78418\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9437.3955 - mean_absolute_error: 9437.3955 - val_loss: 13396.0732 - val_mean_absolute_error: 13396.0732\n",
      "Epoch 2454/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7813.6074 - mean_absolute_error: 7813.6074\n",
      "Epoch 2454: val_loss did not improve from 13388.78418\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9438.4697 - mean_absolute_error: 9438.4697 - val_loss: 13392.5049 - val_mean_absolute_error: 13392.5049\n",
      "Epoch 2455/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9474.3926 - mean_absolute_error: 9474.3926\n",
      "Epoch 2455: val_loss did not improve from 13388.78418\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9432.7939 - mean_absolute_error: 9432.7939 - val_loss: 13406.5518 - val_mean_absolute_error: 13406.5518\n",
      "Epoch 2456/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8011.5684 - mean_absolute_error: 8011.5684\n",
      "Epoch 2456: val_loss did not improve from 13388.78418\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9439.0605 - mean_absolute_error: 9439.0605 - val_loss: 13399.5479 - val_mean_absolute_error: 13399.5479\n",
      "Epoch 2457/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7682.6187 - mean_absolute_error: 7682.6187\n",
      "Epoch 2457: val_loss did not improve from 13388.78418\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9438.5244 - mean_absolute_error: 9438.5244 - val_loss: 13397.2412 - val_mean_absolute_error: 13397.2412\n",
      "Epoch 2458/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7652.4062 - mean_absolute_error: 7652.4062\n",
      "Epoch 2458: val_loss improved from 13388.78418 to 13387.63672, saving model to Weights-02458--13387.63672.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9433.2090 - mean_absolute_error: 9433.2090 - val_loss: 13387.6367 - val_mean_absolute_error: 13387.6367\n",
      "Epoch 2459/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13084.8340 - mean_absolute_error: 13084.8340\n",
      "Epoch 2459: val_loss did not improve from 13387.63672\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9477.9219 - mean_absolute_error: 9477.9219 - val_loss: 13387.8701 - val_mean_absolute_error: 13387.8701\n",
      "Epoch 2460/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7172.6216 - mean_absolute_error: 7172.6216\n",
      "Epoch 2460: val_loss did not improve from 13387.63672\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9434.1924 - mean_absolute_error: 9434.1924 - val_loss: 13406.1924 - val_mean_absolute_error: 13406.1924\n",
      "Epoch 2461/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9449.7158 - mean_absolute_error: 9449.7158\n",
      "Epoch 2461: val_loss did not improve from 13387.63672\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9440.2529 - mean_absolute_error: 9440.2529 - val_loss: 13395.5215 - val_mean_absolute_error: 13395.5215\n",
      "Epoch 2462/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12402.0273 - mean_absolute_error: 12402.0273\n",
      "Epoch 2462: val_loss did not improve from 13387.63672\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9437.2627 - mean_absolute_error: 9437.2627 - val_loss: 13400.6484 - val_mean_absolute_error: 13400.6484\n",
      "Epoch 2463/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8875.7432 - mean_absolute_error: 8875.7432\n",
      "Epoch 2463: val_loss did not improve from 13387.63672\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9440.1582 - mean_absolute_error: 9440.1582 - val_loss: 13394.4795 - val_mean_absolute_error: 13394.4795\n",
      "Epoch 2464/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10065.8223 - mean_absolute_error: 10065.8223\n",
      "Epoch 2464: val_loss did not improve from 13387.63672\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9436.8174 - mean_absolute_error: 9436.8174 - val_loss: 13391.6689 - val_mean_absolute_error: 13391.6689\n",
      "Epoch 2465/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8205.3848 - mean_absolute_error: 8205.3848\n",
      "Epoch 2465: val_loss did not improve from 13387.63672\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9434.5781 - mean_absolute_error: 9434.5781 - val_loss: 13395.1553 - val_mean_absolute_error: 13395.1553\n",
      "Epoch 2466/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9302.1836 - mean_absolute_error: 9302.1836\n",
      "Epoch 2466: val_loss did not improve from 13387.63672\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9436.6514 - mean_absolute_error: 9436.6514 - val_loss: 13391.1680 - val_mean_absolute_error: 13391.1680\n",
      "Epoch 2467/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7727.1602 - mean_absolute_error: 7727.1602\n",
      "Epoch 2467: val_loss did not improve from 13387.63672\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9438.0791 - mean_absolute_error: 9438.0791 - val_loss: 13393.5264 - val_mean_absolute_error: 13393.5264\n",
      "Epoch 2468/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10367.2500 - mean_absolute_error: 10367.2500\n",
      "Epoch 2468: val_loss did not improve from 13387.63672\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9435.6152 - mean_absolute_error: 9435.6152 - val_loss: 13402.4893 - val_mean_absolute_error: 13402.4893\n",
      "Epoch 2469/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8490.4668 - mean_absolute_error: 8490.4668\n",
      "Epoch 2469: val_loss did not improve from 13387.63672\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9443.1113 - mean_absolute_error: 9443.1113 - val_loss: 13390.1514 - val_mean_absolute_error: 13390.1514\n",
      "Epoch 2470/3000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9604.3018 - mean_absolute_error: 9604.3018\n",
      "Epoch 2470: val_loss did not improve from 13387.63672\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9433.8311 - mean_absolute_error: 9433.8311 - val_loss: 13390.3350 - val_mean_absolute_error: 13390.3350\n",
      "Epoch 2471/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12338.2129 - mean_absolute_error: 12338.2129\n",
      "Epoch 2471: val_loss did not improve from 13387.63672\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9433.2861 - mean_absolute_error: 9433.2861 - val_loss: 13394.4736 - val_mean_absolute_error: 13394.4736\n",
      "Epoch 2472/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6739.1191 - mean_absolute_error: 6739.1191\n",
      "Epoch 2472: val_loss did not improve from 13387.63672\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9438.4209 - mean_absolute_error: 9438.4209 - val_loss: 13404.7012 - val_mean_absolute_error: 13404.7012\n",
      "Epoch 2473/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8428.3691 - mean_absolute_error: 8428.3691\n",
      "Epoch 2473: val_loss did not improve from 13387.63672\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9429.5410 - mean_absolute_error: 9429.5410 - val_loss: 13389.1953 - val_mean_absolute_error: 13389.1953\n",
      "Epoch 2474/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10145.2959 - mean_absolute_error: 10145.2959\n",
      "Epoch 2474: val_loss did not improve from 13387.63672\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9439.7949 - mean_absolute_error: 9439.7949 - val_loss: 13391.6621 - val_mean_absolute_error: 13391.6621\n",
      "Epoch 2475/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12869.5234 - mean_absolute_error: 12869.5234\n",
      "Epoch 2475: val_loss did not improve from 13387.63672\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9437.5986 - mean_absolute_error: 9437.5986 - val_loss: 13387.7451 - val_mean_absolute_error: 13387.7451\n",
      "Epoch 2476/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8485.7959 - mean_absolute_error: 8485.7959\n",
      "Epoch 2476: val_loss did not improve from 13387.63672\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9457.1719 - mean_absolute_error: 9457.1719 - val_loss: 13403.8184 - val_mean_absolute_error: 13403.8184\n",
      "Epoch 2477/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5784.0400 - mean_absolute_error: 5784.0400\n",
      "Epoch 2477: val_loss did not improve from 13387.63672\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9445.2168 - mean_absolute_error: 9445.2168 - val_loss: 13396.6836 - val_mean_absolute_error: 13396.6846\n",
      "Epoch 2478/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5337.2642 - mean_absolute_error: 5337.2642\n",
      "Epoch 2478: val_loss improved from 13387.63672 to 13387.05176, saving model to Weights-02478--13387.05176.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9441.9795 - mean_absolute_error: 9441.9795 - val_loss: 13387.0518 - val_mean_absolute_error: 13387.0518\n",
      "Epoch 2479/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6236.4307 - mean_absolute_error: 6236.4307\n",
      "Epoch 2479: val_loss did not improve from 13387.05176\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9435.9912 - mean_absolute_error: 9435.9912 - val_loss: 13401.1064 - val_mean_absolute_error: 13401.1064\n",
      "Epoch 2480/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9462.5361 - mean_absolute_error: 9462.5361\n",
      "Epoch 2480: val_loss did not improve from 13387.05176\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9437.3975 - mean_absolute_error: 9437.3975 - val_loss: 13397.1924 - val_mean_absolute_error: 13397.1924\n",
      "Epoch 2481/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9146.2764 - mean_absolute_error: 9146.2764\n",
      "Epoch 2481: val_loss did not improve from 13387.05176\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9434.8105 - mean_absolute_error: 9434.8105 - val_loss: 13388.7734 - val_mean_absolute_error: 13388.7734\n",
      "Epoch 2482/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8069.5786 - mean_absolute_error: 8069.5786\n",
      "Epoch 2482: val_loss improved from 13387.05176 to 13385.17676, saving model to Weights-02482--13385.17676.hdf5\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 9432.8359 - mean_absolute_error: 9432.8359 - val_loss: 13385.1768 - val_mean_absolute_error: 13385.1768\n",
      "Epoch 2483/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10728.2949 - mean_absolute_error: 10728.2949\n",
      "Epoch 2483: val_loss did not improve from 13385.17676\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9437.5508 - mean_absolute_error: 9437.5508 - val_loss: 13396.8799 - val_mean_absolute_error: 13396.8799\n",
      "Epoch 2484/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9737.8252 - mean_absolute_error: 9737.8252\n",
      "Epoch 2484: val_loss did not improve from 13385.17676\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9433.4180 - mean_absolute_error: 9433.4180 - val_loss: 13387.4219 - val_mean_absolute_error: 13387.4219\n",
      "Epoch 2485/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9382.0098 - mean_absolute_error: 9382.0098\n",
      "Epoch 2485: val_loss did not improve from 13385.17676\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9430.2168 - mean_absolute_error: 9430.2168 - val_loss: 13391.5332 - val_mean_absolute_error: 13391.5332\n",
      "Epoch 2486/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9713.9492 - mean_absolute_error: 9713.9492\n",
      "Epoch 2486: val_loss did not improve from 13385.17676\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9441.6953 - mean_absolute_error: 9441.6953 - val_loss: 13403.8838 - val_mean_absolute_error: 13403.8838\n",
      "Epoch 2487/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11409.3750 - mean_absolute_error: 11409.3750\n",
      "Epoch 2487: val_loss did not improve from 13385.17676\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9435.7188 - mean_absolute_error: 9435.7188 - val_loss: 13393.2178 - val_mean_absolute_error: 13393.2178\n",
      "Epoch 2488/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9727.1797 - mean_absolute_error: 9727.1797\n",
      "Epoch 2488: val_loss did not improve from 13385.17676\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9434.0791 - mean_absolute_error: 9434.0791 - val_loss: 13389.8896 - val_mean_absolute_error: 13389.8896\n",
      "Epoch 2489/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9018.0156 - mean_absolute_error: 9018.0156\n",
      "Epoch 2489: val_loss did not improve from 13385.17676\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9431.7275 - mean_absolute_error: 9431.7275 - val_loss: 13388.8408 - val_mean_absolute_error: 13388.8408\n",
      "Epoch 2490/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8055.7456 - mean_absolute_error: 8055.7456\n",
      "Epoch 2490: val_loss did not improve from 13385.17676\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9443.3750 - mean_absolute_error: 9443.3750 - val_loss: 13395.2334 - val_mean_absolute_error: 13395.2334\n",
      "Epoch 2491/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8523.1279 - mean_absolute_error: 8523.1279\n",
      "Epoch 2491: val_loss improved from 13385.17676 to 13384.47363, saving model to Weights-02491--13384.47363.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9430.1719 - mean_absolute_error: 9430.1719 - val_loss: 13384.4736 - val_mean_absolute_error: 13384.4736\n",
      "Epoch 2492/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8759.3848 - mean_absolute_error: 8759.3848\n",
      "Epoch 2492: val_loss did not improve from 13384.47363\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9433.6904 - mean_absolute_error: 9433.6904 - val_loss: 13385.1328 - val_mean_absolute_error: 13385.1328\n",
      "Epoch 2493/3000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9318.2998 - mean_absolute_error: 9318.2998\n",
      "Epoch 2493: val_loss did not improve from 13384.47363\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9438.6104 - mean_absolute_error: 9438.6104 - val_loss: 13394.5137 - val_mean_absolute_error: 13394.5137\n",
      "Epoch 2494/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9784.1074 - mean_absolute_error: 9784.1074\n",
      "Epoch 2494: val_loss did not improve from 13384.47363\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9435.5264 - mean_absolute_error: 9435.5264 - val_loss: 13393.3789 - val_mean_absolute_error: 13393.3789\n",
      "Epoch 2495/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11517.9600 - mean_absolute_error: 11517.9600\n",
      "Epoch 2495: val_loss did not improve from 13384.47363\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9432.1816 - mean_absolute_error: 9432.1816 - val_loss: 13393.7109 - val_mean_absolute_error: 13393.7109\n",
      "Epoch 2496/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12102.0420 - mean_absolute_error: 12102.0420\n",
      "Epoch 2496: val_loss did not improve from 13384.47363\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9437.1875 - mean_absolute_error: 9437.1875 - val_loss: 13386.0713 - val_mean_absolute_error: 13386.0703\n",
      "Epoch 2497/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8974.9482 - mean_absolute_error: 8974.9482\n",
      "Epoch 2497: val_loss did not improve from 13384.47363\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9441.3896 - mean_absolute_error: 9441.3896 - val_loss: 13413.0049 - val_mean_absolute_error: 13413.0049\n",
      "Epoch 2498/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11242.4551 - mean_absolute_error: 11242.4551\n",
      "Epoch 2498: val_loss did not improve from 13384.47363\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9437.4639 - mean_absolute_error: 9437.4639 - val_loss: 13386.8838 - val_mean_absolute_error: 13386.8838\n",
      "Epoch 2499/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10530.3145 - mean_absolute_error: 10530.3145\n",
      "Epoch 2499: val_loss improved from 13384.47363 to 13384.26562, saving model to Weights-02499--13384.26562.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9434.7793 - mean_absolute_error: 9434.7793 - val_loss: 13384.2656 - val_mean_absolute_error: 13384.2656\n",
      "Epoch 2500/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10026.8965 - mean_absolute_error: 10026.8965\n",
      "Epoch 2500: val_loss did not improve from 13384.26562\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9429.9746 - mean_absolute_error: 9429.9746 - val_loss: 13407.6152 - val_mean_absolute_error: 13407.6152\n",
      "Epoch 2501/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7900.8311 - mean_absolute_error: 7900.8311\n",
      "Epoch 2501: val_loss did not improve from 13384.26562\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9436.0957 - mean_absolute_error: 9436.0957 - val_loss: 13406.0801 - val_mean_absolute_error: 13406.0801\n",
      "Epoch 2502/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8469.4893 - mean_absolute_error: 8469.4893\n",
      "Epoch 2502: val_loss did not improve from 13384.26562\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9438.1475 - mean_absolute_error: 9438.1475 - val_loss: 13386.1611 - val_mean_absolute_error: 13386.1602\n",
      "Epoch 2503/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8519.8203 - mean_absolute_error: 8519.8203\n",
      "Epoch 2503: val_loss did not improve from 13384.26562\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9432.7939 - mean_absolute_error: 9432.7939 - val_loss: 13389.5010 - val_mean_absolute_error: 13389.5010\n",
      "Epoch 2504/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10255.4688 - mean_absolute_error: 10255.4688\n",
      "Epoch 2504: val_loss did not improve from 13384.26562\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9434.4482 - mean_absolute_error: 9434.4482 - val_loss: 13388.8965 - val_mean_absolute_error: 13388.8965\n",
      "Epoch 2505/3000\n",
      "18/18 [==============================] - ETA: 0s - loss: 9434.8271 - mean_absolute_error: 9434.8271\n",
      "Epoch 2505: val_loss did not improve from 13384.26562\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9434.8271 - mean_absolute_error: 9434.8271 - val_loss: 13389.2568 - val_mean_absolute_error: 13389.2568\n",
      "Epoch 2506/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9349.0098 - mean_absolute_error: 9349.0098\n",
      "Epoch 2506: val_loss improved from 13384.26562 to 13383.21777, saving model to Weights-02506--13383.21777.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9436.3057 - mean_absolute_error: 9436.3057 - val_loss: 13383.2178 - val_mean_absolute_error: 13383.2178\n",
      "Epoch 2507/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8781.5000 - mean_absolute_error: 8781.5000\n",
      "Epoch 2507: val_loss did not improve from 13383.21777\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9435.0996 - mean_absolute_error: 9435.0996 - val_loss: 13387.7168 - val_mean_absolute_error: 13387.7168\n",
      "Epoch 2508/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7910.4131 - mean_absolute_error: 7910.4131\n",
      "Epoch 2508: val_loss did not improve from 13383.21777\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9430.5020 - mean_absolute_error: 9430.5020 - val_loss: 13396.3486 - val_mean_absolute_error: 13396.3486\n",
      "Epoch 2509/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7621.8252 - mean_absolute_error: 7621.8252\n",
      "Epoch 2509: val_loss did not improve from 13383.21777\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9446.3076 - mean_absolute_error: 9446.3076 - val_loss: 13410.1367 - val_mean_absolute_error: 13410.1367\n",
      "Epoch 2510/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8678.4717 - mean_absolute_error: 8678.4717\n",
      "Epoch 2510: val_loss did not improve from 13383.21777\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9432.6953 - mean_absolute_error: 9432.6953 - val_loss: 13389.1172 - val_mean_absolute_error: 13389.1172\n",
      "Epoch 2511/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8047.4902 - mean_absolute_error: 8047.4902\n",
      "Epoch 2511: val_loss did not improve from 13383.21777\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9434.3350 - mean_absolute_error: 9434.3350 - val_loss: 13385.6426 - val_mean_absolute_error: 13385.6426\n",
      "Epoch 2512/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8733.5879 - mean_absolute_error: 8733.5879\n",
      "Epoch 2512: val_loss did not improve from 13383.21777\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9432.5918 - mean_absolute_error: 9432.5918 - val_loss: 13391.0957 - val_mean_absolute_error: 13391.0957\n",
      "Epoch 2513/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13756.3291 - mean_absolute_error: 13756.3291\n",
      "Epoch 2513: val_loss improved from 13383.21777 to 13382.58984, saving model to Weights-02513--13382.58984.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9429.7910 - mean_absolute_error: 9429.7910 - val_loss: 13382.5898 - val_mean_absolute_error: 13382.5898\n",
      "Epoch 2514/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7095.8613 - mean_absolute_error: 7095.8613\n",
      "Epoch 2514: val_loss did not improve from 13382.58984\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9438.2969 - mean_absolute_error: 9438.2969 - val_loss: 13391.0020 - val_mean_absolute_error: 13391.0020\n",
      "Epoch 2515/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8307.0674 - mean_absolute_error: 8307.0674\n",
      "Epoch 2515: val_loss did not improve from 13382.58984\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9428.5234 - mean_absolute_error: 9428.5234 - val_loss: 13382.6846 - val_mean_absolute_error: 13382.6846\n",
      "Epoch 2516/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9794.5195 - mean_absolute_error: 9794.5195\n",
      "Epoch 2516: val_loss did not improve from 13382.58984\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9432.1875 - mean_absolute_error: 9432.1875 - val_loss: 13393.2344 - val_mean_absolute_error: 13393.2344\n",
      "Epoch 2517/3000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 9560.6709 - mean_absolute_error: 9560.6709\n",
      "Epoch 2517: val_loss did not improve from 13382.58984\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9435.1104 - mean_absolute_error: 9435.1104 - val_loss: 13386.4639 - val_mean_absolute_error: 13386.4639\n",
      "Epoch 2518/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12908.6367 - mean_absolute_error: 12908.6367\n",
      "Epoch 2518: val_loss did not improve from 13382.58984\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9441.9189 - mean_absolute_error: 9441.9189 - val_loss: 13384.2002 - val_mean_absolute_error: 13384.2002\n",
      "Epoch 2519/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11571.0547 - mean_absolute_error: 11571.0547\n",
      "Epoch 2519: val_loss did not improve from 13382.58984\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9430.7314 - mean_absolute_error: 9430.7314 - val_loss: 13399.1094 - val_mean_absolute_error: 13399.1094\n",
      "Epoch 2520/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12322.8193 - mean_absolute_error: 12322.8193\n",
      "Epoch 2520: val_loss did not improve from 13382.58984\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9437.0898 - mean_absolute_error: 9437.0898 - val_loss: 13392.6162 - val_mean_absolute_error: 13392.6162\n",
      "Epoch 2521/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8361.8242 - mean_absolute_error: 8361.8242\n",
      "Epoch 2521: val_loss did not improve from 13382.58984\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9432.0049 - mean_absolute_error: 9432.0049 - val_loss: 13393.9990 - val_mean_absolute_error: 13393.9990\n",
      "Epoch 2522/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9740.9023 - mean_absolute_error: 9740.9023\n",
      "Epoch 2522: val_loss did not improve from 13382.58984\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9428.8799 - mean_absolute_error: 9428.8799 - val_loss: 13388.2334 - val_mean_absolute_error: 13388.2334\n",
      "Epoch 2523/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11312.7676 - mean_absolute_error: 11312.7676\n",
      "Epoch 2523: val_loss did not improve from 13382.58984\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9433.2197 - mean_absolute_error: 9433.2197 - val_loss: 13385.6416 - val_mean_absolute_error: 13385.6416\n",
      "Epoch 2524/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10265.3184 - mean_absolute_error: 10265.3184\n",
      "Epoch 2524: val_loss did not improve from 13382.58984\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9442.7588 - mean_absolute_error: 9442.7588 - val_loss: 13385.0869 - val_mean_absolute_error: 13385.0869\n",
      "Epoch 2525/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11172.0947 - mean_absolute_error: 11172.0947\n",
      "Epoch 2525: val_loss did not improve from 13382.58984\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9440.3066 - mean_absolute_error: 9440.3066 - val_loss: 13412.7549 - val_mean_absolute_error: 13412.7549\n",
      "Epoch 2526/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11106.4941 - mean_absolute_error: 11106.4941\n",
      "Epoch 2526: val_loss did not improve from 13382.58984\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9429.0381 - mean_absolute_error: 9429.0381 - val_loss: 13391.0566 - val_mean_absolute_error: 13391.0566\n",
      "Epoch 2527/3000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9177.8418 - mean_absolute_error: 9177.8418\n",
      "Epoch 2527: val_loss did not improve from 13382.58984\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9441.0264 - mean_absolute_error: 9441.0264 - val_loss: 13382.9404 - val_mean_absolute_error: 13382.9404\n",
      "Epoch 2528/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9038.1250 - mean_absolute_error: 9038.1250\n",
      "Epoch 2528: val_loss did not improve from 13382.58984\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9442.1045 - mean_absolute_error: 9442.1045 - val_loss: 13394.4287 - val_mean_absolute_error: 13394.4287\n",
      "Epoch 2529/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6478.9141 - mean_absolute_error: 6478.9141\n",
      "Epoch 2529: val_loss did not improve from 13382.58984\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9429.9814 - mean_absolute_error: 9429.9814 - val_loss: 13387.7646 - val_mean_absolute_error: 13387.7646\n",
      "Epoch 2530/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10918.1777 - mean_absolute_error: 10918.1777\n",
      "Epoch 2530: val_loss improved from 13382.58984 to 13381.34863, saving model to Weights-02530--13381.34863.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9438.3604 - mean_absolute_error: 9438.3604 - val_loss: 13381.3486 - val_mean_absolute_error: 13381.3486\n",
      "Epoch 2531/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10627.0332 - mean_absolute_error: 10627.0332\n",
      "Epoch 2531: val_loss did not improve from 13381.34863\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9428.4033 - mean_absolute_error: 9428.4033 - val_loss: 13396.5107 - val_mean_absolute_error: 13396.5107\n",
      "Epoch 2532/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6132.6040 - mean_absolute_error: 6132.6040\n",
      "Epoch 2532: val_loss did not improve from 13381.34863\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9434.5869 - mean_absolute_error: 9434.5869 - val_loss: 13393.8047 - val_mean_absolute_error: 13393.8047\n",
      "Epoch 2533/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8002.7764 - mean_absolute_error: 8002.7764\n",
      "Epoch 2533: val_loss did not improve from 13381.34863\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9436.8018 - mean_absolute_error: 9436.8018 - val_loss: 13398.5791 - val_mean_absolute_error: 13398.5791\n",
      "Epoch 2534/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10660.7773 - mean_absolute_error: 10660.7773\n",
      "Epoch 2534: val_loss did not improve from 13381.34863\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9428.0361 - mean_absolute_error: 9428.0361 - val_loss: 13387.7266 - val_mean_absolute_error: 13387.7266\n",
      "Epoch 2535/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9560.4404 - mean_absolute_error: 9560.4404\n",
      "Epoch 2535: val_loss did not improve from 13381.34863\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9431.1133 - mean_absolute_error: 9431.1133 - val_loss: 13389.3164 - val_mean_absolute_error: 13389.3164\n",
      "Epoch 2536/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9823.4873 - mean_absolute_error: 9823.4873\n",
      "Epoch 2536: val_loss improved from 13381.34863 to 13380.84375, saving model to Weights-02536--13380.84375.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9430.3232 - mean_absolute_error: 9430.3232 - val_loss: 13380.8438 - val_mean_absolute_error: 13380.8438\n",
      "Epoch 2537/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11051.9570 - mean_absolute_error: 11051.9570\n",
      "Epoch 2537: val_loss did not improve from 13380.84375\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9429.2393 - mean_absolute_error: 9429.2393 - val_loss: 13385.8408 - val_mean_absolute_error: 13385.8408\n",
      "Epoch 2538/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11765.6992 - mean_absolute_error: 11765.6992\n",
      "Epoch 2538: val_loss did not improve from 13380.84375\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9436.3271 - mean_absolute_error: 9436.3271 - val_loss: 13391.1904 - val_mean_absolute_error: 13391.1904\n",
      "Epoch 2539/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9527.9141 - mean_absolute_error: 9527.9141\n",
      "Epoch 2539: val_loss improved from 13380.84375 to 13380.41211, saving model to Weights-02539--13380.41211.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9431.3350 - mean_absolute_error: 9431.3350 - val_loss: 13380.4121 - val_mean_absolute_error: 13380.4121\n",
      "Epoch 2540/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9700.8926 - mean_absolute_error: 9700.8926\n",
      "Epoch 2540: val_loss did not improve from 13380.41211\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9431.2490 - mean_absolute_error: 9431.2490 - val_loss: 13393.0762 - val_mean_absolute_error: 13393.0762\n",
      "Epoch 2541/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10713.7295 - mean_absolute_error: 10713.7295\n",
      "Epoch 2541: val_loss did not improve from 13380.41211\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9431.5986 - mean_absolute_error: 9431.5986 - val_loss: 13384.8574 - val_mean_absolute_error: 13384.8574\n",
      "Epoch 2542/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12011.1543 - mean_absolute_error: 12011.1543\n",
      "Epoch 2542: val_loss did not improve from 13380.41211\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9429.9326 - mean_absolute_error: 9429.9326 - val_loss: 13386.6748 - val_mean_absolute_error: 13386.6748\n",
      "Epoch 2543/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9139.2988 - mean_absolute_error: 9139.2988\n",
      "Epoch 2543: val_loss did not improve from 13380.41211\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9433.7891 - mean_absolute_error: 9433.7891 - val_loss: 13392.8828 - val_mean_absolute_error: 13392.8828\n",
      "Epoch 2544/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8256.3428 - mean_absolute_error: 8256.3428\n",
      "Epoch 2544: val_loss improved from 13380.41211 to 13379.96582, saving model to Weights-02544--13379.96582.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9430.6602 - mean_absolute_error: 9430.6602 - val_loss: 13379.9658 - val_mean_absolute_error: 13379.9658\n",
      "Epoch 2545/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11346.1035 - mean_absolute_error: 11346.1035\n",
      "Epoch 2545: val_loss did not improve from 13379.96582\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9432.1660 - mean_absolute_error: 9432.1660 - val_loss: 13385.9121 - val_mean_absolute_error: 13385.9121\n",
      "Epoch 2546/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8091.2910 - mean_absolute_error: 8091.2910\n",
      "Epoch 2546: val_loss did not improve from 13379.96582\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9432.7871 - mean_absolute_error: 9432.7871 - val_loss: 13389.6133 - val_mean_absolute_error: 13389.6133\n",
      "Epoch 2547/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10329.0645 - mean_absolute_error: 10329.0645\n",
      "Epoch 2547: val_loss did not improve from 13379.96582\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9432.7656 - mean_absolute_error: 9432.7656 - val_loss: 13379.9873 - val_mean_absolute_error: 13379.9873\n",
      "Epoch 2548/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9234.3770 - mean_absolute_error: 9234.3770\n",
      "Epoch 2548: val_loss did not improve from 13379.96582\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9456.4941 - mean_absolute_error: 9456.4941 - val_loss: 13388.0391 - val_mean_absolute_error: 13388.0391\n",
      "Epoch 2549/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10164.9531 - mean_absolute_error: 10164.9531\n",
      "Epoch 2549: val_loss did not improve from 13379.96582\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9434.2715 - mean_absolute_error: 9434.2715 - val_loss: 13381.0938 - val_mean_absolute_error: 13381.0938\n",
      "Epoch 2550/3000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9553.4531 - mean_absolute_error: 9553.4531\n",
      "Epoch 2550: val_loss did not improve from 13379.96582\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9428.3584 - mean_absolute_error: 9428.3584 - val_loss: 13395.0859 - val_mean_absolute_error: 13395.0859\n",
      "Epoch 2551/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8591.6514 - mean_absolute_error: 8591.6514\n",
      "Epoch 2551: val_loss did not improve from 13379.96582\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9430.7598 - mean_absolute_error: 9430.7598 - val_loss: 13394.2275 - val_mean_absolute_error: 13394.2275\n",
      "Epoch 2552/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6448.5659 - mean_absolute_error: 6448.5659\n",
      "Epoch 2552: val_loss did not improve from 13379.96582\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9430.9111 - mean_absolute_error: 9430.9111 - val_loss: 13396.2588 - val_mean_absolute_error: 13396.2588\n",
      "Epoch 2553/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12232.2334 - mean_absolute_error: 12232.2334\n",
      "Epoch 2553: val_loss did not improve from 13379.96582\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9440.3496 - mean_absolute_error: 9440.3496 - val_loss: 13382.1924 - val_mean_absolute_error: 13382.1924\n",
      "Epoch 2554/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11966.6914 - mean_absolute_error: 11966.6914\n",
      "Epoch 2554: val_loss did not improve from 13379.96582\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9428.8438 - mean_absolute_error: 9428.8438 - val_loss: 13400.3818 - val_mean_absolute_error: 13400.3818\n",
      "Epoch 2555/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9141.1914 - mean_absolute_error: 9141.1914\n",
      "Epoch 2555: val_loss did not improve from 13379.96582\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9436.8428 - mean_absolute_error: 9436.8428 - val_loss: 13402.2461 - val_mean_absolute_error: 13402.2461\n",
      "Epoch 2556/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10525.8359 - mean_absolute_error: 10525.8359\n",
      "Epoch 2556: val_loss did not improve from 13379.96582\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9428.7500 - mean_absolute_error: 9428.7500 - val_loss: 13390.1934 - val_mean_absolute_error: 13390.1934\n",
      "Epoch 2557/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8650.6328 - mean_absolute_error: 8650.6328\n",
      "Epoch 2557: val_loss did not improve from 13379.96582\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9437.1504 - mean_absolute_error: 9437.1504 - val_loss: 13383.4033 - val_mean_absolute_error: 13383.4033\n",
      "Epoch 2558/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12371.0010 - mean_absolute_error: 12371.0010\n",
      "Epoch 2558: val_loss did not improve from 13379.96582\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9428.4277 - mean_absolute_error: 9428.4277 - val_loss: 13384.7441 - val_mean_absolute_error: 13384.7441\n",
      "Epoch 2559/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8431.2666 - mean_absolute_error: 8431.2666\n",
      "Epoch 2559: val_loss did not improve from 13379.96582\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9430.7764 - mean_absolute_error: 9430.7764 - val_loss: 13384.9922 - val_mean_absolute_error: 13384.9922\n",
      "Epoch 2560/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6970.9629 - mean_absolute_error: 6970.9629\n",
      "Epoch 2560: val_loss did not improve from 13379.96582\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9438.1719 - mean_absolute_error: 9438.1719 - val_loss: 13391.5859 - val_mean_absolute_error: 13391.5859\n",
      "Epoch 2561/3000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9675.4922 - mean_absolute_error: 9675.4922\n",
      "Epoch 2561: val_loss improved from 13379.96582 to 13378.64062, saving model to Weights-02561--13378.64062.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9441.5283 - mean_absolute_error: 9441.5283 - val_loss: 13378.6406 - val_mean_absolute_error: 13378.6406\n",
      "Epoch 2562/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12236.9385 - mean_absolute_error: 12236.9385\n",
      "Epoch 2562: val_loss did not improve from 13378.64062\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9428.1973 - mean_absolute_error: 9428.1973 - val_loss: 13395.3965 - val_mean_absolute_error: 13395.3965\n",
      "Epoch 2563/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7477.2876 - mean_absolute_error: 7477.2876\n",
      "Epoch 2563: val_loss did not improve from 13378.64062\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9430.0967 - mean_absolute_error: 9430.0967 - val_loss: 13387.9844 - val_mean_absolute_error: 13387.9844\n",
      "Epoch 2564/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10556.4824 - mean_absolute_error: 10556.4824\n",
      "Epoch 2564: val_loss did not improve from 13378.64062\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9430.8164 - mean_absolute_error: 9430.8164 - val_loss: 13390.9199 - val_mean_absolute_error: 13390.9199\n",
      "Epoch 2565/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8775.4111 - mean_absolute_error: 8775.4111\n",
      "Epoch 2565: val_loss improved from 13378.64062 to 13378.20703, saving model to Weights-02565--13378.20703.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9430.7139 - mean_absolute_error: 9430.7139 - val_loss: 13378.2070 - val_mean_absolute_error: 13378.2070\n",
      "Epoch 2566/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10998.3340 - mean_absolute_error: 10998.3340\n",
      "Epoch 2566: val_loss did not improve from 13378.20703\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9429.7490 - mean_absolute_error: 9429.7490 - val_loss: 13393.6826 - val_mean_absolute_error: 13393.6826\n",
      "Epoch 2567/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11116.5557 - mean_absolute_error: 11116.5557\n",
      "Epoch 2567: val_loss did not improve from 13378.20703\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9435.7773 - mean_absolute_error: 9435.7773 - val_loss: 13380.0449 - val_mean_absolute_error: 13380.0449\n",
      "Epoch 2568/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10227.2109 - mean_absolute_error: 10227.2109\n",
      "Epoch 2568: val_loss did not improve from 13378.20703\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9450.0918 - mean_absolute_error: 9450.0918 - val_loss: 13399.8682 - val_mean_absolute_error: 13399.8682\n",
      "Epoch 2569/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11788.8369 - mean_absolute_error: 11788.8369\n",
      "Epoch 2569: val_loss did not improve from 13378.20703\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9431.6738 - mean_absolute_error: 9431.6738 - val_loss: 13387.2812 - val_mean_absolute_error: 13387.2812\n",
      "Epoch 2570/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11066.5205 - mean_absolute_error: 11066.5205\n",
      "Epoch 2570: val_loss improved from 13378.20703 to 13377.77148, saving model to Weights-02570--13377.77148.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9438.0986 - mean_absolute_error: 9438.0986 - val_loss: 13377.7715 - val_mean_absolute_error: 13377.7715\n",
      "Epoch 2571/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12421.0879 - mean_absolute_error: 12421.0879\n",
      "Epoch 2571: val_loss did not improve from 13377.77148\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9437.2002 - mean_absolute_error: 9437.2002 - val_loss: 13398.0801 - val_mean_absolute_error: 13398.0801\n",
      "Epoch 2572/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8953.5928 - mean_absolute_error: 8953.5928\n",
      "Epoch 2572: val_loss did not improve from 13377.77148\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9426.6182 - mean_absolute_error: 9426.6182 - val_loss: 13379.9814 - val_mean_absolute_error: 13379.9814\n",
      "Epoch 2573/3000\n",
      "10/18 [===============>..............] - ETA: 0s - loss: 9769.8574 - mean_absolute_error: 9769.8574\n",
      "Epoch 2573: val_loss did not improve from 13377.77148\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9429.1445 - mean_absolute_error: 9429.1445 - val_loss: 13380.7441 - val_mean_absolute_error: 13380.7441\n",
      "Epoch 2574/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9214.4219 - mean_absolute_error: 9214.4219\n",
      "Epoch 2574: val_loss did not improve from 13377.77148\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9428.8330 - mean_absolute_error: 9428.8330 - val_loss: 13385.0449 - val_mean_absolute_error: 13385.0449\n",
      "Epoch 2575/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9381.4805 - mean_absolute_error: 9381.4805\n",
      "Epoch 2575: val_loss did not improve from 13377.77148\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9427.9102 - mean_absolute_error: 9427.9102 - val_loss: 13392.5371 - val_mean_absolute_error: 13392.5371\n",
      "Epoch 2576/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6191.9683 - mean_absolute_error: 6191.9683\n",
      "Epoch 2576: val_loss did not improve from 13377.77148\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9439.5469 - mean_absolute_error: 9439.5469 - val_loss: 13399.3984 - val_mean_absolute_error: 13399.3984\n",
      "Epoch 2577/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10799.8711 - mean_absolute_error: 10799.8711\n",
      "Epoch 2577: val_loss did not improve from 13377.77148\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9423.7695 - mean_absolute_error: 9423.7695 - val_loss: 13383.1094 - val_mean_absolute_error: 13383.1094\n",
      "Epoch 2578/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13573.1699 - mean_absolute_error: 13573.1699\n",
      "Epoch 2578: val_loss improved from 13377.77148 to 13377.12402, saving model to Weights-02578--13377.12402.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9434.3086 - mean_absolute_error: 9434.3086 - val_loss: 13377.1240 - val_mean_absolute_error: 13377.1240\n",
      "Epoch 2579/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6215.4824 - mean_absolute_error: 6215.4824\n",
      "Epoch 2579: val_loss did not improve from 13377.12402\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9434.4951 - mean_absolute_error: 9434.4951 - val_loss: 13380.1572 - val_mean_absolute_error: 13380.1572\n",
      "Epoch 2580/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11287.7871 - mean_absolute_error: 11287.7871\n",
      "Epoch 2580: val_loss did not improve from 13377.12402\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9429.8330 - mean_absolute_error: 9429.8330 - val_loss: 13379.2383 - val_mean_absolute_error: 13379.2383\n",
      "Epoch 2581/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6871.3457 - mean_absolute_error: 6871.3457\n",
      "Epoch 2581: val_loss did not improve from 13377.12402\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9430.5273 - mean_absolute_error: 9430.5273 - val_loss: 13393.0801 - val_mean_absolute_error: 13393.0801\n",
      "Epoch 2582/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5777.6201 - mean_absolute_error: 5777.6201\n",
      "Epoch 2582: val_loss did not improve from 13377.12402\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9437.2725 - mean_absolute_error: 9437.2725 - val_loss: 13377.7578 - val_mean_absolute_error: 13377.7578\n",
      "Epoch 2583/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7221.8042 - mean_absolute_error: 7221.8042\n",
      "Epoch 2583: val_loss did not improve from 13377.12402\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9430.2432 - mean_absolute_error: 9430.2432 - val_loss: 13403.1299 - val_mean_absolute_error: 13403.1299\n",
      "Epoch 2584/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10876.5273 - mean_absolute_error: 10876.5273\n",
      "Epoch 2584: val_loss did not improve from 13377.12402\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9433.7715 - mean_absolute_error: 9433.7715 - val_loss: 13387.3486 - val_mean_absolute_error: 13387.3486\n",
      "Epoch 2585/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12736.6553 - mean_absolute_error: 12736.6553\n",
      "Epoch 2585: val_loss did not improve from 13377.12402\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9431.2812 - mean_absolute_error: 9431.2812 - val_loss: 13385.7803 - val_mean_absolute_error: 13385.7803\n",
      "Epoch 2586/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9112.5566 - mean_absolute_error: 9112.5566\n",
      "Epoch 2586: val_loss did not improve from 13377.12402\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9426.5635 - mean_absolute_error: 9426.5635 - val_loss: 13381.7061 - val_mean_absolute_error: 13381.7061\n",
      "Epoch 2587/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9659.9844 - mean_absolute_error: 9659.9844\n",
      "Epoch 2587: val_loss did not improve from 13377.12402\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9433.5068 - mean_absolute_error: 9433.5068 - val_loss: 13386.9521 - val_mean_absolute_error: 13386.9521\n",
      "Epoch 2588/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9375.0059 - mean_absolute_error: 9375.0059\n",
      "Epoch 2588: val_loss did not improve from 13377.12402\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9441.8701 - mean_absolute_error: 9441.8701 - val_loss: 13380.0674 - val_mean_absolute_error: 13380.0674\n",
      "Epoch 2589/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13506.3594 - mean_absolute_error: 13506.3594\n",
      "Epoch 2589: val_loss did not improve from 13377.12402\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9426.6367 - mean_absolute_error: 9426.6367 - val_loss: 13392.5576 - val_mean_absolute_error: 13392.5576\n",
      "Epoch 2590/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10204.8945 - mean_absolute_error: 10204.8945\n",
      "Epoch 2590: val_loss did not improve from 13377.12402\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9431.9219 - mean_absolute_error: 9431.9219 - val_loss: 13394.8906 - val_mean_absolute_error: 13394.8906\n",
      "Epoch 2591/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8883.0645 - mean_absolute_error: 8883.0645\n",
      "Epoch 2591: val_loss did not improve from 13377.12402\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9435.0967 - mean_absolute_error: 9435.0967 - val_loss: 13385.6465 - val_mean_absolute_error: 13385.6465\n",
      "Epoch 2592/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11766.4082 - mean_absolute_error: 11766.4082\n",
      "Epoch 2592: val_loss did not improve from 13377.12402\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9430.4131 - mean_absolute_error: 9430.4131 - val_loss: 13391.0449 - val_mean_absolute_error: 13391.0449\n",
      "Epoch 2593/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7510.2563 - mean_absolute_error: 7510.2563\n",
      "Epoch 2593: val_loss did not improve from 13377.12402\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9424.3906 - mean_absolute_error: 9424.3906 - val_loss: 13381.5654 - val_mean_absolute_error: 13381.5654\n",
      "Epoch 2594/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8952.5410 - mean_absolute_error: 8952.5410\n",
      "Epoch 2594: val_loss improved from 13377.12402 to 13376.05762, saving model to Weights-02594--13376.05762.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9428.6631 - mean_absolute_error: 9428.6631 - val_loss: 13376.0576 - val_mean_absolute_error: 13376.0576\n",
      "Epoch 2595/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9730.0283 - mean_absolute_error: 9730.0283\n",
      "Epoch 2595: val_loss did not improve from 13376.05762\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9427.8037 - mean_absolute_error: 9427.8037 - val_loss: 13380.5576 - val_mean_absolute_error: 13380.5576\n",
      "Epoch 2596/3000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9494.6924 - mean_absolute_error: 9494.6924\n",
      "Epoch 2596: val_loss did not improve from 13376.05762\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9424.8213 - mean_absolute_error: 9424.8213 - val_loss: 13384.5469 - val_mean_absolute_error: 13384.5469\n",
      "Epoch 2597/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10669.9883 - mean_absolute_error: 10669.9883\n",
      "Epoch 2597: val_loss did not improve from 13376.05762\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9431.1982 - mean_absolute_error: 9431.1982 - val_loss: 13376.4277 - val_mean_absolute_error: 13376.4277\n",
      "Epoch 2598/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10830.7637 - mean_absolute_error: 10830.7637\n",
      "Epoch 2598: val_loss did not improve from 13376.05762\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9428.7656 - mean_absolute_error: 9428.7656 - val_loss: 13383.9463 - val_mean_absolute_error: 13383.9463\n",
      "Epoch 2599/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11176.8457 - mean_absolute_error: 11176.8457\n",
      "Epoch 2599: val_loss did not improve from 13376.05762\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9445.4346 - mean_absolute_error: 9445.4346 - val_loss: 13393.9219 - val_mean_absolute_error: 13393.9219\n",
      "Epoch 2600/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8586.7109 - mean_absolute_error: 8586.7109\n",
      "Epoch 2600: val_loss did not improve from 13376.05762\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9428.4170 - mean_absolute_error: 9428.4170 - val_loss: 13377.0811 - val_mean_absolute_error: 13377.0811\n",
      "Epoch 2601/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7467.2319 - mean_absolute_error: 7467.2319\n",
      "Epoch 2601: val_loss did not improve from 13376.05762\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9440.5127 - mean_absolute_error: 9440.5127 - val_loss: 13392.8555 - val_mean_absolute_error: 13392.8555\n",
      "Epoch 2602/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10803.0195 - mean_absolute_error: 10803.0195\n",
      "Epoch 2602: val_loss improved from 13376.05762 to 13375.71973, saving model to Weights-02602--13375.71973.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9445.0234 - mean_absolute_error: 9445.0234 - val_loss: 13375.7197 - val_mean_absolute_error: 13375.7188\n",
      "Epoch 2603/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10748.2754 - mean_absolute_error: 10748.2754\n",
      "Epoch 2603: val_loss did not improve from 13375.71973\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9425.7139 - mean_absolute_error: 9425.7139 - val_loss: 13377.3799 - val_mean_absolute_error: 13377.3799\n",
      "Epoch 2604/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6753.4268 - mean_absolute_error: 6753.4268\n",
      "Epoch 2604: val_loss did not improve from 13375.71973\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9440.6094 - mean_absolute_error: 9440.6094 - val_loss: 13397.2031 - val_mean_absolute_error: 13397.2031\n",
      "Epoch 2605/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11372.5303 - mean_absolute_error: 11372.5303\n",
      "Epoch 2605: val_loss did not improve from 13375.71973\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9422.3662 - mean_absolute_error: 9422.3662 - val_loss: 13377.0684 - val_mean_absolute_error: 13377.0684\n",
      "Epoch 2606/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12131.9883 - mean_absolute_error: 12131.9883\n",
      "Epoch 2606: val_loss improved from 13375.71973 to 13374.79492, saving model to Weights-02606--13374.79492.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9440.2568 - mean_absolute_error: 9440.2568 - val_loss: 13374.7949 - val_mean_absolute_error: 13374.7949\n",
      "Epoch 2607/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9850.8467 - mean_absolute_error: 9850.8467\n",
      "Epoch 2607: val_loss did not improve from 13374.79492\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9426.9561 - mean_absolute_error: 9426.9561 - val_loss: 13381.9805 - val_mean_absolute_error: 13381.9805\n",
      "Epoch 2608/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12751.4004 - mean_absolute_error: 12751.4004\n",
      "Epoch 2608: val_loss did not improve from 13374.79492\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9425.1582 - mean_absolute_error: 9425.1582 - val_loss: 13404.2637 - val_mean_absolute_error: 13404.2637\n",
      "Epoch 2609/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9186.3066 - mean_absolute_error: 9186.3066\n",
      "Epoch 2609: val_loss did not improve from 13374.79492\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9442.5918 - mean_absolute_error: 9442.5918 - val_loss: 13394.3594 - val_mean_absolute_error: 13394.3594\n",
      "Epoch 2610/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9716.7773 - mean_absolute_error: 9716.7773\n",
      "Epoch 2610: val_loss did not improve from 13374.79492\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9426.8516 - mean_absolute_error: 9426.8516 - val_loss: 13387.6719 - val_mean_absolute_error: 13387.6719\n",
      "Epoch 2611/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9432.7539 - mean_absolute_error: 9432.7539\n",
      "Epoch 2611: val_loss did not improve from 13374.79492\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9426.9336 - mean_absolute_error: 9426.9336 - val_loss: 13382.6709 - val_mean_absolute_error: 13382.6709\n",
      "Epoch 2612/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10287.2852 - mean_absolute_error: 10287.2852\n",
      "Epoch 2612: val_loss did not improve from 13374.79492\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9427.0576 - mean_absolute_error: 9427.0576 - val_loss: 13378.2119 - val_mean_absolute_error: 13378.2119\n",
      "Epoch 2613/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9533.1406 - mean_absolute_error: 9533.1406\n",
      "Epoch 2613: val_loss did not improve from 13374.79492\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9431.0059 - mean_absolute_error: 9431.0059 - val_loss: 13390.0781 - val_mean_absolute_error: 13390.0781\n",
      "Epoch 2614/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5701.6787 - mean_absolute_error: 5701.6787\n",
      "Epoch 2614: val_loss did not improve from 13374.79492\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9428.0166 - mean_absolute_error: 9428.0166 - val_loss: 13382.3408 - val_mean_absolute_error: 13382.3408\n",
      "Epoch 2615/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11567.4336 - mean_absolute_error: 11567.4336\n",
      "Epoch 2615: val_loss did not improve from 13374.79492\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9431.1201 - mean_absolute_error: 9431.1201 - val_loss: 13385.1475 - val_mean_absolute_error: 13385.1475\n",
      "Epoch 2616/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9967.3984 - mean_absolute_error: 9967.3984\n",
      "Epoch 2616: val_loss improved from 13374.79492 to 13373.79590, saving model to Weights-02616--13373.79590.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9421.3789 - mean_absolute_error: 9421.3789 - val_loss: 13373.7959 - val_mean_absolute_error: 13373.7959\n",
      "Epoch 2617/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9402.1172 - mean_absolute_error: 9402.1172\n",
      "Epoch 2617: val_loss did not improve from 13373.79590\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9429.7324 - mean_absolute_error: 9429.7324 - val_loss: 13380.8896 - val_mean_absolute_error: 13380.8896\n",
      "Epoch 2618/3000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9619.5947 - mean_absolute_error: 9619.5947  \n",
      "Epoch 2618: val_loss did not improve from 13373.79590\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9425.5566 - mean_absolute_error: 9425.5566 - val_loss: 13379.1484 - val_mean_absolute_error: 13379.1484\n",
      "Epoch 2619/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8071.7070 - mean_absolute_error: 8071.7070\n",
      "Epoch 2619: val_loss did not improve from 13373.79590\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9423.7266 - mean_absolute_error: 9423.7266 - val_loss: 13377.8350 - val_mean_absolute_error: 13377.8350\n",
      "Epoch 2620/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8460.3848 - mean_absolute_error: 8460.3848\n",
      "Epoch 2620: val_loss did not improve from 13373.79590\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9423.5020 - mean_absolute_error: 9423.5020 - val_loss: 13379.1055 - val_mean_absolute_error: 13379.1055\n",
      "Epoch 2621/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12036.6680 - mean_absolute_error: 12036.6680\n",
      "Epoch 2621: val_loss did not improve from 13373.79590\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9426.3877 - mean_absolute_error: 9426.3877 - val_loss: 13387.3750 - val_mean_absolute_error: 13387.3750\n",
      "Epoch 2622/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8006.8389 - mean_absolute_error: 8006.8389\n",
      "Epoch 2622: val_loss did not improve from 13373.79590\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9427.7432 - mean_absolute_error: 9427.7432 - val_loss: 13381.3730 - val_mean_absolute_error: 13381.3730\n",
      "Epoch 2623/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8525.3262 - mean_absolute_error: 8525.3262\n",
      "Epoch 2623: val_loss improved from 13373.79590 to 13373.33691, saving model to Weights-02623--13373.33691.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9425.0693 - mean_absolute_error: 9425.0693 - val_loss: 13373.3369 - val_mean_absolute_error: 13373.3369\n",
      "Epoch 2624/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10215.8516 - mean_absolute_error: 10215.8516\n",
      "Epoch 2624: val_loss did not improve from 13373.33691\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9425.5693 - mean_absolute_error: 9425.5693 - val_loss: 13378.1611 - val_mean_absolute_error: 13378.1611\n",
      "Epoch 2625/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6300.4756 - mean_absolute_error: 6300.4756\n",
      "Epoch 2625: val_loss did not improve from 13373.33691\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9430.3486 - mean_absolute_error: 9430.3486 - val_loss: 13386.6396 - val_mean_absolute_error: 13386.6396\n",
      "Epoch 2626/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13848.8594 - mean_absolute_error: 13848.8594\n",
      "Epoch 2626: val_loss did not improve from 13373.33691\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9428.2490 - mean_absolute_error: 9428.2490 - val_loss: 13384.3076 - val_mean_absolute_error: 13384.3076\n",
      "Epoch 2627/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10740.3418 - mean_absolute_error: 10740.3418\n",
      "Epoch 2627: val_loss improved from 13373.33691 to 13373.03418, saving model to Weights-02627--13373.03418.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9424.5410 - mean_absolute_error: 9424.5410 - val_loss: 13373.0342 - val_mean_absolute_error: 13373.0342\n",
      "Epoch 2628/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5827.5566 - mean_absolute_error: 5827.5566\n",
      "Epoch 2628: val_loss did not improve from 13373.03418\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9424.4424 - mean_absolute_error: 9424.4424 - val_loss: 13375.4961 - val_mean_absolute_error: 13375.4961\n",
      "Epoch 2629/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8940.4551 - mean_absolute_error: 8940.4551\n",
      "Epoch 2629: val_loss did not improve from 13373.03418\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9426.0859 - mean_absolute_error: 9426.0859 - val_loss: 13380.7744 - val_mean_absolute_error: 13380.7744\n",
      "Epoch 2630/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10564.2656 - mean_absolute_error: 10564.2656\n",
      "Epoch 2630: val_loss did not improve from 13373.03418\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9423.0205 - mean_absolute_error: 9423.0205 - val_loss: 13373.4746 - val_mean_absolute_error: 13373.4746\n",
      "Epoch 2631/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8853.6953 - mean_absolute_error: 8853.6953\n",
      "Epoch 2631: val_loss did not improve from 13373.03418\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9429.7402 - mean_absolute_error: 9429.7402 - val_loss: 13387.5791 - val_mean_absolute_error: 13387.5791\n",
      "Epoch 2632/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10598.7305 - mean_absolute_error: 10598.7305\n",
      "Epoch 2632: val_loss improved from 13373.03418 to 13372.55566, saving model to Weights-02632--13372.55566.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9428.0039 - mean_absolute_error: 9428.0039 - val_loss: 13372.5557 - val_mean_absolute_error: 13372.5557\n",
      "Epoch 2633/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9869.0049 - mean_absolute_error: 9869.0049\n",
      "Epoch 2633: val_loss did not improve from 13372.55566\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9431.6084 - mean_absolute_error: 9431.6084 - val_loss: 13379.7139 - val_mean_absolute_error: 13379.7139\n",
      "Epoch 2634/3000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 9031.6699 - mean_absolute_error: 9031.6699\n",
      "Epoch 2634: val_loss did not improve from 13372.55566\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9424.4648 - mean_absolute_error: 9424.4648 - val_loss: 13377.2715 - val_mean_absolute_error: 13377.2715\n",
      "Epoch 2635/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9328.7461 - mean_absolute_error: 9328.7461\n",
      "Epoch 2635: val_loss did not improve from 13372.55566\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9423.6494 - mean_absolute_error: 9423.6494 - val_loss: 13382.1533 - val_mean_absolute_error: 13382.1533\n",
      "Epoch 2636/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10535.9219 - mean_absolute_error: 10535.9219\n",
      "Epoch 2636: val_loss did not improve from 13372.55566\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9430.1221 - mean_absolute_error: 9430.1221 - val_loss: 13389.6660 - val_mean_absolute_error: 13389.6660\n",
      "Epoch 2637/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8198.3252 - mean_absolute_error: 8198.3252\n",
      "Epoch 2637: val_loss did not improve from 13372.55566\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9425.7568 - mean_absolute_error: 9425.7568 - val_loss: 13376.3896 - val_mean_absolute_error: 13376.3896\n",
      "Epoch 2638/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12543.3701 - mean_absolute_error: 12543.3701\n",
      "Epoch 2638: val_loss did not improve from 13372.55566\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9443.2793 - mean_absolute_error: 9443.2793 - val_loss: 13374.0049 - val_mean_absolute_error: 13374.0049\n",
      "Epoch 2639/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7728.1270 - mean_absolute_error: 7728.1270\n",
      "Epoch 2639: val_loss did not improve from 13372.55566\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9431.2861 - mean_absolute_error: 9431.2861 - val_loss: 13383.7266 - val_mean_absolute_error: 13383.7266\n",
      "Epoch 2640/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6628.2520 - mean_absolute_error: 6628.2520\n",
      "Epoch 2640: val_loss did not improve from 13372.55566\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9441.4424 - mean_absolute_error: 9441.4424 - val_loss: 13377.7139 - val_mean_absolute_error: 13377.7139\n",
      "Epoch 2641/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7733.1963 - mean_absolute_error: 7733.1963\n",
      "Epoch 2641: val_loss did not improve from 13372.55566\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9429.2656 - mean_absolute_error: 9429.2656 - val_loss: 13394.0977 - val_mean_absolute_error: 13394.0977\n",
      "Epoch 2642/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6750.4092 - mean_absolute_error: 6750.4092\n",
      "Epoch 2642: val_loss did not improve from 13372.55566\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9428.4072 - mean_absolute_error: 9428.4072 - val_loss: 13389.7207 - val_mean_absolute_error: 13389.7207\n",
      "Epoch 2643/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9325.2090 - mean_absolute_error: 9325.2090\n",
      "Epoch 2643: val_loss did not improve from 13372.55566\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9427.5947 - mean_absolute_error: 9427.5947 - val_loss: 13373.1357 - val_mean_absolute_error: 13373.1357\n",
      "Epoch 2644/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10795.7617 - mean_absolute_error: 10795.7617\n",
      "Epoch 2644: val_loss did not improve from 13372.55566\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9422.5264 - mean_absolute_error: 9422.5264 - val_loss: 13377.1924 - val_mean_absolute_error: 13377.1924\n",
      "Epoch 2645/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12645.3975 - mean_absolute_error: 12645.3975\n",
      "Epoch 2645: val_loss did not improve from 13372.55566\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9425.8174 - mean_absolute_error: 9425.8174 - val_loss: 13380.5674 - val_mean_absolute_error: 13380.5674\n",
      "Epoch 2646/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8287.7812 - mean_absolute_error: 8287.7812\n",
      "Epoch 2646: val_loss did not improve from 13372.55566\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9422.4287 - mean_absolute_error: 9422.4287 - val_loss: 13395.1514 - val_mean_absolute_error: 13395.1514\n",
      "Epoch 2647/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7144.0264 - mean_absolute_error: 7144.0264\n",
      "Epoch 2647: val_loss did not improve from 13372.55566\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9434.7305 - mean_absolute_error: 9434.7305 - val_loss: 13382.7568 - val_mean_absolute_error: 13382.7568\n",
      "Epoch 2648/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7539.8521 - mean_absolute_error: 7539.8521\n",
      "Epoch 2648: val_loss did not improve from 13372.55566\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9430.7148 - mean_absolute_error: 9430.7148 - val_loss: 13373.3330 - val_mean_absolute_error: 13373.3330\n",
      "Epoch 2649/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13025.4473 - mean_absolute_error: 13025.4473\n",
      "Epoch 2649: val_loss did not improve from 13372.55566\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9421.5449 - mean_absolute_error: 9421.5449 - val_loss: 13380.0527 - val_mean_absolute_error: 13380.0527\n",
      "Epoch 2650/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9162.2363 - mean_absolute_error: 9162.2363\n",
      "Epoch 2650: val_loss did not improve from 13372.55566\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9440.0381 - mean_absolute_error: 9440.0381 - val_loss: 13398.2715 - val_mean_absolute_error: 13398.2715\n",
      "Epoch 2651/3000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9524.7012 - mean_absolute_error: 9524.7012\n",
      "Epoch 2651: val_loss improved from 13372.55566 to 13371.20605, saving model to Weights-02651--13371.20605.hdf5\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9437.9619 - mean_absolute_error: 9437.9619 - val_loss: 13371.2061 - val_mean_absolute_error: 13371.2061\n",
      "Epoch 2652/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6612.9785 - mean_absolute_error: 6612.9785\n",
      "Epoch 2652: val_loss did not improve from 13371.20605\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9421.1709 - mean_absolute_error: 9421.1709 - val_loss: 13386.2080 - val_mean_absolute_error: 13386.2080\n",
      "Epoch 2653/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11469.0859 - mean_absolute_error: 11469.0859\n",
      "Epoch 2653: val_loss did not improve from 13371.20605\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9426.1982 - mean_absolute_error: 9426.1982 - val_loss: 13396.6562 - val_mean_absolute_error: 13396.6562\n",
      "Epoch 2654/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11011.2734 - mean_absolute_error: 11011.2734\n",
      "Epoch 2654: val_loss did not improve from 13371.20605\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9421.4727 - mean_absolute_error: 9421.4727 - val_loss: 13379.9131 - val_mean_absolute_error: 13379.9131\n",
      "Epoch 2655/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8708.1406 - mean_absolute_error: 8708.1406\n",
      "Epoch 2655: val_loss did not improve from 13371.20605\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9422.3525 - mean_absolute_error: 9422.3525 - val_loss: 13373.5498 - val_mean_absolute_error: 13373.5498\n",
      "Epoch 2656/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7127.0146 - mean_absolute_error: 7127.0146\n",
      "Epoch 2656: val_loss did not improve from 13371.20605\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9424.0586 - mean_absolute_error: 9424.0586 - val_loss: 13376.2744 - val_mean_absolute_error: 13376.2744\n",
      "Epoch 2657/3000\n",
      "18/18 [==============================] - ETA: 0s - loss: 9421.7871 - mean_absolute_error: 9421.7871  \n",
      "Epoch 2657: val_loss did not improve from 13371.20605\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9421.7871 - mean_absolute_error: 9421.7871 - val_loss: 13372.2412 - val_mean_absolute_error: 13372.2412\n",
      "Epoch 2658/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9684.7285 - mean_absolute_error: 9684.7285\n",
      "Epoch 2658: val_loss did not improve from 13371.20605\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9423.8750 - mean_absolute_error: 9423.8750 - val_loss: 13379.4365 - val_mean_absolute_error: 13379.4365\n",
      "Epoch 2659/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8572.0156 - mean_absolute_error: 8572.0156\n",
      "Epoch 2659: val_loss did not improve from 13371.20605\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9423.8760 - mean_absolute_error: 9423.8760 - val_loss: 13378.2031 - val_mean_absolute_error: 13378.2031\n",
      "Epoch 2660/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7157.3545 - mean_absolute_error: 7157.3545\n",
      "Epoch 2660: val_loss did not improve from 13371.20605\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9424.6719 - mean_absolute_error: 9424.6719 - val_loss: 13377.5752 - val_mean_absolute_error: 13377.5752\n",
      "Epoch 2661/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8399.3906 - mean_absolute_error: 8399.3906\n",
      "Epoch 2661: val_loss improved from 13371.20605 to 13369.88184, saving model to Weights-02661--13369.88184.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9438.0400 - mean_absolute_error: 9438.0400 - val_loss: 13369.8818 - val_mean_absolute_error: 13369.8818\n",
      "Epoch 2662/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10272.3145 - mean_absolute_error: 10272.3145\n",
      "Epoch 2662: val_loss did not improve from 13369.88184\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9420.9688 - mean_absolute_error: 9420.9688 - val_loss: 13385.0264 - val_mean_absolute_error: 13385.0264\n",
      "Epoch 2663/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9021.6250 - mean_absolute_error: 9021.6250\n",
      "Epoch 2663: val_loss did not improve from 13369.88184\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9423.7939 - mean_absolute_error: 9423.7939 - val_loss: 13381.0586 - val_mean_absolute_error: 13381.0586\n",
      "Epoch 2664/3000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8992.6084 - mean_absolute_error: 8992.6084\n",
      "Epoch 2664: val_loss did not improve from 13369.88184\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9427.4141 - mean_absolute_error: 9427.4141 - val_loss: 13370.0371 - val_mean_absolute_error: 13370.0371\n",
      "Epoch 2665/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9867.5684 - mean_absolute_error: 9867.5684\n",
      "Epoch 2665: val_loss did not improve from 13369.88184\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9424.2891 - mean_absolute_error: 9424.2891 - val_loss: 13381.4883 - val_mean_absolute_error: 13381.4883\n",
      "Epoch 2666/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11030.2314 - mean_absolute_error: 11030.2314\n",
      "Epoch 2666: val_loss did not improve from 13369.88184\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9426.2246 - mean_absolute_error: 9426.2246 - val_loss: 13383.3311 - val_mean_absolute_error: 13383.3311\n",
      "Epoch 2667/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8273.9238 - mean_absolute_error: 8273.9238\n",
      "Epoch 2667: val_loss did not improve from 13369.88184\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9423.3018 - mean_absolute_error: 9423.3018 - val_loss: 13372.8760 - val_mean_absolute_error: 13372.8760\n",
      "Epoch 2668/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7401.6050 - mean_absolute_error: 7401.6050\n",
      "Epoch 2668: val_loss did not improve from 13369.88184\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9425.3750 - mean_absolute_error: 9425.3750 - val_loss: 13372.4160 - val_mean_absolute_error: 13372.4160\n",
      "Epoch 2669/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11236.6533 - mean_absolute_error: 11236.6533\n",
      "Epoch 2669: val_loss did not improve from 13369.88184\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9420.7969 - mean_absolute_error: 9420.7969 - val_loss: 13378.6504 - val_mean_absolute_error: 13378.6504\n",
      "Epoch 2670/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5740.2100 - mean_absolute_error: 5740.2100\n",
      "Epoch 2670: val_loss did not improve from 13369.88184\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9421.5625 - mean_absolute_error: 9421.5625 - val_loss: 13376.8594 - val_mean_absolute_error: 13376.8594\n",
      "Epoch 2671/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7704.2549 - mean_absolute_error: 7704.2549\n",
      "Epoch 2671: val_loss did not improve from 13369.88184\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9426.8525 - mean_absolute_error: 9426.8525 - val_loss: 13371.4756 - val_mean_absolute_error: 13371.4756\n",
      "Epoch 2672/3000\n",
      " 8/18 [============>.................] - ETA: 0s - loss: 9513.1162 - mean_absolute_error: 9513.1162\n",
      "Epoch 2672: val_loss did not improve from 13369.88184\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9423.4238 - mean_absolute_error: 9423.4238 - val_loss: 13369.8838 - val_mean_absolute_error: 13369.8838\n",
      "Epoch 2673/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8750.4287 - mean_absolute_error: 8750.4287\n",
      "Epoch 2673: val_loss did not improve from 13369.88184\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9423.9189 - mean_absolute_error: 9423.9189 - val_loss: 13378.5781 - val_mean_absolute_error: 13378.5781\n",
      "Epoch 2674/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5305.6846 - mean_absolute_error: 5305.6846\n",
      "Epoch 2674: val_loss did not improve from 13369.88184\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9420.7021 - mean_absolute_error: 9420.7021 - val_loss: 13371.4014 - val_mean_absolute_error: 13371.4014\n",
      "Epoch 2675/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11177.2451 - mean_absolute_error: 11177.2451\n",
      "Epoch 2675: val_loss did not improve from 13369.88184\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9425.4668 - mean_absolute_error: 9425.4668 - val_loss: 13384.1680 - val_mean_absolute_error: 13384.1680\n",
      "Epoch 2676/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7115.0767 - mean_absolute_error: 7115.0767\n",
      "Epoch 2676: val_loss did not improve from 13369.88184\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9425.3867 - mean_absolute_error: 9425.3867 - val_loss: 13370.0742 - val_mean_absolute_error: 13370.0742\n",
      "Epoch 2677/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10384.6885 - mean_absolute_error: 10384.6885\n",
      "Epoch 2677: val_loss did not improve from 13369.88184\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9427.2139 - mean_absolute_error: 9427.2139 - val_loss: 13381.2998 - val_mean_absolute_error: 13381.2998\n",
      "Epoch 2678/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5729.0049 - mean_absolute_error: 5729.0049\n",
      "Epoch 2678: val_loss improved from 13369.88184 to 13368.73438, saving model to Weights-02678--13368.73438.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9420.7969 - mean_absolute_error: 9420.7969 - val_loss: 13368.7344 - val_mean_absolute_error: 13368.7344\n",
      "Epoch 2679/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 14234.5459 - mean_absolute_error: 14234.5459\n",
      "Epoch 2679: val_loss did not improve from 13368.73438\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9423.8350 - mean_absolute_error: 9423.8350 - val_loss: 13375.7988 - val_mean_absolute_error: 13375.7988\n",
      "Epoch 2680/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9050.6309 - mean_absolute_error: 9050.6309\n",
      "Epoch 2680: val_loss did not improve from 13368.73438\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9421.0420 - mean_absolute_error: 9421.0420 - val_loss: 13373.8857 - val_mean_absolute_error: 13373.8857\n",
      "Epoch 2681/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7412.1699 - mean_absolute_error: 7412.1699\n",
      "Epoch 2681: val_loss did not improve from 13368.73438\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9423.6660 - mean_absolute_error: 9423.6660 - val_loss: 13371.9521 - val_mean_absolute_error: 13371.9521\n",
      "Epoch 2682/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7481.5830 - mean_absolute_error: 7481.5830\n",
      "Epoch 2682: val_loss did not improve from 13368.73438\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9421.5879 - mean_absolute_error: 9421.5879 - val_loss: 13379.8467 - val_mean_absolute_error: 13379.8467\n",
      "Epoch 2683/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8247.2031 - mean_absolute_error: 8247.2031\n",
      "Epoch 2683: val_loss did not improve from 13368.73438\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9423.7617 - mean_absolute_error: 9423.7617 - val_loss: 13376.3457 - val_mean_absolute_error: 13376.3457\n",
      "Epoch 2684/3000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9433.3838 - mean_absolute_error: 9433.3838  \n",
      "Epoch 2684: val_loss improved from 13368.73438 to 13368.09961, saving model to Weights-02684--13368.09961.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9422.9482 - mean_absolute_error: 9422.9482 - val_loss: 13368.0996 - val_mean_absolute_error: 13368.0996\n",
      "Epoch 2685/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 15064.3398 - mean_absolute_error: 15064.3398\n",
      "Epoch 2685: val_loss did not improve from 13368.09961\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9426.1055 - mean_absolute_error: 9426.1055 - val_loss: 13380.1865 - val_mean_absolute_error: 13380.1865\n",
      "Epoch 2686/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 15436.0244 - mean_absolute_error: 15436.0244\n",
      "Epoch 2686: val_loss did not improve from 13368.09961\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9423.9258 - mean_absolute_error: 9423.9258 - val_loss: 13371.3232 - val_mean_absolute_error: 13371.3223\n",
      "Epoch 2687/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9493.3320 - mean_absolute_error: 9493.3320\n",
      "Epoch 2687: val_loss did not improve from 13368.09961\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9424.4238 - mean_absolute_error: 9424.4238 - val_loss: 13370.9053 - val_mean_absolute_error: 13370.9053\n",
      "Epoch 2688/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12356.5664 - mean_absolute_error: 12356.5664\n",
      "Epoch 2688: val_loss did not improve from 13368.09961\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9425.8496 - mean_absolute_error: 9425.8496 - val_loss: 13368.5879 - val_mean_absolute_error: 13368.5879\n",
      "Epoch 2689/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8408.2168 - mean_absolute_error: 8408.2168\n",
      "Epoch 2689: val_loss did not improve from 13368.09961\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9420.8066 - mean_absolute_error: 9420.8066 - val_loss: 13372.2764 - val_mean_absolute_error: 13372.2764\n",
      "Epoch 2690/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7816.1904 - mean_absolute_error: 7816.1904\n",
      "Epoch 2690: val_loss did not improve from 13368.09961\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9422.5752 - mean_absolute_error: 9422.5752 - val_loss: 13378.8809 - val_mean_absolute_error: 13378.8809\n",
      "Epoch 2691/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6752.5654 - mean_absolute_error: 6752.5654\n",
      "Epoch 2691: val_loss did not improve from 13368.09961\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9424.6230 - mean_absolute_error: 9424.6230 - val_loss: 13383.3350 - val_mean_absolute_error: 13383.3350\n",
      "Epoch 2692/3000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9383.5576 - mean_absolute_error: 9383.5576\n",
      "Epoch 2692: val_loss did not improve from 13368.09961\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9417.1895 - mean_absolute_error: 9417.1895 - val_loss: 13368.8857 - val_mean_absolute_error: 13368.8848\n",
      "Epoch 2693/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11375.0918 - mean_absolute_error: 11375.0918\n",
      "Epoch 2693: val_loss did not improve from 13368.09961\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9443.7520 - mean_absolute_error: 9443.7520 - val_loss: 13368.7646 - val_mean_absolute_error: 13368.7646\n",
      "Epoch 2694/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9994.1836 - mean_absolute_error: 9994.1836\n",
      "Epoch 2694: val_loss did not improve from 13368.09961\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9421.3643 - mean_absolute_error: 9421.3643 - val_loss: 13386.0039 - val_mean_absolute_error: 13386.0039\n",
      "Epoch 2695/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6138.1992 - mean_absolute_error: 6138.1992\n",
      "Epoch 2695: val_loss did not improve from 13368.09961\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9431.4219 - mean_absolute_error: 9431.4219 - val_loss: 13386.1816 - val_mean_absolute_error: 13386.1816\n",
      "Epoch 2696/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7528.9668 - mean_absolute_error: 7528.9668\n",
      "Epoch 2696: val_loss did not improve from 13368.09961\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9421.3027 - mean_absolute_error: 9421.3027 - val_loss: 13376.1494 - val_mean_absolute_error: 13376.1494\n",
      "Epoch 2697/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10999.3350 - mean_absolute_error: 10999.3350\n",
      "Epoch 2697: val_loss improved from 13368.09961 to 13368.08008, saving model to Weights-02697--13368.08008.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9431.3320 - mean_absolute_error: 9431.3320 - val_loss: 13368.0801 - val_mean_absolute_error: 13368.0801\n",
      "Epoch 2698/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11665.7305 - mean_absolute_error: 11665.7305\n",
      "Epoch 2698: val_loss did not improve from 13368.08008\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9427.4639 - mean_absolute_error: 9427.4639 - val_loss: 13385.1387 - val_mean_absolute_error: 13385.1387\n",
      "Epoch 2699/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10100.4824 - mean_absolute_error: 10100.4824\n",
      "Epoch 2699: val_loss improved from 13368.08008 to 13367.87988, saving model to Weights-02699--13367.87988.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9422.6729 - mean_absolute_error: 9422.6729 - val_loss: 13367.8799 - val_mean_absolute_error: 13367.8799\n",
      "Epoch 2700/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9413.7568 - mean_absolute_error: 9413.7568\n",
      "Epoch 2700: val_loss did not improve from 13367.87988\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9419.2451 - mean_absolute_error: 9419.2451 - val_loss: 13376.5322 - val_mean_absolute_error: 13376.5322\n",
      "Epoch 2701/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6531.4741 - mean_absolute_error: 6531.4741\n",
      "Epoch 2701: val_loss did not improve from 13367.87988\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9426.7021 - mean_absolute_error: 9426.7021 - val_loss: 13380.6611 - val_mean_absolute_error: 13380.6611\n",
      "Epoch 2702/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10920.5742 - mean_absolute_error: 10920.5742\n",
      "Epoch 2702: val_loss did not improve from 13367.87988\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9423.5107 - mean_absolute_error: 9423.5107 - val_loss: 13368.0771 - val_mean_absolute_error: 13368.0771\n",
      "Epoch 2703/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7776.0737 - mean_absolute_error: 7776.0737\n",
      "Epoch 2703: val_loss did not improve from 13367.87988\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9421.4736 - mean_absolute_error: 9421.4736 - val_loss: 13388.8799 - val_mean_absolute_error: 13388.8799\n",
      "Epoch 2704/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11119.1768 - mean_absolute_error: 11119.1768\n",
      "Epoch 2704: val_loss did not improve from 13367.87988\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9423.3955 - mean_absolute_error: 9423.3955 - val_loss: 13380.3408 - val_mean_absolute_error: 13380.3408\n",
      "Epoch 2705/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9176.0420 - mean_absolute_error: 9176.0420\n",
      "Epoch 2705: val_loss did not improve from 13367.87988\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9427.2432 - mean_absolute_error: 9427.2432 - val_loss: 13374.7520 - val_mean_absolute_error: 13374.7520\n",
      "Epoch 2706/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5599.0410 - mean_absolute_error: 5599.0410\n",
      "Epoch 2706: val_loss improved from 13367.87988 to 13366.34082, saving model to Weights-02706--13366.34082.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9418.9502 - mean_absolute_error: 9418.9502 - val_loss: 13366.3408 - val_mean_absolute_error: 13366.3408\n",
      "Epoch 2707/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8850.2080 - mean_absolute_error: 8850.2080\n",
      "Epoch 2707: val_loss did not improve from 13366.34082\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9418.2666 - mean_absolute_error: 9418.2666 - val_loss: 13372.6445 - val_mean_absolute_error: 13372.6445\n",
      "Epoch 2708/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10306.1914 - mean_absolute_error: 10306.1914\n",
      "Epoch 2708: val_loss did not improve from 13366.34082\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9421.5781 - mean_absolute_error: 9421.5781 - val_loss: 13374.2363 - val_mean_absolute_error: 13374.2363\n",
      "Epoch 2709/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7508.7227 - mean_absolute_error: 7508.7227\n",
      "Epoch 2709: val_loss did not improve from 13366.34082\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9419.5527 - mean_absolute_error: 9419.5527 - val_loss: 13374.2725 - val_mean_absolute_error: 13374.2725\n",
      "Epoch 2710/3000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9514.9492 - mean_absolute_error: 9514.9492\n",
      "Epoch 2710: val_loss did not improve from 13366.34082\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9431.2930 - mean_absolute_error: 9431.2930 - val_loss: 13385.3477 - val_mean_absolute_error: 13385.3477\n",
      "Epoch 2711/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8164.8809 - mean_absolute_error: 8164.8809\n",
      "Epoch 2711: val_loss did not improve from 13366.34082\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9419.4053 - mean_absolute_error: 9419.4053 - val_loss: 13373.6855 - val_mean_absolute_error: 13373.6855\n",
      "Epoch 2712/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6771.8262 - mean_absolute_error: 6771.8262\n",
      "Epoch 2712: val_loss did not improve from 13366.34082\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9418.1348 - mean_absolute_error: 9418.1348 - val_loss: 13368.2178 - val_mean_absolute_error: 13368.2178\n",
      "Epoch 2713/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6749.6621 - mean_absolute_error: 6749.6621\n",
      "Epoch 2713: val_loss improved from 13366.34082 to 13365.96973, saving model to Weights-02713--13365.96973.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9426.7412 - mean_absolute_error: 9426.7412 - val_loss: 13365.9697 - val_mean_absolute_error: 13365.9697\n",
      "Epoch 2714/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10112.7227 - mean_absolute_error: 10112.7227\n",
      "Epoch 2714: val_loss did not improve from 13365.96973\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9413.2900 - mean_absolute_error: 9413.2900 - val_loss: 13381.2910 - val_mean_absolute_error: 13381.2910\n",
      "Epoch 2715/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8277.9971 - mean_absolute_error: 8277.9971\n",
      "Epoch 2715: val_loss did not improve from 13365.96973\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9437.3594 - mean_absolute_error: 9437.3594 - val_loss: 13395.0791 - val_mean_absolute_error: 13395.0791\n",
      "Epoch 2716/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8756.9316 - mean_absolute_error: 8756.9316\n",
      "Epoch 2716: val_loss improved from 13365.96973 to 13365.86719, saving model to Weights-02716--13365.86719.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9418.2861 - mean_absolute_error: 9418.2861 - val_loss: 13365.8672 - val_mean_absolute_error: 13365.8672\n",
      "Epoch 2717/3000\n",
      "11/18 [=================>............] - ETA: 0s - loss: 9195.9570 - mean_absolute_error: 9195.9570\n",
      "Epoch 2717: val_loss improved from 13365.86719 to 13365.48242, saving model to Weights-02717--13365.48242.hdf5\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9439.1650 - mean_absolute_error: 9439.1650 - val_loss: 13365.4824 - val_mean_absolute_error: 13365.4824\n",
      "Epoch 2718/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10897.6143 - mean_absolute_error: 10897.6143\n",
      "Epoch 2718: val_loss did not improve from 13365.48242\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9417.2158 - mean_absolute_error: 9417.2158 - val_loss: 13390.5918 - val_mean_absolute_error: 13390.5918\n",
      "Epoch 2719/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7740.0811 - mean_absolute_error: 7740.0811\n",
      "Epoch 2719: val_loss did not improve from 13365.48242\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9424.4443 - mean_absolute_error: 9424.4443 - val_loss: 13382.6611 - val_mean_absolute_error: 13382.6611\n",
      "Epoch 2720/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9507.9707 - mean_absolute_error: 9507.9707\n",
      "Epoch 2720: val_loss did not improve from 13365.48242\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9419.7344 - mean_absolute_error: 9419.7344 - val_loss: 13374.2734 - val_mean_absolute_error: 13374.2734\n",
      "Epoch 2721/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9127.4570 - mean_absolute_error: 9127.4570\n",
      "Epoch 2721: val_loss did not improve from 13365.48242\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9427.4443 - mean_absolute_error: 9427.4443 - val_loss: 13365.4844 - val_mean_absolute_error: 13365.4844\n",
      "Epoch 2722/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11001.9287 - mean_absolute_error: 11001.9287\n",
      "Epoch 2722: val_loss did not improve from 13365.48242\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9425.9873 - mean_absolute_error: 9425.9873 - val_loss: 13377.0312 - val_mean_absolute_error: 13377.0312\n",
      "Epoch 2723/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6301.2192 - mean_absolute_error: 6301.2192\n",
      "Epoch 2723: val_loss did not improve from 13365.48242\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9418.1924 - mean_absolute_error: 9418.1924 - val_loss: 13365.7256 - val_mean_absolute_error: 13365.7256\n",
      "Epoch 2724/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7723.6680 - mean_absolute_error: 7723.6680\n",
      "Epoch 2724: val_loss did not improve from 13365.48242\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9423.1602 - mean_absolute_error: 9423.1602 - val_loss: 13377.3428 - val_mean_absolute_error: 13377.3428\n",
      "Epoch 2725/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8246.0312 - mean_absolute_error: 8246.0312\n",
      "Epoch 2725: val_loss did not improve from 13365.48242\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9421.1504 - mean_absolute_error: 9421.1504 - val_loss: 13368.2871 - val_mean_absolute_error: 13368.2871\n",
      "Epoch 2726/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9565.2188 - mean_absolute_error: 9565.2188\n",
      "Epoch 2726: val_loss did not improve from 13365.48242\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9418.6553 - mean_absolute_error: 9418.6553 - val_loss: 13370.4707 - val_mean_absolute_error: 13370.4707\n",
      "Epoch 2727/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 14814.8770 - mean_absolute_error: 14814.8770\n",
      "Epoch 2727: val_loss did not improve from 13365.48242\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9422.2295 - mean_absolute_error: 9422.2295 - val_loss: 13376.4258 - val_mean_absolute_error: 13376.4258\n",
      "Epoch 2728/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8915.0225 - mean_absolute_error: 8915.0225\n",
      "Epoch 2728: val_loss did not improve from 13365.48242\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9419.7441 - mean_absolute_error: 9419.7441 - val_loss: 13370.5049 - val_mean_absolute_error: 13370.5049\n",
      "Epoch 2729/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12725.5312 - mean_absolute_error: 12725.5312\n",
      "Epoch 2729: val_loss did not improve from 13365.48242\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9422.8486 - mean_absolute_error: 9422.8486 - val_loss: 13370.3389 - val_mean_absolute_error: 13370.3389\n",
      "Epoch 2730/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9386.2676 - mean_absolute_error: 9386.2676\n",
      "Epoch 2730: val_loss improved from 13365.48242 to 13363.91406, saving model to Weights-02730--13363.91406.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9416.1260 - mean_absolute_error: 9416.1260 - val_loss: 13363.9141 - val_mean_absolute_error: 13363.9141\n",
      "Epoch 2731/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9332.2012 - mean_absolute_error: 9332.2012\n",
      "Epoch 2731: val_loss did not improve from 13363.91406\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9419.9727 - mean_absolute_error: 9419.9727 - val_loss: 13365.7656 - val_mean_absolute_error: 13365.7656\n",
      "Epoch 2732/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13269.6836 - mean_absolute_error: 13269.6836\n",
      "Epoch 2732: val_loss did not improve from 13363.91406\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9421.8770 - mean_absolute_error: 9421.8770 - val_loss: 13376.9395 - val_mean_absolute_error: 13376.9395\n",
      "Epoch 2733/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8303.6963 - mean_absolute_error: 8303.6963\n",
      "Epoch 2733: val_loss did not improve from 13363.91406\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9420.2373 - mean_absolute_error: 9420.2373 - val_loss: 13378.3506 - val_mean_absolute_error: 13378.3506\n",
      "Epoch 2734/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8700.0586 - mean_absolute_error: 8700.0586\n",
      "Epoch 2734: val_loss improved from 13363.91406 to 13363.51758, saving model to Weights-02734--13363.51758.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9428.0645 - mean_absolute_error: 9428.0645 - val_loss: 13363.5176 - val_mean_absolute_error: 13363.5176\n",
      "Epoch 2735/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9823.6641 - mean_absolute_error: 9823.6641\n",
      "Epoch 2735: val_loss did not improve from 13363.51758\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9430.7334 - mean_absolute_error: 9430.7334 - val_loss: 13367.6729 - val_mean_absolute_error: 13367.6729\n",
      "Epoch 2736/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9621.3740 - mean_absolute_error: 9621.3740\n",
      "Epoch 2736: val_loss did not improve from 13363.51758\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9420.4229 - mean_absolute_error: 9420.4229 - val_loss: 13391.7363 - val_mean_absolute_error: 13391.7363\n",
      "Epoch 2737/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8530.9121 - mean_absolute_error: 8530.9121\n",
      "Epoch 2737: val_loss did not improve from 13363.51758\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9421.6729 - mean_absolute_error: 9421.6729 - val_loss: 13377.3604 - val_mean_absolute_error: 13377.3604\n",
      "Epoch 2738/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10514.0439 - mean_absolute_error: 10514.0439\n",
      "Epoch 2738: val_loss did not improve from 13363.51758\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9415.1260 - mean_absolute_error: 9415.1260 - val_loss: 13364.6719 - val_mean_absolute_error: 13364.6719\n",
      "Epoch 2739/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9120.4160 - mean_absolute_error: 9120.4160\n",
      "Epoch 2739: val_loss did not improve from 13363.51758\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9422.0762 - mean_absolute_error: 9422.0762 - val_loss: 13368.9785 - val_mean_absolute_error: 13368.9785\n",
      "Epoch 2740/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7468.7422 - mean_absolute_error: 7468.7422\n",
      "Epoch 2740: val_loss improved from 13363.51758 to 13362.89355, saving model to Weights-02740--13362.89355.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9421.6650 - mean_absolute_error: 9421.6650 - val_loss: 13362.8936 - val_mean_absolute_error: 13362.8936\n",
      "Epoch 2741/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 14495.1299 - mean_absolute_error: 14495.1299\n",
      "Epoch 2741: val_loss did not improve from 13362.89355\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9420.9570 - mean_absolute_error: 9420.9570 - val_loss: 13378.1729 - val_mean_absolute_error: 13378.1729\n",
      "Epoch 2742/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10064.5840 - mean_absolute_error: 10064.5840\n",
      "Epoch 2742: val_loss did not improve from 13362.89355\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9433.1309 - mean_absolute_error: 9433.1309 - val_loss: 13372.4287 - val_mean_absolute_error: 13372.4287\n",
      "Epoch 2743/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7171.5547 - mean_absolute_error: 7171.5547\n",
      "Epoch 2743: val_loss did not improve from 13362.89355\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9417.8740 - mean_absolute_error: 9417.8740 - val_loss: 13381.9033 - val_mean_absolute_error: 13381.9033\n",
      "Epoch 2744/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8730.4199 - mean_absolute_error: 8730.4199\n",
      "Epoch 2744: val_loss did not improve from 13362.89355\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9421.3389 - mean_absolute_error: 9421.3389 - val_loss: 13378.9072 - val_mean_absolute_error: 13378.9072\n",
      "Epoch 2745/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9807.3975 - mean_absolute_error: 9807.3975\n",
      "Epoch 2745: val_loss did not improve from 13362.89355\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9428.1904 - mean_absolute_error: 9428.1904 - val_loss: 13374.8174 - val_mean_absolute_error: 13374.8174\n",
      "Epoch 2746/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8074.1108 - mean_absolute_error: 8074.1108\n",
      "Epoch 2746: val_loss did not improve from 13362.89355\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9419.3037 - mean_absolute_error: 9419.3037 - val_loss: 13369.3730 - val_mean_absolute_error: 13369.3730\n",
      "Epoch 2747/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5939.0664 - mean_absolute_error: 5939.0664\n",
      "Epoch 2747: val_loss did not improve from 13362.89355\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9417.9814 - mean_absolute_error: 9417.9814 - val_loss: 13371.4971 - val_mean_absolute_error: 13371.4971\n",
      "Epoch 2748/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10948.3164 - mean_absolute_error: 10948.3164\n",
      "Epoch 2748: val_loss improved from 13362.89355 to 13362.34863, saving model to Weights-02748--13362.34863.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9420.7393 - mean_absolute_error: 9420.7393 - val_loss: 13362.3486 - val_mean_absolute_error: 13362.3486\n",
      "Epoch 2749/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9196.2051 - mean_absolute_error: 9196.2051\n",
      "Epoch 2749: val_loss did not improve from 13362.34863\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9415.8682 - mean_absolute_error: 9415.8682 - val_loss: 13366.5566 - val_mean_absolute_error: 13366.5566\n",
      "Epoch 2750/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6070.0327 - mean_absolute_error: 6070.0327\n",
      "Epoch 2750: val_loss did not improve from 13362.34863\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9445.3359 - mean_absolute_error: 9445.3359 - val_loss: 13387.1562 - val_mean_absolute_error: 13387.1562\n",
      "Epoch 2751/3000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9167.1758 - mean_absolute_error: 9167.1758  \n",
      "Epoch 2751: val_loss improved from 13362.34863 to 13362.04102, saving model to Weights-02751--13362.04102.hdf5\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9433.0225 - mean_absolute_error: 9433.0225 - val_loss: 13362.0410 - val_mean_absolute_error: 13362.0410\n",
      "Epoch 2752/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10064.0703 - mean_absolute_error: 10064.0703\n",
      "Epoch 2752: val_loss did not improve from 13362.04102\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9417.6670 - mean_absolute_error: 9417.6670 - val_loss: 13368.7764 - val_mean_absolute_error: 13368.7764\n",
      "Epoch 2753/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11142.3115 - mean_absolute_error: 11142.3115\n",
      "Epoch 2753: val_loss did not improve from 13362.04102\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9420.5957 - mean_absolute_error: 9420.5957 - val_loss: 13371.2471 - val_mean_absolute_error: 13371.2471\n",
      "Epoch 2754/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9008.0742 - mean_absolute_error: 9008.0742\n",
      "Epoch 2754: val_loss did not improve from 13362.04102\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9413.3242 - mean_absolute_error: 9413.3242 - val_loss: 13362.3447 - val_mean_absolute_error: 13362.3447\n",
      "Epoch 2755/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11944.0195 - mean_absolute_error: 11944.0195\n",
      "Epoch 2755: val_loss did not improve from 13362.04102\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9420.4209 - mean_absolute_error: 9420.4209 - val_loss: 13365.4707 - val_mean_absolute_error: 13365.4707\n",
      "Epoch 2756/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10534.1719 - mean_absolute_error: 10534.1719\n",
      "Epoch 2756: val_loss did not improve from 13362.04102\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9418.6133 - mean_absolute_error: 9418.6133 - val_loss: 13374.6924 - val_mean_absolute_error: 13374.6924\n",
      "Epoch 2757/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9270.2012 - mean_absolute_error: 9270.2012\n",
      "Epoch 2757: val_loss did not improve from 13362.04102\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9425.2285 - mean_absolute_error: 9425.2285 - val_loss: 13362.2920 - val_mean_absolute_error: 13362.2920\n",
      "Epoch 2758/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8487.7998 - mean_absolute_error: 8487.7998\n",
      "Epoch 2758: val_loss did not improve from 13362.04102\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9420.3037 - mean_absolute_error: 9420.3037 - val_loss: 13364.1758 - val_mean_absolute_error: 13364.1758\n",
      "Epoch 2759/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6762.0684 - mean_absolute_error: 6762.0684\n",
      "Epoch 2759: val_loss did not improve from 13362.04102\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9422.0264 - mean_absolute_error: 9422.0264 - val_loss: 13373.2871 - val_mean_absolute_error: 13373.2871\n",
      "Epoch 2760/3000\n",
      "18/18 [==============================] - ETA: 0s - loss: 9416.5889 - mean_absolute_error: 9416.5889  \n",
      "Epoch 2760: val_loss did not improve from 13362.04102\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9416.5889 - mean_absolute_error: 9416.5889 - val_loss: 13372.3174 - val_mean_absolute_error: 13372.3174\n",
      "Epoch 2761/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8121.7549 - mean_absolute_error: 8121.7549\n",
      "Epoch 2761: val_loss did not improve from 13362.04102\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9418.9492 - mean_absolute_error: 9418.9492 - val_loss: 13366.2598 - val_mean_absolute_error: 13366.2598\n",
      "Epoch 2762/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7578.5273 - mean_absolute_error: 7578.5273\n",
      "Epoch 2762: val_loss improved from 13362.04102 to 13360.96973, saving model to Weights-02762--13360.96973.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9425.8076 - mean_absolute_error: 9425.8076 - val_loss: 13360.9697 - val_mean_absolute_error: 13360.9697\n",
      "Epoch 2763/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13625.1250 - mean_absolute_error: 13625.1250\n",
      "Epoch 2763: val_loss did not improve from 13360.96973\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9419.7822 - mean_absolute_error: 9419.7822 - val_loss: 13366.4434 - val_mean_absolute_error: 13366.4434\n",
      "Epoch 2764/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8391.1641 - mean_absolute_error: 8391.1641\n",
      "Epoch 2764: val_loss did not improve from 13360.96973\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9424.4424 - mean_absolute_error: 9424.4424 - val_loss: 13361.9385 - val_mean_absolute_error: 13361.9385\n",
      "Epoch 2765/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8742.5029 - mean_absolute_error: 8742.5029\n",
      "Epoch 2765: val_loss did not improve from 13360.96973\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9423.4033 - mean_absolute_error: 9423.4033 - val_loss: 13367.5322 - val_mean_absolute_error: 13367.5322\n",
      "Epoch 2766/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10141.6553 - mean_absolute_error: 10141.6553\n",
      "Epoch 2766: val_loss did not improve from 13360.96973\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9420.7861 - mean_absolute_error: 9420.7861 - val_loss: 13373.5811 - val_mean_absolute_error: 13373.5811\n",
      "Epoch 2767/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10715.8398 - mean_absolute_error: 10715.8398\n",
      "Epoch 2767: val_loss did not improve from 13360.96973\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9421.3496 - mean_absolute_error: 9421.3496 - val_loss: 13366.3389 - val_mean_absolute_error: 13366.3389\n",
      "Epoch 2768/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10834.3672 - mean_absolute_error: 10834.3672\n",
      "Epoch 2768: val_loss improved from 13360.96973 to 13360.45996, saving model to Weights-02768--13360.45996.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9425.9014 - mean_absolute_error: 9425.9014 - val_loss: 13360.4600 - val_mean_absolute_error: 13360.4600\n",
      "Epoch 2769/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8659.6973 - mean_absolute_error: 8659.6973\n",
      "Epoch 2769: val_loss did not improve from 13360.45996\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9413.8760 - mean_absolute_error: 9413.8760 - val_loss: 13373.7158 - val_mean_absolute_error: 13373.7158\n",
      "Epoch 2770/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11488.2207 - mean_absolute_error: 11488.2207\n",
      "Epoch 2770: val_loss did not improve from 13360.45996\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9417.1611 - mean_absolute_error: 9417.1611 - val_loss: 13383.1416 - val_mean_absolute_error: 13383.1416\n",
      "Epoch 2771/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12003.3350 - mean_absolute_error: 12003.3350\n",
      "Epoch 2771: val_loss did not improve from 13360.45996\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9420.1133 - mean_absolute_error: 9420.1133 - val_loss: 13381.5771 - val_mean_absolute_error: 13381.5771\n",
      "Epoch 2772/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8614.5938 - mean_absolute_error: 8614.5938\n",
      "Epoch 2772: val_loss did not improve from 13360.45996\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9415.1924 - mean_absolute_error: 9415.1924 - val_loss: 13364.3760 - val_mean_absolute_error: 13364.3760\n",
      "Epoch 2773/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9964.1230 - mean_absolute_error: 9964.1230\n",
      "Epoch 2773: val_loss did not improve from 13360.45996\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9417.0723 - mean_absolute_error: 9417.0723 - val_loss: 13361.0967 - val_mean_absolute_error: 13361.0967\n",
      "Epoch 2774/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12221.2246 - mean_absolute_error: 12221.2246\n",
      "Epoch 2774: val_loss did not improve from 13360.45996\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9450.0273 - mean_absolute_error: 9450.0273 - val_loss: 13377.4092 - val_mean_absolute_error: 13377.4092\n",
      "Epoch 2775/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8156.1011 - mean_absolute_error: 8156.1011\n",
      "Epoch 2775: val_loss did not improve from 13360.45996\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9411.0703 - mean_absolute_error: 9411.0703 - val_loss: 13360.7666 - val_mean_absolute_error: 13360.7666\n",
      "Epoch 2776/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8436.0137 - mean_absolute_error: 8436.0137\n",
      "Epoch 2776: val_loss improved from 13360.45996 to 13359.76074, saving model to Weights-02776--13359.76074.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9418.2061 - mean_absolute_error: 9418.2061 - val_loss: 13359.7607 - val_mean_absolute_error: 13359.7607\n",
      "Epoch 2777/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6910.6865 - mean_absolute_error: 6910.6865\n",
      "Epoch 2777: val_loss did not improve from 13359.76074\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9419.9014 - mean_absolute_error: 9419.9014 - val_loss: 13360.5557 - val_mean_absolute_error: 13360.5557\n",
      "Epoch 2778/3000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9399.8994 - mean_absolute_error: 9399.8994\n",
      "Epoch 2778: val_loss did not improve from 13359.76074\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9414.4844 - mean_absolute_error: 9414.4844 - val_loss: 13363.7412 - val_mean_absolute_error: 13363.7412\n",
      "Epoch 2779/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10040.2266 - mean_absolute_error: 10040.2266\n",
      "Epoch 2779: val_loss did not improve from 13359.76074\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9424.4316 - mean_absolute_error: 9424.4316 - val_loss: 13362.5928 - val_mean_absolute_error: 13362.5928\n",
      "Epoch 2780/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7728.9229 - mean_absolute_error: 7728.9229\n",
      "Epoch 2780: val_loss did not improve from 13359.76074\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9438.6719 - mean_absolute_error: 9438.6719 - val_loss: 13387.9072 - val_mean_absolute_error: 13387.9072\n",
      "Epoch 2781/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10405.5703 - mean_absolute_error: 10405.5703\n",
      "Epoch 2781: val_loss did not improve from 13359.76074\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9411.3848 - mean_absolute_error: 9411.3848 - val_loss: 13362.0029 - val_mean_absolute_error: 13362.0029\n",
      "Epoch 2782/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8058.6367 - mean_absolute_error: 8058.6367\n",
      "Epoch 2782: val_loss improved from 13359.76074 to 13359.71387, saving model to Weights-02782--13359.71387.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9424.3115 - mean_absolute_error: 9424.3115 - val_loss: 13359.7139 - val_mean_absolute_error: 13359.7139\n",
      "Epoch 2783/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7881.4561 - mean_absolute_error: 7881.4561\n",
      "Epoch 2783: val_loss did not improve from 13359.71387\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9422.1338 - mean_absolute_error: 9422.1338 - val_loss: 13361.4326 - val_mean_absolute_error: 13361.4326\n",
      "Epoch 2784/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8617.6230 - mean_absolute_error: 8617.6230\n",
      "Epoch 2784: val_loss did not improve from 13359.71387\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9414.8779 - mean_absolute_error: 9414.8779 - val_loss: 13377.9023 - val_mean_absolute_error: 13377.9023\n",
      "Epoch 2785/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6390.0957 - mean_absolute_error: 6390.0957\n",
      "Epoch 2785: val_loss did not improve from 13359.71387\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9415.1826 - mean_absolute_error: 9415.1826 - val_loss: 13371.5439 - val_mean_absolute_error: 13371.5439\n",
      "Epoch 2786/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8151.7432 - mean_absolute_error: 8151.7432\n",
      "Epoch 2786: val_loss did not improve from 13359.71387\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9416.7666 - mean_absolute_error: 9416.7666 - val_loss: 13359.7959 - val_mean_absolute_error: 13359.7959\n",
      "Epoch 2787/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7693.2314 - mean_absolute_error: 7693.2314\n",
      "Epoch 2787: val_loss did not improve from 13359.71387\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9422.3701 - mean_absolute_error: 9422.3701 - val_loss: 13376.8701 - val_mean_absolute_error: 13376.8701\n",
      "Epoch 2788/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11429.5762 - mean_absolute_error: 11429.5762\n",
      "Epoch 2788: val_loss did not improve from 13359.71387\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9424.0576 - mean_absolute_error: 9424.0576 - val_loss: 13362.3965 - val_mean_absolute_error: 13362.3965\n",
      "Epoch 2789/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9464.3447 - mean_absolute_error: 9464.3447\n",
      "Epoch 2789: val_loss did not improve from 13359.71387\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9417.3096 - mean_absolute_error: 9417.3096 - val_loss: 13366.1123 - val_mean_absolute_error: 13366.1123\n",
      "Epoch 2790/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8029.4512 - mean_absolute_error: 8029.4512\n",
      "Epoch 2790: val_loss did not improve from 13359.71387\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9421.8975 - mean_absolute_error: 9421.8975 - val_loss: 13360.6719 - val_mean_absolute_error: 13360.6719\n",
      "Epoch 2791/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8498.0186 - mean_absolute_error: 8498.0186\n",
      "Epoch 2791: val_loss did not improve from 13359.71387\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9412.5186 - mean_absolute_error: 9412.5186 - val_loss: 13364.2520 - val_mean_absolute_error: 13364.2520\n",
      "Epoch 2792/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7372.5977 - mean_absolute_error: 7372.5977\n",
      "Epoch 2792: val_loss did not improve from 13359.71387\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9419.3926 - mean_absolute_error: 9419.3926 - val_loss: 13361.3018 - val_mean_absolute_error: 13361.3018\n",
      "Epoch 2793/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8671.1104 - mean_absolute_error: 8671.1104\n",
      "Epoch 2793: val_loss did not improve from 13359.71387\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9418.9297 - mean_absolute_error: 9418.9297 - val_loss: 13370.7686 - val_mean_absolute_error: 13370.7686\n",
      "Epoch 2794/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 14100.9648 - mean_absolute_error: 14100.9648\n",
      "Epoch 2794: val_loss did not improve from 13359.71387\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9433.5547 - mean_absolute_error: 9433.5547 - val_loss: 13367.6191 - val_mean_absolute_error: 13367.6191\n",
      "Epoch 2795/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8479.7676 - mean_absolute_error: 8479.7676\n",
      "Epoch 2795: val_loss improved from 13359.71387 to 13359.22754, saving model to Weights-02795--13359.22754.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9415.9404 - mean_absolute_error: 9415.9404 - val_loss: 13359.2275 - val_mean_absolute_error: 13359.2275\n",
      "Epoch 2796/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10153.9766 - mean_absolute_error: 10153.9766\n",
      "Epoch 2796: val_loss did not improve from 13359.22754\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9415.1465 - mean_absolute_error: 9415.1465 - val_loss: 13360.4092 - val_mean_absolute_error: 13360.4092\n",
      "Epoch 2797/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7916.4844 - mean_absolute_error: 7916.4844\n",
      "Epoch 2797: val_loss did not improve from 13359.22754\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9415.1426 - mean_absolute_error: 9415.1426 - val_loss: 13371.2891 - val_mean_absolute_error: 13371.2891\n",
      "Epoch 2798/3000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 9250.4541 - mean_absolute_error: 9250.4541\n",
      "Epoch 2798: val_loss did not improve from 13359.22754\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9422.0576 - mean_absolute_error: 9422.0576 - val_loss: 13373.8643 - val_mean_absolute_error: 13373.8643\n",
      "Epoch 2799/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8069.9219 - mean_absolute_error: 8069.9219\n",
      "Epoch 2799: val_loss did not improve from 13359.22754\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9414.3926 - mean_absolute_error: 9414.3926 - val_loss: 13359.5234 - val_mean_absolute_error: 13359.5234\n",
      "Epoch 2800/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8138.7480 - mean_absolute_error: 8138.7480\n",
      "Epoch 2800: val_loss improved from 13359.22754 to 13357.57715, saving model to Weights-02800--13357.57715.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9422.9990 - mean_absolute_error: 9422.9990 - val_loss: 13357.5771 - val_mean_absolute_error: 13357.5771\n",
      "Epoch 2801/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9570.4082 - mean_absolute_error: 9570.4082\n",
      "Epoch 2801: val_loss did not improve from 13357.57715\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9417.0869 - mean_absolute_error: 9417.0869 - val_loss: 13360.6445 - val_mean_absolute_error: 13360.6445\n",
      "Epoch 2802/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12111.9375 - mean_absolute_error: 12111.9375\n",
      "Epoch 2802: val_loss did not improve from 13357.57715\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9413.2451 - mean_absolute_error: 9413.2451 - val_loss: 13363.3438 - val_mean_absolute_error: 13363.3438\n",
      "Epoch 2803/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8048.1836 - mean_absolute_error: 8048.1836\n",
      "Epoch 2803: val_loss did not improve from 13357.57715\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9418.6553 - mean_absolute_error: 9418.6553 - val_loss: 13382.1650 - val_mean_absolute_error: 13382.1650\n",
      "Epoch 2804/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9822.2793 - mean_absolute_error: 9822.2793\n",
      "Epoch 2804: val_loss did not improve from 13357.57715\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9419.6836 - mean_absolute_error: 9419.6836 - val_loss: 13381.3945 - val_mean_absolute_error: 13381.3945\n",
      "Epoch 2805/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8849.0488 - mean_absolute_error: 8849.0488\n",
      "Epoch 2805: val_loss did not improve from 13357.57715\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9414.1445 - mean_absolute_error: 9414.1445 - val_loss: 13365.0986 - val_mean_absolute_error: 13365.0986\n",
      "Epoch 2806/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8817.6055 - mean_absolute_error: 8817.6055\n",
      "Epoch 2806: val_loss did not improve from 13357.57715\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9414.8721 - mean_absolute_error: 9414.8721 - val_loss: 13358.7275 - val_mean_absolute_error: 13358.7275\n",
      "Epoch 2807/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8504.6611 - mean_absolute_error: 8504.6611\n",
      "Epoch 2807: val_loss did not improve from 13357.57715\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9414.8799 - mean_absolute_error: 9414.8799 - val_loss: 13358.6680 - val_mean_absolute_error: 13358.6680\n",
      "Epoch 2808/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 13640.9814 - mean_absolute_error: 13640.9814\n",
      "Epoch 2808: val_loss did not improve from 13357.57715\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9418.9971 - mean_absolute_error: 9418.9971 - val_loss: 13359.2637 - val_mean_absolute_error: 13359.2637\n",
      "Epoch 2809/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8675.2344 - mean_absolute_error: 8675.2344\n",
      "Epoch 2809: val_loss did not improve from 13357.57715\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9413.1602 - mean_absolute_error: 9413.1602 - val_loss: 13360.0264 - val_mean_absolute_error: 13360.0264\n",
      "Epoch 2810/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6486.6328 - mean_absolute_error: 6486.6328\n",
      "Epoch 2810: val_loss did not improve from 13357.57715\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9415.7354 - mean_absolute_error: 9415.7354 - val_loss: 13360.2266 - val_mean_absolute_error: 13360.2266\n",
      "Epoch 2811/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11731.6494 - mean_absolute_error: 11731.6494\n",
      "Epoch 2811: val_loss did not improve from 13357.57715\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9413.5811 - mean_absolute_error: 9413.5811 - val_loss: 13367.9980 - val_mean_absolute_error: 13367.9980\n",
      "Epoch 2812/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10363.9590 - mean_absolute_error: 10363.9590\n",
      "Epoch 2812: val_loss did not improve from 13357.57715\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9415.0957 - mean_absolute_error: 9415.0957 - val_loss: 13368.1670 - val_mean_absolute_error: 13368.1670\n",
      "Epoch 2813/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8946.7793 - mean_absolute_error: 8946.7793\n",
      "Epoch 2813: val_loss did not improve from 13357.57715\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9426.0107 - mean_absolute_error: 9426.0107 - val_loss: 13357.7139 - val_mean_absolute_error: 13357.7139\n",
      "Epoch 2814/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9128.9297 - mean_absolute_error: 9128.9297\n",
      "Epoch 2814: val_loss did not improve from 13357.57715\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9411.0615 - mean_absolute_error: 9411.0615 - val_loss: 13370.7900 - val_mean_absolute_error: 13370.7900\n",
      "Epoch 2815/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9135.3096 - mean_absolute_error: 9135.3096\n",
      "Epoch 2815: val_loss did not improve from 13357.57715\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9416.2676 - mean_absolute_error: 9416.2676 - val_loss: 13374.8799 - val_mean_absolute_error: 13374.8799\n",
      "Epoch 2816/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8950.8271 - mean_absolute_error: 8950.8271\n",
      "Epoch 2816: val_loss did not improve from 13357.57715\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9414.6562 - mean_absolute_error: 9414.6562 - val_loss: 13363.1143 - val_mean_absolute_error: 13363.1143\n",
      "Epoch 2817/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8057.1528 - mean_absolute_error: 8057.1528\n",
      "Epoch 2817: val_loss improved from 13357.57715 to 13356.08203, saving model to Weights-02817--13356.08203.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9417.3740 - mean_absolute_error: 9417.3740 - val_loss: 13356.0820 - val_mean_absolute_error: 13356.0820\n",
      "Epoch 2818/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10882.0020 - mean_absolute_error: 10882.0020\n",
      "Epoch 2818: val_loss did not improve from 13356.08203\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9454.2617 - mean_absolute_error: 9454.2617 - val_loss: 13380.7695 - val_mean_absolute_error: 13380.7695\n",
      "Epoch 2819/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11933.8066 - mean_absolute_error: 11933.8066\n",
      "Epoch 2819: val_loss did not improve from 13356.08203\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9441.0254 - mean_absolute_error: 9441.0254 - val_loss: 13357.0361 - val_mean_absolute_error: 13357.0361\n",
      "Epoch 2820/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9649.1738 - mean_absolute_error: 9649.1738\n",
      "Epoch 2820: val_loss did not improve from 13356.08203\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9418.4287 - mean_absolute_error: 9418.4287 - val_loss: 13364.9805 - val_mean_absolute_error: 13364.9805\n",
      "Epoch 2821/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9470.9502 - mean_absolute_error: 9470.9502\n",
      "Epoch 2821: val_loss did not improve from 13356.08203\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9415.8115 - mean_absolute_error: 9415.8115 - val_loss: 13364.1895 - val_mean_absolute_error: 13364.1895\n",
      "Epoch 2822/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7657.9805 - mean_absolute_error: 7657.9805\n",
      "Epoch 2822: val_loss did not improve from 13356.08203\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9412.8359 - mean_absolute_error: 9412.8359 - val_loss: 13356.1445 - val_mean_absolute_error: 13356.1445\n",
      "Epoch 2823/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11345.9023 - mean_absolute_error: 11345.9023\n",
      "Epoch 2823: val_loss did not improve from 13356.08203\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9419.0967 - mean_absolute_error: 9419.0967 - val_loss: 13361.8379 - val_mean_absolute_error: 13361.8379\n",
      "Epoch 2824/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7994.2441 - mean_absolute_error: 7994.2441\n",
      "Epoch 2824: val_loss improved from 13356.08203 to 13355.66602, saving model to Weights-02824--13355.66602.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9415.2383 - mean_absolute_error: 9415.2383 - val_loss: 13355.6660 - val_mean_absolute_error: 13355.6660\n",
      "Epoch 2825/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10463.9414 - mean_absolute_error: 10463.9414\n",
      "Epoch 2825: val_loss did not improve from 13355.66602\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9412.3164 - mean_absolute_error: 9412.3164 - val_loss: 13361.8086 - val_mean_absolute_error: 13361.8086\n",
      "Epoch 2826/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8059.5371 - mean_absolute_error: 8059.5371\n",
      "Epoch 2826: val_loss did not improve from 13355.66602\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9415.9521 - mean_absolute_error: 9415.9521 - val_loss: 13371.0449 - val_mean_absolute_error: 13371.0449\n",
      "Epoch 2827/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10808.1475 - mean_absolute_error: 10808.1475\n",
      "Epoch 2827: val_loss did not improve from 13355.66602\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9414.8203 - mean_absolute_error: 9414.8203 - val_loss: 13369.7031 - val_mean_absolute_error: 13369.7031\n",
      "Epoch 2828/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7276.1538 - mean_absolute_error: 7276.1538\n",
      "Epoch 2828: val_loss did not improve from 13355.66602\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9423.7422 - mean_absolute_error: 9423.7422 - val_loss: 13356.8467 - val_mean_absolute_error: 13356.8467\n",
      "Epoch 2829/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11190.4609 - mean_absolute_error: 11190.4609\n",
      "Epoch 2829: val_loss did not improve from 13355.66602\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9410.5039 - mean_absolute_error: 9410.5039 - val_loss: 13363.2490 - val_mean_absolute_error: 13363.2490\n",
      "Epoch 2830/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11333.4854 - mean_absolute_error: 11333.4854\n",
      "Epoch 2830: val_loss did not improve from 13355.66602\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9414.9893 - mean_absolute_error: 9414.9893 - val_loss: 13369.0283 - val_mean_absolute_error: 13369.0283\n",
      "Epoch 2831/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9066.6416 - mean_absolute_error: 9066.6416\n",
      "Epoch 2831: val_loss did not improve from 13355.66602\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9415.1084 - mean_absolute_error: 9415.1084 - val_loss: 13364.3359 - val_mean_absolute_error: 13364.3359\n",
      "Epoch 2832/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7347.8154 - mean_absolute_error: 7347.8154\n",
      "Epoch 2832: val_loss did not improve from 13355.66602\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9421.1953 - mean_absolute_error: 9421.1953 - val_loss: 13355.8066 - val_mean_absolute_error: 13355.8066\n",
      "Epoch 2833/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12155.8223 - mean_absolute_error: 12155.8223\n",
      "Epoch 2833: val_loss did not improve from 13355.66602\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9413.2725 - mean_absolute_error: 9413.2725 - val_loss: 13356.1904 - val_mean_absolute_error: 13356.1904\n",
      "Epoch 2834/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12063.0742 - mean_absolute_error: 12063.0742\n",
      "Epoch 2834: val_loss did not improve from 13355.66602\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9414.8984 - mean_absolute_error: 9414.8984 - val_loss: 13358.1172 - val_mean_absolute_error: 13358.1172\n",
      "Epoch 2835/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7820.5488 - mean_absolute_error: 7820.5488\n",
      "Epoch 2835: val_loss did not improve from 13355.66602\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9420.7656 - mean_absolute_error: 9420.7656 - val_loss: 13377.7051 - val_mean_absolute_error: 13377.7051\n",
      "Epoch 2836/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8871.3301 - mean_absolute_error: 8871.3301\n",
      "Epoch 2836: val_loss did not improve from 13355.66602\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9434.3486 - mean_absolute_error: 9434.3486 - val_loss: 13356.2979 - val_mean_absolute_error: 13356.2979\n",
      "Epoch 2837/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9156.2002 - mean_absolute_error: 9156.2002\n",
      "Epoch 2837: val_loss did not improve from 13355.66602\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9427.6816 - mean_absolute_error: 9427.6816 - val_loss: 13387.6387 - val_mean_absolute_error: 13387.6387\n",
      "Epoch 2838/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9435.0566 - mean_absolute_error: 9435.0566\n",
      "Epoch 2838: val_loss did not improve from 13355.66602\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9412.7783 - mean_absolute_error: 9412.7783 - val_loss: 13366.3828 - val_mean_absolute_error: 13366.3828\n",
      "Epoch 2839/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11315.8809 - mean_absolute_error: 11315.8809\n",
      "Epoch 2839: val_loss improved from 13355.66602 to 13355.46094, saving model to Weights-02839--13355.46094.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9421.8428 - mean_absolute_error: 9421.8428 - val_loss: 13355.4609 - val_mean_absolute_error: 13355.4609\n",
      "Epoch 2840/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9037.8896 - mean_absolute_error: 9037.8896\n",
      "Epoch 2840: val_loss did not improve from 13355.46094\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9408.7080 - mean_absolute_error: 9408.7080 - val_loss: 13367.6826 - val_mean_absolute_error: 13367.6826\n",
      "Epoch 2841/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9312.1035 - mean_absolute_error: 9312.1035\n",
      "Epoch 2841: val_loss did not improve from 13355.46094\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9413.3633 - mean_absolute_error: 9413.3633 - val_loss: 13365.7666 - val_mean_absolute_error: 13365.7666\n",
      "Epoch 2842/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9070.7520 - mean_absolute_error: 9070.7520\n",
      "Epoch 2842: val_loss did not improve from 13355.46094\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9415.3047 - mean_absolute_error: 9415.3047 - val_loss: 13360.3945 - val_mean_absolute_error: 13360.3945\n",
      "Epoch 2843/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10497.1035 - mean_absolute_error: 10497.1035\n",
      "Epoch 2843: val_loss did not improve from 13355.46094\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9413.1055 - mean_absolute_error: 9413.1055 - val_loss: 13356.4668 - val_mean_absolute_error: 13356.4668\n",
      "Epoch 2844/3000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9729.4902 - mean_absolute_error: 9729.4902\n",
      "Epoch 2844: val_loss did not improve from 13355.46094\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9412.8906 - mean_absolute_error: 9412.8906 - val_loss: 13364.1592 - val_mean_absolute_error: 13364.1592\n",
      "Epoch 2845/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9117.7715 - mean_absolute_error: 9117.7715\n",
      "Epoch 2845: val_loss did not improve from 13355.46094\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9414.8740 - mean_absolute_error: 9414.8740 - val_loss: 13356.3076 - val_mean_absolute_error: 13356.3076\n",
      "Epoch 2846/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8165.4551 - mean_absolute_error: 8165.4551\n",
      "Epoch 2846: val_loss did not improve from 13355.46094\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9419.4062 - mean_absolute_error: 9419.4062 - val_loss: 13365.9248 - val_mean_absolute_error: 13365.9248\n",
      "Epoch 2847/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8513.8379 - mean_absolute_error: 8513.8379\n",
      "Epoch 2847: val_loss did not improve from 13355.46094\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9408.9658 - mean_absolute_error: 9408.9658 - val_loss: 13356.0127 - val_mean_absolute_error: 13356.0127\n",
      "Epoch 2848/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10815.3242 - mean_absolute_error: 10815.3242\n",
      "Epoch 2848: val_loss improved from 13355.46094 to 13353.52246, saving model to Weights-02848--13353.52246.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9416.9053 - mean_absolute_error: 9416.9053 - val_loss: 13353.5225 - val_mean_absolute_error: 13353.5225\n",
      "Epoch 2849/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10379.5840 - mean_absolute_error: 10379.5840\n",
      "Epoch 2849: val_loss did not improve from 13353.52246\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9408.1494 - mean_absolute_error: 9408.1494 - val_loss: 13369.5449 - val_mean_absolute_error: 13369.5449\n",
      "Epoch 2850/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8089.6328 - mean_absolute_error: 8089.6328\n",
      "Epoch 2850: val_loss did not improve from 13353.52246\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9416.4951 - mean_absolute_error: 9416.4951 - val_loss: 13372.9277 - val_mean_absolute_error: 13372.9277\n",
      "Epoch 2851/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8351.9355 - mean_absolute_error: 8351.9355\n",
      "Epoch 2851: val_loss did not improve from 13353.52246\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9409.8965 - mean_absolute_error: 9409.8965 - val_loss: 13357.2178 - val_mean_absolute_error: 13357.2178\n",
      "Epoch 2852/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8404.9600 - mean_absolute_error: 8404.9600\n",
      "Epoch 2852: val_loss improved from 13353.52246 to 13353.38574, saving model to Weights-02852--13353.38574.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9416.8770 - mean_absolute_error: 9416.8770 - val_loss: 13353.3857 - val_mean_absolute_error: 13353.3857\n",
      "Epoch 2853/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9065.6582 - mean_absolute_error: 9065.6582\n",
      "Epoch 2853: val_loss did not improve from 13353.38574\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9410.2939 - mean_absolute_error: 9410.2939 - val_loss: 13359.4150 - val_mean_absolute_error: 13359.4150\n",
      "Epoch 2854/3000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9505.9287 - mean_absolute_error: 9505.9287  \n",
      "Epoch 2854: val_loss did not improve from 13353.38574\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9409.6738 - mean_absolute_error: 9409.6738 - val_loss: 13356.1572 - val_mean_absolute_error: 13356.1572\n",
      "Epoch 2855/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 14479.9668 - mean_absolute_error: 14479.9668\n",
      "Epoch 2855: val_loss did not improve from 13353.38574\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9411.0713 - mean_absolute_error: 9411.0713 - val_loss: 13357.1367 - val_mean_absolute_error: 13357.1367\n",
      "Epoch 2856/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9091.2070 - mean_absolute_error: 9091.2070\n",
      "Epoch 2856: val_loss improved from 13353.38574 to 13353.28027, saving model to Weights-02856--13353.28027.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9419.2275 - mean_absolute_error: 9419.2275 - val_loss: 13353.2803 - val_mean_absolute_error: 13353.2803\n",
      "Epoch 2857/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12941.7627 - mean_absolute_error: 12941.7627\n",
      "Epoch 2857: val_loss did not improve from 13353.28027\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9417.8867 - mean_absolute_error: 9417.8867 - val_loss: 13365.3711 - val_mean_absolute_error: 13365.3711\n",
      "Epoch 2858/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9285.5107 - mean_absolute_error: 9285.5107\n",
      "Epoch 2858: val_loss did not improve from 13353.28027\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9411.7676 - mean_absolute_error: 9411.7676 - val_loss: 13359.1104 - val_mean_absolute_error: 13359.1104\n",
      "Epoch 2859/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7595.5610 - mean_absolute_error: 7595.5610\n",
      "Epoch 2859: val_loss did not improve from 13353.28027\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9411.5156 - mean_absolute_error: 9411.5156 - val_loss: 13362.7451 - val_mean_absolute_error: 13362.7451\n",
      "Epoch 2860/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9653.5605 - mean_absolute_error: 9653.5605\n",
      "Epoch 2860: val_loss improved from 13353.28027 to 13353.09863, saving model to Weights-02860--13353.09863.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9432.5781 - mean_absolute_error: 9432.5781 - val_loss: 13353.0986 - val_mean_absolute_error: 13353.0986\n",
      "Epoch 2861/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9615.2148 - mean_absolute_error: 9615.2148\n",
      "Epoch 2861: val_loss did not improve from 13353.09863\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9414.2861 - mean_absolute_error: 9414.2861 - val_loss: 13383.8691 - val_mean_absolute_error: 13383.8691\n",
      "Epoch 2862/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6956.1182 - mean_absolute_error: 6956.1182\n",
      "Epoch 2862: val_loss did not improve from 13353.09863\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9425.2256 - mean_absolute_error: 9425.2256 - val_loss: 13376.2041 - val_mean_absolute_error: 13376.2041\n",
      "Epoch 2863/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12528.5020 - mean_absolute_error: 12528.5020\n",
      "Epoch 2863: val_loss did not improve from 13353.09863\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9407.9600 - mean_absolute_error: 9407.9600 - val_loss: 13360.9688 - val_mean_absolute_error: 13360.9688\n",
      "Epoch 2864/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8028.0210 - mean_absolute_error: 8028.0210\n",
      "Epoch 2864: val_loss did not improve from 13353.09863\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9428.7588 - mean_absolute_error: 9428.7588 - val_loss: 13354.3281 - val_mean_absolute_error: 13354.3281\n",
      "Epoch 2865/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9161.2422 - mean_absolute_error: 9161.2422\n",
      "Epoch 2865: val_loss did not improve from 13353.09863\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9411.8945 - mean_absolute_error: 9411.8945 - val_loss: 13361.2500 - val_mean_absolute_error: 13361.2500\n",
      "Epoch 2866/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8200.4893 - mean_absolute_error: 8200.4893\n",
      "Epoch 2866: val_loss did not improve from 13353.09863\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9420.6104 - mean_absolute_error: 9420.6104 - val_loss: 13362.0488 - val_mean_absolute_error: 13362.0488\n",
      "Epoch 2867/3000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9504.2812 - mean_absolute_error: 9504.2812\n",
      "Epoch 2867: val_loss did not improve from 13353.09863\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9423.9473 - mean_absolute_error: 9423.9473 - val_loss: 13377.9658 - val_mean_absolute_error: 13377.9658\n",
      "Epoch 2868/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9874.0625 - mean_absolute_error: 9874.0625\n",
      "Epoch 2868: val_loss improved from 13353.09863 to 13352.43262, saving model to Weights-02868--13352.43262.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9417.2998 - mean_absolute_error: 9417.2998 - val_loss: 13352.4326 - val_mean_absolute_error: 13352.4326\n",
      "Epoch 2869/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8540.9248 - mean_absolute_error: 8540.9248\n",
      "Epoch 2869: val_loss did not improve from 13352.43262\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9409.4629 - mean_absolute_error: 9409.4629 - val_loss: 13360.9297 - val_mean_absolute_error: 13360.9297\n",
      "Epoch 2870/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9874.7207 - mean_absolute_error: 9874.7207\n",
      "Epoch 2870: val_loss did not improve from 13352.43262\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9411.0537 - mean_absolute_error: 9411.0537 - val_loss: 13359.1133 - val_mean_absolute_error: 13359.1133\n",
      "Epoch 2871/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5819.0366 - mean_absolute_error: 5819.0366\n",
      "Epoch 2871: val_loss did not improve from 13352.43262\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9413.8740 - mean_absolute_error: 9413.8740 - val_loss: 13354.3057 - val_mean_absolute_error: 13354.3057\n",
      "Epoch 2872/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 4687.7788 - mean_absolute_error: 4687.7788\n",
      "Epoch 2872: val_loss did not improve from 13352.43262\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9411.8076 - mean_absolute_error: 9411.8076 - val_loss: 13353.6094 - val_mean_absolute_error: 13353.6094\n",
      "Epoch 2873/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9475.4551 - mean_absolute_error: 9475.4551\n",
      "Epoch 2873: val_loss did not improve from 13352.43262\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9411.8066 - mean_absolute_error: 9411.8066 - val_loss: 13367.7920 - val_mean_absolute_error: 13367.7920\n",
      "Epoch 2874/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9920.4512 - mean_absolute_error: 9920.4512\n",
      "Epoch 2874: val_loss did not improve from 13352.43262\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9417.1016 - mean_absolute_error: 9417.1016 - val_loss: 13366.0195 - val_mean_absolute_error: 13366.0195\n",
      "Epoch 2875/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11541.0898 - mean_absolute_error: 11541.0898\n",
      "Epoch 2875: val_loss did not improve from 13352.43262\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9419.1992 - mean_absolute_error: 9419.1992 - val_loss: 13371.5615 - val_mean_absolute_error: 13371.5615\n",
      "Epoch 2876/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7619.5176 - mean_absolute_error: 7619.5176\n",
      "Epoch 2876: val_loss did not improve from 13352.43262\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9411.2148 - mean_absolute_error: 9411.2148 - val_loss: 13356.9990 - val_mean_absolute_error: 13356.9990\n",
      "Epoch 2877/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8784.1094 - mean_absolute_error: 8784.1094\n",
      "Epoch 2877: val_loss did not improve from 13352.43262\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9410.6572 - mean_absolute_error: 9410.6572 - val_loss: 13352.4346 - val_mean_absolute_error: 13352.4346\n",
      "Epoch 2878/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5839.9785 - mean_absolute_error: 5839.9785\n",
      "Epoch 2878: val_loss did not improve from 13352.43262\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9415.6230 - mean_absolute_error: 9415.6230 - val_loss: 13359.2764 - val_mean_absolute_error: 13359.2764\n",
      "Epoch 2879/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8066.1924 - mean_absolute_error: 8066.1924\n",
      "Epoch 2879: val_loss improved from 13352.43262 to 13351.25391, saving model to Weights-02879--13351.25391.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9409.2979 - mean_absolute_error: 9409.2979 - val_loss: 13351.2539 - val_mean_absolute_error: 13351.2529\n",
      "Epoch 2880/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9438.9648 - mean_absolute_error: 9438.9648\n",
      "Epoch 2880: val_loss did not improve from 13351.25391\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9410.0137 - mean_absolute_error: 9410.0137 - val_loss: 13358.2031 - val_mean_absolute_error: 13358.2031\n",
      "Epoch 2881/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7606.0884 - mean_absolute_error: 7606.0884\n",
      "Epoch 2881: val_loss improved from 13351.25391 to 13351.15820, saving model to Weights-02881--13351.15820.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9408.5566 - mean_absolute_error: 9408.5566 - val_loss: 13351.1582 - val_mean_absolute_error: 13351.1582\n",
      "Epoch 2882/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8545.2695 - mean_absolute_error: 8545.2695\n",
      "Epoch 2882: val_loss did not improve from 13351.15820\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9411.0244 - mean_absolute_error: 9411.0244 - val_loss: 13356.6846 - val_mean_absolute_error: 13356.6846\n",
      "Epoch 2883/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8140.9023 - mean_absolute_error: 8140.9023\n",
      "Epoch 2883: val_loss improved from 13351.15820 to 13350.43848, saving model to Weights-02883--13350.43848.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9415.6260 - mean_absolute_error: 9415.6260 - val_loss: 13350.4385 - val_mean_absolute_error: 13350.4385\n",
      "Epoch 2884/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10729.0137 - mean_absolute_error: 10729.0137\n",
      "Epoch 2884: val_loss did not improve from 13350.43848\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9420.2041 - mean_absolute_error: 9420.2041 - val_loss: 13360.1484 - val_mean_absolute_error: 13360.1484\n",
      "Epoch 2885/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9915.5117 - mean_absolute_error: 9915.5117\n",
      "Epoch 2885: val_loss did not improve from 13350.43848\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9410.6523 - mean_absolute_error: 9410.6523 - val_loss: 13351.1699 - val_mean_absolute_error: 13351.1699\n",
      "Epoch 2886/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9273.2559 - mean_absolute_error: 9273.2559\n",
      "Epoch 2886: val_loss did not improve from 13350.43848\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9421.7734 - mean_absolute_error: 9421.7734 - val_loss: 13359.4805 - val_mean_absolute_error: 13359.4805\n",
      "Epoch 2887/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5738.3452 - mean_absolute_error: 5738.3452\n",
      "Epoch 2887: val_loss did not improve from 13350.43848\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9419.1982 - mean_absolute_error: 9419.1982 - val_loss: 13355.6094 - val_mean_absolute_error: 13355.6094\n",
      "Epoch 2888/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9674.2217 - mean_absolute_error: 9674.2217\n",
      "Epoch 2888: val_loss did not improve from 13350.43848\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9415.0576 - mean_absolute_error: 9415.0576 - val_loss: 13362.2021 - val_mean_absolute_error: 13362.2021\n",
      "Epoch 2889/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10057.2227 - mean_absolute_error: 10057.2227\n",
      "Epoch 2889: val_loss did not improve from 13350.43848\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9421.2461 - mean_absolute_error: 9421.2461 - val_loss: 13375.6318 - val_mean_absolute_error: 13375.6318\n",
      "Epoch 2890/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7188.8232 - mean_absolute_error: 7188.8232\n",
      "Epoch 2890: val_loss did not improve from 13350.43848\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9412.2344 - mean_absolute_error: 9412.2344 - val_loss: 13352.2910 - val_mean_absolute_error: 13352.2910\n",
      "Epoch 2891/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11356.4980 - mean_absolute_error: 11356.4980\n",
      "Epoch 2891: val_loss did not improve from 13350.43848\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9409.7832 - mean_absolute_error: 9409.7832 - val_loss: 13351.6250 - val_mean_absolute_error: 13351.6250\n",
      "Epoch 2892/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8130.9814 - mean_absolute_error: 8130.9814\n",
      "Epoch 2892: val_loss did not improve from 13350.43848\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9410.6953 - mean_absolute_error: 9410.6953 - val_loss: 13358.5049 - val_mean_absolute_error: 13358.5049\n",
      "Epoch 2893/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9381.2920 - mean_absolute_error: 9381.2920\n",
      "Epoch 2893: val_loss improved from 13350.43848 to 13349.96387, saving model to Weights-02893--13349.96387.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9407.2822 - mean_absolute_error: 9407.2822 - val_loss: 13349.9639 - val_mean_absolute_error: 13349.9639\n",
      "Epoch 2894/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6266.5933 - mean_absolute_error: 6266.5933\n",
      "Epoch 2894: val_loss did not improve from 13349.96387\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9414.5000 - mean_absolute_error: 9414.5000 - val_loss: 13353.4902 - val_mean_absolute_error: 13353.4902\n",
      "Epoch 2895/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9645.9336 - mean_absolute_error: 9645.9336\n",
      "Epoch 2895: val_loss improved from 13349.96387 to 13349.08887, saving model to Weights-02895--13349.08887.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9417.9082 - mean_absolute_error: 9417.9082 - val_loss: 13349.0889 - val_mean_absolute_error: 13349.0889\n",
      "Epoch 2896/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10465.3750 - mean_absolute_error: 10465.3750\n",
      "Epoch 2896: val_loss did not improve from 13349.08887\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9411.1846 - mean_absolute_error: 9411.1846 - val_loss: 13369.5371 - val_mean_absolute_error: 13369.5371\n",
      "Epoch 2897/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8942.3760 - mean_absolute_error: 8942.3760\n",
      "Epoch 2897: val_loss did not improve from 13349.08887\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9414.2969 - mean_absolute_error: 9414.2969 - val_loss: 13354.9482 - val_mean_absolute_error: 13354.9482\n",
      "Epoch 2898/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7649.8877 - mean_absolute_error: 7649.8877\n",
      "Epoch 2898: val_loss did not improve from 13349.08887\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9408.4805 - mean_absolute_error: 9408.4805 - val_loss: 13360.9912 - val_mean_absolute_error: 13360.9912\n",
      "Epoch 2899/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10226.2852 - mean_absolute_error: 10226.2852\n",
      "Epoch 2899: val_loss did not improve from 13349.08887\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9410.5723 - mean_absolute_error: 9410.5723 - val_loss: 13359.6768 - val_mean_absolute_error: 13359.6768\n",
      "Epoch 2900/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8657.5547 - mean_absolute_error: 8657.5547\n",
      "Epoch 2900: val_loss improved from 13349.08887 to 13348.60352, saving model to Weights-02900--13348.60352.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9411.4287 - mean_absolute_error: 9411.4287 - val_loss: 13348.6035 - val_mean_absolute_error: 13348.6035\n",
      "Epoch 2901/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8285.5273 - mean_absolute_error: 8285.5273\n",
      "Epoch 2901: val_loss did not improve from 13348.60352\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9409.0420 - mean_absolute_error: 9409.0420 - val_loss: 13350.7393 - val_mean_absolute_error: 13350.7393\n",
      "Epoch 2902/3000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9441.2432 - mean_absolute_error: 9441.2432  \n",
      "Epoch 2902: val_loss did not improve from 13348.60352\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9410.3477 - mean_absolute_error: 9410.3477 - val_loss: 13365.8848 - val_mean_absolute_error: 13365.8848\n",
      "Epoch 2903/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9025.2686 - mean_absolute_error: 9025.2686\n",
      "Epoch 2903: val_loss did not improve from 13348.60352\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9416.8066 - mean_absolute_error: 9416.8066 - val_loss: 13362.1914 - val_mean_absolute_error: 13362.1914\n",
      "Epoch 2904/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10327.5508 - mean_absolute_error: 10327.5508\n",
      "Epoch 2904: val_loss improved from 13348.60352 to 13348.45410, saving model to Weights-02904--13348.45410.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9407.4414 - mean_absolute_error: 9407.4414 - val_loss: 13348.4541 - val_mean_absolute_error: 13348.4541\n",
      "Epoch 2905/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9269.2363 - mean_absolute_error: 9269.2363\n",
      "Epoch 2905: val_loss did not improve from 13348.45410\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9409.8916 - mean_absolute_error: 9409.8916 - val_loss: 13352.8389 - val_mean_absolute_error: 13352.8389\n",
      "Epoch 2906/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9242.8154 - mean_absolute_error: 9242.8154\n",
      "Epoch 2906: val_loss did not improve from 13348.45410\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9408.9395 - mean_absolute_error: 9408.9395 - val_loss: 13354.4648 - val_mean_absolute_error: 13354.4648\n",
      "Epoch 2907/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9149.5146 - mean_absolute_error: 9149.5146\n",
      "Epoch 2907: val_loss did not improve from 13348.45410\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9407.7158 - mean_absolute_error: 9407.7158 - val_loss: 13354.3057 - val_mean_absolute_error: 13354.3057\n",
      "Epoch 2908/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8243.7637 - mean_absolute_error: 8243.7637\n",
      "Epoch 2908: val_loss did not improve from 13348.45410\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9406.7881 - mean_absolute_error: 9406.7881 - val_loss: 13358.9951 - val_mean_absolute_error: 13358.9951\n",
      "Epoch 2909/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8002.1260 - mean_absolute_error: 8002.1260\n",
      "Epoch 2909: val_loss did not improve from 13348.45410\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9406.7451 - mean_absolute_error: 9406.7451 - val_loss: 13353.5098 - val_mean_absolute_error: 13353.5098\n",
      "Epoch 2910/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7516.1182 - mean_absolute_error: 7516.1182\n",
      "Epoch 2910: val_loss did not improve from 13348.45410\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9412.9180 - mean_absolute_error: 9412.9180 - val_loss: 13355.0312 - val_mean_absolute_error: 13355.0312\n",
      "Epoch 2911/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 15400.5771 - mean_absolute_error: 15400.5771\n",
      "Epoch 2911: val_loss did not improve from 13348.45410\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9411.2373 - mean_absolute_error: 9411.2373 - val_loss: 13349.5537 - val_mean_absolute_error: 13349.5537\n",
      "Epoch 2912/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10946.1592 - mean_absolute_error: 10946.1592\n",
      "Epoch 2912: val_loss did not improve from 13348.45410\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9407.6553 - mean_absolute_error: 9407.6553 - val_loss: 13352.2676 - val_mean_absolute_error: 13352.2676\n",
      "Epoch 2913/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9053.3398 - mean_absolute_error: 9053.3398\n",
      "Epoch 2913: val_loss did not improve from 13348.45410\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9406.3887 - mean_absolute_error: 9406.3887 - val_loss: 13356.2588 - val_mean_absolute_error: 13356.2588\n",
      "Epoch 2914/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8988.4180 - mean_absolute_error: 8988.4180\n",
      "Epoch 2914: val_loss did not improve from 13348.45410\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9406.8125 - mean_absolute_error: 9406.8125 - val_loss: 13357.3838 - val_mean_absolute_error: 13357.3838\n",
      "Epoch 2915/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12500.5820 - mean_absolute_error: 12500.5820\n",
      "Epoch 2915: val_loss did not improve from 13348.45410\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9415.0449 - mean_absolute_error: 9415.0449 - val_loss: 13357.9883 - val_mean_absolute_error: 13357.9883\n",
      "Epoch 2916/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11395.8301 - mean_absolute_error: 11395.8301\n",
      "Epoch 2916: val_loss did not improve from 13348.45410\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9410.7627 - mean_absolute_error: 9410.7627 - val_loss: 13349.2305 - val_mean_absolute_error: 13349.2305\n",
      "Epoch 2917/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8690.9824 - mean_absolute_error: 8690.9824\n",
      "Epoch 2917: val_loss did not improve from 13348.45410\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9407.0342 - mean_absolute_error: 9407.0342 - val_loss: 13358.5381 - val_mean_absolute_error: 13358.5381\n",
      "Epoch 2918/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9128.4736 - mean_absolute_error: 9128.4736\n",
      "Epoch 2918: val_loss did not improve from 13348.45410\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9408.9199 - mean_absolute_error: 9408.9199 - val_loss: 13368.8467 - val_mean_absolute_error: 13368.8467\n",
      "Epoch 2919/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9618.7393 - mean_absolute_error: 9618.7393\n",
      "Epoch 2919: val_loss did not improve from 13348.45410\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9418.4990 - mean_absolute_error: 9418.4990 - val_loss: 13354.7217 - val_mean_absolute_error: 13354.7217\n",
      "Epoch 2920/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7510.6729 - mean_absolute_error: 7510.6729\n",
      "Epoch 2920: val_loss did not improve from 13348.45410\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9404.8389 - mean_absolute_error: 9404.8389 - val_loss: 13349.8896 - val_mean_absolute_error: 13349.8896\n",
      "Epoch 2921/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8793.4453 - mean_absolute_error: 8793.4453\n",
      "Epoch 2921: val_loss did not improve from 13348.45410\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9421.1104 - mean_absolute_error: 9421.1104 - val_loss: 13354.8604 - val_mean_absolute_error: 13354.8604\n",
      "Epoch 2922/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9922.2695 - mean_absolute_error: 9922.2695\n",
      "Epoch 2922: val_loss improved from 13348.45410 to 13346.73242, saving model to Weights-02922--13346.73242.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9414.9141 - mean_absolute_error: 9414.9141 - val_loss: 13346.7324 - val_mean_absolute_error: 13346.7324\n",
      "Epoch 2923/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9479.4785 - mean_absolute_error: 9479.4785\n",
      "Epoch 2923: val_loss did not improve from 13346.73242\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9408.7021 - mean_absolute_error: 9408.7021 - val_loss: 13356.8799 - val_mean_absolute_error: 13356.8799\n",
      "Epoch 2924/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11095.5195 - mean_absolute_error: 11095.5195\n",
      "Epoch 2924: val_loss improved from 13346.73242 to 13346.12988, saving model to Weights-02924--13346.12988.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9407.5479 - mean_absolute_error: 9407.5479 - val_loss: 13346.1299 - val_mean_absolute_error: 13346.1299\n",
      "Epoch 2925/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10837.5684 - mean_absolute_error: 10837.5684\n",
      "Epoch 2925: val_loss did not improve from 13346.12988\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9416.2148 - mean_absolute_error: 9416.2148 - val_loss: 13356.6045 - val_mean_absolute_error: 13356.6045\n",
      "Epoch 2926/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11560.2432 - mean_absolute_error: 11560.2432\n",
      "Epoch 2926: val_loss did not improve from 13346.12988\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9408.2188 - mean_absolute_error: 9408.2188 - val_loss: 13349.1211 - val_mean_absolute_error: 13349.1211\n",
      "Epoch 2927/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9675.0059 - mean_absolute_error: 9675.0059\n",
      "Epoch 2927: val_loss did not improve from 13346.12988\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9404.5469 - mean_absolute_error: 9404.5469 - val_loss: 13347.0020 - val_mean_absolute_error: 13347.0020\n",
      "Epoch 2928/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11185.7861 - mean_absolute_error: 11185.7861\n",
      "Epoch 2928: val_loss did not improve from 13346.12988\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9403.2334 - mean_absolute_error: 9403.2334 - val_loss: 13353.5488 - val_mean_absolute_error: 13353.5488\n",
      "Epoch 2929/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8743.1230 - mean_absolute_error: 8743.1230\n",
      "Epoch 2929: val_loss did not improve from 13346.12988\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9413.2490 - mean_absolute_error: 9413.2490 - val_loss: 13364.3428 - val_mean_absolute_error: 13364.3428\n",
      "Epoch 2930/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10581.9980 - mean_absolute_error: 10581.9980\n",
      "Epoch 2930: val_loss did not improve from 13346.12988\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9405.9248 - mean_absolute_error: 9405.9248 - val_loss: 13348.0352 - val_mean_absolute_error: 13348.0352\n",
      "Epoch 2931/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12494.0195 - mean_absolute_error: 12494.0195\n",
      "Epoch 2931: val_loss did not improve from 13346.12988\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9414.1406 - mean_absolute_error: 9414.1406 - val_loss: 13359.3613 - val_mean_absolute_error: 13359.3613\n",
      "Epoch 2932/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8148.8452 - mean_absolute_error: 8148.8452\n",
      "Epoch 2932: val_loss did not improve from 13346.12988\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9403.5322 - mean_absolute_error: 9403.5322 - val_loss: 13347.4551 - val_mean_absolute_error: 13347.4551\n",
      "Epoch 2933/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8207.1836 - mean_absolute_error: 8207.1836\n",
      "Epoch 2933: val_loss improved from 13346.12988 to 13345.23535, saving model to Weights-02933--13345.23535.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9411.3701 - mean_absolute_error: 9411.3701 - val_loss: 13345.2354 - val_mean_absolute_error: 13345.2354\n",
      "Epoch 2934/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10851.8750 - mean_absolute_error: 10851.8750\n",
      "Epoch 2934: val_loss did not improve from 13345.23535\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9409.9736 - mean_absolute_error: 9409.9736 - val_loss: 13347.8721 - val_mean_absolute_error: 13347.8721\n",
      "Epoch 2935/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6794.4775 - mean_absolute_error: 6794.4775\n",
      "Epoch 2935: val_loss did not improve from 13345.23535\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9423.8555 - mean_absolute_error: 9423.8555 - val_loss: 13347.6533 - val_mean_absolute_error: 13347.6533\n",
      "Epoch 2936/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9285.2539 - mean_absolute_error: 9285.2539\n",
      "Epoch 2936: val_loss did not improve from 13345.23535\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9449.6846 - mean_absolute_error: 9449.6846 - val_loss: 13373.1074 - val_mean_absolute_error: 13373.1074\n",
      "Epoch 2937/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9093.8223 - mean_absolute_error: 9093.8223\n",
      "Epoch 2937: val_loss did not improve from 13345.23535\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9409.4258 - mean_absolute_error: 9409.4258 - val_loss: 13347.3818 - val_mean_absolute_error: 13347.3818\n",
      "Epoch 2938/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12118.8457 - mean_absolute_error: 12118.8457\n",
      "Epoch 2938: val_loss did not improve from 13345.23535\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9405.8076 - mean_absolute_error: 9405.8076 - val_loss: 13347.6709 - val_mean_absolute_error: 13347.6709\n",
      "Epoch 2939/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8053.2012 - mean_absolute_error: 8053.2012\n",
      "Epoch 2939: val_loss did not improve from 13345.23535\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9411.1826 - mean_absolute_error: 9411.1826 - val_loss: 13363.4424 - val_mean_absolute_error: 13363.4424\n",
      "Epoch 2940/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11065.6211 - mean_absolute_error: 11065.6211\n",
      "Epoch 2940: val_loss did not improve from 13345.23535\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9406.6680 - mean_absolute_error: 9406.6680 - val_loss: 13357.2715 - val_mean_absolute_error: 13357.2715\n",
      "Epoch 2941/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8369.6377 - mean_absolute_error: 8369.6377\n",
      "Epoch 2941: val_loss did not improve from 13345.23535\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9412.8447 - mean_absolute_error: 9412.8447 - val_loss: 13346.2080 - val_mean_absolute_error: 13346.2080\n",
      "Epoch 2942/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12556.5176 - mean_absolute_error: 12556.5176\n",
      "Epoch 2942: val_loss did not improve from 13345.23535\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9403.8398 - mean_absolute_error: 9403.8398 - val_loss: 13349.0479 - val_mean_absolute_error: 13349.0479\n",
      "Epoch 2943/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9037.2266 - mean_absolute_error: 9037.2266\n",
      "Epoch 2943: val_loss did not improve from 13345.23535\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9407.7568 - mean_absolute_error: 9407.7568 - val_loss: 13358.3906 - val_mean_absolute_error: 13358.3906\n",
      "Epoch 2944/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12822.3857 - mean_absolute_error: 12822.3857\n",
      "Epoch 2944: val_loss did not improve from 13345.23535\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9411.4160 - mean_absolute_error: 9411.4160 - val_loss: 13347.4863 - val_mean_absolute_error: 13347.4863\n",
      "Epoch 2945/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8878.3809 - mean_absolute_error: 8878.3809\n",
      "Epoch 2945: val_loss did not improve from 13345.23535\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9407.4639 - mean_absolute_error: 9407.4639 - val_loss: 13345.8789 - val_mean_absolute_error: 13345.8789\n",
      "Epoch 2946/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9432.5693 - mean_absolute_error: 9432.5693\n",
      "Epoch 2946: val_loss did not improve from 13345.23535\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9405.4326 - mean_absolute_error: 9405.4326 - val_loss: 13362.2129 - val_mean_absolute_error: 13362.2129\n",
      "Epoch 2947/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12090.8516 - mean_absolute_error: 12090.8516\n",
      "Epoch 2947: val_loss did not improve from 13345.23535\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9408.1699 - mean_absolute_error: 9408.1699 - val_loss: 13358.1953 - val_mean_absolute_error: 13358.1953\n",
      "Epoch 2948/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12444.6250 - mean_absolute_error: 12444.6250\n",
      "Epoch 2948: val_loss did not improve from 13345.23535\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9406.3203 - mean_absolute_error: 9406.3203 - val_loss: 13353.0781 - val_mean_absolute_error: 13353.0781\n",
      "Epoch 2949/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8983.8916 - mean_absolute_error: 8983.8916\n",
      "Epoch 2949: val_loss did not improve from 13345.23535\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9413.0820 - mean_absolute_error: 9413.0820 - val_loss: 13347.2471 - val_mean_absolute_error: 13347.2471\n",
      "Epoch 2950/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8441.6230 - mean_absolute_error: 8441.6230\n",
      "Epoch 2950: val_loss did not improve from 13345.23535\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9404.9746 - mean_absolute_error: 9404.9746 - val_loss: 13350.1162 - val_mean_absolute_error: 13350.1162\n",
      "Epoch 2951/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7589.2788 - mean_absolute_error: 7589.2788\n",
      "Epoch 2951: val_loss did not improve from 13345.23535\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9411.7979 - mean_absolute_error: 9411.7979 - val_loss: 13355.5498 - val_mean_absolute_error: 13355.5498\n",
      "Epoch 2952/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10226.7422 - mean_absolute_error: 10226.7422\n",
      "Epoch 2952: val_loss did not improve from 13345.23535\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9403.6533 - mean_absolute_error: 9403.6533 - val_loss: 13346.2861 - val_mean_absolute_error: 13346.2861\n",
      "Epoch 2953/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10308.9121 - mean_absolute_error: 10308.9121\n",
      "Epoch 2953: val_loss improved from 13345.23535 to 13343.80664, saving model to Weights-02953--13343.80664.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9409.0889 - mean_absolute_error: 9409.0889 - val_loss: 13343.8066 - val_mean_absolute_error: 13343.8066\n",
      "Epoch 2954/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11796.4355 - mean_absolute_error: 11796.4355\n",
      "Epoch 2954: val_loss did not improve from 13343.80664\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9407.7656 - mean_absolute_error: 9407.7656 - val_loss: 13347.8701 - val_mean_absolute_error: 13347.8701\n",
      "Epoch 2955/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8389.5059 - mean_absolute_error: 8389.5059\n",
      "Epoch 2955: val_loss did not improve from 13343.80664\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9405.1230 - mean_absolute_error: 9405.1230 - val_loss: 13356.5391 - val_mean_absolute_error: 13356.5391\n",
      "Epoch 2956/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8665.7764 - mean_absolute_error: 8665.7764\n",
      "Epoch 2956: val_loss did not improve from 13343.80664\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9411.4229 - mean_absolute_error: 9411.4229 - val_loss: 13355.2490 - val_mean_absolute_error: 13355.2490\n",
      "Epoch 2957/3000\n",
      "11/18 [=================>............] - ETA: 0s - loss: 9488.2314 - mean_absolute_error: 9488.2314\n",
      "Epoch 2957: val_loss did not improve from 13343.80664\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9410.4785 - mean_absolute_error: 9410.4785 - val_loss: 13346.1055 - val_mean_absolute_error: 13346.1055\n",
      "Epoch 2958/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7901.5713 - mean_absolute_error: 7901.5713\n",
      "Epoch 2958: val_loss did not improve from 13343.80664\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9405.0947 - mean_absolute_error: 9405.0947 - val_loss: 13349.4990 - val_mean_absolute_error: 13349.4990\n",
      "Epoch 2959/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10024.3164 - mean_absolute_error: 10024.3164\n",
      "Epoch 2959: val_loss improved from 13343.80664 to 13343.45215, saving model to Weights-02959--13343.45215.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9408.7041 - mean_absolute_error: 9408.7041 - val_loss: 13343.4521 - val_mean_absolute_error: 13343.4521\n",
      "Epoch 2960/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6313.9204 - mean_absolute_error: 6313.9204\n",
      "Epoch 2960: val_loss did not improve from 13343.45215\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9406.0742 - mean_absolute_error: 9406.0742 - val_loss: 13358.7998 - val_mean_absolute_error: 13358.7998\n",
      "Epoch 2961/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9799.3281 - mean_absolute_error: 9799.3281\n",
      "Epoch 2961: val_loss did not improve from 13343.45215\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9408.4561 - mean_absolute_error: 9408.4561 - val_loss: 13348.5215 - val_mean_absolute_error: 13348.5205\n",
      "Epoch 2962/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9203.0645 - mean_absolute_error: 9203.0645\n",
      "Epoch 2962: val_loss did not improve from 13343.45215\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9415.6592 - mean_absolute_error: 9415.6592 - val_loss: 13361.6924 - val_mean_absolute_error: 13361.6924\n",
      "Epoch 2963/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9163.4141 - mean_absolute_error: 9163.4141\n",
      "Epoch 2963: val_loss did not improve from 13343.45215\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9403.3896 - mean_absolute_error: 9403.3896 - val_loss: 13345.1641 - val_mean_absolute_error: 13345.1641\n",
      "Epoch 2964/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11457.9609 - mean_absolute_error: 11457.9609\n",
      "Epoch 2964: val_loss did not improve from 13343.45215\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9402.6455 - mean_absolute_error: 9402.6455 - val_loss: 13345.1475 - val_mean_absolute_error: 13345.1475\n",
      "Epoch 2965/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9502.3516 - mean_absolute_error: 9502.3516\n",
      "Epoch 2965: val_loss did not improve from 13343.45215\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9409.6357 - mean_absolute_error: 9409.6357 - val_loss: 13355.5322 - val_mean_absolute_error: 13355.5322\n",
      "Epoch 2966/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11049.0215 - mean_absolute_error: 11049.0215\n",
      "Epoch 2966: val_loss did not improve from 13343.45215\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9400.7861 - mean_absolute_error: 9400.7861 - val_loss: 13343.8037 - val_mean_absolute_error: 13343.8037\n",
      "Epoch 2967/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10485.0918 - mean_absolute_error: 10485.0918\n",
      "Epoch 2967: val_loss improved from 13343.45215 to 13342.50000, saving model to Weights-02967--13342.50000.hdf5\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9414.9131 - mean_absolute_error: 9414.9131 - val_loss: 13342.5000 - val_mean_absolute_error: 13342.5000\n",
      "Epoch 2968/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6638.7524 - mean_absolute_error: 6638.7524\n",
      "Epoch 2968: val_loss did not improve from 13342.50000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9420.4590 - mean_absolute_error: 9420.4590 - val_loss: 13361.2461 - val_mean_absolute_error: 13361.2461\n",
      "Epoch 2969/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9462.5293 - mean_absolute_error: 9462.5293\n",
      "Epoch 2969: val_loss did not improve from 13342.50000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9414.3965 - mean_absolute_error: 9414.3965 - val_loss: 13372.4326 - val_mean_absolute_error: 13372.4326\n",
      "Epoch 2970/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10338.2432 - mean_absolute_error: 10338.2432\n",
      "Epoch 2970: val_loss did not improve from 13342.50000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9404.6494 - mean_absolute_error: 9404.6494 - val_loss: 13347.2344 - val_mean_absolute_error: 13347.2344\n",
      "Epoch 2971/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 5991.6284 - mean_absolute_error: 5991.6284\n",
      "Epoch 2971: val_loss did not improve from 13342.50000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9405.2988 - mean_absolute_error: 9405.2988 - val_loss: 13345.6416 - val_mean_absolute_error: 13345.6416\n",
      "Epoch 2972/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 7268.3921 - mean_absolute_error: 7268.3921\n",
      "Epoch 2972: val_loss did not improve from 13342.50000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9400.8379 - mean_absolute_error: 9400.8379 - val_loss: 13353.8486 - val_mean_absolute_error: 13353.8486\n",
      "Epoch 2973/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9205.9102 - mean_absolute_error: 9205.9102\n",
      "Epoch 2973: val_loss did not improve from 13342.50000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9425.1543 - mean_absolute_error: 9425.1543 - val_loss: 13343.1719 - val_mean_absolute_error: 13343.1719\n",
      "Epoch 2974/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10436.2959 - mean_absolute_error: 10436.2959\n",
      "Epoch 2974: val_loss did not improve from 13342.50000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9406.2822 - mean_absolute_error: 9406.2822 - val_loss: 13363.2344 - val_mean_absolute_error: 13363.2344\n",
      "Epoch 2975/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8735.4902 - mean_absolute_error: 8735.4902\n",
      "Epoch 2975: val_loss did not improve from 13342.50000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9419.0537 - mean_absolute_error: 9419.0537 - val_loss: 13364.7432 - val_mean_absolute_error: 13364.7432\n",
      "Epoch 2976/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12836.0801 - mean_absolute_error: 12836.0801\n",
      "Epoch 2976: val_loss did not improve from 13342.50000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9406.2275 - mean_absolute_error: 9406.2275 - val_loss: 13348.3711 - val_mean_absolute_error: 13348.3711\n",
      "Epoch 2977/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11173.8066 - mean_absolute_error: 11173.8066\n",
      "Epoch 2977: val_loss did not improve from 13342.50000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9401.8877 - mean_absolute_error: 9401.8877 - val_loss: 13342.7764 - val_mean_absolute_error: 13342.7764\n",
      "Epoch 2978/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6295.6968 - mean_absolute_error: 6295.6968\n",
      "Epoch 2978: val_loss did not improve from 13342.50000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9412.4082 - mean_absolute_error: 9412.4082 - val_loss: 13342.6914 - val_mean_absolute_error: 13342.6914\n",
      "Epoch 2979/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9477.4883 - mean_absolute_error: 9477.4883\n",
      "Epoch 2979: val_loss did not improve from 13342.50000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9410.5273 - mean_absolute_error: 9410.5273 - val_loss: 13355.4912 - val_mean_absolute_error: 13355.4912\n",
      "Epoch 2980/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11143.4043 - mean_absolute_error: 11143.4043\n",
      "Epoch 2980: val_loss improved from 13342.50000 to 13342.07715, saving model to Weights-02980--13342.07715.hdf5\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9411.9014 - mean_absolute_error: 9411.9014 - val_loss: 13342.0771 - val_mean_absolute_error: 13342.0771\n",
      "Epoch 2981/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8373.9395 - mean_absolute_error: 8373.9395\n",
      "Epoch 2981: val_loss did not improve from 13342.07715\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9417.3350 - mean_absolute_error: 9417.3350 - val_loss: 13360.6689 - val_mean_absolute_error: 13360.6689\n",
      "Epoch 2982/3000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 9183.8760 - mean_absolute_error: 9183.8760\n",
      "Epoch 2982: val_loss improved from 13342.07715 to 13341.90234, saving model to Weights-02982--13341.90234.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9413.7705 - mean_absolute_error: 9413.7705 - val_loss: 13341.9023 - val_mean_absolute_error: 13341.9023\n",
      "Epoch 2983/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9240.3594 - mean_absolute_error: 9240.3594\n",
      "Epoch 2983: val_loss did not improve from 13341.90234\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9417.1680 - mean_absolute_error: 9417.1680 - val_loss: 13350.0781 - val_mean_absolute_error: 13350.0781\n",
      "Epoch 2984/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11303.7148 - mean_absolute_error: 11303.7148\n",
      "Epoch 2984: val_loss did not improve from 13341.90234\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9405.3730 - mean_absolute_error: 9405.3730 - val_loss: 13354.6230 - val_mean_absolute_error: 13354.6230\n",
      "Epoch 2985/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11361.9873 - mean_absolute_error: 11361.9873\n",
      "Epoch 2985: val_loss did not improve from 13341.90234\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9400.7930 - mean_absolute_error: 9400.7930 - val_loss: 13342.0889 - val_mean_absolute_error: 13342.0889\n",
      "Epoch 2986/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12646.5225 - mean_absolute_error: 12646.5225\n",
      "Epoch 2986: val_loss did not improve from 13341.90234\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9403.2432 - mean_absolute_error: 9403.2432 - val_loss: 13344.1201 - val_mean_absolute_error: 13344.1201\n",
      "Epoch 2987/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9371.8213 - mean_absolute_error: 9371.8213\n",
      "Epoch 2987: val_loss did not improve from 13341.90234\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9407.3701 - mean_absolute_error: 9407.3701 - val_loss: 13353.4385 - val_mean_absolute_error: 13353.4385\n",
      "Epoch 2988/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9812.5938 - mean_absolute_error: 9812.5938\n",
      "Epoch 2988: val_loss did not improve from 13341.90234\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9408.0371 - mean_absolute_error: 9408.0371 - val_loss: 13359.7871 - val_mean_absolute_error: 13359.7871\n",
      "Epoch 2989/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8293.5547 - mean_absolute_error: 8293.5547\n",
      "Epoch 2989: val_loss did not improve from 13341.90234\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9408.5762 - mean_absolute_error: 9408.5762 - val_loss: 13357.1338 - val_mean_absolute_error: 13357.1338\n",
      "Epoch 2990/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10950.1123 - mean_absolute_error: 10950.1123\n",
      "Epoch 2990: val_loss did not improve from 13341.90234\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9407.8662 - mean_absolute_error: 9407.8662 - val_loss: 13343.4229 - val_mean_absolute_error: 13343.4229\n",
      "Epoch 2991/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8937.9707 - mean_absolute_error: 8937.9707\n",
      "Epoch 2991: val_loss did not improve from 13341.90234\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9403.9639 - mean_absolute_error: 9403.9639 - val_loss: 13344.2070 - val_mean_absolute_error: 13344.2070\n",
      "Epoch 2992/3000\n",
      "10/18 [===============>..............] - ETA: 0s - loss: 9582.3340 - mean_absolute_error: 9582.3340  \n",
      "Epoch 2992: val_loss improved from 13341.90234 to 13339.79297, saving model to Weights-02992--13339.79297.hdf5\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9417.9160 - mean_absolute_error: 9417.9160 - val_loss: 13339.7930 - val_mean_absolute_error: 13339.7930\n",
      "Epoch 2993/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 12219.5479 - mean_absolute_error: 12219.5479\n",
      "Epoch 2993: val_loss did not improve from 13339.79297\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9422.8369 - mean_absolute_error: 9422.8369 - val_loss: 13368.9453 - val_mean_absolute_error: 13368.9453\n",
      "Epoch 2994/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11682.7793 - mean_absolute_error: 11682.7793\n",
      "Epoch 2994: val_loss did not improve from 13339.79297\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9415.8076 - mean_absolute_error: 9415.8076 - val_loss: 13341.0859 - val_mean_absolute_error: 13341.0859\n",
      "Epoch 2995/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 10272.7041 - mean_absolute_error: 10272.7041\n",
      "Epoch 2995: val_loss did not improve from 13339.79297\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9399.4102 - mean_absolute_error: 9399.4102 - val_loss: 13349.6074 - val_mean_absolute_error: 13349.6074\n",
      "Epoch 2996/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6680.0059 - mean_absolute_error: 6680.0059\n",
      "Epoch 2996: val_loss did not improve from 13339.79297\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9411.7461 - mean_absolute_error: 9411.7461 - val_loss: 13342.5283 - val_mean_absolute_error: 13342.5283\n",
      "Epoch 2997/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 6187.4463 - mean_absolute_error: 6187.4463\n",
      "Epoch 2997: val_loss did not improve from 13339.79297\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9401.0586 - mean_absolute_error: 9401.0586 - val_loss: 13356.6035 - val_mean_absolute_error: 13356.6035\n",
      "Epoch 2998/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 8561.3477 - mean_absolute_error: 8561.3477\n",
      "Epoch 2998: val_loss did not improve from 13339.79297\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9402.8281 - mean_absolute_error: 9402.8281 - val_loss: 13350.7773 - val_mean_absolute_error: 13350.7773\n",
      "Epoch 2999/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 9560.3691 - mean_absolute_error: 9560.3691\n",
      "Epoch 2999: val_loss improved from 13339.79297 to 13338.98047, saving model to Weights-02999--13338.98047.hdf5\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9415.1035 - mean_absolute_error: 9415.1035 - val_loss: 13338.9805 - val_mean_absolute_error: 13338.9805\n",
      "Epoch 3000/3000\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 11177.3809 - mean_absolute_error: 11177.3809\n",
      "Epoch 3000: val_loss did not improve from 13338.98047\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9403.1602 - mean_absolute_error: 9403.1602 - val_loss: 13344.2715 - val_mean_absolute_error: 13344.2715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1a3eea1a80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model.fit(train_x, train_y, epochs=3000, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 963us/step\n"
     ]
    }
   ],
   "source": [
    "wights_file = 'Weights-02999--13338.98047.hdf5' \n",
    "NN_model.load_weights(wights_file) \n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "predictions = NN_model.predict(test_x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Regresión de Gradiente Extremo (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBModel = XGBRegressor(objective=\"reg:squarederror\", random_state=42,max_depth=10)\n",
    "XGBModel.fit(train_x,train_y, verbose=False)\n",
    "\n",
    "XGBpredictions = XGBModel.predict(test_x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Bosque Aleatorio (Random Forest Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor()\n",
    "model.fit(train_x,train_y)\n",
    "\n",
    "RF_predictions = model.predict(test_x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de Resultados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluación de la precisión de los tres modelos entrenados mediante tres métricas diferentes; MAE, MAPE y MSE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18729.293597946526\n",
      "16305.161105157387\n",
      "15888.492171986505\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NN_MAE = mean_absolute_error(test_y, predictions)\n",
    "NN_MAPE = mean_absolute_percentage_error(test_y, predictions)\n",
    "NN_MSE = mean_squared_error(test_y, predictions)\n",
    "\n",
    "XGB_MAE = mean_absolute_error(test_y , XGBpredictions)\n",
    "XGB_MAPE = mean_absolute_percentage_error(test_y , XGBpredictions)\n",
    "XGB_MSE = mean_squared_error(test_y , XGBpredictions)\n",
    "\n",
    "RF_MAE = mean_absolute_error(test_y , RF_predictions)\n",
    "RF_MAPE = mean_absolute_percentage_error(test_y , RF_predictions)\n",
    "RF_MSE = mean_squared_error(test_y , RF_predictions)\n",
    "print(NN_MAE)\n",
    "print(XGB_MAE)\n",
    "print(RF_MAE)\n",
    "\n",
    "MAE_scores = [NN_MAE, XGB_MAE, RF_MAE]\n",
    "MAPE_scores = [NN_MAPE, XGB_MAPE, RF_MAPE]\n",
    "MSE_scores = [NN_MSE, XGB_MSE, RF_MSE]\n",
    "results = [MAE_scores,MAPE_scores, MSE_scores]\n",
    "models = ['Neural Network', \"XGBoost\", \"Random Forest\"]\n",
    "labels = ['MAE', 'MAPE', 'MSE']\n",
    "colors = ['Turquoise', 'Orange', 'Darkslategrey']\n",
    "fig,ax = plt.subplots(1,3,figsize=(12,3))\n",
    "for i in range(len(labels)):\n",
    "    for j in range(len(colors)):\n",
    "        ax[i].bar(models[j],results[i][j], color=colors[j])\n",
    "    ax[i].set_xlabel(labels[i])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nótese que los mejores resultados fueron obtenidos por los modelos de regresión XGBoost y Random Forest, puede que esto se deba a un bajo poder de cómputo a la hora de entrenar a la raíz neuronal o algún fallo en la parametrización/normalización del dataframe. \n",
    "Así entonces se optó por implementar el modelo de XGBoost Regression en el despliegue a producción."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
