{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DD360 Coding Challenge: análisis del ciclo de desarrollo\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paquetes necesarios "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 21:31:50.731328: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-25 21:31:51.027370: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-25 21:31:51.027955: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-25 21:31:52.689860: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación y limpieza del Data Frame\n",
    "Partimos importando el dataset mediante pandas y procederemos a hacer un análisis exploratorio de los datos.\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 981 entries, 0 to 980\n",
      "Data columns (total 35 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   main_name             981 non-null    object \n",
      " 1   subtitle              981 non-null    object \n",
      " 2   link                  981 non-null    object \n",
      " 3   location              981 non-null    object \n",
      " 4   price                 981 non-null    object \n",
      " 5   attributes            981 non-null    object \n",
      " 6   timestamp             981 non-null    object \n",
      " 7   id                    981 non-null    int64  \n",
      " 8   address               702 non-null    object \n",
      " 9   since                 981 non-null    object \n",
      " 10  description           981 non-null    object \n",
      " 11  vendor                981 non-null    object \n",
      " 12  lat                   981 non-null    float64\n",
      " 13  lon                   981 non-null    float64\n",
      " 14  price_mod             981 non-null    float64\n",
      " 15  price_currency        981 non-null    object \n",
      " 16  since_period          981 non-null    object \n",
      " 17  since_value           981 non-null    int64  \n",
      " 18  days_on_site          981 non-null    float64\n",
      " 19  amenities             504 non-null    float64\n",
      " 20  age_in_years          981 non-null    float64\n",
      " 21  bathrooms             981 non-null    float64\n",
      " 22  cellars               52 non-null     float64\n",
      " 23  num_floors            84 non-null     float64\n",
      " 24  monthly_fee           128 non-null    object \n",
      " 25  apartments_per_floor  15 non-null     float64\n",
      " 26  disposition           20 non-null     object \n",
      " 27  parking_lots          981 non-null    int64  \n",
      " 28  floor_situated        24 non-null     float64\n",
      " 29  orientation           8 non-null      object \n",
      " 30  num_bedrooms          981 non-null    float64\n",
      " 31  department_type       39 non-null     object \n",
      " 32  m2                    981 non-null    float64\n",
      " 33  final_price           981 non-null    float64\n",
      " 34  price_square_meter    981 non-null    float64\n",
      "dtypes: float64(15), int64(3), object(17)\n",
      "memory usage: 268.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv(r'reto_precios.csv')\n",
    "print(raw_data.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se implementó una función para limpiar el DataSet y manetner unicamente las columnas con features definidos en cada una de las observaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols_with_no_nans(df,col_type):\n",
    "    '''\n",
    "    Arguments :\n",
    "    df : The dataframe to process\n",
    "    col_type : \n",
    "          num : to only get numerical columns with no nans\n",
    "          no_num : to only get nun-numerical columns with no nans\n",
    "          all : to get any columns with no nans    \n",
    "    '''\n",
    "    if (col_type == 'num'):\n",
    "        predictors = df.select_dtypes(exclude=['object'])\n",
    "    elif (col_type == 'no_num'):\n",
    "        predictors = df.select_dtypes(include=['object'])\n",
    "    elif (col_type == 'all'):\n",
    "        predictors = df\n",
    "    else :\n",
    "        print('Error : choose a type (num, no_num, all)')\n",
    "        return 0\n",
    "    cols_with_no_nans = []\n",
    "    for col in predictors.columns:\n",
    "        if not df[col].isnull().any():\n",
    "            cols_with_no_nans.append(col)\n",
    "    return cols_with_no_nans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se dividió el dataset entre los datos numéricos y no numéricos, aunque en un inicio se experimentó utilizando los datos no numéricos como parte del dataframe y codificandolos, no se obtuvieron buenos resultados por lo que se decidió trabajar únicamente con los datos numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of numerical columns with no nan values : 13\n",
      "Number of nun-numerical columns with no nan values : 12\n"
     ]
    }
   ],
   "source": [
    "num_cols = get_cols_with_no_nans(raw_data , 'num')\n",
    "cat_cols = get_cols_with_no_nans(raw_data , 'no_num')\n",
    "print ('Number of numerical columns with no nan values :',len(num_cols))\n",
    "print ('Number of nun-numerical columns with no nan values :',len(cat_cols))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impresión en histograma de las features útilies, mediante este análisis podemos observar el comportamiento de cada feautre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9oAAANECAYAAABPe1d0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdeVxU9f4/8NeAzLA5IMqaiGSm4h4mTK4pgoqmyTdFuYbp1RuCN6VMKRdwQ7HUNNAsQ0u5lt201FJww1viRplbkRqGNx2oFHGJYYTP7w9/c67DPjDDsLyej8c89HzOZ875fD6ccz7nPWfm85EJIQSIiIiIiIiIyCgszF0AIiIiIiIiosaEgTYRERERERGRETHQJiIiIiIiIjIiBtpERERERERERsRAm4iIiIiIiMiIGGgTERERERERGREDbSIiIiIiIiIjYqBNREREREREZEQMtImIiIiIiIiMiIE2VWjz5s2QyWS4evVqpfnatm2LSZMm1UmZiKhmqns+E1H9x/OZqH6TyWSIjY01dzHMhteohxhoExFRhVJSUrBmzRpzF4OIiIioQWlm7gJQ/TVx4kSEhoZCoVCYuyhEZCYpKSk4f/48Zs6cae6iEBERNQh//fUXmjVjmNXU8QigCllaWsLS0tLcxSAiIiIiqtdKSkpQVFQEa2trWFtbm7s4VA/wq+NUodK/rxBCYMmSJWjdujVsbW3x7LPP4sKFC+YtJBHVyBdffIHg4GB4eHhAoVCgXbt2WLx4MYqLi6U8AwcOxN69e/Hrr79CJpNBJpOhbdu25is0EVUoKSkJnTt3hkKhgIeHByIjI5Gfn6+XZ+DAgejSpQsuXryIZ599Fra2tnjssceQkJBgnkIT1UOxsbGQyWT46aefMHbsWCiVSrRs2RKvvPIKCgsLpXwymQxRUVHYtm2bdO7t27dPWlf6N9q//fYbpkyZIvW73t7eiIiIQFFRkZQnPz8fM2fOhKenJxQKBZ544gmsWLECJSUlBtVBd66fPXsWAwYMgK2tLZ544gl89tlnAID09HT4+fnBxsYGHTp0wIEDB8ps4/vvv8ewYcOgVCphb2+PwYMH4/jx42XyXbhwAYMGDYKNjQ1at26NJUuWGFzexopPtKnaFixYgCVLlmD48OEYPnw4vvvuOwQGBupdIIioYdi8eTPs7e0RHR0Ne3t7HDp0CAsWLEBBQQFWrlwJAHjzzTdx+/Zt/Pe//8Xq1asBAPb29uYsNhGVIzY2FnFxcQgICEBERASysrKwfv16nDp1Ct9++y2srKykvLdu3cLQoUMxZswYjB07Fp999hnmzJmDrl27YtiwYWasBVH9MnbsWLRt2xbx8fE4fvw41q5di1u3buGjjz6S8hw6dAiffvopoqKi0KpVqwo/jL5+/Tp69+6N/Px8TJs2DR07dsRvv/2Gzz77DPfv34dcLsf9+/cxYMAA/Pbbb/jHP/6BNm3a4NixY4iJicGNGzcMHi/l1q1bGDFiBEJDQ/HCCy9g/fr1CA0NxbZt2zBz5ky8/PLLmDBhAlauXIn/+7//w7Vr19C8eXMAD4Pnfv36QalU4vXXX4eVlRXee+89DBw4UArSAUCtVuPZZ5/FgwcPMHfuXNjZ2WHjxo2wsbGpUZs3OoKoAsnJyQKAyM7OFnl5eUIul4vg4GBRUlIi5XnjjTcEABEeHm6+ghJRlR49n4UQ4v79+2Xy/OMf/xC2traisLBQSgsODhZeXl51VEoiqo7y+ufAwEBRXFws5Xn33XcFAPHhhx9KaQMGDBAAxEcffSSlaTQa4ebmJkJCQuq0DkT11cKFCwUA8dxzz+mlT58+XQAQP/zwgxBCCADCwsJCXLhwocw2AIiFCxdKyy+++KKwsLAQp06dKpNXd1+9ePFiYWdnJ37++We99XPnzhWWlpYiJyen2nXQnespKSlS2k8//SSV+fjx41L6/v37BQCRnJwspY0ePVrI5XJx5coVKe369euiefPmon///lLazJkzBQBx4sQJKS0vL084ODjo3XM0VfzqOFXLgQMHUFRUhBkzZkAmk0npHCCJqGF69NPmO3fu4I8//kC/fv1w//59/PTTT2YsGREZQtc/z5w5ExYW/7utmzp1KpRKJfbu3auX397eHn/729+kZblcjt69e+OXX36pszITNQSRkZF6yzNmzAAAfPXVV1LagAED4OPjU+l2SkpKsGvXLowcORK9evUqs153X71jxw7069cPLVq0wB9//CG9AgICUFxcjKNHjxpUfnt7e4SGhkrLHTp0gKOjIzp16iQ9kQYg/V93DSguLkZqaipGjx6Nxx9/XMrn7u6OCRMm4JtvvkFBQYHUFv7+/ujdu7eUz9nZGWFhYQaVtbHiV8epWn799VcAQPv27fXSnZ2d0aJFC3MUiYhq4cKFC5g3bx4OHTokdZg6t2/fNlOpiMhQuv65Q4cOeulyuRyPP/64tF6ndevWeh+YA0CLFi1w9uxZ0xaUqIEpfc/brl07WFhY6M0N7e3tXeV2fv/9dxQUFKBLly6V5rt06RLOnj0LZ2fnctfn5eVVXehHlHeuOzg4wNPTs0wa8PCr5rry3r9/v8w1BQA6deqEkpISXLt2DZ07d8avv/6qF7TrlPfepoiBNhFRE5Ofn48BAwZAqVRi0aJFaNeuHaytrfHdd99hzpw5HMSEqBGraDYRIUQdl4SoYSkdtAIw6m+RS0pKMGTIELz++uvlrn/yyScN2l5F5zqvAXWHgTZVi5eXF4CHn7Y9+jWS33//XfoEjIgahiNHjuDPP//E559/jv79+0vp2dnZZfKWd2NBRPWHrn/OysrS65+LioqQnZ2NgIAAcxWNqEG7dOmS3hPry5cvo6SkxODZN5ydnaFUKnH+/PlK87Vr1w537941+znr7OwMW1tbZGVllVn3008/wcLCQnoq7uXlhUuXLpXJV957myL+RpuqJSAgAFZWVli3bp3eJ16GjoBIROan+zT70XO5qKgISUlJZfLa2dnxq+RE9VhAQADkcjnWrl2rd05v2rQJt2/fRnBwsBlLR9RwJSYm6i2vW7cOAAwend/CwgKjR4/G7t27cfr06TLrdeft2LFjkZGRgf3795fJk5+fjwcPHhi035qytLREYGAgvvjiC72vyefm5iIlJQV9+/aFUqkEAAwfPhzHjx/HyZMnpXy///47tm3bVidlre/4RJuqxdnZGa+99hri4+MxYsQIDB8+HN9//z2+/vprtGrVytzFIyIDPPPMM2jRogXCw8Pxz3/+EzKZDB9//HG5Xxvz9fXFJ598gujoaDz99NOwt7fHyJEjzVBqIiqPs7MzYmJiEBcXh6FDh+K5555DVlYWkpKS8PTTT+sNfEZE1ZednY3nnnsOQ4cORUZGBrZu3YoJEyage/fuBm9r2bJlSE1NxYABAzBt2jR06tQJN27cwI4dO/DNN9/A0dERs2fPxpdffokRI0Zg0qRJ8PX1xb1793Du3Dl89tlnuHr1ap3dcy9ZsgRpaWno27cvpk+fjmbNmuG9996DRqNBQkKClO/111/Hxx9/jKFDh+KVV16Rpvfy8vLiuA9goE0GWLJkCaytrbFhwwYcPnwYfn5+SE1N5aflRA1My5YtsWfPHrz66quYN28eWrRogb/97W8YPHgwgoKC9PJOnz4dZ86cQXJyMlavXg0vLy8G2kT1TGxsLJydnfHuu+9i1qxZcHJywrRp07Bs2TK9ObSJqPo++eQTLFiwAHPnzkWzZs0QFRWFlStX1mhbjz32GE6cOIH58+dj27ZtKCgowGOPPYZhw4bB1tYWAGBra4v09HQsW7YMO3bswEcffQSlUoknn3wScXFx0qBldaFz5874z3/+g5iYGMTHx6OkpAR+fn7YunWr3uBn7u7uOHz4MGbMmIHly5ejZcuWePnll+Hh4YEpU6bUWXnrK5ngL9+JiIiIiIgQGxuLuLg4/P777/zWJtUKf6NNREREREREZET86jgREREREVE9d/PmTRQVFVW43tLSssJ5uKnuMdAmIiIiIiKq58aMGYP09PQK13t5eemNFE7mxd9oExERERER1XOZmZm4detWhettbGzQp0+fOiwRVYaBNhEREREREZERcTA0IiIiIiIiIiNqkL/RLikpwfXr19G8eXPIZDJzF4eoTgghcOfOHXh4eMDConF+RsZzm5ointtEjQ/Pa6LGyaBzWzRA165dEwD44qtJvq5du2buU9BkeG7z1ZRfhp7b6enpYsSIEcLd3V0AEDt37tRbX1JSIubPny/c3NyEtbW1GDx4sPj555/18vz5559iwoQJonnz5sLBwUFMnjxZ3LlzRy/PDz/8IPr27SsUCoVo3bq1WLFiBc9tvviq5ot9Nl98Nc5Xdc7tBvlEu3nz5gCAa9euQalUlptHq9UiNTUVgYGBsLKyqsviNXpsW9OqqH0LCgrg6ekpHf+NUXXO7arw+GQb6DSUdqjpuX3v3j10794dkydPxpgxY8qsT0hIwNq1a7FlyxZ4e3tj/vz5CAoKwsWLF2FtbQ0ACAsLw40bN5CWlgatVouXXnoJ06ZNQ0pKilS2wMBABAQEYMOGDTh37hwmT54MR0dHTJs2rdplNca5bYiG8revCMtvXsYof1Pssxv6392c2Ha1U5ftZ8i5bXCgffToUaxcuRKZmZm4ceMGdu7cidGjR0vrhRBYuHAh3n//feTn56NPnz5Yv3492rdvL+W5efMmZsyYgd27d8PCwgIhISF45513YG9vX60y6L6eolQqKw20bW1toVQqecAaGdvWtKpq38b89azqnNtV4fHJNtBpaO1g6Lk9bNgwDBs2rNx1QgisWbMG8+bNw6hRowAAH330EVxdXbFr1y6Ehobixx9/xL59+3Dq1Cn06tULALBu3ToMHz4cb731Fjw8PLBt2zYUFRXhww8/hFwuR+fOnXHmzBmsWrXKoEDbGOe2IRra3740lt+8jFn+ptRnN/S/uzmx7WrHHO1XnXPb4B+N6D5BT0xMLHe97hP0DRs24MSJE7Czs0NQUBAKCwulPGFhYbhw4QLS0tKwZ88eHD161KAOm4iIiCqWnZ0NtVqNgIAAKc3BwQF+fn7IyMgAAGRkZMDR0VEKsgEgICAAFhYWOHHihJSnf//+kMvlUp6goCBkZWVVOsUMERFRU2fwE+26+ASdiIiIak6tVgMAXF1d9dJdXV2ldWq1Gi4uLnrrmzVrBicnJ7083t7eZbahW9eiRYty96/RaKDRaKTlgoICAA+fOmi12ppWq9p0+6iLfZkCy29exih/Q607ERmPUX+jXdUn6KGhoVV+gv7888+X2W5NOuyGfpGvz9i2plVR+7K9iaihiI+PR1xcXJn01NRU2Nra1lk50tLS6mxfpsDym1dtyn///n0jloSIGiKjBtrG+gS9tNp02A39Il+fsW1Nq3T7stMmoupyc3MDAOTm5sLd3V1Kz83NRY8ePaQ8eXl5eu978OABbt68Kb3fzc0Nubm5enl0y7o85YmJiUF0dLS0rBs8JjAwsM5+o52WloYhQ4Y0yN87svzmZYzy6x4KEVHT1SBGHa9Jh93QL/L1GdvWtCpqX3baRFRd3t7ecHNzw8GDB6XAuqCgACdOnEBERAQAQKVSIT8/H5mZmfD19QUAHDp0CCUlJfDz85PyvPnmm9BqtdL1KC0tDR06dKjwa+MAoFAooFAoyqRbWVnVab9R1/szNpbfvGpT/oZcbyIyDqMG2sb6BL202nTYPZcegqa45iM+Xl0eXOP36rSdu7fW2zBGOYylS+x+JPSuXdsaqz71pW1NUY7Sxzc77YeqamuFpUBC74fHaWXHZ306p4hq4u7du7h8+bK0nJ2djTNnzsDJyQlt2rTBzJkzsWTJErRv316a3svDw0OaKaRTp04YOnQopk6dig0bNkCr1SIqKgqhoaHSeCkTJkxAXFwcpkyZgjlz5uD8+fN45513sHr1anNUmcgo2I80PPXlfo/IEEYNtI31CTqVZYwLjLEoLGu/jfpUn/pUFiKi6jp9+jSeffZZaVn3za/w8HBs3rwZr7/+Ou7du4dp06YhPz8fffv2xb59+6Q5tAFg27ZtiIqKwuDBg6XpNteuXSutd3BwQGpqKiIjI+Hr64tWrVphwYIFnCmEiIioCgYH2nXxCToRERFVbuDAgRBCVLheJpNh0aJFWLRoUYV5nJyckJKSUul+unXrhv/85z81LicREVFTZHCgXRefoBMRERERERE1VAYH2nX1CToRERERERFRQ2Rh7gIQERERERERNSYMtImIiIiIiIiMqEHMo21OHJGaiIiIiIiIDMEn2kRERERERERGxECbiIiIiIiIyIgYaBMREREREREZEQNtIiIiIqIGYv369ejWrRuUSiWUSiVUKhW+/vpraX1hYSEiIyPRsmVL2NvbIyQkBLm5uXrbyMnJQXBwMGxtbeHi4oLZs2fjwYMHdV0VokaNgTYRERERUQPRunVrLF++HJmZmTh9+jQGDRqEUaNG4cKFCwCAWbNmYffu3dixYwfS09Nx/fp1jBkzRnp/cXExgoODUVRUhGPHjmHLli3YvHkzFixYYK4qETVKHHWciIiIiKiBGDlypN7y0qVLsX79ehw/fhytW7fGpk2bkJKSgkGDBgEAkpOT0alTJxw/fhz+/v5ITU3FxYsXceDAAbi6uqJHjx5YvHgx5syZg9jYWMjlcnNUi6jR4RNtIiIiIqIGqLi4GNu3b8e9e/egUqmQmZkJrVaLgIAAKU/Hjh3Rpk0bZGRkAAAyMjLQtWtXuLq6SnmCgoJQUFAgPRUnotrjE20iIiIiogbk3LlzUKlUKCwshL29PXbu3AkfHx+cOXMGcrkcjo6OevldXV2hVqsBAGq1Wi/I1q3XrauIRqOBRqORlgsKCgAAWq1WeumWjU1hKWq9DVOUy1hM2XZNQV22nyH7YKBNRERERNSAdOjQAWfOnMHt27fx2WefITw8HOnp6SbdZ3x8POLi4sqkp6amwtbWVlpOS0sz+r4Tetd+G1999VXtN2Jipmi7pqQu2u/+/fvVzstAm4iIiIioAZHL5XjiiScAAL6+vjh16hTeeecdjBs3DkVFRcjPz9d7qp2bmws3NzcAgJubG06ePKm3Pd2o5Lo85YmJiUF0dLS0XFBQAE9PTwQGBkKpVEKr1SItLQ1DhgyBlZWVsaoKAOgSu7/W2zgfG2SEkpiGKduuKajL9tN9k6M6GGgTEYqLixEbG4utW7dCrVbDw8MDkyZNwrx58yCTyQAAQggsXLgQ77//PvLz89GnTx+sX78e7du3l7Zz8+ZNzJgxA7t374aFhQVCQkLwzjvvwN7e3lxVIyIiavRKSkqg0Wjg6+sLKysrHDx4ECEhIQCArKws5OTkQKVSAQBUKhWWLl2KvLw8uLi4AHj4JFCpVMLHx6fCfSgUCigUijLpVlZWesFN6WVj0BTLar2NhhDAmqLtmpK6aD9Dts9Am4iwYsUKrF+/Hlu2bEHnzp1x+vRpvPTSS3BwcMA///lPAEBCQgLWrl2LLVu2wNvbG/Pnz0dQUBAuXrwIa2trAEBYWBhu3LiBtLQ0aLVavPTSS5g2bRpSUlLMWT0iIqJGIyYmBsOGDUObNm1w584dpKSk4MiRI9i/fz8cHBwwZcoUREdHw8nJCUqlEjNmzIBKpYK/vz8AIDAwED4+Ppg4cSISEhKgVqsxb948REZGlhtIE1HNMNAmIhw7dgyjRo1CcHAwAKBt27b417/+JX21TAiBNWvWYN68eRg1ahQA4KOPPoKrqyt27dqF0NBQ/Pjjj9i3bx9OnTqFXr16AQDWrVuH4cOH46233oKHh4d5KkdERNSI5OXl4cUXX8SNGzfg4OCAbt26Yf/+/RgyZAgAYPXq1dK3yjQaDYKCgpCUlCS939LSEnv27EFERARUKhXs7OwQHh6ORYsWmatKRI0SA20iwjPPPIONGzfi559/xpNPPokffvgB33zzDVatWgUAyM7Ohlqt1psuxMHBAX5+fsjIyEBoaCgyMjLg6OgoBdkAEBAQAAsLC5w4cQLPP/98ndeLiIiosdm0aVOl662trZGYmIjExMQK83h5eTWIwcGMqe3cvUbZztXlwUbZDjV+DLSJCHPnzkVBQQE6duwIS0tLFBcXY+nSpQgLCwPwv+k+ypsO5NHpQnS/9dJp1qwZnJycKpwupKqpQspT1RQfCguh929FGvMUGpwm5KGG0g71vXxERERkOAbaRIRPP/0U27ZtQ0pKCjp37owzZ85g5syZ8PDwQHh4uMn2W92pQh5V3Sk+FvcqqXR9U/gkn9OEPFTf28GQqUKIiIioYWCgTUSYPXs25s6di9DQUABA165d8euvvyI+Ph7h4eHSdB+5ublwd3eX3pebm4sePXoAeDglSF5ent52Hzx4gJs3b1Y4XUhVU4WUp6opPhQWAot7lWD+aQtoSioepbQ+T/NRW5wm5KGG0g6GTBVCREREDQMDbSLC/fv3YWFhoZdmaWmJkpKHT4W9vb3h5uaGgwcPSoF1QUEBTpw4gYiICAAPpwvJz89HZmYmfH19AQCHDh1CSUkJ/Pz8yt1vdacKeVR1p/jQlMgqzVufAy9j4TQhD9X3dqjPZSMiIqKaYaBNRBg5ciSWLl2KNm3aoHPnzvj++++xatUqTJ48GQAgk8kwc+ZMLFmyBO3bt5em9/Lw8MDo0aMBAJ06dcLQoUMxdepUbNiwAVqtFlFRUQgNDeWI40RERETUpDDQJiKsW7cO8+fPx/Tp05GXlwcPDw/84x//wIIFC6Q8r7/+Ou7du4dp06YhPz8fffv2xb59+6Q5tAFg27ZtiIqKwuDBg6WpRdauXWuOKhERERERmQ0DbSJC8+bNsWbNGqxZs6bCPDKZDIsWLap0nk0nJyekpKSYoIRERERERA2HRdVZiIiIiIiIiKi6GGgTERE1Um3btoVMJivzioyMBAAMHDiwzLqXX35Zbxs5OTkIDg6Gra0tXFxcMHv2bDx48MAc1SEiImow+NVxIiKiRurUqVMoLi6Wls+fP48hQ4bghRdekNKmTp2q95OQR+ewLy4uRnBwMNzc3HDs2DHcuHEDL774IqysrLBs2bK6qQQREVEDZPQn2sb49JyIiIhqz9nZGW5ubtJrz549aNeuHQYMGCDlsbW11cvz6Bz2qampuHjxIrZu3YoePXpg2LBhWLx4MRITE1FUVGSOKhERETUIRg+0T506hRs3bkivtLQ0ACjz6fmjeRISEoxdDCIiInpEUVERtm7dismTJ0Mm+98c89u2bUOrVq3QpUsXxMTE4P79+9K6jIwMdO3aFa6urlJaUFAQCgoKcOHChTotPxERUUNi9K+OOzs76y0vX768wk/PiYiIqG7s2rUL+fn5mDRpkpQ2YcIEeHl5wcPDA2fPnsWcOXOQlZWFzz//HACgVqv1gmwA0rJara5wXxqNBhqNRlouKCgAAGi1Wmi1WmNVqUK6fdTFvkyB5TcthaWofL2F0Pu3IpXVr77WnYjqjkl/o6379Dw6OrrMp+dbt26Fm5sbRo4cifnz5+v9Jqy0mnTYuvSqLpJkuOp2QGSY0jcmpY9tdtpEVBubNm3CsGHD4OHhIaVNmzZN+n/Xrl3h7u6OwYMH48qVK2jXrl2N9xUfH4+4uLgy6ampqZX298am+1ZdQ8Xym0ZC7+rlW9yrpNL1X331VYXrHv1mCBE1TSYNtGvy6Xl5atNhV3WRpJpj2xpX6Q679A0KO20iqqlff/0VBw4cqLSvBQA/Pz8AwOXLl9GuXTu4ubnh5MmTenlyc3MBoNJvpsXExCA6OlpaLigogKenJwIDA/V+A24qWq0WaWlpGDJkCKysrEy+P2Nj+U2rS+z+StcrLAQW9yrB/NMW0JTIKsx3PjaownW6h0JE1HSZNNA21qfnNemwdRf5qi6SZLjqdkBkGF2HXdENCjttIqqp5ORkuLi4IDg4uNJ8Z86cAQC4u7sDAFQqFZYuXYq8vDy4uLgAePghoFKphI+PT4XbUSgUUCgUZdKtrKzqNPCq6/0ZG8tvGpri6t27aEpkleatrG71sd5EVLdMFmjX9NPz8tSmw67qIkk1x7Y1rtLHcunjm502EdVESUkJkpOTER4ejmbN/tftX7lyBSkpKRg+fDhatmyJs2fPYtasWejfvz+6desGAAgMDISPjw8mTpyIhIQEqNVqzJs3D5GRkeX2y0RERPSQyQLtmn56TkRERMZz4MAB5OTkYPLkyXrpcrkcBw4cwJo1a3Dv3j14enoiJCQE8+bNk/JYWlpiz549iIiIgEqlgp2dHcLDw/Xm3SYiIqKyTBJo1+bTcyIiIjKewMBACFF28EpPT0+kp6dX+X4vL69KB30iIiKiskwSaNfm03MiIiIiIiKihswkgXZtPz0nIiIiIiIiaqgszF0AIiIiIiIiosaEgTYRERERERGRETHQJiIiIiIiIjIiBtpERERERERERsRAm4iIiIiIiMiIGGgTERERERERGREDbSIiIiIiIiIjYqBNRACA3377DX/729/QsmVL2NjYoGvXrjh9+rS0XgiBBQsWwN3dHTY2NggICMClS5f0tnHz5k2EhYVBqVTC0dERU6ZMwd27d+u6KkREREREZsVAm4hw69Yt9OnTB1ZWVvj6669x8eJFvP3222jRooWUJyEhAWvXrsWGDRtw4sQJ2NnZISgoCIWFhVKesLAwXLhwAWlpadizZw+OHj2KadOmmaNKRERERERm08zcBSAi81uxYgU8PT2RnJwspXl7e0v/F0JgzZo1mDdvHkaNGgUA+Oijj+Dq6opdu3YhNDQUP/74I/bt24dTp06hV69eAIB169Zh+PDheOutt+Dh4VG3lSIiIiIiMhMG2kSEL7/8EkFBQXjhhReQnp6Oxx57DNOnT8fUqVMBANnZ2VCr1QgICJDe4+DgAD8/P2RkZCA0NBQZGRlwdHSUgmwACAgIgIWFBU6cOIHnn3++zH41Gg00Go20XFBQAADQarXQarXlllVhKSqti8JC6P1bkYq23xjo6taY61gdDaUd6nv5iIiIyHAMtIkIv/zyC9avX4/o6Gi88cYbOHXqFP75z39CLpcjPDwcarUaAODq6qr3PldXV2mdWq2Gi4uL3vpmzZrByclJylNafHw84uLiyqSnpqbC1ta23Pck9K5enRb3Kql0/VdffVW9DTVgaWlp5i5CvVDf2+H+/fvmLgIREREZGQNtIkJJSQl69eqFZcuWAQB69uyJ8+fPY8OGDQgPDzfZfmNiYhAdHS0tFxQUwNPTE4GBgVAqleW+p0vs/kq3qbAQWNyrBPNPW0BTIqsw3/nYoJoVugHQarVIS0vDkCFDYGVlZe7imE1DaQfdNzmIiIio8WCgTURwd3eHj4+PXlqnTp3w73//GwDg5uYGAMjNzYW7u7uUJzc3Fz169JDy5OXl6W3jwYMHuHnzpvT+0hQKBRQKRZl0KyurCgMjTXHFwbNevhJZpXnrc+BlLJW1Y1NS39uhPpeNiOqf+Ph4fP755/jpp59gY2ODZ555BitWrECHDh2kPIWFhXj11Vexfft2aDQaBAUFISkpSe+baTk5OYiIiMDhw4dhb2+P8PBwxMfHo1kzhgdExsBRx4kIffr0QVZWll7azz//DC8vLwAPB0Zzc3PDwYMHpfUFBQU4ceIEVCoVAEClUiE/Px+ZmZlSnkOHDqGkpAR+fn51UAsiIqLGLz09HZGRkTh+/DjS0tKg1WoRGBiIe/fuSXlmzZqF3bt3Y8eOHUhPT8f169cxZswYaX1xcTGCg4NRVFSEY8eOYcuWLdi8eTMWLFhgjioRNUr8yIqIMGvWLDzzzDNYtmwZxo4di5MnT2Ljxo3YuHEjAEAmk2HmzJlYsmQJ2rdvD29vb8yfPx8eHh4YPXo0gIdPwIcOHYqpU6diw4YN0Gq1iIqKQmhoKEccJyIiMpJ9+/bpLW/evBkuLi7IzMxE//79cfv2bWzatAkpKSkYNGgQACA5ORmdOnXC8ePH4e/vj9TUVFy8eBEHDhyAq6srevTogcWLF2POnDmIjY2FXC43R9WIGhUG2kSEp59+Gjt37kRMTAwWLVoEb29vrFmzBmFhYVKe119/Hffu3cO0adOQn5+Pvn37Yt++fbC2tpbybNu2DVFRURg8eDAsLCwQEhKCtWvXmqNKRERETcLt27cBAE5OTgCAzMxMaLVavZlCOnbsiDZt2iAjIwP+/v7IyMhA165d9b5KHhQUhIiICFy4cAE9e/Yss5+qZgox5UwPVc04UpdMUb+GMktGfVWX7WfIPhhoExEAYMSIERgxYkSF62UyGRYtWoRFixZVmMfJyQkpKSmmKB4RERGVUlJSgpkzZ6JPnz7o0qULgIezgMjlcjg6OurlLT1TSHkziejWlae6M4WYYqaH6s44UhdMOWtJfZ8lo76ri/YzZKYQBtpERERERA1QZGQkzp8/j2+++cbk+6pqphBTzvRQ1YwjdckUs5Y0lFky6qu6bD9DZgphoE1ERERE1MBERUVhz549OHr0KFq3bi2lu7m5oaioCPn5+XpPtXNzc6VZQNzc3HDy5Em97eXm5krrylPdmUJMMdNDdWccqQumDOTq+ywZ9V1dtJ8h2+eo40REREREDYQQAlFRUdi5cycOHToEb29vvfW+vr6wsrLSmykkKysLOTk5ejOFnDt3Tm9azrS0NCiVyjLTfRJRzfCJNhERERFRAxEZGYmUlBR88cUXaN68ufSbagcHB9jY2MDBwQFTpkxBdHQ0nJycoFQqMWPGDKhUKvj7+wMAAgMD4ePjg4kTJyIhIQFqtRrz5s1DZGRkuU+tichwDLSJiIiIiBqI9evXAwAGDhyol56cnIxJkyYBAFavXi3N/qHRaBAUFISkpCQpr6WlJfbs2YOIiAioVCrY2dkhPDy80gFPicgwDLSJiIiIiBoIIaqe6sra2hqJiYlITEysMI+Xl5dJR9Amaur4G20iIiIiIiIiI2KgTURERERERGRERg+0Y2NjIZPJ9F4dO3aU1hcWFiIyMhItW7aEvb09QkJCpOkEiIiIyHiM0Sfn5OQgODgYtra2cHFxwezZs/HgwYO6rgoREVGDYpIn2p07d8aNGzek1zfffCOtmzVrFnbv3o0dO3YgPT0d169fx5gxY0xRDCIioiavNn1ycXExgoODUVRUhGPHjmHLli3YvHkzFixYYI6qEBERNRgmGQytWbNm5U52f/v2bWzatAkpKSkYNGgQgIcjJHbq1AnHjx+XphwgIiIi46hNn5yamoqLFy/iwIEDcHV1RY8ePbB48WLMmTMHsbGxkMvldV0dIiKiBsEkgfalS5fg4eEBa2trqFQqxMfHo02bNsjMzIRWq0VAQICUt2PHjmjTpg0yMjIYaBMRERlZbfrkjIwMdO3aFa6urlKeoKAgRERE4MKFC+jZs2e5+9RoNNBoNNJyQUEBAECr1UKr1Zqopv+j20dd7MsUWH7TUlhWPmq3wkLo/VuRyupXX+tORHXH6IG2n58fNm/ejA4dOuDGjRuIi4tDv379cP78eajVasjlcjg6Ouq9x9XVFWq1usJt1qTD1qVXdZEkw1W3AyLDlL4xKX1ss9MmIkPVtk9Wq9V6QbZuvW5dReLj4xEXF1cmPTU1Fba2trWsVfWlpaXV2b5MgeU3jYTe1cu3uFdJpesrmxrr/v37hhSJiBohowfaw4YNk/7frVs3+Pn5wcvLC59++ilsbGxqtM3adNhVXSSp5ti2xlW6wy59g8JOm4gMZYo+uTpiYmIQHR0tLRcUFMDT0xOBgYFQKpUm26+OVqtFWloahgwZAisrK5Pvz9hYftPqEru/0vUKC4HFvUow/7QFNCWyCvOdjw2qcJ3uoRARNV0m+er4oxwdHfHkk0/i8uXLGDJkCIqKipCfn6/3CXpubm65vx/TqUmHrbvIV3WRJMNVtwMiw+g67IpuUNhpE1FtGdonu7m54eTJk3rb0I1KXlm/rVAooFAoyqRbWVnVaeBV1/szNpbfNDTF1bt30ZTIKs1bWd3qY72JqG6ZPNC+e/curly5gokTJ8LX1xdWVlY4ePAgQkJCAABZWVnIycmBSqWqcBu16bCrukhSzbFtjav0sVz6+GanTUS1ZWifrFKpsHTpUuTl5cHFxQXAw2/bKJVK+Pj4mK0eRERE9Z3RA+3XXnsNI0eOhJeXF65fv46FCxfC0tIS48ePh4ODA6ZMmYLo6Gg4OTlBqVRixowZUKlUHAiNiIjIyGrbJwcGBsLHxwcTJ05EQkIC1Go15s2bh8jIyHI/ACciIqKHjB5o//e//8X48ePx559/wtnZGX379sXx48fh7OwMAFi9ejUsLCwQEhICjUaDoKAgJCUlGbsYRERETV5t+2RLS0vs2bMHERERUKlUsLOzQ3h4OBYtWmSuKhERETUIRg+0t2/fXul6a2trJCYmIjEx0di7JiIiokcYo0/28vKqdHRlIiIiKsvC3AUgIiIiIiIiakwYaBMREREREREZEQNtIipj+fLlkMlkmDlzppRWWFiIyMhItGzZEvb29ggJCZGm+dHJyclBcHAwbG1t4eLigtmzZ+PBgwd1XHoiIiIiIvNioE1Eek6dOoX33nsP3bp100ufNWsWdu/ejR07diA9PR3Xr1/HmDFjpPXFxcUIDg5GUVERjh07hi1btmDz5s1YsGBBXVeBiIiIiMisGGgTkeTu3bsICwvD+++/jxYtWkjpt2/fxqZNm7Bq1SoMGjQIvr6+SE5OxrFjx3D8+HEAQGpqKi5evIitW7eiR48eGDZsGBYvXozExEQUFRWZq0pERERERHXO6KOOE1HDFRkZieDgYAQEBGDJkiVSemZmJrRaLQICAqS0jh07ok2bNsjIyIC/vz8yMjLQtWtXuLq6SnmCgoIQERGBCxcuoGfPnmX2p9FooNFopOWCggIAgFarhVarLbeMCktRaR0UFkLv34pUtP3GQFe3xlzH6mgo7VDfy0dERESGY6BNRAAeTgP03Xff4dSpU2XWqdVqyOVyODo66qW7urpCrVZLeR4NsnXrdevKEx8fj7i4uDLpqampsLW1Lfc9Cb2rrAoAYHGvkkrXN4XpitLS0sxdhHqhvrfD/fv3zV0EIiIiMjIG2kSEa9eu4ZVXXkFaWhqsra3rbL8xMTGIjo6WlgsKCuDp6YnAwEAolcpy39Mldn+l21RYCCzuVYL5py2gKZFVmO98bFDNCt0AaLVapKWlYciQIbCysjJ3ccymobSD7pscRERE1Hgw0CYiZGZmIi8vD0899ZSUVlxcjKNHj+Ldd9/F/v37UVRUhPz8fL2n2rm5uXBzcwMAuLm54eTJk3rb1Y1KrstTmkKhgEKhKJNuZWVVYWCkKa44eNbLVyKrNG99DryMpbJ2bErqezvU57IREZG+tnP31nobV5cHG6EkVN9xMDQiwuDBg3Hu3DmcOXNGevXq1QthYWHS/62srHDw4EHpPVlZWcjJyYFKpQIAqFQqnDt3Dnl5eVKetLQ0KJVK+Pj41HmdiIiIiIjMhU+0iQjNmzdHly5d9NLs7OzQsmVLKX3KlCmIjo6Gk5MTlEolZsyYAZVKBX9/fwBAYGAgfHx8MHHiRCQkJECtVmPevHmIjIws96k1EREREVFjxUCbiKpl9erVsLCwQEhICDQaDYKCgpCUlCStt7S0xJ49exAREQGVSgU7OzuEh4dj0aJFZiw1EREREVHdY6BNROU6cuSI3rK1tTUSExORmJhY4Xu8vLyaxGjeRERERESV4W+0iYiIiIiIiIyIgTYRERERERGRETHQJiIiIiIiIjIiBtpERERERERERsRAm4iIiIiIiMiIGGgTERERERERGREDbSIiIiIiIiIjYqBNRERERNSAHD16FCNHjoSHhwdkMhl27dqlt14IgQULFsDd3R02NjYICAjApUuX9PLcvHkTYWFhUCqVcHR0xJQpU3D37t06rAVR48ZAm4iIiIioAbl37x66d++OxMTEctcnJCRg7dq12LBhA06cOAE7OzsEBQWhsLBQyhMWFoYLFy4gLS0Ne/bswdGjRzFt2rS6qgJRo9fM3AUgIiIiIqLqGzZsGIYNG1buOiEE1qxZg3nz5mHUqFEAgI8++giurq7YtWsXQkND8eOPP2Lfvn04deoUevXqBQBYt24dhg8fjrfeegseHh51VheixopPtImIiIiIGons7Gyo1WoEBARIaQ4ODvDz80NGRgYAICMjA46OjlKQDQABAQGwsLDAiRMn6rzMRI0Rn2gTERERETUSarUaAODq6qqX7urqKq1Tq9VwcXHRW9+sWTM4OTlJeUrTaDTQaDTSckFBAQBAq9VKL92ysSkshdG3aU6l28iUbdcU1GX7GbIPBtpERERERFSp+Ph4xMXFlUlPTU2Fra2ttJyWlmb0fSf0Nvomzeqrr74qN90UbdeU1EX73b9/v9p5GWgTERERETUSbm5uAIDc3Fy4u7tL6bm5uejRo4eUJy8vT+99Dx48wM2bN6X3lxYTE4Po6GhpuaCgAJ6enggMDIRSqYRWq0VaWhqGDBkCKysro9apS+x+o27P3M7HBuktm7LtmoK6bD/dNzmqw+i/0Y6Pj8fTTz+N5s2bw8XFBaNHj0ZWVpZenoEDB0Imk+m9Xn75ZWMXhYiIqEkzVp+ck5OD4OBg2NrawsXFBbNnz8aDBw/qsipEVE3e3t5wc3PDwYMHpbSCggKcOHECKpUKAKBSqZCfn4/MzEwpz6FDh1BSUgI/P79yt6tQKKBUKvVeAGBlZSW9Si8b66UpljWqV3l1NFXbNZVXXbZfdRn9iXZ6ejoiIyPx9NNP48GDB3jjjTcQGBiIixcvws7OTso3depULFq0SFp+9CsnREREVHvG6JOLi4sRHBwMNzc3HDt2DDdu3MCLL74IKysrLFu2rE7rQ0QP3b17F5cvX5aWs7OzcebMGTg5OaFNmzaYOXMmlixZgvbt28Pb2xvz58+Hh4cHRo8eDQDo1KkThg4diqlTp2LDhg3QarWIiopCaGgoRxyvA23n7tVbVlgKJPR++OReUyyr1jauLg82RdHIiIweaO/bt09vefPmzXBxcUFmZib69+8vpdva2lb41RQiIiKqPWP0yampqbh48SIOHDgAV1dX9OjRA4sXL8acOXMQGxsLuVxu0joQUVmnT5/Gs88+Ky3rvtIdHh6OzZs34/XXX8e9e/cwbdo05Ofno2/fvti3bx+sra2l92zbtg1RUVEYPHgwLCwsEBISgrVr19Z5XYgaK5P/Rvv27dsAACcnJ730bdu2YevWrXBzc8PIkSMxf/58PtUmIiIyoZr0yRkZGejataveCMZBQUGIiIjAhQsX0LNnzzL7qWp0YlNr6CP4svymVdUI1goLofdvRSqrn6nrPnDgQAhRcflkMhkWLVqk902V0pycnJCSkmKK4hERTBxol5SUYObMmejTpw+6dOkipU+YMAFeXl7w8PDA2bNnMWfOHGRlZeHzzz8vdzs16bB16VVdJMlw1e2AyDClb0wqmvqBiKgmatonq9XqcqcJ0q0rT3VHJza1hj6CL8tvGtUdwXpxr5JK11c0cjRg2MjERNQ4mTTQjoyMxPnz5/HNN9/opU+bNk36f9euXeHu7o7BgwfjypUraNeuXZnt1KbDruoiSTXHtjWu0h126RsUdtpEVBvG6pOro6rRiU2toY/gy/KbVlUjWCssBBb3KsH80xbQlFT8e9nSI0c/ypCRiYmocTJZoB0VFYU9e/bg6NGjaN26daV5daMbXr58udxOvSYdtu4iX9VFkgxX3Q6IDKPrsCu6QTFlpx0fH4/PP/8cP/30E2xsbPDMM89gxYoV6NChg5SnsLAQr776KrZv3w6NRoOgoCAkJSXpPenKyclBREQEDh8+DHt7e4SHhyM+Ph7NmnEmQSJzqk2f7ObmhpMnT+rlyc3NBYAKf9etUCigUCjKpBs6Ymtt1fX+jI3lN43qDjalKZFVmreyutXHehNR3TL63a8QAjNmzMDOnTtx5MgReHt7V/meM2fOAIDeXH+Pqk2HXdVFkmqObWtcpY/l0se3KTvt6oxMPGvWLOzduxc7duyAg4MDoqKiMGbMGHz77bcAODIxUX1kjD5ZpVJh6dKlyMvLg4uLC4CH37hRKpXw8fExWdmJiIgaMqMH2pGRkUhJScEXX3yB5s2bS7/fcnBwgI2NDa5cuYKUlBQMHz4cLVu2xNmzZzFr1iz0798f3bp1M3ZxiKgaqhqZ+Pbt29i0aRNSUlIwaNAgAEBycjI6deqE48ePw9/fnyMTE9VDxuiTAwMD4ePjg4kTJyIhIQFqtRrz5s1DZGRkuR+CExERkQkC7fXr1wN4OBrio5KTkzFp0iTI5XIcOHAAa9aswb179+Dp6YmQkBDMmzfP2EUhohoqPTJxZmYmtFotAgICpDwdO3ZEmzZtkJGRAX9//xqNTExEpmWMPtnS0hJ79uxBREQEVCoV7OzsEB4eXuloxkREOqXnjCZqKkzy1fHKeHp6Ij093di7JSIjKW9kYrVaDblcDkdHR728rq6u0hOymoxMXJMZBepiWpaGrr5PrVNXGko7mLJ8xuqTvby8Kh1hmYiIiPRxhCIi0lPRyMSmUJMZBepiWpbGor5OrVPX6ns7cEYBIiKixoeBNhFJKhqZ2M3NDUVFRcjPz9d7qp2bmyuNOlyTkYlrMqNAXUzL0tDV96l16kpDaQdOA0RERNT4MNAmoipHJvb19YWVlRUOHjyIkJAQAEBWVhZycnKgUqkA1Gxk4prMKFAX07I0FvV1ap26Vt/boT6XjYiIiGqGgTYRVTkysYODA6ZMmYLo6Gg4OTlBqVRixowZUKlU8Pf3B8CRiYmIiIiIdBhoE1GVIxMDwOrVq2FhYYGQkBBoNBoEBQUhKSlJysuRiYmIiIiIHmKgTURVjkwMANbW1khMTERiYmKFeTgyMRERERERYGHuAhARERERERE1Jgy0iYiIiIiIiIyIgTYRERERERGRETHQJiIiIiIiIjIiBtpERERERERERsRAm4iIiIiIiMiIGGgTERERERERGREDbSIiIiIiIiIjYqBNREREREREZETNzF0AIiIiIiIiqr62c/fWehtXlwcboSRUET7RJiIiIiIiIjIiBtpERERERERERsRAm4iIiIiIiMiIGGgTERERERERGREDbSIiIiIiIiIjYqBNREREREREZEQMtImIiIiIiIiMiIE2ERERERERkREx0CYiIiIiIiIyombmLgARERERERHVrbZz9xplO1eXBxtlO40NA20iogaudEepsBRI6A10id0PTbGs2tthR0lERERkHGb96nhiYiLatm0La2tr+Pn54eTJk+YsDhEZAc9rosaJ5zZR48Rzm8g0zBZof/LJJ4iOjsbChQvx3XffoXv37ggKCkJeXp65ikREtcTzmqhx4rlN1Djx3CYyHbMF2qtWrcLUqVPx0ksvwcfHBxs2bICtrS0+/PBDcxWJiGqJ5zVR48Rzm6hx4rlNZDpm+Y12UVERMjMzERMTI6VZWFggICAAGRkZZfJrNBpoNBpp+fbt2wCAmzdvQqvVlrsPrVaL+/fvo5nWAsUl1f+NIlWtWYnA/fslbFsj+/PPPwH879j9888/YWVlJa2/c+cOAEAIYZbyVcXQ8xqo2bnd7MG9SstR3eNT196NQek2qek52pjaBKj4XKpveG4bX0P521eE5TetuuhH6vt5DRj/fryiv3tV7U0N/97a3PcPdXnNMeTcNkug/ccff6C4uBiurq566a6urvjpp5/K5I+Pj0dcXFyZdG9vb5OVkSo3wdwFaIRavV29fHfu3IGDg4NpC1MDhp7XgOnO7eocn9Vt74aqJudoY2+T+o7nNlH9Yax+pL6e1wDvx+ubhnxv3RTvH6pzbjeIUcdjYmIQHR0tLZeUlODmzZto2bIlZLLyP/UpKCiAp6cnrl27BqVSWVdFbRLYtqZVUfsKIXDnzh14eHiYsXTGVZNzuyo8PtkGOg2lHXhuG19D+dtXhOU3L2OUvyme1w39725ObLvaqcv2M+TcNkug3apVK1haWiI3N1cvPTc3F25ubmXyKxQKKBQKvTRHR8dq7UupVPKANRG2rWmV17719VNxwPDzGqjduV0VHp9sA52G0A48t02jIfztK8Pym1dty1+fz2vAdPfjDf3vbk5su9qpq/ar7rltlsHQ5HI5fH19cfDgQSmtpKQEBw8ehEqlMkeRiKiWeF4TNU48t4kaJ57bRKZltq+OR0dHIzw8HL169ULv3r2xZs0a3Lt3Dy+99JK5ikREtcTzmqhx4rlN1Djx3CYyHbMF2uPGjcPvv/+OBQsWQK1Wo0ePHti3b1+ZARlqSqFQYOHChWW+4kK1x7Y1rYbcvqY+r6ujIbefsbANHmI7GE99OLcN0dD/9iy/eTX08hvCmOd2U2o3Y2Pb1U59bT+ZqM/zDhARERERERE1MGb5jTYRERERERFRY8VAm4iIiIiIiMiIGGgTERERERERGREDbSIiIiIiIiIjapSBdmJiItq2bQtra2v4+fnh5MmT5i5SvRcbGwuZTKb36tixo7S+sLAQkZGRaNmyJezt7RESEoLc3Fy9beTk5CA4OBi2trZwcXHB7Nmz8eDBg7quSr1w9OhRjBw5Eh4eHpDJZNi1a5feeiEEFixYAHd3d9jY2CAgIACXLl3Sy3Pz5k2EhYVBqVTC0dERU6ZMwd27d/XynD17Fv369YO1tTU8PT2RkJBg6qrVC/Hx8Xj66afRvHlzuLi4YPTo0cjKytLLU51jtqGrTjsMHDiwzLn98ssvm6nExrd+/Xp069YNSqUSSqUSKpUKX3/9tbS+KRwHTdnSpUvxzDPPwNbWFo6OjuXm+ec//wlfX18oFAr06NGjzPqrV6+WOUdkMhmOHz9u2sL/f8aoA2C+/qA65a/q/uDIkSPl/g3UanWDKL+uDk899RQUCgWeeOIJbN682eRlr094711zVd0zUsWqcx9kTo0u0P7kk08QHR2NhQsX4rvvvkP37t0RFBSEvLw8cxet3uvcuTNu3Lghvb755htp3axZs7B7927s2LED6enpuH79OsaMGSOtLy4uRnBwMIqKinDs2DFs2bIFmzdvxoIFC8xRFbO7d+8eunfvjsTExHLXJyQkYO3atdiwYQNOnDgBOzs7BAUFobCwUMoTFhaGCxcuIC0tDXv27MHRo0cxbdo0aX1BQQECAwPh5eWFzMxMrFy5ErGxsdi4caPJ62du6enpiIyMxPHjx5GWlgatVovAwEDcu3dPylPVMdsYVKcdAGDq1Kl653Zj+kCmdevWWL58OTIzM3H69GkMGjQIo0aNwoULFwA0jeOgKSsqKsILL7yAiIiISvNNnjwZ48aNqzTPgQMH9M4TX19fYxa1Qsaogzn7g6rKb8j9QVZWlt7fwMXFxdTFN0r5s7OzERwcjGeffRZnzpzBzJkz8fe//x379+83efnrA957105V94xUsereB5mNaGR69+4tIiMjpeXi4mLh4eEh4uPjzViq+m/hwoWie/fu5a7Lz88XVlZWYseOHVLajz/+KACIjIwMIYQQX331lbCwsBBqtVrKs379eqFUKoVGozFp2es7AGLnzp3ScklJiXBzcxMrV66U0vLz84VCoRD/+te/hBBCXLx4UQAQp06dkvJ8/fXXQiaTid9++00IIURSUpJo0aKFXvvOmTNHdOjQwcQ1qn/y8vIEAJGeni6EqN4x2xiVbgchhBgwYIB45ZVXzFcoM2jRooX44IMPmuxx0BQlJycLBweHSvNU1M9lZ2cLAOL77783SdmqqzZ1qA/9QUXlr879weHDhwUAcevWrToqbVm1Kf/rr78uOnfurPe+cePGiaCgIJOWub7gvbfxlL5nJMOUdx9kTo3qiXZRUREyMzMREBAgpVlYWCAgIAAZGRlmLFnDcOnSJXh4eODxxx9HWFgYcnJyAACZmZnQarV67dqxY0e0adNGateMjAx07doVrq6uUp6goCAUFBRIT5booezsbKjVar32dHBwgJ+fn157Ojo6olevXlKegIAAWFhY4MSJE1Ke/v37Qy6XS3mCgoKQlZWFW7du1VFt6ofbt28DAJycnABU75htjEq3g862bdvQqlUrdOnSBTExMbh//745imdyxcXF2L59O+7duweVStVkjwOqmeeeew4uLi7o27cvvvzyS3MXxyD1uT8w5P6gR48ecHd3x5AhQ/Dtt9/WdVHLVZ3yZ2Rk6F1ndHmawnWG995Un1R0H2QuzcxdAGP6448/UFxcrHcxBABXV1f89NNPZipVw+Dn54fNmzejQ4cOuHHjBuLi4tCvXz+cP38earUacrm8zG+XXF1dpd9PqdXqcttdt47+R9ce5bXXo+1Z+itzzZo1g5OTk14eb2/vMtvQrWvRooVJyl/flJSUYObMmejTpw+6dOkCANU6Zhub8toBACZMmAAvLy94eHjg7NmzmDNnDrKysvD555+bsbTGde7cOahUKhQWFsLe3h47d+6Ej48Pzpw50+SOAzKcvb093n77bfTp0wcWFhb497//jdGjR2PXrl147rnnzF28aqnP/UF17g/c3d2xYcMG9OrVCxqNBh988AEGDhyIEydO4KmnnqrzMj+qOuWvKE9BQQH++usv2NjY1E1hzYD33lRfVHQfZE6NKtCmmhs2bJj0/27dusHPzw9eXl749NNPG3UHQQ1fZGQkzp8/rzemQFNUUTs8+rv+rl27wt3dHYMHD8aVK1fQrl27ui6mSXTo0AFnzpzB7du38dlnnyE8PBzp6enmLhbV0Ny5c7FixYpK8/z44496A3bWRqtWrRAdHS0tP/3007h+/TpWrlxZ40C7rutgbHVd/g4dOqBDhw7S8jPPPIMrV65g9erV+Pjjjw3eXkNvfyIyXH28H2xUgXarVq1gaWlZZkTZ3NxcuLm5malUDZOjoyOefPJJXL58GUOGDEFRURHy8/P1ngw92q5ubm5lRpjU/R3Y9vp07ZGbmwt3d3cpPTc3VxpN1s3NrcwgIg8ePMDNmzf12ry8Y/3RfTR2UVFR0kBxrVu3ltLd3NyqPGYbk4raoTx+fn4AgMuXLzeaQFsul+OJJ54AAPj6+uLUqVN45513MG7cuCZ1HDQWr776KiZNmlRpnscff9ykZfDz80NaWlqN31/XdTB2f2DM8tf0/qB37941vmGu6/JX1P5KpbLRP6zgvTfVB4bcB9WlRhVoy+Vy+Pr64uDBgxg9ejSAh18jOHjwIKKiosxbuAbm7t27uHLlCiZOnAhfX19YWVnh4MGDCAkJAfBwZNCcnByoVCoAgEqlwtKlS5GXlyd95TktLQ1KpRI+Pj5mq0d95O3tDTc3Nxw8eFAKrAsKCnDixAlp1FOVSoX8/HxkZmZKI98eOnQIJSUlUqCkUqnw5ptvQqvVwsrKCsDDNu/QoUOj/9q4EAIzZszAzp07ceTIkTJfmazOMdsYVNUO5Tlz5gwA6H3I09iUlJRAo9E0meOgsXF2doazs7NZy3DmzJlanSN1XQdj9wfGLH9N7w9q8zeo6/KrVCp89dVXeu9LS0trEtcZ3nuTOdXkPqhOmXkwNqPbvn27UCgUYvPmzeLixYti2rRpwtHRUW+0SCrr1VdfFUeOHBHZ2dni22+/FQEBAaJVq1YiLy9PCCHEyy+/LNq0aSMOHTokTp8+LVQqlVCpVNL7Hzx4ILp06SICAwPFmTNnxL59+4Szs7OIiYkxV5XM6s6dO+L7778X33//vQAgVq1aJb7//nvx66+/CiGEWL58uXB0dBRffPGFOHv2rBg1apTw9vYWf/31l7SNoUOHip49e4oTJ06Ib775RrRv316MHz9eWp+fny9cXV3FxIkTxfnz58X27duFra2teO+99+q8vnUtIiJCODg4iCNHjogbN25Ir/v370t5qjpmG4Oq2uHy5cti0aJF4vTp0yI7O1t88cUX4vHHHxf9+/c3c8mNZ+7cuSI9PV1kZ2eLs2fPirlz5wqZTCZSU1OFEE3jOGjKfv31V/H999+LuLg4YW9vL11379y5I+W5dOmS+P7778U//vEP8eSTT0p5dCNGb968WaSkpIgff/xR/Pjjj2Lp0qXCwsJCfPjhhw2mDubsD6oqf3XuD1avXi127dolLl26JM6dOydeeeUVYWFhIQ4cONAgyv/LL78IW1tbMXv2bPHjjz+KxMREYWlpKfbt22fy8tcHvPeunaruGali1bkfNKdGF2gLIcS6detEmzZthFwuF7179xbHjx83d5HqvXHjxgl3d3chl8vFY489JsaNGycuX74srf/rr7/E9OnTRYsWLYStra14/vnnxY0bN/S2cfXqVTFs2DBhY2MjWrVqJV599VWh1Wrruir1gm6qktKv8PBwIcTDKb7mz58vXF1dhUKhEIMHDxZZWVl62/jzzz/F+PHjhb29vVAqleKll17Su/ESQogffvhB9O3bVygUCvHYY4+J5cuX11UVzaq8tgUgkpOTpTzVOWYbuqraIScnR/Tv3184OTkJhUIhnnjiCTF79mxx+/Zt8xbciCZPniy8vLyEXC4Xzs7OYvDgwVKQLUTTOA6asvDw8HLPgcOHD0t5BgwYUG6e7OxsIcTDQLtTp07C1tZWKJVK0bt3b70p4RpCHYQwX39QnfJXdX+wYsUK0a5dO2FtbS2cnJzEwIEDxaFDhxpM+YV42O/36NFDyOVy8fjjj+v1R00B771rrqp7RqpYde4HzUkmhBDGeTZORERERERERI1qHm0iIiIiIiIic2OgTURERERERGREDLSJiIiIiIiIjIiBNhERERERNXmxsbGQyWT4448/TLqfzZs3QyaT4fTp0ybdD5kXA+16atKkSWjbtq25i2EWAwcOxMCBA81dDKIa03XUZDiZTIbY2FhzF4Oo3rl69SpkMhk2b95s7qIQUTUlJSXxnG3CGGgTEVG9dezYMcTGxiI/P9/cRSEiIjIIA+2mrZm5C0Dle//991FSUmLuYhAR1am//voLzZr9r2s6duwY4uLiMGnSJDg6OpqvYERm5uXlhb/++gtWVlbmLgoRmZEQAoWFhbCxsTF3UagKfKJdT1lZWUGhUJi7GEREdcra2lov0Caih2QyGaytrWFpaWnuopjcvXv3zF0EauL++OMPjB07FkqlEi1btsQrr7yCwsJCaX1ycjIGDRoEFxcXKBQK+Pj4YP369XrbaNu2LS5cuID09HTIZDLIZLIyP43UaDSIjo6Gs7Mz7Ozs8Pzzz+P3338vs50RI0Zg//796NWrF2xsbPDee+8BAH755Re88MILcHJygq2tLfz9/bF3794y9cnLy8OUKVPg6uoKa2trdO/eHVu2bNHLo/t5yltvvYXExEQ8/vjjsLW1RWBgIK5duwYhBBYvXozWrVvDxsYGo0aNws2bN/W2cfr0aQQFBaFVq1awsbGBt7c3Jk+ebHD719bRo0cxcuRIeHh4QCaTYdeuXQa9X/cTwNIvOzs7g7bDQNtM7ty5g5kzZ6Jt27ZQKBRwcXHBkCFD8N133wEo+xvtRw/+jRs3ol27dlAoFHj66adx6tSpMtv/6aefMHbsWDg7O8PGxgYdOnTAm2++qZfnt99+w+TJk+Hq6gqFQoHOnTvjww8/NKgeI0aMwOOPP17uOpVKhV69eknL1bkolUc3YMTVq1f10o8cOQKZTIYjR47opZ84cQJDhw6Fg4MDbG1tMWDAAHz77bcG1Yuour755hs8/fTTsLa2Rrt27aTO71HVOfbDw8PRqlUraLXaMu8PDAxEhw4dpOW0tDT07dsXjo6OsLe3R4cOHfDGG28YXPakpCR07twZCoUCHh4eiIyMLPMV7YEDB6JLly64ePEinn32Wdja2uKxxx5DQkKCwfurTgf86G+0Y2NjMXv2bACAt7e31NE9ei3YunUrfH19YWNjAycnJ4SGhuLatWsGl40IAH799VdMnz4dHTp0gI2NDVq2bIkXXnihTP8DAGfPnsWAAQNgY2OD1q1bY8mSJUhOTi63v/r666/Rr18/2NnZoXnz5ggODsaFCxcMKlt5v9GeNGkS7O3t8dtvv2H06NGwt7eHs7MzXnvtNRQXF1d72wsXLoSVlVWZG3wAmDZtGhwdHfWCjOrU5+zZs5g0aRIef/xxWFtbw83NDZMnT8aff/6pl093Q3vx4kVMmDABLVq0QN++fQEAarUaL730Elq3bg2FQgF3d3eMGjWq3L8HkTGNHTsWhYWFiI+Px/Dhw7F27VpMmzZNWr9+/Xp4eXnhjTfewNtvvw1PT09Mnz4diYmJUp41a9agdevW6NixIz7++GN8/PHHZe7FZ8yYgR9++AELFy5EREQEdu/ejaioqDLlycrKwvjx4zFkyBC888476NGjB3Jzc/HMM89g//79mD59OpYuXYrCwkI899xz2Llzp/Tev/76CwMHDsTHH3+MsLAwrFy5Eg4ODpg0aRLeeeedMvvatm0bkpKSMGPGDLz66qtIT0/H2LFjMW/ePOzbtw9z5szBtGnTsHv3brz22mvS+/Ly8hAYGIirV69i7ty5WLduHcLCwnD8+PFa/S1q4t69e+jevbve38MQr732Gm7cuKH38vHxwQsvvGDYhgSZxYQJE4RcLhfR0dHigw8+ECtWrBAjR44UW7duFUIIER4eLry8vKT82dnZAoDo2bOneOKJJ8SKFStEQkKCaNWqlWjdurUoKiqS8v7www9CqVSKli1bipiYGPHee++J119/XXTt2lXKo1arRevWrYWnp6dYtGiRWL9+vXjuuecEALF69epq1+Ojjz4SAMTJkyf10q9evSoAiJUrV0ppTz/9tJg0aZJYvXq1WLdunQgMDBQAxLvvvqv33gEDBogBAwZIy8nJyQKAyM7O1st3+PBhAUAcPnxYSjt48KCQy+VCpVKJt99+W6xevVp069ZNyOVyceLEiWrXi6g6zp49K2xsbESbNm1EfHy8WLx4sXB1dRXdunUTj15eq3Psp6WlCQBi9+7devu4ceOGsLS0FIsWLRJCCHH+/Hkhl8tFr169xDvvvCM2bNggXnvtNdG/f3+Dyr5w4UIBQAQEBIh169aJqKgoYWlpKZ5++mm968mAAQOEh4eH8PT0FK+88opISkoSgwYNEgDEV199Ve395ebmihYtWognn3xSrFy5Urz//vvizTffFJ06ddLLB0AsXLhQCPHwWjZ+/HjpuvTxxx+Ljz/+WNy9e1cIIcSSJUuETCYT48aNE0lJSSIuLk60atVKtG3bVty6dcug9iASQogdO3aI7t27iwULFoiNGzeKN954Q7Ro0UJ4eXmJe/fuSfn++9//CicnJ9GyZUsRFxcn3nrrLdGxY0fRvXv3Mv3VRx99JGQymRg6dKhYt26dWLFihWjbtq1wdHQs069VRncfkJycLKWFh4cLa2tr0blzZzF58mSxfv16ERISIgCIpKSkam/70qVLAoBYt26dXrpGoxEtWrQQkydPNrg+b731lujXr59YtGiR2Lhxo3jllVeEjY2N6N27tygpKZHy6a5FPj4+YtSoUSIpKUkkJiYKIYR45plnhIODg5g3b5744IMPxLJly8Szzz4r0tPTq103IkPojsfnnntOL3369OkCgPjhhx+EEELcv3+/zHuDgoLE448/rpfWuXNnvXtaHd29bUBAgN75MGvWLGFpaSny8/OlNC8vLwFA7Nu3T28bM2fOFADEf/7zHyntzp07wtvbW7Rt21YUFxcLIYRYs2aNACDFGEIIUVRUJFQqlbC3txcFBQVCiP9dY5ydnfX2HxMTIwCI7t27C61WK6WPHz9eyOVyUVhYKIQQYufOnQKAOHXqVJn6mhMAsXPnTr20wsJC8eqrrwoPDw9ha2srevfurRdPlHbmzBkBQBw9etSwfdegvGQEDg4OIjIyssL1FQXaLVu2FDdv3pTSv/jiizI35/379xfNmzcXv/76q942Hz2Rp0yZItzd3cUff/yhlyc0NFQ4ODiUewEpz+3bt4VCoRCvvvqqXnpCQoKQyWR6ZajuRammgXZJSYlo3769CAoK0qvr/fv3hbe3txgyZEi16kRUXaNHjxbW1tZ6x/nFixeFpaWlXqBdnWO/uLhYtG7dWowbN04v36pVq4RMJhO//PKLEEKI1atXCwDi999/r3G58/LyhFwuF4GBgVJHLIQQ7777rgAgPvzwQyltwIABAoD46KOPpDSNRiPc3NxESEhItfdZ3Q740UBbCCFWrlxZ7vl/9epVYWlpKZYuXaqXfu7cOdGsWbMy6UTVUd65mpGRUeYcmDFjhpDJZOL777+X0v7880/h5OSkd7zeuXNHODo6iqlTp+ptU61WCwcHhzLplako0AYgfRCn07NnT+Hr61vtbQshhEqlEn5+fnppn3/+uV4/a0h9ymvLf/3rX2VuVnWBzfjx4/Xy3rp1q8wH9kSmpjse9+/fr5f+448/CgAiPj6+zHvy8/PF77//LpYtWyYA6AWpVQXan376qV667pzTBfRCPAy0vb29y2zjySefFL179y6THh8fLwCIc+fOCSGECAwMFG5ubnr9vRD/Ox91MYTuGjN9+nS9fLt27Sr3XNQF8FeuXBFC/O++fOHChXof2JtbeYH23//+d/HMM8+Io0ePisuXL4uVK1cKhUIhfv7553K3ERUVJZ588kmD982vjpuJo6MjTpw4gevXrxv0vnHjxqFFixbScr9+/QA8/I0GAPz+++84evQoJk+ejDZt2ui9VzfdkBAC//73vzFy5EgIIfDHH39Ir6CgINy+fVv6CntVlEolhg0bhk8//RQPj+WHPvnkE/j7++uV4dFBG27fvo0//vgDAwYMwC+//ILbt28b1A7lOXPmDC5duoQJEybgzz//lOp07949DB48GEePHuUAc2Q0xcXF2L9/P0aPHq13nHfq1AlBQUF6eatz7FtYWCAsLAxffvkl7ty5I+Xftm0bnnnmGXh7ewOANCDYF198UePj+cCBAygqKsLMmTNhYfG/bmDq1KlQKpVlft9lb2+Pv/3tb9KyXC5H7969petOdejKvWfPnnK/Hm+ozz//HCUlJRg7dqzeNczNzQ3t27fH4cOHa70PanoePVe1Wi3+/PNPPPHEE3B0dNTrF/ft2weVSoUePXpIaU5OTggLC9PbXlpaGvLz8zF+/Hi949TS0hJ+fn5GO05ffvllveV+/foZdH4CwIsvvogTJ07gypUrUtq2bdvg6emJAQMGADCsPo+2ZWFhIf744w/4+/sDQLn3GKXrYGNjA7lcjiNHjuDWrVsG1YWottq3b6+33K5dO1hYWEg/W/j2228REBAAOzs7ODo6wtnZWfoJlyH3tKXv1XX3+KWPed09wKN+/fVXvZ+V6XTq1Elar/u3ffv2ev19efkqKpODgwMAwNPTs9x0XVkHDBiAkJAQxMXFoVWrVhg1ahSSk5Oh0WjKlNGccnJykJycjB07dqBfv35o164dXnvtNfTt2xfJycll8hcWFmLbtm2YMmWKwftioG0mCQkJOH/+PDw9PdG7d2/ExsZWq1Os6oTUbaNLly4VbuP3339Hfn4+Nm7cCGdnZ73XSy+9BODh7yyqa9y4cbh27RoyMjIAAFeuXEFmZibGjRunl89YF6WKXLp0CcDD37qWrtcHH3wAjUZjlP0QAQ/Po7/++qtMZwygTMdX3WP/xRdfxF9//SX9tiorKwuZmZmYOHGilGfcuHHo06cP/v73v8PV1RWhoaH49NNPDQq6dZ1q6XLK5XI8/vjjZTrd1q1bl5kXvEWLFgbd/Bq7A7506RKEEGjfvn2Z8/3HH3806BpGpPPXX39hwYIF8PT0hEKhQKtWreDs7Iz8/Hy9c/XXX3/FE088Ueb9pdN0/dKgQYPKHKepqalGOU6tra3h7Oysl2bo+Qk8vLYoFAps27YNwMNr0549exAWFiad/4bU5+bNm3jllVfg6uoKGxsbODs7S8FCeX1x6UBCoVBgxYoV+Prrr+Hq6or+/fsjISEBarXaoHoRGcOjfeCVK1cwePBg/PHHH1i1ahX27t2LtLQ0zJo1CwAM6o8rGtzw0YdXAOp0hPGKylRVWWUyGT777DNkZGQgKipKGgvK19cXd+/eNVl5DXXu3DkUFxfjySefhL29vfRKT0/X+6BRZ+fOnbhz5w7Cw8MN3heHdjWTsWPHol+/fti5cydSU1OxcuVKrFixAp9//jmGDRtW4fuqe0JWRncB+Nvf/lbhQdOtW7dqb2/kyJGwtbXFp59+imeeeQaffvopLCws9AYM0F2UOnbsiFWrVsHT0xNyuRxfffUVVq9eXelFqfQNvk7pgV5021i5cqXeU4ZH2dvbV7teRMZgyLHv4+MDX19fbN26FS+++CK2bt0KuVyOsWPHSnlsbGxw9OhRHD58GHv37sW+ffvwySefYNCgQUhNTTXJiMTGuO7oOuDjx49j9+7d2L9/PyZPnoy3334bx48fN/jcLCkpgUwmw9dff11u+XiuU03MmDEDycnJmDlzJlQqFRwcHCCTyRAaGlqjb5Do3vPxxx/Dzc2tzHpjjLBvrHO+RYsWGDFiBLZt24YFCxbgs88+g0aj0fs2iyH1GTt2LI4dO4bZs2ejR48esLe3R0lJCYYOHVpuW5YXSMycORMjR47Erl27sH//fsyfPx/x8fE4dOgQevbsaYxqE5Xr0qVLeh/+XL58GSUlJWjbti12794NjUaDL7/8Uu8BWHnfUKnoHtYYvLy8kJWVVSb9p59+ktbr/j179ixKSkr0nmqXzmcs/v7+8Pf3x9KlS5GSkoKwsDBs374df//73426n5q6e/cuLC0tkZmZWeb6Wd69wwcffIARI0bA1dXV4H0x0DYjd3d3TJ8+HdOnT0deXh6eeuopLF26tNJAuyq6EcDPnz9fYR5nZ2c0b94cxcXFCAgIqPG+dOzs7DBixAjs2LEDq1atwieffIJ+/frBw8NDymPIRak03VP70qMhl37q1q5dOwAPv85ujHoRVUY3or/uCc+jHu34DD32X3zxRURHR+PGjRtISUlBcHCw3s9FgIdfMx88eDAGDx6MVatWYdmyZXjzzTdx+PDhah37uk41KytLb9aAoqIiZGdnm/T8MbQDrugmpV27dhBCwNvbG08++aTJyktNy2effYbw8HC8/fbbUlphYWGZ/sfLywuXL18u8/7Sabp+ycXFpUH0Sy+++CJGjRqFU6dOYdu2bejZsyc6d+4sra9ufW7duoWDBw8iLi4OCxYskNLLu15WpV27dnj11Vfx6quv4tKlS+jRowfefvttbN261eBtEVVXYmIiAgMDpeV169YBAIYNG4ajR48C0P+w+fbt2+V+7djOzq7M9cNYhg8fjjVr1iAjIwMqlQrAw9G2N27ciLZt28LHx0fKl5qaik8++QTjx48HADx48ADr1q2Dvb299NOQ2rp16xYcHR31+m3dg6/69PXxnj17ori4GHl5edJPcCuSnZ2Nw4cP48svv6zRvvjVcTMoLi4u87UpFxcXeHh41PpAdHZ2Rv/+/fHhhx8iJydHb53ugmBpaYmQkBD8+9//LjcgL296j6qMGzcO169fxwcffIAffvihzNfGdZ8YVeeiVJquY9dd2ICHbbhx40a9fL6+vmjXrh3eeuutcr+iUpN6EVXE0tISQUFB2LVrl9659uOPP2L//v16+YDqH/vjx4+HTCbDK6+8gl9++UXvaRKAMnNWAoZ3ZAEBAZDL5Vi7dq1euTZt2oTbt28jODi4WtsxxK1bt8o8Aa9OuXVzVpa+URkzZgwsLS0RFxdXZrtCiDJTCBFVh6WlZZnjad26dWW+QRUUFISMjAycOXNGSrt586b0tetH8ymVSixbtqzcsQnqW780bNgwtGrVCitWrEB6enqZ609161PedQ94ON1Rdd2/f19vSjHg4f1A8+bN69VNOzVO2dnZeO6555CUlISJEyciKSkJEyZMQPfu3REYGAi5XI6RI0ciMTERK1asgK+vL1xcXMpsx9fXF2fPnsWSJUuwfft2HDp0yGhlnDt3LlxdXTFs2DAsWLAAa9asQd++fZGdnY1Vq1ZJT6+nTZuGTp06YdKkSXjttdfw7rvvIiAgAN9++y2WLFmC5s2bG6U8W7ZsQYcOHTBnzhxs3LgRb7/9NsaMGQOlUonhw4cbZR/VdffuXZw5c0a6RmdnZ+PMmTPIycnBk08+ibCwMLz44ov4/PPPkZ2djZMnTyI+Pr7MGDUffvgh3N3da/wQlE+0zeDOnTto3bo1/u///g/du3eHvb09Dhw4gFOnTul9il5Ta9euRd++ffHUU09h2rRp8Pb2xtWrV7F3717pgFu+fDkOHz4MPz8/TJ06FT4+Prh58ya+++47HDhwoNyb+coMHz4czZs3x2uvvSYF8o969KL0j3/8A3fv3sX7778PFxcX3Lhxo9Jtd+7cGf7+/oiJicHNmzfh5OSE7du348GDB3r5LCws8MEHH2DYsGHo3LkzXnrpJTz22GP47bffcPjwYSiVSuzevdugehFVJi4uDvv27UO/fv0wffp06RPizp074+zZswAMP/adnZ0xdOhQ7NixA46OjmWC3kWLFuHo0aMIDg6Gl5cX8vLykJSUhNatW0tzz1bF2dkZMTExiIuLw9ChQ/Hcc88hKysLSUlJePrpp8vcXBvDli1bkJSUhOeffx7t2rXDnTt38P7771fZAfv6+gIA3nzzTYSGhsLKygojR45Eu3btsGTJEsTExODq1asYPXo0mjdvjuzsbOzcuRPTpk3Tm9+TqDpGjBiBjz/+GA4ODvDx8UFGRgYOHDiAli1b6uV7/fXXsXXrVgwZMgQzZsyAnZ0dPvjgA7Rp0wY3b96UnugolUqsX78eEydOxFNPPYXQ0FA4OzsjJycHe/fuRZ8+ffDuu++ao6rlsrKyQmhoKN59911YWlpKT790qlsfpVIp/aZaq9XiscceQ2pqKrKzs6tdlp9//hmDBw/G2LFj4ePjg2bNmmHnzp3Izc1FaGiosatOpOeTTz7BggULMHfuXDRr1gxRUVFYuXIlgIfjm3z22WeYN28eXnvtNbi5uSEiIgLOzs6YPHmy3nYWLFiAX3/9FQkJCbhz5w4GDBiAQYMGGaWMrq6uOHbsGObMmYN169ahsLAQ3bp1w+7du/XuHWxsbHDkyBHMnTsXW7ZsQUFBATp06IDk5GRMmjTJKGUBHo7FcvLkSWzfvh25ublwcHBA7969sW3btnIHczOl06dP49lnn5WWo6OjATwcx2nz5s1ITk7GkiVL8Oqrr+K3335Dq1at4O/vjxEjRkjvKSkpwebNmzFp0qSa/0TH4HHKqdY0Go2YPXu26N69u2jevLmws7MT3bt315vzsqLpvcqb5gKlpsMR4uFcu88//7xwdHQU1tbWokOHDmL+/Pl6eXJzc0VkZKTw9PQUVlZWws3NTQwePFhs3LixRvUKCwuT5gQsz5dffim6desmrK2tRdu2bcWKFSvEhx9+WGbqntLTewkhxJUrV0RAQIBQKBTC1dVVvPHGG9K8w6Xnvfv+++/FmDFjRMuWLYVCoRBeXl5i7Nix4uDBgzWqF1Fl0tPTha+vr5DL5eLxxx8XGzZskKYH0anusa/z6aefCgBi2rRpZdYdPHhQjBo1Snh4eAi5XC48PDzE+PHjK5ySojLvvvuu6Nixo7CyshKurq4iIiKizPzTAwYMEJ07dy7z3tLXqKp89913Yvz48aJNmzZCoVAIFxcXMWLECHH69Gm9fOVdzxYvXiwee+wxYWFhUabN/v3vf4u+ffsKOzs7YWdnJzp27CgiIyNFVlZWtctGpHPr1i3x0ksviVatWgl7e3sRFBQkfvrpJ+Hl5SXCw8P18n7//feiX79+QqFQiNatW4v4+Hixdu1aAUCo1Wq9vIcPHxZBQUHCwcFBWFtbi3bt2olJkyaVOf4rU9H0XnZ2dmXylr4GGeLkyZMCgAgMDKwwT3Xq89///le6D3FwcBAvvPCCuH79eplzXFfW0lMW/vHHHyIyMlJ07NhR2NnZCQcHB+Hn51dmOiQiovpKJoQBo9kQEZHJffHFFxg9ejSOHj1a5e+HiKj+mDlzJt577z1psJ2G6IcffkCPHj3w0Ucf6c14QEREhuFvtImI6pn3338fjz/+eLW/Ck5Ede+vv/7SW/7zzz/x8ccfo2/fvg02yAYeXn/s7e0xZswYcxeFiKhB42+0qUK///57mQFgHiWXy+Hk5FSHJSJq3LZv346zZ89i7969eOedd2o0LYg5zlteK6gpUqlUGDhwIDp16oTc3Fxs2rQJBQUFmD9/vkHbKSoqqnJcFAcHhxrPo3vz5k0UFRVVuN7S0hLOzs7YvXs3Ll68iI0bNyIqKkoaiJCIiGqGXx2nCrVt27bMFFqPGjBgAI4cOVJ3BSJq5GQyGezt7TFu3Dhs2LChRnPsmuO85bWCmqI33ngDn332Gf773/9CJpPhqaeewsKFCw2exuvIkSN6g/aUpzaDFg0cOBDp6ekVrvfy8sLVq1fRtm1b5ObmIigoCB9//LHRRiImImqqGGhThb799tsyX417VIsWLaQRgYmofjDHectrBVHN3bp1C5mZmZXm6dy5M9zd3Wu0/czMTNy6davC9TY2NujTp0+Ntk1ERBVjoE1ERERERERkRBwMjYiIiIionjh69ChGjhwJDw8PyGQy7Nq1S2+9EAILFiyAu7s7bGxsEBAQgEuXLunluXnzJsLCwqBUKuHo6IgpU6bg7t27ennOnj2Lfv36wdraGp6enkhISDB11YialAY5GFpJSQmuX7+O5s2b12iwIKKGSAiBO3fuwMPDAxYWjfMzMp7b1BTx3CZqfGpzXt+7dw/du3fH5MmTyx39PSEhAWvXrsWWLVvg7e2N+fPnIygoCBcvXoS1tTUAICwsDDdu3EBaWhq0Wi1eeuklTJs2DSkpKQCAgoICBAYGIiAgABs2bMC5c+cwefJkODo6Ytq0adUqJ89raooMOrfNMnt3LV27dk0A4IuvJvm6du2auU9Bk+G5zVdTfhl6bqenp4sRI0YId3d3AUDs3LlTb31JSYmYP3++cHNzE9bW1mLw4MHi559/1svz559/igkTJojmzZsLBwcHMXnyZHHnzh29PD/88IPo27evUCgUonXr1mLFihU8t/niq5qv2vbZgP65XVJSItzc3MTKlSultPz8fKFQKMS//vUvIYQQFy9eFADEqVOnpDxff/21kMlk4rfffhNCCJGUlCRatGghNBqNlGfOnDmiQ4cO1S4bz2u+mvKrOud2rZ5oL1++HDExMXjllVewZs0aAEBhYSFeffVVbN++HRqNBkFBQUhKSoKrq6v0vpycHERERODw4cOwt7dHeHg44uPjqz3Crm4kzGvXrkGpVErpWq0WqampCAwMhJWVVW2qVu81pboCTau+FdW1oKAAnp6ejXok2IrObR0eB41XU6pv6brW9NxuKE+9AJ7b5sJ2NZ2q2tZUfXZ2djbUarXe6PYODg7w8/NDRkYGQkNDkZGRAUdHR/Tq1UvKExAQAAsLC5w4cQLPP/88MjIy0L9/f8jlcilPUFAQVqxYgVu3bqFFixZl9q3RaKDRaKRl8f+Hefrggw8QHBzMY8xAWq0Whw8fxrPPPsu2M4C52+3OnTvw9vau1rld40D71KlTeO+999CtWze99FmzZmHv3r3YsWMHHBwcEBUVhTFjxuDbb78FABQXFyM4OBhubm44duwYbty4gRdffBFWVlZYtmxZtfat+3qKUqksE2jb2tpCqVQ2+gO2KdUVaFr1raqujfnrWRWd2zo8DhqvplTfiupq6Lk9bNgwDBs2rNx1QgisWbMG8+bNw6hRowAAH330EVxdXbFr1y6Ehobixx9/xL59+3Dq1CnphnzdunUYPnw43nrrLXh4eGDbtm0oKirChx9+CLlcjs6dO+PMmTNYtWqVQYE2z23zYLuaTnXb1th9tlqtBgC9B1i6Zd06tVoNFxcXvfXNmjWDk5OTXh5vb+8y29CtKy/Qjo+PR1xcXJl0W1tbnDhxooY1atrYdjVjzna7f/8+gOqd2zUKtO/evYuwsDC8//77WLJkiZR++/ZtbNq0CSkpKRg0aBCAh3M/durUCcePH4e/vz9SU1Nx8eJFHDhwAK6urujRowcWL16MOXPmIDY2Vu+TNSIiIjKcOZ96AWWffBUUFAB4GJxotdoy+XVp5a2jmmO7mk5VbdsY2zwmJgbR0dHSsu6pPQAMGTKEH+YYSKvVIi0tjW1nIHO3m64/q44aBdqRkZEIDg5GQECAXqCdmZkJrVar17F37NgRbdq0QUZGBvz9/ZGRkYGuXbvqfRIXFBSEiIgIXLhwAT179iyzv+p22E2pQ2lKdQWaVn0rqmtTqDsRGYc5n3oBFT/5Sk1Nha2tbYXlTktLq6xaVENsV9OpqG11T72Mzc3NDQCQm5urN7d6bm4uevToIeXJy8vTe9+DBw9w8+ZN6f1ubm7Izc3Vy6Nb1uUpTaFQQKFQlLvOysqKwWINse1qxlztZsg+DQ60t2/fju+++w6nTp0qs06tVkMul8PR0VEvvXTHXl7Hr1tXHkM77KbUoTSlugJNq76l62qqTpuIyNgqevIVGBhY4VfH+WTH+NiuplNV2xry1MsQ3t7ecHNzw8GDB6XAuqCgACdOnEBERAQAQKVSIT8/H5mZmfD19QUAHDp0CCUlJfDz85PyvPnmm9BqtVL509LS0KFDhwo/QCMiwxgUaF+7dg2vvPIK0tLSpIFU6kJ1O+ym1KE0pboCTau+FdXVVJ02ETU+5nzqBVT85KuqJxB8smMabFfTqahta9Ped+/exeXLl6Xl7OxsnDlzBk5OTmjTpg1mzpyJJUuWoH379tJAhx4eHhg9ejQAoFOnThg6dCimTp2KDRs2QKvVIioqCqGhofDw8AAATJgwAXFxcZgyZQrmzJmD8+fP45133sHq1atrXG4i0mdQoJ2ZmYm8vDw89dRTUlpxcTGOHj2Kd999F/v370dRURHy8/P1nmrn5ubqddonT57U225Nv6pS2cXNysoKbefuNaR65bq6PLjW2zClptZ5NqX6lq5rU6l3dXSJ3Q9Nce0GmKnv5zZRbfCpFz2K18yG5fTp03j22WelZd3DpvDwcGzevBmvv/467t27h2nTpiE/Px99+/bFvn379B6Cbdu2DVFRURg8eDAsLCwQEhKCtWvXSusdHByQmpqKyMhI+Pr6olWrVliwYIFBgxxWV1O4Hycqj0GB9uDBg3Hu3Dm9tJdeegkdO3bEnDlz4OnpCSsrKxw8eBAhISEAgKysLOTk5EClUgF42GkvXboUeXl50m/D0tLSoFQq4ePjY4w6ERERNXp86kXUOA0cOFCaOqs8MpkMixYtwqJFiyrM4+TkJE3TV5Fu3brhP//5T43LSUSVMyjQbt68Obp06aKXZmdnh5YtW0rpU6ZMQXR0NJycnKBUKjFjxgyoVCr4+/sDAAIDA+Hj44OJEyciISEBarUa8+bNQ2RkZIUDLBAREZG+xvbUi4iIqDGp8TzaFVm9erXUWWs0GgQFBSEpKUlab2lpiT179iAiIgIqlQp2dnYIDw+v9FM5IiIi0senXkRERPVXrQPtI0eO6C1bW1sjMTERiYmJFb7Hy8sLX331VW13TURERERERFTvWJi7AERERERERESNCQNtIiIiIiIiIiNioE1EAIDffvsNf/vb39CyZUvY2Niga9euOH36tLReCIEFCxbA3d0dNjY2CAgIwKVLl/S2cfPmTYSFhUGpVMLR0RFTpkzB3bt367oqRERERERmxUCbiHDr1i306dMHVlZW+Prrr3Hx4kW8/fbbevPkJiQkYO3atdiwYQNOnDgBOzs7BAUFobCwUMoTFhaGCxcuIC0tDXv27MHRo0c5OjERERERNTlGH3WciBqeFStWwNPTE8nJyVKat7e39H8hBNasWYN58+Zh1KhRAICPPvoIrq6u2LVrF0JDQ/Hjjz9i3759OHXqFHr16gUAWLduHYYPH4633npLmpeXiIiIiKixY6BNRPjyyy8RFBSEF154Aenp6Xjssccwffp0TJ06FQCQnZ0NtVqNgIAA6T0ODg7w8/NDRkYGQkNDkZGRAUdHRynIBoCAgABYWFjgxIkTeP7558vsV6PRQKPRSMsFBQUAAK1WC61WWya/Lk1hUfGURtVV3vbrE1356ns5jaUp1bd0XZtCnYmIiJoaBtpEhF9++QXr169HdHQ03njjDZw6dQr//Oc/IZfLER4eDrVaDQBwdXXVe5+rq6u0Tq1Ww8XFRW99s2bN4OTkJOUpLT4+HnFxcWXSU1NTYWtrW2F5F/cqMah+5WkoUwympaWZuwh1qinVV1fX+/fvm7kkREREZGwMtIkIJSUl6NWrF5YtWwYA6NmzJ86fP48NGzYgPDzcZPuNiYlBdHS0tFxQUABPT08EBgZCqVSWya/VapGWlob5py2gKZHVat/nY4Nq9X5T09V1yJAhsLKyMndxTK4p1bd0XXXf5CAiIqLGg4E2EcHd3R0+Pj56aZ06dcK///1vAICbmxsAIDc3F+7u7lKe3Nxc9OjRQ8qTl5ent40HDx7g5s2b0vtLUygUUCgUZdKtrKwqDbY0JTJoimsXaDeUYK6qtmhsmlJ9dXVtKvUlIiJqSjjqOBGhT58+yMrK0kv7+eef4eXlBeDhwGhubm44ePCgtL6goAAnTpyASqUCAKhUKuTn5yMzM1PKc+jQIZSUlMDPz68OakFEREREVD/wiTYRYdasWXjmmWewbNkyjB07FidPnsTGjRuxceNGAIBMJsPMmTOxZMkStG/fHt7e3pg/fz48PDwwevRoAA+fgA8dOhRTp07Fhg0boNVqERUVhdDQUI44TkRERERNCgNtIsLTTz+NnTt3IiYmBosWLYK3tzfWrFmDsLAwKc/rr7+Oe/fuYdq0acjPz0ffvn2xb98+WFtbS3m2bduGqKgoDB48GBYWFggJCcHatWvNUSUiIiIiIrNhoE1EAIARI0ZgxIgRFa6XyWRYtGgRFi1aVGEeJycnpKSkmKJ4REREREQNBn+jTURERERERGREDLSJiIiIiIiIjIiBNhEREREREZERMdAmIiIiIiIiMiIG2kRERERERERGxECbiIiIiIiIyIgYaBMREREREREZEQNtIiIiIiIiIiNioE1ERERERERkRAy0iYiIiIiIiIyIgTYRERERERGRETHQJiIiIiJqINq2bQuZTFbmFRkZCQAYOHBgmXUvv/yy3jZycnIQHBwMW1tbuLi4YPbs2Xjw4IE5qkPUaDUzdwGIiIiIiKh6Tp06heLiYmn5/PnzGDJkCF544QUpberUqVi0aJG0bGtrK/2/uLgYwcHBcHNzw7Fjx3Djxg28+OKLsLKywrJly+qmEkRNAJ9oExERNVJ88kXU+Dg7O8PNzU167dmzB+3atcOAAQOkPLa2tnp5lEqltC41NRUXL17E1q1b0aNHDwwbNgyLFy9GYmIiioqKzFElokbJoEB7/fr16NatG5RKJZRKJVQqFb7++mtpfWFhISIjI9GyZUvY29sjJCQEubm5ettgh01ERFQ3Tp06hRs3bkivtLQ0ACjz5OvRPAkJCdI63ZOvoqIiHDt2DFu2bMHmzZuxYMGCOq8LEZVVVFSErVu3YvLkyZDJZFL6tm3b0KpVK3Tp0gUxMTG4f/++tC4jIwNdu3aFq6urlBYUFISCggJcuHChTstP1JgZ9NXx1q1bY/ny5Wjfvj2EENiyZQtGjRqF77//Hp07d8asWbOwd+9e7NixAw4ODoiKisKYMWPw7bffAuBXVYiIiOqSs7Oz3vLy5csrfPJVHt2TrwMHDsDV1RU9evTA4sWLMWfOHMTGxkIul5u0/ERUuV27diE/Px+TJk2S0iZMmAAvLy94eHjg7NmzmDNnDrKysvD5558DANRqtV6QDUBaVqvVFe5Lo9FAo9FIywUFBdL/tVpthe9TWAqD6lSeyrbfUOnq1BjrZkrmbjdD9mtQoD1y5Ei95aVLl2L9+vU4fvw4WrdujU2bNiElJQWDBg0CACQnJ6NTp044fvw4/P392WETERGZie7JV3R0dJknX1u3boWbmxtGjhyJ+fPnS7/nrOjJV0REBC5cuICePXuWu6+Kbsi1Wm25NynmvnFqrHTtqbBgoGNsVR2zddVemzZtwrBhw+Dh4SGlTZs2Tfp/165d4e7ujsGDB+PKlSto165djfcVHx+PuLi4ctfpvi1TnoTeNd6l5Kuvvqr9RuqpytqOKmaudnv02yFVqfFgaMXFxdixYwfu3bsHlUqFzMxMaLVaBAQESHk6duyINm3aICMjA/7+/ibvsEtf9BrzJ2hN7aakKdW3oro2hboTkenU5ZOvim7IU1NT9QZlKo03nKaxuFdJrbfRmAOd2qjomDXkZrymfv31Vxw4cEA6Xyvi5+cHALh8+TLatWsHNzc3nDx5Ui+P7qeeFX27BQBiYmIQHR0tLRcUFMDT0xMAMGTIEFhZWZX7vi6x+6uuTBXOxwbVehv1jVarRVpaWqVtR2WZu90e/SZHVQwOtM+dOweVSoXCwkLY29tj586d8PHxwZkzZyCXy+Ho6KiX39XVVeqM66rD1l30msInaE3tpqQp1bd0Xeui0yaixqsun3xVdEMeGBioNyiTjrlvnBorXbvOP20BTYms6jdUojEGOrVR1TFryM14TSUnJ8PFxQXBwcGV5jtz5gwAwN3dHQCgUqmwdOlS5OXlwcXFBcDDew6lUgkfH58Kt6NQKKBQKMpdZ2VlVeG5qymu3bGn235jVVnbUcXM1W6G7NPgQLtDhw44c+YMbt++jc8++wzh4eFIT083dDMGqW6HXfqi15g/QWtqNyVNqb4V1bUuOm0iapzq+slXRTfkVd0Y8YbTNDQlsloHO/y7lK+iY9bU7VVSUoLk5GSEh4ejWbP/3c5fuXIFKSkpGD58OFq2bImzZ89i1qxZ6N+/P7p16wYACAwMhI+PDyZOnIiEhASo1WrMmzcPkZGRFQbSRGQ4gwNtuVyOJ554AgDg6+uLU6dO4Z133sG4ceNQVFSE/Px8vafaubm5UmdcVx22Lr0pfILW1G5KmlJ9S9e1qdSbiIyvrp98EZFpHThwADk5OZg8ebJeulwux4EDB7BmzRrcu3cPnp6eCAkJwbx586Q8lpaW2LNnDyIiIqBSqWBnZ4fw8HC9ebeJqPZq/BttnZKSEmg0Gvj6+sLKygoHDx5ESEgIACArKws5OTlQqVQA2GETERHVNT75Imp8AgMDIUTZsYg8PT2r9U1TLy+vev/zSKKGzqBAOyYmBsOGDUObNm1w584dpKSk4MiRI9i/fz8cHBwwZcoUREdHw8nJCUqlEjNmzIBKpYK/vz8AdthERER1jU++iIiI6p5BgXZeXh5efPFF3LhxAw4ODujWrRv279+PIUOGAABWr14NCwsLhISEQKPRICgoCElJSdL72WETERHVLT75IiIiqnsGBdqbNm2qdL21tTUSExORmJhYYR522ERERERERNSYWZi7AERERERERESNCQNtIiIiIiIiIiNioE1ERERERERkRAy0iYiIiIiIiIyIgTYRERERERGRETHQJiIiIiIiIjIig6b3aorazt1b621cXR5shJIQERERERFRQ8An2kRERERERERGxECbiIiIiIiIyIgYaBMREREREREZEQNtIipj+fLlkMlkmDlzppRWWFiIyMhItGzZEvb29ggJCUFubq7e+3JychAcHAxbW1u4uLhg9uzZePDgQR2XnoiIiIjIvBhoE5GeU6dO4b333kO3bt300mfNmoXdu3djx44dSE9Px/Xr1zFmzBhpfXFxMYKDg1FUVIRjx45hy5Yt2Lx5MxYsWFDXVSAiIiIiMisG2kQkuXv3LsLCwvD++++jRYsWUvrt27exadMmrFq1CoMGDYKvry+Sk5Nx7NgxHD9+HACQmpqKixcvYuvWrejRoweGDRuGxYsXIzExEUVFReaqEhERERFRneP0XkQkiYyMRHBwMAICArBkyRIpPTMzE1qtFgEBAVJax44d0aZNG2RkZMDf3x8ZGRno2rUrXF1dpTxBQUGIiIjAhQsX0LNnzzL702g00Gg00nJBQQEAQKvVQqvVlsmvS1NYiFrXtbzt1ye68tX3chpLU6pv6bo2hToTERE1NQy0iQgAsH37dnz33Xc4depUmXVqtRpyuRyOjo566a6urlCr1VKeR4Ns3XrduvLEx8cjLi6uTHpqaipsbW0rLOviXiWV1qU6vvrqq1pvoy6kpaWZuwh1qinVV1fX+/fvm7kkREREZGwMtIkI165dwyuvvIK0tDRYW1vX2X5jYmIQHR0tLRcUFMDT0xOBgYFQKpVl8mu1WqSlpWH+aQtoSmS12vf52KBavd/UdHUdMmQIrKyszF0ck2tK9S1dV903OYiIiKjxYKBNRMjMzEReXh6eeuopKa24uBhHjx7Fu+++i/3796OoqAj5+fl6T7Vzc3Ph5uYGAHBzc8PJkyf1tqsblVyXpzSFQgGFQlEm3crKqtJgS1Mig6a4doF2QwnmqmqLxqYp1VdX16ZSXyIioqaEg6EREQYPHoxz587hzJkz0qtXr14ICwuT/m9lZYWDBw9K78nKykJOTg5UKhUAQKVS4dy5c8jLy5PypKWlQalUwsfHp87rRERERERkLnyiTURo3rw5unTpopdmZ2eHli1bSulTpkxBdHQ0nJycoFQqMWPGDKhUKvj7+wMAAgMD4ePjg4kTJyIhIQFqtRrz5s1DZGRkuU+tiYiIiIgaKwbaRFQtq1evhoWFBUJCQqDRaBAUFISkpCRpvaWlJfbs2YOIiAioVCrY2dkhPDwcixYtMmOpiYiIiIjqHgNtIirXkSNH9Jatra2RmJiIxMTECt/j5eXVYEbzJiIiIiIyFf5Gm4iIiIiIiMiIGGgTERERERERGREDbSIiIiIiIiIjYqBNREREREREZEQMtImIiIiIGojY2FjIZDK9V8eOHaX1hYWFiIyMRMuWLWFvb4+QkBDk5ubqbSMnJwfBwcGwtbWFi4sLZs+ejQcPHtR1VYgaNYMC7fj4eDz99NNo3rw5XFxcMHr0aGRlZenl4clNRERUP/CGnKhx6ty5M27cuCG9vvnmG2ndrFmzsHv3buzYsQPp6em4fv06xowZI60vLi5GcHAwioqKcOzYMWzZsgWbN2/GggULzFEVokbLoEA7PT0dkZGROH78ONLS0qDVahEYGIh79+5JeXhyExER1R+8ISdqfJo1awY3Nzfp1apVKwDA7du3sWnTJqxatQqDBg2Cr68vkpOTcezYMRw/fhwAkJqaiosXL2Lr1q3o0aMHhg0bhsWLFyMxMRFFRUXmrBZRo2LQPNr79u3TW968eTNcXFyQmZmJ/v37Syd3SkoKBg0aBABITk5Gp06dcPz4cfj7+0sn94EDB+Dq6ooePXpg8eLFmDNnDmJjYyGXy41XOyIioiZOd0NeGvtsoobr0qVL8PDwgLW1NVQqFeLj49GmTRtkZmZCq9UiICBAytuxY0e0adMGGRkZ8Pf3R0ZGBrp27QpXV1cpT1BQECIiInDhwgX07Nmz3H1qNBpoNBppuaCgQPq/VqutsKwKS1Gbqla5/YZKV6fGWDdTMne7GbJfgwLt0m7fvg0AcHJyAgCTntxERERkuPp0Q67Vasu9STH3jVNjpWtPhQUDHWOr6pg1ZXv5+flh8+bN6NChA27cuIG4uDj069cP58+fh1qthlwuh6Ojo957XF1doVarAQBqtVrvnNat162rSHx8POLi4spdl5aWVuH7EnpXp1aV++qrr2q/kXqqsrajipmr3e7fv1/tvDUOtEtKSjBz5kz06dMHXbp0AQCTndzV7bBLX/SM8QmaMZjiYtvUbkqaUn0rqmtTqDsRGVd9uyFPTU2Fra1the/jDadpLO5VUuttNOZApzYqOmYNuRk31LBhw6T/d+vWDX5+fvDy8sKnn34KGxsbk+03JiYG0dHR0nJBQQE8PT0BAEOGDIGVlVW57+sSu7/W+z4fG1TrbdQ3Wq0WaWlplbYdlWXudnv0mxxVqXGgHRkZifPnz+v91stUDO2wdRc9Y3yCZgym7Jya2k1JU6pv6bqastMmosapvt2QBwYGQqlUlslv7hunxkrXrvNPW0BTIqvVthpjoFMbVR2zhtyM15ajoyOefPJJXL58GUOGDEFRURHy8/P1PkTLzc2VfkLi5uaGkydP6m1DNwhieT8z0VEoFFAoFOWus7KyqvDc1RTX7tjTbb+xqqztqGLmajdD9lmjQDsqKgp79uzB0aNH0bp1ayndzc3NJCd3dTvs0hc9Y3yCZgym6Jya2k1JU6pvRXWty06biBonc9+QV3VjxBtO09CUyGod7PDvUr6Kjtm6bK+7d+/iypUrmDhxInx9fWFlZYWDBw8iJCQEAJCVlYWcnByoVCoAgEqlwtKlS5GXlwcXFxcADz/cVyqV8PHxqbNyEzV2BgXaQgjMmDEDO3fuxJEjR+Dt7a233lQnt6Edti7dGJ+gGYMpL7ZN7aakKdW3dF2bSr2JyHR4Q07U8L322msYOXIkvLy8cP36dSxcuBCWlpYYP348HBwcMGXKFERHR8PJyQlKpRIzZsyASqWCv78/ACAwMBA+Pj6YOHEiEhISoFarMW/ePERGRlb4xJqIDGdQoB0ZGYmUlBR88cUXaN68ufT7LAcHB9jY2PDkJiIiqkd4Q07U+Pz3v//F+PHj8eeff8LZ2Rl9+/bF8ePH4ezsDABYvXo1LCwsEBISAo1Gg6CgICQlJUnvt7S0xJ49exAREQGVSgU7OzuEh4dj0aJF5qoSUaNkUKC9fv16AMDAgQP10pOTkzFp0iQAPLmJiIjqC96QEzU+27dvr3S9tbU1EhMTkZiYWGEeLy8vDnBHZGIGf3W8Kjy5iYiI6gfekBMREZmHhbkLQERERERERNSYMNAmIiIiIiIiMiIG2kRERERERERGxECbiIiIiIiIyIgYaBMREREREREZEQNtIiIiIiIiIiNioE1ERERERERkRAy0iYiIiIiIiIyIgTYRERERERGRETHQJiIiIiIiIjIiBtpERERERERERsRAm4iIiIiIiMiIGGgTERERERERGREDbSIiIiIiIiIjYqBNREREREREZEQMtImIiIiIiIiMiIE2ERERERERkREx0CYiIiIiIiIyIgbaREREREREREbUzNwFoIan7dy9td7G1eXBRigJGUt8fDw+//xz/PTTT7CxscEzzzyDFStWoEOHDlKewsJCvPrqq9i+fTs0Gg2CgoKQlJQEV1dXKU9OTg4iIiJw+PBh2NvbIzw8HPHx8WjWjJcaIiIiImo6+ESbiJCeno7IyEgcP34caWlp0Gq1CAwMxL1796Q8s2bNwu7du7Fjxw6kp6fj+vXrGDNmjLS+uLgYwcHBKCoqwrFjx7BlyxZs3rwZCxYsMEeViIiIiIjMho+ZiAj79u3TW968eTNcXFyQmZmJ/v374/bt29i0aRNSUlIwaNAgAEBycjI6deqE48ePw9/fH6mpqbh48SIOHDgAV1dX9OjRA4sXL8acOXMQGxsLuVxujqoREREREdU5PtEmojJu374NAHBycgIAZGZmQqvVIiAgQMrTsWNHtGnTBhkZGQCAjIwMdO3aVe+r5EFBQSgoKMCFCxfqsPRERERERObFJ9pEpKekpAQzZ85Enz590KVLFwCAWq2GXC6Ho6OjXl5XV1eo1Wopz6NBtm69bl15NBoNNBqNtFxQUAAA0Gq10Gq1ZfLr0hQWogY1K39b9ZWufPW9nMbSlOpbuq5Noc5ERERNDQNtItITGRmJ8+fP45tvvjH5vuLj4xEXF1cmPTU1Fba2thW+b3Gvklrv+6uvvqr1NupCWlqauYtQp5pSfXV1vX//vplLQkRERMbGQJuIJFFRUdizZw+OHj2K1q1bS+lubm4oKipCfn6+3lPt3NxcuLm5SXlOnjypt73c3FxpXXliYmIQHR0tLRcUFMDT0xOBgYFQKpVl8mu1WqSlpWH+aQtoSmQ1ricAnI8NqtX7TU1X1yFDhsDKysrcxTG5plTf0nXVfZODiIiIGg8G2kQEIQRmzJiBnTt34siRI/D29tZb7+vrCysrKxw8eBAhISEAgKysLOTk5EClUgEAVCoVli5diry8PLi4uAB4+MROqVTCx8en3P0qFAooFIoy6VZWVpUGW5oSGTTFtQu0G0owV1VbNDZNqb66ujaV+hIRETUlBg+GdvToUYwcORIeHh6QyWTYtWuX3nohBBYsWAB3d3fY2NggICAAly5d0stz8+ZNhIWFQalUwtHREVOmTMHdu3drVREiqrnIyEhs3boVKSkpaN68OdRqNdRqNf766y8AgIODA6ZMmYLo6GgcPnwYmZmZeOmll6BSqeDv7w8A+H/s3XtYVNX+P/D3DJcB1AFRuR0RSE3FGwaKk6amCCmaJkezTPGSloGleEzteEEtUbtoegi7gh31WFZqmiF4w1PijSKvkZqKRwUqAxR0GJj1+8Pf7G8jFxnYMMzwfj0Pj87aa/b+rDV7zezP7D17hYaGwt/fH+PHj8dPP/2EPXv2YMGCBYiKiqowmSaiuhcXF4eePXuiWbNmcHNzw8iRI5GVlWVUZ8CAAVAoFEZ/L774olGd7OxshIeHw8nJCW5ubpgzZw5KS0vrsylE9P9xXBNZBpMT7aKiInTv3h3x8fEVLl+1ahXWrl2L9evX4+jRo2jSpAnCwsJw9+5dqc64ceNw5swZpKamSpepTps2reatIKJaSUhIQEFBAQYMGABPT0/p77PPPpPqrF69GsOGDUNERAT69esHDw8PfPXVV9JyGxsb7Nq1CzY2NtBoNHjuuecwYcIELF261BxNIiIAaWlpiIqKwpEjR5CamgqdTofQ0FAUFRUZ1Zs6dSpu3Lgh/a1atUpaVlZWhvDwcJSUlODw4cPYsGEDkpKSsGjRovpuDhGB45rIUph86fiQIUMwZMiQCpcJIbBmzRosWLAAI0aMAAB8+umncHd3x/bt2zF27FicO3cOycnJOH78OIKCggAA69atw9ChQ/HWW2/By8urFs0hopoQ4sF38XZwcEB8fHylX7IBgI+Pj8XcZIyoMUhOTjZ6nJSUBDc3N2RkZKBfv35SuZOTU6X3UkhJScHZs2exd+9euLu7IyAgAMuWLcPcuXMRGxsLe3v7Om0DERnjuCayDLL+RvvSpUvIyckxmmvX2dkZwcHBSE9Px9ixY5Geng4XFxcpyQaAkJAQKJVKHD16FE899ZScIREREdH/V1BQAABwdXU1Kt+0aRM2btwIDw8PDB8+HAsXLpTu/J+eno6uXbsaTd8XFhaG6dOn48yZM+jRo0f9NYCIyqmvcV3ZlJxA1dMUqmysf0rOmuAUjzVj7n4zZbuyJtqGuXIrmkv3r3PtGm6UJAVhawtXV9daz7V7f8fLMbDlUBc7gjl3MnO8YZp7UNWnytraGNpORHVHr9dj5syZ6NOnD7p06SKVP/vss/Dx8YGXlxdOnjyJuXPnIisrS/ppSE5OToWf64ZlFanu57ZBY3qPr0/S8ZCSiY7cHrTP1ld/1ee4rmxKTqDqqRlX9TKpSRWy5qvlGtO0lnIyV7+ZMiWnRdx13NS5dg0dL8fAlkNdvjmYYycz5xtmY3ozur+tnGuXiGojKioKp0+fxnfffWdU/td7pHTt2hWenp4YNGgQLl68iLZt29ZoW6Z+bhs0pvf4+rQsSF/rdVhzolMble2z9fWZXZ/jurIpOQFUOTVjl9g9NdreXzX0KTlrojFNayknc/ebKVNyyppoG34HkpubC09PT6k8NzcXAQEBUp28vDyj55WWluLmzZu1nmv3/o6XY2DLoS7eHMy5k5njDdPcg6o+VdZWzrVLRDUVHR0t3Xy0devWVdYNDg4GAFy4cAFt27aFh4cHjh07ZlQnNzcXAGr9uW3QmN7j65OhXxeeUEKrr92UiNaY6NTGg/bZ+vjMru9xXdmUnEDVUzPWdjpOw/qtFad5rBlz9Zsp25Q10fbz84OHhwf27dsnJdaFhYU4evQopk+fDuDeXLv5+fnIyMhAYGAgAGD//v3Q6/XSm8D9TJ1r11Aux8CWQ13uBObYycz5htmY3ozub2tjaTcRyUcIgRkzZmDbtm04ePAg/Pz8HviczMxMAJC+MNdoNHjjjTeQl5cn/fQrNTUVarUa/v7+Fa7D1M/t6i6nmtHqFbX+7ObrUrGqjkXrirnGNRGZxuRE+/bt27hw4YL0+NKlS8jMzISrqyvatGmDmTNn4vXXX0f79u3h5+eHhQsXwsvLCyNHjgQAdOrUCU888QSmTp2K9evXQ6fTITo6GmPHjuUdx4mIiGQUFRWFzZs3Y8eOHWjWrJn020tnZ2c4Ojri4sWL2Lx5M4YOHYoWLVrg5MmTmDVrFvr164du3boBAEJDQ+Hv74/x48dj1apVyMnJwYIFCxAVFVXp2S0iqjsc10SWweRE+8SJE3j88celx4ZLwyIjI5GUlIRXX30VRUVFmDZtGvLz89G3b18kJyfDwcFBes6mTZsQHR2NQYMGQalUIiIiAmvXrpWhOURERGSQkJAAABgwYIBReWJiIiZOnAh7e3vs3bsXa9asQVFREby9vREREYEFCxZIdW1sbLBr1y5Mnz4dGo0GTZo0QWRkJJYuXVqfTSGi/4/jmsgymJxoDxgwoMo5dxUKBZYuXVrlQHV1dcXmzZtN3TQRERGZoKrPawDw9vZGWlraA9fj4+PDm2ERNRAc10SWQWnuAIiIiIiIiIisiUVM70VERJXznfeNLOu5vCJclvUQERERNXY8o01EREREREQkIybaRERERERERDJiok1EREREREQkIybaRERERERERDJiok1EREREREQkIybaRERERERERDJiok1EREREREQkIybaRERERERERDJiok1EREREREQkI1tzB0BEZA6+876p9TourwiXIRIiIiIisjZMtIlkwKSNiIiIiIgMeOk4ERERERERkYyYaBMRERERERHJiIk2ERERERERkYz4G20yC1N/06yyEVjVC+gSuwfaMoVUzt81ExERERFRQ8Mz2kREREREREQyYqJNREREREREJCNeOm4h7r/UurJLqR+El1oTyUeOad0qU9MxTkRERETmxzPaRERERERERDJiok1EREREREQkIybaRERERERERDJiok1EREREREQkIybaRERERERERDLiXccbmbq8SzIREREREREx0SYLxy8OiIiIiIiooTHrpePx8fHw9fWFg4MDgoODcezYMXOGQ0Qy4Lgmsk4c20TWiWObqG6Y7Yz2Z599hpiYGKxfvx7BwcFYs2YNwsLCkJWVBTc3N3OFVSd41pUai8Y0rokaE45tIuvEsU1Ud8x2Rvudd97B1KlTMWnSJPj7+2P9+vVwcnLCJ598Yq6QiKiWOK6JrBPHNpF14tgmqjtmOaNdUlKCjIwMzJ8/XypTKpUICQlBenq6OUIiolriuCayThzbRNbJksa2HFeHXl4RLkMkRNVnlkT7999/R1lZGdzd3Y3K3d3d8fPPP5err9VqodVqpccFBQUAgJs3b0Kn00nlOp0OxcXF+OOPP2BnZwfb0qI6aoH52eoFiov1sNUpUaZXmDucOtcY2vvHH38AKL8fG9y6dQsAIIQwS3wPYuq4Bqo/tg0MfWPN+4GBOfZ5wz5oDpXt9+YWHLev1us4On+Q0eP728qx3XBff0sn53umOd8fGqIH7bMNfVwD8h2PP2jsNpTj8Ya2D/N9r2bM3W+mjG2LuOt4XFwclixZUq7cz8/PDNE0HM+aO4B6Zu3tbfl29erdunULzs7OdRtMPeHYrlp97/PV3QfJNBzb/4dj23Lx/aFmGsO4fv75580Qjem4D5OcqjO2zZJot2zZEjY2NsjNzTUqz83NhYeHR7n68+fPR0xMjPRYr9fj5s2baNGiBRSK//uGtrCwEN7e3rh69SrUanXdNaABaExtBRpXeytrqxACt27dgpeXlxmjq5yp4xqo/tg24H5gvRpTe+9vK8d243r96xP7te48qG8b+rgG5Dkev3LlCgICAriP1QDHZ82Yu99MGdtmSbTt7e0RGBiIffv2YeTIkQDuDdZ9+/YhOjq6XH2VSgWVSmVU5uLiUun61Wp1o9lhG1NbgcbV3ora2pC/FTd1XAOmj22Dxr4fWLPG1N6/tpVj+57G9PrXJ/Zr3amqbxvyuAbkOR5XKu/dV5n7WM2x72rGnP1W3bFttkvHY2JiEBkZiaCgIPTq1Qtr1qxBUVERJk2aZK6QiKiWOK6JrBPHNpF14tgmqjtmS7Sffvpp/Pbbb1i0aBFycnIQEBCA5OTkcjdkICLLwXFNZJ04tomsE8c2Ud0x683QoqOjK73srCZUKhUWL15c7rIWa9SY2go0rvZaelvlHtd/Zel9Y4rG1FagcbXXUtvKsW152K91x5r6tjZj25r6ob6x72rGkvpNIRryvANEREREREREFkZp7gCIiIiIiIiIrAkTbSIiIiIiIiIZMdEmIiIiIiIikpHVJNrx8fHw9fWFg4MDgoODcezYMXOHVGtxcXHo2bMnmjVrBjc3N4wcORJZWVlGde7evYuoqCi0aNECTZs2RUREBHJzc80UsbxWrFgBhUKBmTNnSmXW1N5r167hueeeQ4sWLeDo6IiuXbvixIkT0nIhBBYtWgRPT084OjoiJCQE58+fN2PE5mfp47w6Y3rAgAFQKBRGfy+++KJRnezsbISHh8PJyQlubm6YM2cOSktL67Mp1RIbG1uuLR07dpSWV2c8W0pbfX19y7VVoVAgKioKgHW9rnK5efMmxo0bB7VaDRcXF0yZMgW3b9+u8jnV6cfGxtT3xa1bt6Jjx45wcHBA165dsXv37nqK1PKY0rdJSUnl9k0HB4d6jNY8LP1zua4dOnQIw4cPh5eXFxQKBbZv3260nMd6FbOaHEhYgS1btgh7e3vxySefiDNnzoipU6cKFxcXkZuba+7QaiUsLEwkJiaK06dPi8zMTDF06FDRpk0bcfv2banOiy++KLy9vcW+ffvEiRMnRO/evcWjjz5qxqjlcezYMeHr6yu6desmXnnlFancWtp78+ZN4ePjIyZOnCiOHj0qfv31V7Fnzx5x4cIFqc6KFSuEs7Oz2L59u/jpp5/Ek08+Kfz8/MSdO3fMGLn5WMM4r86Y7t+/v5g6daq4ceOG9FdQUCAtLy0tFV26dBEhISHixx9/FLt37xYtW7YU8+fPN0eTqrR48WLRuXNno7b89ttv0vIHjWdLamteXp5RO1NTUwUAceDAASGEdb2ucnniiSdE9+7dxZEjR8R///tf0a5dO/HMM89U+ZwH9WNjY+r74vfffy9sbGzEqlWrxNmzZ8WCBQuEnZ2dOHXqVD1H3vCZ2reJiYlCrVYb7Zs5OTn1HHX9sobP5bq2e/du8c9//lN89dVXAoDYtm2b0XIe61XMWnIgq0i0e/XqJaKioqTHZWVlwsvLS8TFxZkxKvnl5eUJACItLU0IIUR+fr6ws7MTW7duleqcO3dOABDp6enmCrPWbt26Jdq3by9SU1NF//79pUTbmto7d+5c0bdv30qX6/V64eHhId58802pLD8/X6hUKvGf//ynPkJscKxxnN8/poUQRvt8RXbv3i2USqXRAVxCQoJQq9VCq9XWZbgmW7x4sejevXuFy6ozni2prfd75ZVXRNu2bYVerxdCWNfrKoezZ88KAOL48eNS2bfffisUCoW4du1apc97UD82Nqa+L44ZM0aEh4cblQUHB4sXXnihTuO0RKb2bWJionB2dq6n6BoGa/xcrkv3J9o81qs+S82BLP7S8ZKSEmRkZCAkJEQqUyqVCAkJQXp6uhkjk19BQQEAwNXVFQCQkZEBnU5n1PaOHTuiTZs2Ft32qKgohIeHG7ULsK72fv311wgKCsLo0aPh5uaGHj164MMPP5SWX7p0CTk5OUZtdXZ2RnBwsMW1VQ7WOs7vH9MGmzZtQsuWLdGlSxfMnz8fxcXF0rL09HR07doV7u7uUllYWBgKCwtx5syZ+gncBOfPn4eXlxceeughjBs3DtnZ2QCqN54tra0GJSUl2LhxIyZPngyFQiGVW9PrWlvp6elwcXFBUFCQVBYSEgKlUomjR49W+dyq+rExqcn7Ynp6ernP1rCwMIt+H60LNf3MuX37Nnx8fODt7Y0RI0ZY5dg1sNbP5frEY73qs9QcyNbcAdTW77//jrKyMqODEwBwd3fHzz//bKao5KfX6zFz5kz06dMHXbp0AQDk5OTA3t4eLi4uRnXd3d2Rk5Njhihrb8uWLfjhhx9w/Pjxcsusqb2//vorEhISEBMTg9deew3Hjx/Hyy+/DHt7e0RGRkrtqWi/trS2ysEax3lFYxoAnn32Wfj4+MDLywsnT57E3LlzkZWVha+++grAvXFQUT8YljUkwcHBSEpKQocOHXDjxg0sWbIEjz32GE6fPl2t8WxJbf2r7du3Iz8/HxMnTpTKrOl1lUNOTg7c3NyMymxtbeHq6lplex/Uj41JTd4XK9vPrHEfq42a9G2HDh3wySefoFu3bigoKMBbb72FRx99FGfOnEHr1q3rI+x6ZY2fy/WNx3rVY8k5kMUn2o1FVFQUTp8+je+++87codSZq1ev4pVXXkFqaqrV30BEr9cjKCgIy5cvBwD06NEDp0+fxvr16xEZGWnm6Kg+VDamp02bJv2/a9eu8PT0xKBBg3Dx4kW0bdu2vsOslSFDhkj/79atG4KDg+Hj44PPP/8cjo6OZoysbn388ccYMmQIvLy8pDJrel2rMm/ePKxcubLKOufOnavx+htLP5Ll0Wg00Gg00uNHH30UnTp1wvvvv49ly5aZMTIiy2bJOZDFXzresmVL2NjYlLvLXG5uLjw8PMwUlbyio6Oxa9cuHDhwwOhbUQ8PD5SUlCA/P9+ovqW2PSMjA3l5eXjkkUdga2sLW1tbpKWlYe3atbC1tYW7u7vVtNfT0xP+/v5GZZ06dZIuqzW0x5r3a1NY2zivbExXJDg4GABw4cIFAPf2jYr6wbCsIXNxccHDDz+MCxcuVOv9yxLbeuXKFezduxfPP/98lfWs6XX9q9mzZ+PcuXNV/j300EPw8PBAXl6e0XNLS0tx8+ZNk9p7fz82JjV5X6xsP7Okfaw+yPGZY2dnhx49eljtvmltn8vmwGO9B7P0HMjiE217e3sEBgZi3759Upler8e+ffuMvlm0REIIREdHY9u2bdi/fz/8/PyMlgcGBsLOzs6o7VlZWcjOzrbItg8aNAinTp1CZmam9BcUFIRx48ZJ/7eW9vbp06fcNAW//PILfHx8AAB+fn7w8PAwamthYSGOHj1qcW2Vg7WM8weN6YpkZmYCuPflDHDvrMmpU6eMkpTU1FSo1epyX940NLdv38bFixfh6elZrfcvS2xrYmIi3NzcEB4eXmU9a3pd/6pVq1bo2LFjlX/29vbQaDTIz89HRkaG9Nz9+/dDr9dLyXN13N+PjUlN3hc1Go1RfeDefmZJ76P1QY7PnLKyMpw6dcpq901r+Vw2Jx7rVc5qciAz34xNFlu2bBEqlUokJSWJs2fPimnTpgkXFxeLn1Zh+vTpwtnZWRw8eNBouoji4mKpzosvvijatGkj9u/fL06cOCE0Go3QaDRmjFpe999h1lrae+zYMWFrayveeOMNcf78ebFp0ybh5OQkNm7cKNVZsWKFcHFxETt27BAnT54UI0aMaNRTPljDOH/QmL5w4YJYunSpOHHihLh06ZLYsWOHeOihh0S/fv2kdRimgQoNDRWZmZkiOTlZtGrVqkFOAzV79mxx8OBBcenSJfH999+LkJAQ0bJlS5GXlyeEePB4tqS2CnHvjrtt2rQRc+fONSq3ttdVLk888YTo0aOHOHr0qPjuu+9E+/btjab3+t///ic6dOggjh49KoSoXj82Ng96Xxw/fryYN2+eVP/7778Xtra24q233hLnzp0Tixcv5vRelTC1b5csWSL27NkjLl68KDIyMsTYsWOFg4ODOHPmjLmaUOes4XO5rt26dUv8+OOP4scffxQAxDvvvCN+/PFHceXKFSEEj/UqYy05kFUk2kIIsW7dOtGmTRthb28vevXqJY4cOWLukGoNQIV/iYmJUp07d+6Il156STRv3lw4OTmJp556Sty4ccN8Qcvs/kTbmtq7c+dO0aVLF6FSqUTHjh3FBx98YLRcr9eLhQsXCnd3d6FSqcSgQYNEVlaWmaJtGCx9nD9oTGdnZ4t+/foJV1dXoVKpRLt27cScOXPKzRN8+fJlMWTIEOHo6ChatmwpZs+eLXQ6nRlaVLWnn35aeHp6Cnt7e/G3v/1NPP3000ZzxVdnPFtKW4UQYs+ePQJAuXFqba+rXP744w/xzDPPiKZNmwq1Wi0mTZokbt26JS2/dOmS0Vzk1e3Hxqaq98X+/fuLyMhIo/qff/65ePjhh4W9vb3o3Lmz+Oabb+o5YsthSt/OnDlTquvu7i6GDh0qfvjhBzNEXb8s/XO5rh04cKDCz33DvsNjvYpZSw6kEEKI+jp7TkRERERERGTtLP432kREREREREQNCRNtIiIiIiIiIhkx0SYiIiIiIiKSERNtIiIiIiIiIhkx0bZiCoUC0dHRVda5fPkyFAoFkpKS6ieoBh4HkSXy9fXFsGHD6nw7HKdERNRYHD9+HI8++iiaNGkChUKBkSNHQqFQ1Ok2Dx48CIVCgYMHD9bpdiri6+uLiRMn1vt2rRkTbbJ4hw8fRmxsLPLz880dChERUYN29epVLFmyBL169ULz5s3RsmVLDBgwAHv37jV3aEQNhk6nw+jRo3Hz5k2sXr0a//73v+Hj42PusMjC2Jo7ADIvHx8f3LlzB3Z2duYOpcYOHz6MJUuWYOLEiXBxcTF3OERERA3Wjh07sHLlSowcORKRkZEoLS3Fp59+isGDB+OTTz7BpEmTzB0ikdldvHgRV65cwYcffojnn38eADB27FisXLnSzJHVnaysLCiVPAcrJybaVkYIgbt378LR0bFa9RUKBRwcHOo4KiJqTIqKitCkSRNzh0FEFXj88ceRnZ2Nli1bSmUvvvgiAgICsGjRIibaRADy8vIAwOgEjq2tLWxtrSt1+mveoFKpzB2O1eHXFvUsNjYWCoUCP//8M8aMGQO1Wo0WLVrglVdewd27d6V6iYmJGDhwINzc3KBSqeDv74+EhIRy6zP8NnPPnj0ICgqCo6Mj3n///Uq3//rrr0OpVGLdunUAKv7N5cSJE9G0aVNcu3YNI0eORNOmTdGqVSv84x//QFlZmdH6/vjjD4wfPx5qtRouLi6IjIzETz/9JNvvOPfv34/HHnsMTZo0gYuLC0aMGIFz585Jy2NjYzFnzhwAgJ+fHxQKBRQKBS5fvgwASE1NRd++feHi4oKmTZuiQ4cOeO2112odF1kvwxi9cOGCdJWEs7MzJk2ahOLiYgBV/1ZZoVAgNja23Pp++eUXPPfcc3B2dkarVq2wcOFCCCFw9epVjBgxAmq1Gh4eHnj77bdrHHtKSgoCAgLg4OAAf39/fPXVV+Xq5OfnY+bMmfD29oZKpUK7du2wcuVK6PX6cvUmTpwIZ2dnaWxX9PMMw/vFxYsXMXToUDRr1gzjxo0DcC/hnj17trStDh064K233oIQwmgdpaWlWLZsGdq2bQuVSgVfX1+89tpr0Gq1RvUM73cHDx6U3u+6du0q/Zbtq6++QteuXeHg4IDAwED8+OOPRs/PycnBpEmT0Lp1a6hUKnh6emLEiBHS+wWRpajN+0rnzp2NkmwAUKlUGDp0KP73v//h1q1b9d0cogZl4sSJ6N+/PwBg9OjRUCgUGDBggDTu/spwP6Tt27ejS5cuUKlU6Ny5M5KTk43qXblyBS+99BI6dOgAR0dHtGjRAqNHj5bl8ycpKQkKhQKHDh3CCy+8gBYtWkCtVmPChAn4888/jepWlTdU9Bvt/Px8zJo1C76+vlCpVGjdujUmTJiA33//Xaqj1WqxePFitGvXDiqVCt7e3nj11VfLfYY3Rtb1tYwFGTNmDHx9fREXF4cjR45g7dq1+PPPP/Hpp58CABISEtC5c2c8+eSTsLW1xc6dO/HSSy9Br9cjKirKaF1ZWVl45pln8MILL2Dq1Kno0KFDhdtcsGABli9fjvfffx9Tp06tMr6ysjKEhYUhODgYb731Fvbu3Yu3334bbdu2xfTp0wEAer0ew4cPx7FjxzB9+nR07NgRO3bsQGRkpAw9BOzduxdDhgzBQw89hNjYWNy5cwfr1q1Dnz598MMPP8DX1xejRo3CL7/8gv/85z9YvXq1dPDQqlUrnDlzBsOGDUO3bt2wdOlSqFQqXLhwAd9//70s8ZF1GzNmDPz8/BAXF4cffvgBH330Edzc3Gp82djTTz+NTp06YcWKFfjmm2/w+uuvw9XVFe+//z4GDhyIlStXYtOmTfjHP/6Bnj17ol+/fiat//z583j66afx4osvIjIyEomJiRg9ejSSk5MxePBgAEBxcTH69++Pa9eu4YUXXkCbNm1w+PBhzJ8/Hzdu3MCaNWsA3PuGe8SIEfjuu+/w4osvolOnTti2bVulY7u0tBRhYWHo27cv3nrrLTg5OUEIgSeffBIHDhzAlClTEBAQgD179mDOnDm4du0aVq9eLT3/+eefx4YNG/D3v/8ds2fPxtGjRxEXF4dz585h27ZtRtu6cOECnn32Wbzwwgt47rnn8NZbb2H48OFYv349XnvtNbz00ksAgLi4OIwZM8boUriIiAicOXMGM2bMgK+vL/Ly8pCamors7Gz4+vqa1N9EDYGc7ys5OTlwcnKCk5NTPbaAqOF54YUX8Le//Q3Lly/Hyy+/jJ49e8Ld3b3S48fvvvsOX331FV566SU0a9YMa9euRUREBLKzs9GiRQsA926sdvjwYYwdOxatW7fG5cuXkZCQgAEDBuDs2bOyjLvo6Gi4uLggNjYWWVlZSEhIwJUrV6QbrBlUN2+4ffs2HnvsMZw7dw6TJ0/GI488gt9//x1ff/01/ve//6Fly5bQ6/V48skn8d1332HatGno1KkTTp06hdWrV+OXX37B9u3ba90uiyaoXi1evFgAEE8++aRR+UsvvSQAiJ9++kkIIURxcXG554aFhYmHHnrIqMzHx0cAEMnJyeXqAxBRUVFCCCFmz54tlEqlSEpKMqpz6dIlAUAkJiZKZZGRkQKAWLp0qVHdHj16iMDAQOnxl19+KQCINWvWSGVlZWVi4MCB5db5IBXFERAQINzc3MQff/whlf30009CqVSKCRMmSGVvvvmmACAuXbpktM7Vq1cLAOK3336rdhxEhjE6efJko/KnnnpKtGjRQghR8f5qAEAsXry43PqmTZsmlZWWlorWrVsLhUIhVqxYIZX/+eefwtHRUURGRpoUs+F94Msvv5TKCgoKhKenp+jRo4dUtmzZMtGkSRPxyy+/GD1/3rx5wsbGRmRnZwshhNi+fbsAIFatWmUU82OPPVbp+8W8efOM1mlYx+uvv25U/ve//10oFApx4cIFIYQQmZmZAoB4/vnnjer94x//EADE/v37y7Xz8OHDUtmePXsEAOHo6CiuXLkilb///vsCgDhw4IAQ4l7fAhBvvvlm5R1JZCHkfl85f/68cHBwEOPHj6/LsIksxoEDBwQAsXXrVqnMMO7+CoCwt7eXPtOEuHesCkCsW7dOKqvouD49PV0AEJ9++mm57Ro+u6ojMTFRABCBgYGipKREKl+1apUAIHbs2CGVVZU3+Pj4GL1PLFq0SAAQX331Vbm6er1eCCHEv//9b6FUKsV///tfo+Xr168XAMT3339f7XZYI146bib3n5WeMWMGAGD37t0AYPQb64KCAvz+++/o378/fv31VxQUFBg918/PD2FhYRVuRwiB6OhovPvuu9i4caNJZ5tffPFFo8ePPfYYfv31V+lxcnIy7OzsjM6OK5XKcm2riRs3biAzMxMTJ06Eq6urVN6tWzcMHjxY6qeqGH5Xs2PHjnKXxRI9SEX7/x9//IHCwsIarc9wMxUAsLGxQVBQEIQQmDJlilTu4uKCDh06GI2z6vLy8sJTTz0lPTZcNvbjjz8iJycHALB161Y89thjaN68OX7//XfpLyQkBGVlZTh06BCAe+9Dtra20tUrhpgN71MV+WtdwzpsbGzw8ssvG5XPnj0bQgh8++23Uj0AiImJKVcPAL755hujcn9/f2g0GulxcHAwAGDgwIFo06ZNuXJDXzo6OsLe3h4HDx4sdykdkaWS432luLgYo0ePhqOjI1asWFHnMRNZm5CQELRt21Z63K1bN6jVaqMx99fjep1Ohz/++APt2rWDi4sLfvjhB1nimDZtmtHNjadPnw5bW9tyx8xV5Q1/9eWXX6J79+5GxxYGhjPkW7duRadOndCxY0ej44qBAwcCAA4cOFCbJlk8Jtpm0r59e6PHbdu2hVKplH6r8f333yMkJET6bXKrVq2k3xZXlGhX5tNPP0V8fDzWrVuHZ555ptrxOTg4oFWrVkZlzZs3NzpAvXLlCjw9Pctd7tKuXbtqb6cyV65cAYAKL2fp1KkTfv/9dxQVFVW5jqeffhp9+vTB888/D3d3d4wdOxaff/45k26qlr8mbcC9/R9AjZO0+9fn7OwMBweHcr+VdHZ2rtE22rVrV+63Yw8//DAASO8r58+fR3JyMlq1amX0FxISAuD/bv5iGNtNmzY1Wl9ll5fZ2tqidevWRmVXrlyBl5cXmjVrZlTeqVMnabnhX6VSWe59w8PDAy4uLlI9g4r6EQC8vb0rLDf0pUqlwsqVK/Htt9/C3d0d/fr1w6pVq6QvIYgsUW3fV8rKyjB27FicPXsWX3zxBby8vOo0XiJrdP84BMofM9+5cweLFi2S7lnSsmVLtGrVCvn5+eWO62vq/tyiadOm8PT0LPc78Kryhr+6ePEiunTpUmWd8+fP48yZM+WOKwzHH4bjisaKv9FuIP56gHzx4kUMGjQIHTt2xDvvvANvb2/Y29tj9+7dWL16dblEsao7jPfp0weZmZn417/+hTFjxhidHa6KjY1NzRrSgDg6OuLQoUM4cOAAvvnmGyQnJ+Ozzz7DwIEDkZKSYhVtpLpT2f4hhCiX0Brcf7PAB62vqm3UBb1ej8GDB+PVV1+tcLnhg9FUKpWq1lOCVNan96usz6rTlzNnzsTw4cOxfft27NmzBwsXLkRcXBz279+PHj16mB40kZnV9n1l6tSp2LVrFzZt2iSdgSIi01RnzM2YMQOJiYmYOXMmNBoNnJ2doVAoMHbs2Ho/AVTdmYmqQ6/Xo2vXrnjnnXcqXH7/l+CNDRNtMzl//rzRN0oXLlyAXq+Hr68vdu7cCa1Wi6+//troW7KaXH7Rrl07rFq1CgMGDMATTzyBffv2lTvDVFM+Pj44cOAAiouLjc5qX7hwQZZ1A/du2HC/n3/+GS1btpSmD6rqAF2pVGLQoEEYNGgQ3nnnHSxfvhz//Oc/ceDAAeksHpGpDGe3778L9/1nX+vThQsXyn0J8MsvvwCAdKOvtm3b4vbt2w/c9318fLBv3z7cvn3b6Kx2ReOxqnXs3bsXt27dMnrP+fnnn6Xlhn/1ej3Onz8vne0GgNzcXOTn50v15NK2bVvMnj0bs2fPxvnz5xEQEIC3334bGzdulHU7RA3dnDlzkJiYiDVr1ph0xRsRme6LL75AZGSk0QwAd+/erXA2j5o6f/48Hn/8cenx7du3cePGDQwdOrRG62vbti1Onz79wDo//fQTBg0aVO0vzBsTXjpuJvHx8UaPDdNtDRkyRPpm7K/fhBUUFCAxMbFG2+rWrRt2796Nc+fOYfjw4bhz504NozYWFhYGnU6HDz/8UCrT6/Xl2lYTnp6eCAgIwIYNG4zehE6fPo2UlBSjNw1Dwn3/m9XNmzfLrTcgIAAAOOUA1YparUbLli2l3zQbvPfee2aKCLh+/brRHboLCwvx6aefIiAgAB4eHgDu3Uk9PT0de/bsKff8/Px8lJaWAgCGDh2K0tJSoykFy8rKpPep6hg6dCjKysrwr3/9y6h89erVUCgUGDJkiFQPgHTHcwPDt+Ph4eHV3mZViouLjaZQBO4dIDRr1ozvB9TovPnmm3jrrbfw2muv4ZVXXjF3OERWz8bGptxVJevWravySjhTffDBB9DpdNLjhIQElJaWSp+3poqIiMBPP/1UbvYP4P9ylDFjxuDatWtGuYDBnTt3HvgzT2vHM9pmcunSJTz55JN44oknkJ6ejo0bN+LZZ59F9+7d4eDgAHt7ewwfPhwvvPACbt++jQ8//BBubm64ceNGjbbXu3dv7NixA0OHDsXf//53bN++3eiGCTUxcuRI9OrVC7Nnz8aFCxfQsWNHfP3111KCW9tvtt58800MGTIEGo0GU6ZMkab3cnZ2NpqnODAwEADwz3/+E2PHjoWdnR2GDx+OpUuX4tChQwgPD4ePjw/y8vLw3nvvoXXr1ujbt2+tYiN6/vnnsWLFCjz//PMICgrCoUOHpDPI5vDwww9jypQpOH78ONzd3fHJJ58gNzfX6Au6OXPm4Ouvv8awYcMwceJEBAYGoqioCKdOncIXX3yBy5cvo2XLlhg+fDj69OmDefPm4fLly9Kc3Kb8jmz48OF4/PHH8c9//hOXL19G9+7dkZKSgh07dmDmzJnSjWO6d++OyMhIfPDBB8jPz0f//v1x7NgxbNiwASNHjjT6dr42fvnlFwwaNAhjxoyBv78/bG1tsW3bNuTm5mLs2LGybIPIEmzbtg2vvvoq2rdvj06dOpW7mmPw4MFwd3c3U3RE1mnYsGH497//DWdnZ/j7+yM9PR179+6Vpv+SQ0lJifQ5l5WVhffeew99+/bFk08+WaP1zZkzB1988QVGjx6NyZMnIzAwEDdv3sTXX3+N9evXo3v37hg/fjw+//xzvPjiizhw4AD69OmDsrIy/Pzzz/j888+l+bobKybaZvLZZ59h0aJFmDdvHmxtbREdHY0333wTwL0bDn3xxRdYsGAB/vGPf8DDwwPTp09Hq1atMHny5Bpvc+DAgfj8888RERGB8ePHY/PmzbVqg42NDb755hu88sor2LBhA5RKJZ566iksXrwYffr0gYODQ63WHxISguTkZCxevBiLFi2CnZ0d+vfvj5UrVxpddt+zZ08sW7YM69evR3JyMvR6vfRFxuXLl/HJJ5/g999/R8uWLdG/f38sWbJEulESUU0tWrQIv/32G7744gt8/vnnGDJkCL799lu4ubmZJZ727dtj3bp1mDNnDrKysuDn54fPPvvM6M6iTk5OSEtLw/Lly7F161Z8+umnUKvVePjhh43GhVKpxNdff42ZM2di48aNUCgUePLJJ/H2229X+7fMhnUsWrQIn332GRITE+Hr64s333xTuqO4wUcffYSHHnoISUlJ2LZtGzw8PDB//nwsXrxYtv7x9vbGM888g3379uHf//43bG1t0bFjR+k9kaix+OmnnwDcu8x0/Pjx5ZYfOHCAiTaRzN59913Y2Nhg06ZNuHv3Lvr06YO9e/dW6+7f1fWvf/0LmzZtwqJFi6DT6fDMM89g7dq1NT7x1bRpU/z3v//F4sWLsW3bNmzYsAFubm4YNGiQdANUpVKJ7du3Y/Xq1fj000+xbds2ODk54aGHHsIrr7xS43u/WAuFqKu77lCFYmNjsWTJEvz222/l7gpqLbZv346nnnoK3333Hfr06WPucIiIiIiIrFJSUhImTZqE48ePN+qzxw0Rf6NNtXL/770Nv+NUq9V45JFHzBQVERERERGR+fDScaqVGTNm4M6dO9BoNNBqtfjqq69w+PBhLF++HI6OjigpKanwpmR/5ezsLOtUA0TW4rfffqvyRin29vbVnrKPiIiILMedO3ceeG8UHgM0bEy0qVYGDhyIt99+G7t27cLdu3fRrl07rFu3DtHR0QCAw4cPP/BmRomJiZg4cWI9REtkWXr27FnllGH9+/fHwYMH6y8gIiIiqhefffYZJk2aVGWdmkz9S/WHv9GmOvXnn38iIyOjyjqdO3eGp6dnPUVEZDm+//77Kqfja968uXTXfSIiIrIeN27cwJkzZ6qsExgYiObNm9dTRGQqJtpEREREREREMuLN0IiIiIiIiIhkZJG/0dbr9bh+/TqaNWtW47nhiCyNEAK3bt2Cl5cXlErr/I6MY5saI45tIuvDcU1knUwa28ICXb16VQDgH/8a5d/Vq1fNPQTrDMc2/xrzn6ljOy0tTQwbNkx4enoKAGLbtm1Gy/V6vVi4cKHw8PAQDg4OYtCgQeKXX34xqvPHH3+IZ599VjRr1kw4OzuLyZMni1u3bhnV+emnn0Tfvn2FSqUSrVu3FitXruTY5h//qvnHz2z+8c86/6ozti3yjHazZs0AAFevXoVara6wjk6nQ0pKCkJDQ2FnZ1ef4Vk19mvdqE6/FhYWwtvbW9r/5Xbt2jXMnTsX3377LYqLi9GuXTskJiYiKCgIACCEwOLFi/Hhhx8iPz8fffr0QUJCAtq3by+t4+bNm5gxYwZ27twJpVKJiIgIvPvuu2jatGm1YnjQ2G4s+19jaGdjaCNQt2O7qKgI3bt3x+TJkzFq1Khyy1etWoW1a9diw4YN8PPzw8KFCxEWFoazZ8/CwcEBADBu3DjcuHEDqamp0Ol0mDRpEqZNm4bNmzdLsYWGhiIkJATr16/HqVOnMHnyZLi4uGDatGnVjrWqsW0N+4Klt4Hxy6+uP7MbgvvHdUN8HSwF+6526rP/TBnbFploGy5PUavVVSbaTk5OUKvV3GFlxH6tG6b0a11cnvXnn3+iT58+ePzxx/Htt9+iVatWOH/+vNGdLOU4aH+QB43txrL/NYZ2NoY2AnU7tocMGYIhQ4ZUuEwIgTVr1mDBggUYMWIEAODTTz+Fu7s7tm/fjrFjx+LcuXNITk7G8ePHpS/U1q1bh6FDh+Ktt96Cl5cXNm3ahJKSEnzyySewt7dH586dkZmZiXfeecekRLuqsW0N+4Klt4Hx1x1rvqT6/nHdkF+Hho59Vzvm6L/qjG2LTLSJSF4rV66Et7c3EhMTpTI/Pz/p/3IdtBNR/bh06RJycnIQEhIilTk7OyM4OBjp6ekYO3Ys0tPT4eLiIo1XAAgJCYFSqcTRo0fx1FNPIT09Hf369YO9vb1UJywsDCtXrsSff/5Z6bQyWq0WWq1WelxYWAjg3sGQTqczqmt4fH+5JbH0NjB++TWkWIjIPJhoExG+/vprhIWFYfTo0UhLS8Pf/vY3vPTSS5g6dSoA+Q7aiah+5OTkAADc3d2Nyt3d3aVlOTk5cHNzM1pua2sLV1dXozp//dLtr+vMycmpNNGOi4vDkiVLypWnpKTAycmpwuekpqY+qFkNnqW3gfHLp7i42NwhEJGZMdEmIvz6669ISEhATEwMXnvtNRw/fhwvv/wy7O3tERkZKdtB+/1MOetlKP/rv9aqMbSzMbQRqF47rbEP5s+fj5iYGOmx4TdtoaGhFV46npqaisGDB1vsJZOW3gbGLz/D5xkRNV5MtIkIer0eQUFBWL58OQCgR48eOH36NNavX4/IyMg6225NznoBDeusRV1qDO1sDG0Eqm5nXZz58vDwAADk5ubC09NTKs/NzUVAQIBUJy8vz+h5paWluHnzpvR8Dw8P5ObmGtUxPDbUqYhKpYJKpSpXbmdnV2kiVNUyS2HpbWD88mkocRCR+Vh9ot0ldg+0ZTW/EcXlFeEyRkPUMHl6esLf39+orFOnTvjyyy8ByHfQfj9TznoBDfOsRW11id1TrkylFFgWpMfCE0po9Q9+/zodG1YXodUpa3wtK1KddtbFmS8/Pz94eHhg37590hgtLCzE0aNHMX36dACARqNBfn4+MjIyEBgYCADYv38/9Ho9goODpTr//Oc/odPppPhTU1PRoUOHSi8br6nafl4D/Mwmsla+876p9Tr4/kD1zeoTbSJ6sD59+iArK8uo7JdffoGPjw8A+Q7a71eTs17VWW5JqkostHpFtRIPS+4La3otq/KgM7k1cfv2bVy4cEF6fOnSJWRmZsLV1RVt2rTBzJkz8frrr6N9+/bSTAFeXl4YOXIkgHtfpj3xxBOYOnUq1q9fD51Oh+joaIwdO1a6eeGzzz6LJUuWYMqUKZg7dy5Onz6Nd999F6tXr65RzERERI0FE20iwqxZs/Doo49i+fLlGDNmDI4dO4YPPvgAH3zwAYB7UxjIcdBORPI5ceIEHn/8cemx4eqQyMhIJCUl4dVXX0VRURGmTZuG/Px89O3bF8nJydJ0fACwadMmREdHY9CgQVAqlYiIiMDatWul5c7OzkhJSUFUVBQCAwPRsmVLLFq0yKSpvYiIiBojJtpEhJ49e2Lbtm2YP38+li5dCj8/P6xZswbjxo2T6shx0E5E8hkwYACEEJUuVygUWLp0KZYuXVppHVdX1wfOc9+tWzf897//rXGcREREjRETbSICAAwbNgzDhg2rdLlcB+1ERERERNZOae4AiIiIiIiIiKwJE20iIiIiIiIiGTHRJiIiIiIiIpIRE20iIiIiIiIiGTHRJiIiIiIiIpKRyYn2tWvX8Nxzz6FFixZwdHRE165dceLECWm5EAKLFi2Cp6cnHB0dERISgvPnzxut4+bNmxg3bhzUajVcXFwwZcoU3L59u/atISIiIiIiIjIzkxLtP//8E3369IGdnR2+/fZbnD17Fm+//TaaN28u1Vm1ahXWrl2L9evX4+jRo2jSpAnCwsJw9+5dqc64ceNw5swZpKamYteuXTh06BCmTZsmX6uIiIiIiIiIzMSkRHvlypXw9vZGYmIievXqBT8/P4SGhqJt27YA7p3NXrNmDRYsWIARI0agW7du+PTTT3H9+nVs374dAHDu3DkkJyfjo48+QnBwMPr27Yt169Zhy5YtuH79uuwNJCIiIiKyFgkJCejWrRvUajXUajU0Gg2+/fZbafndu3cRFRWFFi1aoGnTpoiIiEBubq7ROrKzsxEeHg4nJye4ublhzpw5KC0tre+mEFk1W1Mqf/311wgLC8Po0aORlpaGv/3tb3jppZcwdepUAMClS5eQk5ODkJAQ6TnOzs4IDg5Geno6xo4di/T0dLi4uCAoKEiqExISAqVSiaNHj+Kpp54qt12tVgutVis9LiwsBADodDrodLoKYzWUq5TClCZWuh66x9Af7Bd5Vadf2edERETUunVrrFixAu3bt4cQAhs2bMCIESPw448/onPnzpg1axa++eYbbN26Fc7OzoiOjsaoUaPw/fffAwDKysoQHh4ODw8PHD58GDdu3MCECRNgZ2eH5cuXm7l1RNbDpET7119/RUJCAmJiYvDaa6/h+PHjePnll2Fvb4/IyEjk5OQAANzd3Y2e5+7uLi3LycmBm5ubcRC2tnB1dZXq3C8uLg5LliwpV56SkgInJ6cqY14WpK92+yqye/fuWj3fWqWmppo7BKtUVb8WFxfXYyRERETUEA0fPtzo8RtvvIGEhAQcOXIErVu3xscff4zNmzdj4MCBAIDExER06tQJR44cQe/evZGSkoKzZ89i7969cHd3R0BAAJYtW4a5c+ciNjYW9vb25mgWkdUxKdHW6/UICgqSvu3q0aMHTp8+jfXr1yMyMrJOAgSA+fPnIyYmRnpcWFgIb29vhIaGQq1WV/gcnU6H1NRULDyhhFavqPG2T8eG1fi51sjQr4MHD4adnZ25w7Ea1elXw5UcRERERMC9s9Nbt25FUVERNBoNMjIyoNPpjK4u7dixI9q0aYP09HT07t0b6enp6Nq1q9GJsbCwMEyfPh1nzpxBjx49KtzWg64wrcurHlU2tbtCFWjYVwbyitHaqc/+M2UbJiXanp6e8Pf3Nyrr1KkTvvzySwCAh4cHACA3Nxeenp5SndzcXAQEBEh18vLyjNZRWlqKmzdvSs+/n0qlgkqlKlduZ2f3wGRPq1dAW1bzRJvJZMWq0/dkuqr6lf1NREREAHDq1CloNBrcvXsXTZs2xbZt2+Dv74/MzEzY29vDxcXFqP79V5dWdPWpYVllqnuFaV1c9biqV+3XYQlXqfKK0dqpj/4z5QpTkxLtPn36ICsry6jsl19+gY+PDwDAz88PHh4e2Ldvn5RYFxYW4ujRo5g+fToAQKPRID8/HxkZGQgMDAQA7N+/H3q9HsHBwaaEQ0RERETU6HTo0AGZmZkoKCjAF198gcjISKSlpdXpNh90hWldXvXYJXZPrdfRkK9S5RWjtVOf/WfKFaYmJdqzZs3Co48+iuXLl2PMmDE4duwYPvjgA3zwwQcAAIVCgZkzZ+L1119H+/bt4efnh4ULF8LLywsjR44EcO8M+BNPPIGpU6di/fr10Ol0iI6OxtixY+Hl5WVKOEREREREjY69vT3atWsHAAgMDMTx48fx7rvv4umnn0ZJSQny8/ONzmrn5uZKV456eHjg2LFjRusz3JW8sqtLgepfYVoXVz3W5upUA0tIYHnFaO3UR/+Zsn6Tpvfq2bMntm3bhv/85z/o0qULli1bhjVr1mDcuHFSnVdffRUzZszAtGnT0LNnT9y+fRvJyclwcHCQ6mzatAkdO3bEoEGDMHToUPTt21dK1omIiIiIqPr0ej20Wi0CAwNhZ2eHffv2ScuysrKQnZ0NjUYD4N7VpadOnTL6KWdqairUanW5n4gSUc2ZdEYbAIYNG4Zhw4ZVulyhUGDp0qVYunRppXVcXV2xefNmUzdNRERERNSozZ8/H0OGDEGbNm1w69YtbN68GQcPHsSePXvg7OyMKVOmICYmBq6urlCr1ZgxYwY0Gg169+4NAAgNDYW/vz/Gjx+PVatWIScnBwsWLEBUVFSFZ6yJqGZMTrSJiIiIiMg88vLyMGHCBNy4cQPOzs7o1q0b9uzZg8GDBwMAVq9eDaVSiYiICGi1WoSFheG9996Tnm9jY4Ndu3Zh+vTp0Gg0aNKkCSIjI6s8SUZEpmOiTURERERkIT7++OMqlzs4OCA+Ph7x8fGV1vHx8bGIu3DLyXfeN7Ks5/KKcFnWQ9bPpN9oExEREREREVHVmGgTERERERERyYiJNhEREREREZGMmGgTERERERERyYiJNhEREREREZGMmGgTERERERERyYiJNhEREREREZGMmGgTERERERERyYiJNhERkZXy9fWFQqEo9xcVFQUAGDBgQLllL774otE6srOzER4eDicnJ7i5uWHOnDkoLS01R3OIiIgshq25AyAiIqK6cfz4cZSVlUmPT58+jcGDB2P06NFS2dSpU7F06VLpsZOTk/T/srIyhIeHw8PDA4cPH8aNGzcwYcIE2NnZYfny5fXTCCIiIgvERJuIiMhKtWrVyujxihUr0LZtW/Tv318qc3JygoeHR4XPT0lJwdmzZ7F37164u7sjICAAy5Ytw9y5cxEbGwt7e/s6jZ+IiMhSMdEmIiJqBEpKSrBx40bExMRAoVBI5Zs2bcLGjRvh4eGB4cOHY+HChdJZ7fT0dHTt2hXu7u5S/bCwMEyfPh1nzpxBjx49KtyWVquFVquVHhcWFgIAdDoddDqdUV3DY5VS1LqN96+7vhi2a67t1xbjl19DioWIzIOJNhERUSOwfft25OfnY+LEiVLZs88+Cx8fH3h5eeHkyZOYO3cusrKy8NVXXwEAcnJyjJJsANLjnJycSrcVFxeHJUuWlCtPSUkxujT9r5YF6U1tUjm7d++u9TpqIzU11azbry3GL5/i4mJzh0BEZsZEm4iIqBH4+OOPMWTIEHh5eUll06ZNk/7ftWtXeHp6YtCgQbh48SLatm1b423Nnz8fMTEx0uPCwkJ4e3sjNDQUarXaqK5Op0NqaioWnlBCq1fcvyqTnI4Nq9Xza8rQhsGDB8POzs4sMdQG45ef4SoOImq8mGgTERFZuStXrmDv3r3SmerKBAcHAwAuXLiAtm3bwsPDA8eOHTOqk5ubCwCV/q4bAFQqFVQqVblyOzu7ShMhrV4BbVntEm1zJ1lVtc8SMH75NJQ4iMh8OL0XERGRlUtMTISbmxvCw8OrrJeZmQkA8PT0BABoNBqcOnUKeXl5Up3U1FSo1Wr4+/vXWbxERESWjme0iYiIrJher0diYiIiIyNha/t/H/sXL17E5s2bMXToULRo0QInT57ErFmz0K9fP3Tr1g0AEBoaCn9/f4wfPx6rVq1CTk4OFixYgKioqArPWBMREdE9TLSJiIis2N69e5GdnY3Jkycbldvb22Pv3r1Ys2YNioqK4O3tjYiICCxYsECqY2Njg127dmH69OnQaDRo0qQJIiMjjebdJiIiovKYaBMREVmx0NBQCFF+6ixvb2+kpaU98Pk+Pj5mv5s3ERGRpeFvtImIiIiIiIhkxESbiIiIiIiISEZMtImIiIiIiIhkxESbiMpZsWIFFAoFZs6cKZXdvXsXUVFRaNGiBZo2bYqIiAhpPl2D7OxshIeHw8nJCW5ubpgzZw5KS0vrOXoiIiIiIvNiok1ERo4fP473339fmt7HYNasWdi5cye2bt2KtLQ0XL9+HaNGjZKWl5WVITw8HCUlJTh8+DA2bNiApKQkLFq0qL6bQERERERkVky0iUhy+/ZtjBs3Dh9++CGaN28ulRcUFODjjz/GO++8g4EDByIwMBCJiYk4fPgwjhw5AgBISUnB2bNnsXHjRgQEBGDIkCFYtmwZ4uPjUVJSYq4mERERERHVO07vRUSSqKgohIeHIyQkBK+//rpUnpGRAZ1Oh5CQEKmsY8eOaNOmDdLT09G7d2+kp6eja9eucHd3l+qEhYVh+vTpOHPmDHr06FFue1qtFlqtVnpcWFgIANDpdNDpdOXqG8oqWmapVDblp11SKYXRvw9iif1hja9lRarTTmvvAyIiosaIiTYRAQC2bNmCH374AcePHy+3LCcnB/b29nBxcTEqd3d3R05OjlTnr0m2YblhWUXi4uKwZMmScuUpKSlwcnKqNNbU1NQq22JJVvWqfNmyIH211mHJcxxb02tZlaraWVxcXI+REBERUX1gok1EuHr1Kl555RWkpqbCwcGh3rY7f/58xMTESI8LCwvh7e2N0NBQqNXqcvV1Oh1SU1MxePBg2NnZ1VucdalL7J5yZSqlwLIgPRaeUEKrVzxwHadjw+oitDplja9lRarTTsOVHERERGQ9mGgTETIyMpCXl4dHHnlEKisrK8OhQ4fwr3/9C3v27EFJSQny8/ONzmrn5ubCw8MDAODh4YFjx44ZrddwV3JDnfupVCqoVKpy5XZ2dlUmXw9abkm0ZZUn0lq9osrlBpbcF9b0WlalqnY2hvYTERE1NrwZGhFh0KBBOHXqFDIzM6W/oKAgjBs3Tvq/nZ0d9u3bJz0nKysL2dnZ0Gg0AACNRoNTp04hLy9PqpOamgq1Wg1/f/96bxMRERERkbnwjDYRoVmzZujSpYtRWZMmTdCiRQupfMqUKYiJiYGrqyvUajVmzJgBjUaD3r17AwBCQ0Ph7++P8ePHY9WqVcjJycGCBQsQFRVV4VlrIiIiIiJrxUSbiKpl9erVUCqViIiIgFarRVhYGN577z1puY2NDXbt2oXp06dDo9GgSZMmiIyMxNKlS80YNRERERFR/avVpeMrVqyAQqHAzJkzpbK7d+8iKioKLVq0QNOmTRERESH9TtMgOzsb4eHhcHJygpubG+bMmYPS0tLahEJEMjt48CDWrFkjPXZwcEB8fDxu3ryJoqIifPXVV+V+e+3j44Pdu3ejuLgYv/32G9566y3Y2vL7PCIiIiJqXGqcaB8/fhzvv/8+unXrZlQ+a9Ys7Ny5E1u3bkVaWhquX7+OUaNGScvLysoQHh6OkpISHD58GBs2bEBSUhIWLVpU81YQERERETUCcXFx6NmzJ5o1awY3NzeMHDkSWVlZRnV44ovI/GqUaN++fRvjxo3Dhx9+iObNm0vlBQUF+Pjjj/HOO+9g4MCBCAwMRGJiIg4fPowjR44AuDc/7tmzZ7Fx40YEBARgyJAhWLZsGeLj41FSUiJPq4iIiIiIrFBaWhqioqJw5MgRpKamQqfTITQ0FEVFRVIdnvgiMr8aXdMZFRWF8PBwhISE4PXXX5fKMzIyoNPpEBISIpV17NgRbdq0QXp6Onr37o309HR07doV7u7uUp2wsDBMnz4dZ86cQY8ePcptT6vVQqvVSo8Nc47qdDrodLoKYzSUq5SiJk0stx66x9Af7Bd5Vadf2edERESUnJxs9DgpKQlubm7IyMhAv379pBNfmzdvxsCBAwEAiYmJ6NSpE44cOYLevXtLJ7727t0Ld3d3BAQEYNmyZZg7dy5iY2Nhb29vjqYRWRWTE+0tW7bghx9+wPHjx8sty8nJgb29vdE8uwDg7u6OnJwcqc5fk2zDcsOyisTFxWHJkiXlylNSUuDk5FRlvMuC9FUuf5Ddu3fX6vnWKjU11dwhWKWq+rW4uLgeIyEiIiJLUFBQAABwdXUFUHcnvojINCYl2levXsUrr7yC1NRUODg41FVM5cyfPx8xMTHS48LCQnh7eyM0NBRqtbrC5+h0OqSmpmLhCSW0ekWNt306NqzGz7VGhn4dPHgw7OzszB2O1ahOvxqu5CAiIiICAL1ej5kzZ6JPnz7SdJx1deLrQVeY1uVVjyqb2l2hKqe6aB+vGK2d+uw/U7ZhUqKdkZGBvLw8PPLII1JZWVkZDh06hH/961/Ys2cPSkpKkJ+fbzS4c3NzpbsTe3h44NixY0brNdyc4f47GBuoVKoK5+G1s7N7YLKn1SugLat5os1ksmLV6XsyXVX9yv4mIiKiv4qKisLp06fx3Xff1fm2qnuFaV1c9biql+yrrLG6vNqVV4zWTn30nylXmJqUaA8aNAinTp0yKps0aRI6duyIuXPnwtvbG3Z2dti3bx8iIiIAAFlZWcjOzoZGowEAaDQavPHGG8jLy4ObmxuAe52iVqvh7+9vSjhERERERI1SdHQ0du3ahUOHDqF169ZSuYeHR52c+HrQFaZ1edVjl9g9sq6vNurialdeMVo79dl/plxhalKi3axZM+myFIMmTZqgRYsWUvmUKVMQExMDV1dXqNVqzJgxAxqNBr179wYAhIaGwt/fH+PHj8eqVauQk5ODBQsWICoqqsKz1kREREREdI8QAjNmzMC2bdtw8OBB+Pn5GS0PDAyskxNf1b3CtC6ueqzN1alyq8tEjleM1k599J8p66/RXcersnr1aiiVSkRERECr1SIsLAzvvfeetNzGxga7du3C9OnTodFo0KRJE0RGRmLp0qVyh0JEREREZFWioqKwefNm7NixA82aNZN+U+3s7AxHR0c4OzvzxBdRA1DrRPvgwYNGjx0cHBAfH4/4+PhKn+Pj48O7eRMRERERmSghIQEAMGDAAKPyxMRETJw4EQBPfBE1BLKf0SYiIiIiorohxIPvwM0TX0TmpzR3AERERERERETWhIk2ERERERERkYyYaBMREVmp2NhYKBQKo7+OHTtKy+/evYuoqCi0aNECTZs2RUREhDTFj0F2djbCw8Ph5OQENzc3zJkzB6WlpfXdFCIiIovC32gTERFZsc6dO2Pv3r3SY1vb//vonzVrFr755hts3boVzs7OiI6OxqhRo/D9998DAMrKyhAeHg4PDw8cPnwYN27cwIQJE2BnZ4fly5fXe1uIiIgsBRNtIiIiK2ZrawsPD49y5QUFBfj444+xefNmDBw4EMC9uxZ36tQJR44cQe/evZGSkoKzZ89i7969cHd3R0BAAJYtW4a5c+ciNjYW9vb29d0cIiIii8BLx4mIiKzY+fPn4eXlhYceegjjxo1DdnY2ACAjIwM6nQ4hISFS3Y4dO6JNmzZIT08HAKSnp6Nr165wd3eX6oSFhaGwsBBnzpyp34YQERFZEJ7RJiIislLBwcFISkpChw4dcOPGDSxZsgSPPfYYTp8+jZycHNjb28PFxcXoOe7u7sjJyQEA5OTkGCXZhuWGZZXRarXQarXS48LCQgCATqeDTqczqmt4rFI+eMqiB7l/3fXFsF1zbb+2GL/8GlIsRGQeTLSJiIis1JAhQ6T/d+vWDcHBwfDx8cHnn38OR0fHOttuXFwclixZUq48JSUFTk5OFT5nWZC+1ts195zAqampZt1+bTF++RQXF5s7BCIyMybaREREjYSLiwsefvhhXLhwAYMHD0ZJSQny8/ONzmrn5uZKv+n28PDAsWPHjNZhuCt5Rb/7Npg/fz5iYmKkx4WFhfD29kZoaCjUarVRXZ1Oh9TUVCw8oYRWr6hV+07HhtXq+TVlaMPgwYNhZ2dnlhhqg/HLz3AVBxE1Xky0iYiIGonbt2/j4sWLGD9+PAIDA2FnZ4d9+/YhIiICAJCVlYXs7GxoNBoAgEajwRtvvIG8vDy4ubkBuHfWUK1Ww9/fv9LtqFQqqFSqcuV2dnaVJkJavQLastol2uZOsqpqnyVg/PJpKHEQkfkw0SYiIrJS//jHPzB8+HD4+Pjg+vXrWLx4MWxsbPDMM8/A2dkZU6ZMQUxMDFxdXaFWqzFjxgxoNBr07t0bABAaGgp/f3+MHz8eq1atQk5ODhYsWICoqKgKE2kiIiK6h4k2ERGRlfrf//6HZ555Bn/88QdatWqFvn374siRI2jVqhUAYPXq1VAqlYiIiIBWq0VYWBjee+896fk2NjbYtWsXpk+fDo1GgyZNmiAyMhJLly41V5OIiIgsAhNtqpEusXtqdYnf5RXhMkZDREQV2bJlS5XLHRwcEB8fj/j4+Err+Pj4mP0mY0RERJaG82gTERERERERyYiJNhEREREREZGMmGgTERERERERyYiJNhEREREREZGMmGgTERERERERyYiJNhEREREREZGMmGgTERERERERyYiJNhEREREREZGMmGgTERERERERycjW3AEQERERERFZAt9539R6HZdXhMsQCTV0TLSJiEg21T0AUdkIrOoFdIndA22ZwmgZD0CIiIjI0vHScSIiIiIiIiIZMdEmIiIiIiIikhETbSIiIiIiIiIZMdEmIiIiIiIikhETbSJCXFwcevbsiWbNmsHNzQ0jR45EVlaWUZ27d+8iKioKLVq0QNOmTREREYHc3FyjOtnZ2QgPD4eTkxPc3NwwZ84clJaW1mdTiIiIiIjMjok2ESEtLQ1RUVE4cuQIUlNTodPpEBoaiqKiIqnOrFmzsHPnTmzduhVpaWm4fv06Ro0aJS0vKytDeHg4SkpKcPjwYWzYsAFJSUlYtGiROZpERERERGQ2nN6LiJCcnGz0OCkpCW5ubsjIyEC/fv1QUFCAjz/+GJs3b8bAgQMBAImJiejUqROOHDmC3r17IyUlBWfPnsXevXvh7u6OgIAALFu2DHPnzkVsbCzs7e3N0TQiIiIionrHM9pEVE5BQQEAwNXVFQCQkZEBnU6HkJAQqU7Hjh3Rpk0bpKenAwDS09PRtWtXuLu7S3XCwsJQWFiIM2fO1GP0RERERETmxTPaRGREr9dj5syZ6NOnD7p06QIAyMnJgb29PVxcXIzquru7IycnR6rz1yTbsNywrCJarRZarVZ6XFhYCADQ6XTQ6XTl6hvKKlpmqVQ2onyZUhj9+yANqT8qak+F9apoY0NqT21VZ5+1pvYSERHRPSYl2nFxcfjqq6/w888/w9HREY8++ihWrlyJDh06SHXu3r2L2bNnY8uWLdBqtQgLC8N7771ndACenZ2N6dOn48CBA2jatCkiIyMRFxcHW1vm/UTmFhUVhdOnT+O7776r823FxcVhyZIl5cpTUlLg5ORU6fNSU1PrMqx6tapX5cuWBemrtY7du3fLFE3tVdWeilTUxobUHrlUtc8WFxfXYyRERERUH0zKbA03TOrZsydKS0vx2muvITQ0FGfPnkWTJk0A3Lth0jfffIOtW7fC2dkZ0dHRGDVqFL7//nsA/3fDJA8PDxw+fBg3btzAhAkTYGdnh+XLl8vfQiKqtujoaOzatQuHDh1C69atpXIPDw+UlJQgPz/f6Kx2bm4uPDw8pDrHjh0zWp/hruSGOvebP38+YmJipMeFhYXw9vZGaGgo1Gp1ufo6nQ6pqakYPHgw7OzsatzOhqRL7J5yZSqlwLIgPRaeUEKrVzxwHadjw+oitBqpqD0VqaqNDak9tVWdfdZwJQcRUXUdOnQIb775JjIyMnDjxg1s27YNI0eOlJYLIbB48WJ8+OGHyM/PR58+fZCQkID27dtLdW7evIkZM2Zg586dUCqViIiIwLvvvoumTZuaoUVE1sekRJs3TCKyTkIIzJgxA9u2bcPBgwfh5+dntDwwMBB2dnbYt28fIiIiAABZWVnIzs6GRqMBAGg0GrzxxhvIy8uDm5sbgHtn8dRqNfz9/SvcrkqlgkqlKlduZ2dXZSL9oOWWRFtWeSKt1SuqXG7QkPqiOvEa1a+gjQ2pPXKpap+1xvYSUd0qKipC9+7dMXnyZKMZQAxWrVqFtWvXYsOGDfDz88PChQsRFhaGs2fPwsHBAQAwbtw43LhxQ5ptZNKkSZg2bRo2b95c380hskq1uhkab5hEZB2ioqKwceNGbN68Gc2aNUNOTg5ycnJw584dAICzszOmTJmCmJgYHDhwABkZGZg0aRI0Gg169+4NAAgNDYW/vz/Gjx+Pn376CXv27MGCBQsQFRVVYTJNRERENTNkyBC8/vrreOqpp8otE0JgzZo1WLBgAUaMGIFu3brh008/xfXr17F9+3YAwLlz55CcnIyPPvoIwcHB6Nu3L9atW4ctW7bg+vXr9dwaIutU4x9FN+QbJhmWAdW/mVBleJMaY+zXumHuGyYlJCQAAAYMGGBUnpiYiIkTJwIAVq9eLV1a9tf7LxjY2Nhg165dmD59OjQaDZo0aYLIyEgsXbq0zuImIiIiY5cuXUJOTo7RiS9nZ2cEBwcjPT0dY8eORXp6OlxcXBAUFCTVCQkJgVKpxNGjRytM4B90PF6XNyyt7o02LcX9fWSNN3utT/XZf6Zso8aJtiXcMAmo/s2EKmONN+WRA/u1bpjrhklCPPgDzMHBAfHx8YiPj6+0jo+PD19bIiIiMzKcuKroxNZfT3wZfuZlYGtrC1dX10pPfFX3eLwublhq6o02G7rKjpWs6Wav5lAf/WfK8XiNEu2GfsMk4P9uQFPdmwlVxppuyiMH9mvd4A2TiIiIqCF70PF4Xd6wtLo32rQU9x8HW+PNXutTffafKcfjJiXalnbDJKD6NxOqDHf2irFf6wZvmEREcqrOtJwDBgxAWlqa0fNeeOEFrF+/XnrMaTmJLIfhxFVubi48PT2l8tzcXAQEBEh18vLyjJ5XWlqKmzdvVnriq7rH43Vxw9LaHHM2RFUd6/F4r+bqo/9MWb9JN0PjDZOIiIgsh2FaziNHjkh3Fg4NDUVRUZFRvalTp+LGjRvS36pVq6Rlhmk5S0pKcPjwYWzYsAFJSUlYtGhRfTeHiKrBz88PHh4e2Ldvn1RWWFiIo0ePGp34ys/PR0ZGhlRn//790Ov1CA4OrveYiayRSV9F84ZJREREluNB03IaODk5VXoWi9NyEjU8t2/fxoULF6THly5dQmZmJlxdXdGmTRvMnDkTr7/+Otq3by9N7+Xl5SXNtd2pUyc88cQTmDp1KtavXw+dTofo6GiMHTsWXl5eZmpV4+E77xujxyobgVW97l0iX92z95dXhNdFaCQjky8dfxDeMImIiKhhun9aToNNmzZh48aN8PDwwPDhw7Fw4ULp5kaVTcs5ffp0nDlzBj169Ki/BhARAODEiRN4/PHHpceG305HRkYiKSkJr776KoqKijBt2jTk5+ejb9++SE5OlubQBu6N++joaAwaNEg6SbZ27dp6bwuRteKPq4iIiBqBiqblBIBnn30WPj4+8PLywsmTJzF37lxkZWXhq6++AlD303LKNW3kX9dV3yx9ah7GL7+6jmXAgAFVngBTKBRYunRplVeMurq6YvPmzXURHhGBiTYREVGjUNm0nNOmTZP+37VrV3h6emLQoEG4ePEi2rZtW6Nt1WRaztpOGwmYf+pIS5+ah/HLpy6n5CQiy8BEm4iIyMpVNi1nRQw3Qrpw4QLatm1b59NyyjVtJGC+qSMtfWoexi8/TslJREy0icjimHKzkMrwJiLUGDxoWs6KZGZmAoA0LVB9TctZ22kjDes3J0ufmofxy6ehxEFE5sNEm4iIyEpFRUVh8+bN2LFjhzQtJ3BvOk5HR0dcvHgRmzdvxtChQ9GiRQucPHkSs2bNQr9+/dCtWzcAxtNyrlq1Cjk5OZyWk4iI6AFMmkebiIiILEdCQgIKCgowYMAAeHp6Sn+fffYZAMDe3h579+5FaGgoOnbsiNmzZyMiIgI7d+6U1mGYltPGxgYajQbPPfccJkyYwGk5iYiIqsAz2kRERFbqQdNyent7Iy0t7YHr4bScRFRT988ZTdRY8Iw2ERERERERkYyYaBMRERERERHJiIk2ERERERERkYyYaBMRERERERHJiIk2ERERERERkYyYaBMRERERERHJiIk2ERERERERkYyYaBMRERERERHJiIk2ERERERERkYyYaBMRERERERHJiIk2ERERERERkYyYaBMRERERERHJiIk2ERERERERkYyYaBMRERERERHJiIk2ERERERERkYyYaBMRERERERHJyNbcARAREREREVH1+c77ptbruLwiXIZIqDI8o01EREREREQkIybaRERERERERDJiok1EREREREQkIybaRERERERERDJiok1EREREREQkIybaRERERERERDJiok1EREREREQkIybaRERERERERDKyNXcAREREREREVL98530jy3ourwiXZT3Whme0iYiIiIiIiGTERJuIiIiIiIhIRmZNtOPj4+Hr6wsHBwcEBwfj2LFj5gyHiGTAcU1knTi2iawTxzZR3TBbov3ZZ58hJiYGixcvxg8//IDu3bsjLCwMeXl55gqJiGqJ45rIOnFsE1knjm2iumO2RPudd97B1KlTMWnSJPj7+2P9+vVwcnLCJ598Yq6QiKiWOK6JrBPHNpF14tgmqjtmuet4SUkJMjIyMH/+fKlMqVQiJCQE6enp5eprtVpotVrpcUFBAQDg5s2b0Ol0FW5Dp9OhuLgYtjolyvSKGsf6xx9/1Pi51oj9WrHguH21er5KKbCghx5//PEH7OzsKqxz69YtAIAQolbbqiumjmvA9LEt1/4HNJx90La0qHyZXqC4WF/tdjaUtgAVt6fCelW0sSG1h2O77se2NYxrQxuqep0bMsYvv4Y+rgH5j8crex2q+7nQmJn6ud/QtPvH57Vex9H5g2r83Pp8DzBlbJsl0f79999RVlYGd3d3o3J3d3f8/PPP5erHxcVhyZIl5cr9/PzqLEaDlm/X+SYaJfZrec9Ws96tW7fg7Oxcp7HUhKnjGuDYrkp19weg4belMpW10VLbUxmO7f9T12Pb2vYdsnwNdVwDlnU83hiY8rlvjSzt/bs6Y9si5tGeP38+YmJipMd6vR43b95EixYtoFBU/K1PYWEhvL29cfXqVajV6voK1eqxX+tGdfpVCIFbt27By8urnqOrO6aO7cay/zWGdjaGNgIc2wZVjW1r2BcsvQ2MX36NcVw3xNfBUrDvaqc++8+UsW2WRLtly5awsbFBbm6uUXlubi48PDzK1VepVFCpVEZlLi4u1dqWWq3mDlsH2K9140H92lC/FQdMH9dAzcd2Y9n/GkM7G0MbAY5t4MFj2xr2BUtvA+OXV0Me10DdHY83tNfBkrDvaqe++q+6Y9ssN0Ozt7dHYGAg9u37v9++6fV67Nu3DxqNxhwhEVEtcVwTWSeObSLrxLFNVLfMdul4TEwMIiMjERQUhF69emHNmjUoKirCpEmTzBUSEdUSxzWRdeLYJrJOHNtEdcdsifbTTz+N3377DYsWLUJOTg4CAgKQnJxc7oYMNaVSqbB48eJyl7hQ7bBf64a19CvHtTwaQzsbQxsB62lnXY5ta+gjS28D42+85BzbfB1qjn1XOw21/xSiIc87QERERERERGRhzPIbbSIiIiIiIiJrxUSbiIiIiIiISEZMtImIiIiIiIhkxESbiIiIiIiISEZWl2gfOnQIw4cPh5eXFxQKBbZv327ukKxCXFwcevbsiWbNmsHNzQ0jR45EVlaWucOyeAkJCejWrRvUajXUajU0Gg2+/fZbc4fVIDWGsd0Yxllj3OdXrFgBhUKBmTNnmjuUBik+Ph6+vr5wcHBAcHAwjh07Vu8xVGfs3b17F1FRUWjRogWaNm2KiIgI5ObmGtXJzs5GeHg4nJyc4Obmhjlz5qC0tNSozsGDB/HII49ApVKhXbt2SEpKkr09Fe1zDT3+a9eu4bnnnkOLFi3g6OiIrl274sSJE9JyIQQWLVoET09PODo6IiQkBOfPnzdax82bNzFu3Dio1Wq4uLhgypQpuH37tlGdkydP4rHHHoODgwO8vb2xatUqWeJv7BrCOLZUjeH4pq409OMmq0u0i4qK0L17d8THx5s7FKuSlpaGqKgoHDlyBKmpqdDpdAgNDUVRUZG5Q7NorVu3xooVK5CRkYETJ05g4MCBGDFiBM6cOWPu0BqcxjC2G8M4a2z7/PHjx/H++++jW7du5g6lQfrss88QExODxYsX44cffkD37t0RFhaGvLy8eo2jOmNv1qxZ2LlzJ7Zu3Yq0tDRcv34do0aNkpaXlZUhPDwcJSUlOHz4MDZs2ICkpCQsWrRIqnPp0iWEh4fj8ccfR2ZmJmbOnInnn38ee/bska0tle1zDTn+P//8E3369IGdnR2+/fZbnD17Fm+//TaaN28u1Vm1ahXWrl2L9evX4+jRo2jSpAnCwsJw9+5dqc64ceNw5swZpKamYteuXTh06BCmTZsmLS8sLERoaCh8fHyQkZGBN998E7Gxsfjggw9qFX9j11DGsaVqDMc3daXBHzcJKwZAbNu2zdxhWKW8vDwBQKSlpZk7FKvTvHlz8dFHH5k7jAatsYztxjLOrHWfv3Xrlmjfvr1ITU0V/fv3F6+88oq5Q2pwevXqJaKioqTHZWVlwsvLS8TFxZkxqvJjLz8/X9jZ2YmtW7dKdc6dOycAiPT0dCGEELt37xZKpVLk5ORIdRISEoRarRZarVYIIcSrr74qOnfubLStp59+WoSFhckSd2X7XEOPf+7cuaJv376VLtfr9cLDw0O8+eabUll+fr5QqVTiP//5jxBCiLNnzwoA4vjx41Kdb7/9VigUCnHt2jUhhBDvvfeeaN68udQew7Y7dOhQq/gbu4Y6ji1RYzm+qSsN7bjJ6s5oU/0oKCgAALi6upo5EutRVlaGLVu2oKioCBqNxtzhUANg7ePM2vf5qKgohIeHIyQkxNyhNEglJSXIyMgw6h+lUomQkBCkp6ebMbLyYy8jIwM6nc4o1o4dO6JNmzZSrOnp6ejatSvc3d2lOmFhYSgsLJSu2EhPTy+3P4SFhcnW3sr2uYYe/9dff42goCCMHj0abm5u6NGjBz788ENp+aVLl5CTk2O0bWdnZwQHBxvF7+LigqCgIKlOSEgIlEoljh49KtXp168f7O3tjeLPysrCn3/+Was2NFYNeRxT49PQjptszR0AWR69Xo+ZM2eiT58+6NKli7nDsXinTp2CRqPB3bt30bRpU2zbtg3+/v7mDovMzJrHWWPY57ds2YIffvgBx48fN3coDdbvv/+OsrIyo8QOANzd3fHzzz+bKaqKx15OTg7s7e3h4uJiVNfd3R05OTlSnYraYlhWVZ3CwkLcuXMHjo6ONY67qn2uocf/66+/IiEhATExMXjttddw/PhxvPzyy7C3t0dkZKS0/Yq2/dfY3NzcjJbb2trC1dXVqI6fn1+lbfzrpepUPQ11HFPj0xCPm5hok8mioqJw+vRpfPfdd+YOxSp06NABmZmZKCgowBdffIHIyEikpaVZXeJBprHmcWbt+/zVq1fxyiuvIDU1FQ4ODuYOh0xkiWPP0vc5vV6PoKAgLF++HADQo0cPnD59GuvXr0dkZKSZoyMiS9AQ37t56TiZJDo6Grt27cKBAwfQunVrc4djFezt7dGuXTsEBgYiLi4O3bt3x7vvvmvusMiMrH2cWfs+n5GRgby8PDzyyCOwtbWFra0t0tLSsHbtWtja2qKsrMzcITYILVu2hI2NTbk7X+fm5sLDw8MsMVU29jw8PFBSUoL8/Hyj+n+N1cPDo8K2GJZVVUetVtfqbPaD9jl3d/cGHb+np2e5L9o6deqE7Oxso+1Xta94eHiUu/lWaWkpbt68aVIbyTQNcRxT49NQj5uYaFO1CCEQHR2Nbdu2Yf/+/eUuvSL56PV6aLVac4dBZtBYx5m17fODBg3CqVOnkJmZKf0FBQVh3LhxyMzMhI2NjblDbBDs7e0RGBiIffv2SWV6vR779u2r99/sP2jsBQYGws7OzijWrKwsZGdnS7FqNBqcOnXKKNlLTU2FWq2WkkiNRmO0DkOd2rb3QftcUFBQg46/T58+5abk+eWXX+Dj4wMA8PPzg4eHh9G2CwsLcfToUaP48/PzkZGRIdXZv38/9Ho9goODpTqHDh2CTqczir9Dhw68bLyGGtI4psanwR83mfdebPK7deuW+PHHH8WPP/4oAIh33nlH/Pjjj+LKlSvmDs2iTZ8+XTg7O4uDBw+KGzduSH/FxcXmDs2izZs3T6SlpYlLly6JkydPinnz5gmFQiFSUlLMHVqD0xjGdmMYZ411n+ddxyu2ZcsWoVKpRFJSkjh79qyYNm2acHFxMbrzdX2ozth78cUXRZs2bcT+/fvFiRMnhEajERqNRlpeWloqunTpIkJDQ0VmZqZITk4WrVq1EvPnz5fq/Prrr8LJyUnMmTNHnDt3TsTHxwsbGxuRnJwse5vu3+cacvzHjh0Ttra24o033hDnz58XmzZtEk5OTmLjxo1SnRUrVggXFxexY8cOcfLkSTFixAjh5+cn7ty5I9V54oknRI8ePcTRo0fFd999J9q3by+eeeYZaXl+fr5wd3cX48ePF6dPnxZbtmwRTk5O4v33369V/I1dQxnHlqoxHN/UlYZ+3GR1ifaBAwcEgHJ/kZGR5g7NolXUpwBEYmKiuUOzaJMnTxY+Pj7C3t5etGrVSgwaNMjqE46aagxjuzGMs8a6zzPRrty6detEmzZthL29vejVq5c4cuRIvcdQnbF3584d8dJLL4nmzZsLJycn8dRTT4kbN24Yrefy5ctiyJAhwtHRUbRs2VLMnj1b6HQ6ozoHDhwQAQEBwt7eXjz00EN1Nr7v3+caevw7d+4UXbp0ESqVSnTs2FF88MEHRsv1er1YuHChcHd3FyqVSgwaNEhkZWUZ1fnjjz/EM888I5o2bSrUarWYNGmSuHXrllGdn376SfTt21eoVCrxt7/9TaxYsUKW+Bu7hjCOLVVjOL6pKw39uEkhhBB1dbaciIiIiIiIqLHhb7SJiIiIiIiIZMREm4iIiIiIiEhGTLSJiIiIiIiIZMREuwYUCgViY2PNHQYRERERERE1QEy0iapw/fp1xMbGIjMz09yhEBERERGRhbA1dwCW6M6dO7C1Zdc1BtevX8eSJUvg6+uLgIAAc4dDREREREQWgGe0q0mv1+Pu3bsAAAcHBybaJhBC4M6dO+YOo0EpKioydwhERERERFRHGl2iHRsbC4VCgZ9//hljxoyBWq1GixYt8Morr0iJNHDvd9jR0dHYtGkTOnfuDJVKheTkZGnZ/b/RvnbtGqZMmQIvLy+oVCr4+flh+vTpKCkpkerk5+dj5syZ8Pb2hkqlQrt27bBy5Uro9XqT2nD+/HlERETAw8MDDg4OaN26NcaOHYuCggKpjlarxaxZs9CqVSs0a9YMTz75JP73v/+Vi33ixInw9fWttJ/+KjExEQMHDoSbmxtUKhX8/f2RkJBQ7rm+vr4YNmwY9uzZg6CgIDg6OuL999+XtQ8GDBiALl264OTJk+jfvz+cnJzQrl07fPHFFwCAtLQ0BAcHw9HRER06dMDevXvLrePatWuYPHky3N3doVKp0LlzZ3zyySfS8oMHD6Jnz54AgEmTJkGhUEChUCApKUmqc/ToUTzxxBNwdnaGk5MT+vfvj++//77Cvjx79iyeffZZNG/eHH379jWpvURERERE9GCHDh3C8OHD4eXlBYVCge3bt5v0fMOx+/1/TZo0MWk9jfa07JgxY+Dr64u4uDgcOXIEa9euxZ9//olPP/1UqrN//358/vnniI6ORsuWLStMSIF7lxf36tUL+fn5mDZtGjp27Ihr167hiy++QHFxMezt7VFcXIz+/fvj2rVreOGFF9CmTRscPnwY8+fPx40bN7BmzZpqxV1SUoKwsDBotVrMmDEDHh4euHbtGnbt2oX8/Hw4OzsDAJ5//nls3LgRzz77LB599FHs378f4eHhteqzhIQEdO7cGU8++SRsbW2xc+dOvPTSS9Dr9YiKijKqm5WVhWeeeQYvvPACpk6dig4dOsjWBwZ//vknhg0bhrFjx2L06NFISEjA2LFjsWnTJsycORMvvvginn32Wbz55pv4+9//jqtXr6JZs2YAgNzcXPTu3Vv6QqVVq1b49ttvMWXKFBQWFmLmzJno1KkTli5dikWLFmHatGl47LHHAACPPvoogHv7x5AhQxAYGIjFixdDqVRKX0b897//Ra9evYziHT16NNq3b4/ly5dDCFHDV4GIiIiIiCpTVFSE7t27Y/LkyRg1apTJz//HP/6BF1980ahs0KBB0gm4ahONzOLFiwUA8eSTTxqVv/TSSwKA+Omnn4QQQgAQSqVSnDlzptw6AIjFixdLjydMmCCUSqU4fvx4ubp6vV4IIcSyZctEkyZNxC+//GK0fN68ecLGxkZkZ2dXK/4ff/xRABBbt26ttE5mZqYAIF566SWj8meffbZc7JGRkcLHx6fcOgz99FfFxcXl6oWFhYmHHnrIqMzHx0cAEMnJyUblcvWBEEL0799fABCbN2+Wyn7++WfpdTty5IhUvmfPHgFAJCYmSmVTpkwRnp6e4vfffzda79ixY4Wzs7PU1uPHj5d7rhD3Xtf27duLsLAw6TUW4l4f+fn5icGDB0tlhr585plnqt0+IiIiIiKqHQBi27ZtRmV3794Vs2fPFl5eXsLJyUn06tVLHDhwoNJ1GHKrQ4cOmbTtRnfpuMH9Z2BnzJgBANi9e7dU1r9/f/j7+1e5Hr1ej+3bt2P48OEICgoqt9xw+fXWrVvx2GOPoXnz5vj999+lv5CQEJSVleHQoUPVittwxnrPnj0oLi6usI6hDS+//LJR+cyZM6u1jco4OjpK/y8oKMDvv/+O/v3749dffzW6bB0A/Pz8EBYWZlQmVx8YNG3aFGPHjpUed+jQAS4uLujUqROCg4OlcsP/f/31VwD3fjP+5ZdfYvjw4RBCGMUSFhaGgoIC/PDDD1VuOzMzE+fPn8ezzz6LP/74Q3p+UVERBg0ahEOHDpW7HP7+b8aIiIiIiKh+RUdHIz09HVu2bMHJkycxevRoPPHEEzh//nyF9T/66CM8/PDD0tWt1dVoLx1v37690eO2bdtCqVTi8uXLUpmfn98D1/Pbb7+hsLAQXbp0qbLe+fPncfLkSbRq1arC5Xl5eQ8O+v/HFBMTg3feeQebNm3CY489hieffBLPPfeclIRfuXIFSqUSbdu2NXpuhw4dqrWNynz//fdYvHgx0tPTyyX5BQUF0vYNcd5Prj4waN26dbnfkTs7O8Pb27tcGXDvUnPg3muWn5+PDz74AB988EGNYjEMxMjIyErrFBQUoHnz5tLj6uxPRERERERUN7Kzs5GYmIjs7Gx4eXkBuHepeHJyMhITE7F8+XKj+nfv3sWmTZswb948k7fVaBPt+92fsAHGZ3BrS6/XY/DgwXj11VcrXP7www9Xe11vv/02Jk6ciB07diAlJQUvv/yy9Fvz1q1bmxRXRe0GgLKyMqPHFy9exKBBg9CxY0e888478Pb2hr29PXbv3o3Vq1eXO3tbUd/J2QcAYGNjY1K5+P+/izbE+txzz1WaKHfr1q3KbRvW8eabb1Y67VfTpk2NHsu5PxERERERkWlOnTqFsrKycnmHVqtFixYtytXftm0bbt26VeXJtco02kT7/PnzRmcYL1y4AL1eX+kNzyrTqlUrqNVqnD59usp6bdu2xe3btxESElKTcMvp2rUrunbtigULFuDw4cPo06cP1q9fj9dffx0+Pj7Q6/W4ePGi0VnsrKyscutp3rw58vPzy5VfuXLF6PHOnTuh1Wrx9ddfo02bNlL5gQMHqh2z3H1QU4Y7sZeVlT0wlsq+iDBcLaBWq83eHiIiIiIierDbt2/DxsYGGRkZ5U7O3X+SDLh32fiwYcPg7u5u8rYa7W+04+PjjR6vW7cOADBkyBCT1qNUKjFy5Ejs3LkTJ06cKLfccBZ1zJgxSE9Px549e8rVyc/PR2lpabW2V1hYWK5u165doVQqodVqjdqwdu1ao3oV3dW7bdu2KCgowMmTJ6WyGzduYNu2bUb1DDui+MvdsgsKCpCYmFituAH5+qC2bGxsEBERgS+//LLCL0h+++036f+G2/jf/2VEYGAg2rZti7feegu3b9+uch1ERERERGR+PXr0QFlZGfLy8tCuXTujPw8PD6O6ly5dwoEDBzBlypQabavRntG+dOkSnnzySTzxxBNIT0+XpsLq3r27yetavnw5UlJS0L9/f0ybNg2dOnXCjRs3sHXrVnz33XdwcXHBnDlz8PXXX2PYsGGYOHEiAgMDUVRUhFOnTuGLL77A5cuX0bJlywdua//+/YiOjsbo0aPx8MMPo7S0FP/+97+l5BEAAgIC8Mwzz+C9995DQUEBHn30Uezbtw8XLlwot76xY8di7ty5eOqpp/Dyyy+juLgYCQkJePjhh41uCBYaGgp7e3sMHz4cL7zwAm7fvo0PP/wQbm5uuHHjRrX6Sa4+kMOKFStw4MABBAcHY+rUqfD398fNmzfxww8/YO/evbh58yaAe19EuLi4YP369WjWrBmaNGmC4OBg+Pn54aOPPsKQIUPQuXNnTJo0CX/7299w7do1HDhwAGq1Gjt37qyXthARERER0T23b982ynsuXbqEzMxMuLq64uGHH8a4ceMwYcIEvP322+jRowd+++037Nu3D926dTOaDvmTTz6Bp6enySdiJabdIN3yGaZaOnv2rPj73/8umjVrJpo3by6io6PFnTt3pHoARFRUVIXrwH1TZAkhxJUrV8SECRNEq1athEqlEg899JCIiooSWq1WqnPr1i0xf/580a5dO2Fvby9atmwpHn30UfHWW2+JkpKSasX/66+/ismTJ4u2bdsKBwcH4erqKh5//HGxd+9eo3p37twRL7/8smjRooVo0qSJGD58uLh69WqFsaekpIguXboIe3t70aFDB7Fx48YKp/f6+uuvRbdu3YSDg4Pw9fUVK1euFJ988okAIC5duiTV8/HxEeHh4RXGL0cfCHFveq/OnTuXK69s2xW9nrm5uSIqKkp4e3sLOzs74eHhIQYNGiQ++OADo3o7duwQ/v7+wtbWttxUXz/++KMYNWqUaNGihVCpVMLHx0eMGTNG7Nu3T6pj6Mvffvut2u0jIiIiIiLTHThwQAAo9xcZGSmEEKKkpEQsWrRI+Pr6Cjs7O+Hp6SmeeuopcfLkSWkdZWVlonXr1uK1116rcRwKIf5yLXAjEBsbiyVLluC3336rt7OnDYlCocDixYsRGxtr7lCIiIiIiIisUqP9jTYRERERERFRXWi0v9FuiG7evImSkpJKl9vY2FQ6B7W1YB8QEREREZGlY6LdgIwaNQppaWmVLvfx8cHly5frLyAzYB8QEREREZGla3S/0W7IMjIy8Oeff1a63NHREX369KnHiOof+4CIiIiIiCwdE20iIiIiIiIiGfFmaEREREREREQyssjfaOv1ely/fh3NmjWDQqEwdzhE9UIIgVu3bsHLywtKJb8jIyIiIiJqqCwy0b5+/Tq8vb3NHQaRWVy9ehWtW7c2dxhERERERFQJi0y0mzVrBuBewqFWq8st1+l0SElJQWhoKOzs7Oo7vHrTGNrZGNoIVK+dhYWF8Pb2lvZ/IiIiIiJqmCwy0TZcLq5WqytNtJ2cnKBWq60+ObP2djaGNgKmtZM/lyAiIiIiatj4Q08iIiIiIiIiGTHRJiIiIiIiIpIRE20iIiIiIiIiGTHRJiIiIiIiIpIRE20iIiIiIiIiGVnkXcep5nznfVPrdVxeES5DJERERERERNaJZ7SJiIiIiIiIZMREm4iIiIiIiEhGTLSJiIiIiIiIZMREm4iIiIiIiEhGTLSJiIiIiIiIZMREm4iIiIiIiEhGTLSJiIiIiIiIZMREm4iIiIiIiEhGTLSJiIiIiIiIZMREm4iIiIiIiEhGTLSJiIiIiIiIZMREm4iIiIiIiEhGTLSJiIiIiIiIZMREm4iIiIiIiEhGTLSJiIiIiIiIZMREm4iIiIiIiEhGTLSJiIiIiIiIZMREm4iIiIiIiEhGTLSJiIiIiIiIZMREm4iIiIiIiEhGtqZUTkhIQEJCAi5fvgwA6Ny5MxYtWoQhQ4YAAO7evYvZs2djy5Yt0Gq1CAsLw3vvvQd3d3dpHdnZ2Zg+fToOHDiApk2bIjIyEnFxcbC1NSmURsd33jflylQ2Aqt6AV1i90BbpjBDVERERERERHQ/k85ot27dGitWrEBGRgZOnDiBgQMHYsSIEThz5gwAYNasWdi5cye2bt2KtLQ0XL9+HaNGjZKeX1ZWhvDwcJSUlODw4cPYsGEDkpKSsGjRInlbRURERERERGQmJp1GHj58uNHjN954AwkJCThy5Ahat26Njz/+GJs3b8bAgQMBAImJiejUqROOHDmC3r17IyUlBWfPnsXevXvh7u6OgIAALFu2DHPnzkVsbCzs7e3laxkRERERERGRGdT4N9plZWXYsmULioqKoNFokJGRAZ1Oh5CQEKlOx44d0aZNG6SnpwMA0tPT0bVrV6NLycPCwlBYWCidFSciIiIiIiKyZCb/MPrUqVPQaDS4e/cumjZtim3btsHf3x+ZmZmwt7eHi4uLUX13d3fk5OQAAHJycoySbMNyw7LKaLVaaLVa6XFhYSEAQKfTQafTlatvKKtomaVS2YjyZUph9G99qc9+tcbXsiLVaae19wERERERkbUwOdHu0KEDMjMzUVBQgC+++AKRkZFIS0uri9gkcXFxWLJkSbnylJQUODk5Vfq81NTUugyrXq3qVfmyZUH6+gsEwO7du+t1e4B1vZZVqaqdxcXF9RgJERERERHVlMmJtr29Pdq1awcACAwMxPHjx/Huu+/i6aefRklJCfLz843Oaufm5sLDwwMA4OHhgWPHjhmtLzc3V1pWmfnz5yMmJkZ6XFhYCG9vb4SGhkKtVperr9PpkJqaisGDB8POzs7UJjZIXWL3lCtTKQWWBemx8IQSWn393XX8dGxYvW3LGl/LilSnnYYrOYiIiIiIqGGr9Zxaer0eWq0WgYGBsLOzw759+xAREQEAyMrKQnZ2NjQaDQBAo9HgjTfeQF5eHtzc3ADcO4OnVqvh7+9f6TZUKhVUKlW5cjs7uyqTrwcttyRVTd+l1SvqdXovc/SpNb2WVamqnY2h/URERERE1sCkRHv+/PkYMmQI2rRpg1u3bmHz5s04ePAg9uzZA2dnZ0yZW19ghQAAFy1JREFUMgUxMTFwdXWFWq3GjBkzoNFo0Lt3bwBAaGgo/P39MX78eKxatQo5OTlYsGABoqKiKkykiYiIiIiIiCyNSYl2Xl4eJkyYgBs3bsDZ2RndunXDnj17MHjwYADA6tWroVQqERERAa1Wi7CwMLz33nvS821sbLBr1y5Mnz4dGo0GTZo0QWRkJJYuXSpvq4iIiIiIiIjMxKRE++OPP65yuYODA+Lj4xEfH19pHR8fH7PcTIuIiIiIiIioPtR4Hm0iIiIiIiIiKo+JNhEREREREZGMmGgTERERERERyYiJNhEREREREZGMmGgTERERERERyYiJNhEREREREZGMmGgTERERERERyYiJNhEREREREZGMmGgTERERERERyYiJNhEREREREZGMmGgTERERERERyYiJNhEREREREZGMmGgTERERERERyYiJNhEREREREZGMmGgTERERERERyYiJNhEREREREZGMmGgTERERERERyYiJNhEREREREZGMmGgTERERERERyYiJNhEREREREZGMmGgTERERERERyYiJNhEREREREZGMmGgTERERERERyYiJNhEREREREZGMmGgTERERERERyYiJNhEREREREZGMmGgTERERERERyYiJNhEREREREZGMmGgTERERERERyYiJNhEREREREZGMmGgTERERERERycikRDsuLg49e/ZEs2bN4ObmhpEjRyIrK8uozt27dxEVFYUWLVqgadOmiIiIQG5urlGd7OxshIeHw8nJCW5ubpgzZw5KS0tr3xoiIiIiIiIiMzMp0U5LS0NUVBSOHDmC1NRU6HQ6hIaGoqioSKoza9Ys7Ny5E1u3bkVaWhquX7+OUaNGScvLysoQHh6OkpISHD58GBs2bEBSUhIWLVokX6uIiIiIiIiIzMTWlMrJyclGj5OSkuDm5oaMjAz069cPBQUF+Pjjj7F582YMHDgQAJCYmIhOnTrhyJEj6N27N1JSUnD27Fns3bsX7u7uCAgIwLJlyzB37lzExsbC3t5evtYRERERERER1TOTEu37FRQUAABcXV0BABkZGdDpdAgJCZHqdOzYEW3atEF6ejp69+6N9PR0dO3aFe7u7lKdsLAwTJ8+HWfOnEGPHj3KbUer1UKr1UqPCwsLAQA6nQ46na5cfUNZRcsslcpGlC9TCqN/60t99qs1vpYVqU47rb0PiIiIiIisRY0Tbb1ej5kzZ6JPnz7o0qULACAnJwf29vZwcXExquvu7o6cnBypzl+TbMNyw7KKxMXFYcmSJeXKU1JS4OTkVGmMqamp1W5PQ7eqV+XLlgXp6y8QALt3767X7QHW9VpWpap2FhcX12MkRERERERUUzVOtKOionD69Gl89913csZTofnz5yMmJkZ6XFhYCG9vb4SGhkKtVperr9PpkJqaisGDB8POzq7O46sPXWL3lCtTKQWWBemx8IQSWr2i3mI5HRtWb9uyxteyItVpp+FKDiIiIiIiathqlGhHR0dj165dOHToEFq3bi2Ve3h4oKSkBPn5+UZntXNzc+Hh4SHVOXbsmNH6DHclN9S5n0qlgkqlKlduZ2dXZfL1oOWWRFtWeSKt1SuqXC43c/SpNb2WVamqnY2h/URERERE1sCku44LIRAdHY1t27Zh//798PPzM1oeGBgIOzs77Nu3TyrLyspCdnY2NBoNAECj0eDUqVPIy8uT6qSmpkKtVsPf3782bSEiIiIiIiIyO5POaEdFRWHz5s3YsWMHmjVrJv2m2tnZGY6OjnB2dsaUKVMQExMDV1dXqNVqzJgxAxqNBr179wYAhIaGwt/fH+PHj8eqVauQk5ODBQsWICoqqsKz1kRERERERESWxKREOyEhAQAwYMAAo/LExERMnDgRALB69WoolUpERERAq9UiLCwM7733nlTXxsYGu3btwvTp06HRaNCkSRNERkZi6dKltWsJERERERERUQNgUqItxIOnkXJwcEB8fDzi4+MrrePj42OWO1cTERERERER1TWTfqNNRERERERERFVjok1EREREREQkIybaRERERERERDJiok1EREREREQkIybaRERERERERDJiok1EREREREQkIybaRERERERERDJiok1EREREREQkIybaRERERERERDJiok1EREREREQkIybaRERERERERDJiok1EREREREQkIybaRERERERERDJiok1EREREREQkIybaRERERERERDJiok1EREREREQkIybaRERERERERDJiok1EREREREQkIybaRERERERERDJiok1EREREREQkIybaRERERERERDJiok1EREREREQkIybaRERERERERDJiok1EREREREQkIybaRERERERERDJiok1EREREREQkIybaRERERERERDJiok1EREREREQkI1tzB0CWx3feN7Vex+UV4TJEQkRERERE1PDwjDYRERERERGRjExOtA8dOoThw4fDy8sLCoUC27dvN1ouhMCiRYvg6ekJR0dHhISE4Pz580Z1bt68iXHjxkGtVsPFxQVTpkzB7du3a9UQIiIiIiIioobA5ES7qKgI3bt3R3x8fIXLV61ahbVr12L9+vU4evQomjRpgrCwMNy9e1eqM27cOJw5cwapqanYtWsXDh06hGnTptW8FUREREREREQNhMm/0R4yZAiGDBlS4TIhBNasWYMFCxZgxIgRAIBPP/0U7u7u2L59O8aOHYtz584hOTkZx48fR1BQEABg3bp1GDp0KN566y14eXnVojlERERERERE5iXrzdAuXbqEnJwchISESGXOzs4IDg5Geno6xo4di/T0dLi4uEhJNgCEhIRAqVTi6NGjeOqpp8qtV6vVQqvVSo8LCwsBADqdDjqdrlx9Q1lFyyyVykaUL1MKo38tSXVfG2t8LStSnXZaex8QEREREVkLWRPtnJwcAIC7u7tRubu7u7QsJycHbm5uxkHY2sLV1VWqc7+4uDgsWbKkXHlKSgqcnJwqjSc1NdWk+BuyVb0qX7YsSF9/gchk9+7dJtW3pteyKlW1s7i4uB4jISIiIiKimrKI6b3mz5+PmJgY6XFhYSG8vb0RGhoKtVpdrr5Op0NqaioGDx4MOzu7+gy1znSJ3VOuTKUUWBakx8ITSmj1CjNEVXOnY8OqVc8aX8uKVKedhis5iIiIiIioYZM10fbw8AAA5ObmwtPTUyrPzc1FQECAVCcvL8/oeaWlpbh586b0/PupVCqoVKpy5XZ2dlUmXw9abkm0ZZUn0lq9osrlDZGpr4s1vZZVqaqdjaH9RERERETWQNZ5tP38/ODh4YF9+/ZJZYWFhTh69Cg0Gg0AQKPRID8/HxkZGVKd/fv3Q6/XIzg4WM5wiIiIiIiIiOqdyWe0b9++jQsXLkiPL126hMzMTLi6uqJNmzaYOXMmXn/9dbRv3x5+fn5YuHAhvLy8MHLkSABAp06d8MQTT2Dq1KlYv349dDodoqOjMXbsWN5xnIiIiIiIiCyeyYn2iRMn8Pjjj0uPDb+djoyMRFJSEl599VUUFRVh2rRpyM/PR9++fZGcnAwHBwfpOZs2bUJ0dDQGDRoEpVKJiIgIrF27VobmEBEREREREZmXyYn2gAEDIETl00kpFAosXboUS5curbSOq6srNm/ebOqmiYiIiIiIiBo8WX+jTURERERERNTYWcT0XpbOd9435g6BiIiIiIiI6gnPaBMRERERERHJiIk2ERERERERkYyYaBMRERERERHJiIk2ERERERERkYyYaBMRERERERHJiIk2ERERERERkYyYaBMRERERERHJiIk2ERERERERkYyYaBMRERERERHJiIk2ERERERERkYyYaBMRERERERHJiIk2ERERERERkYyYaBMRERERERHJiIk2ERERERERkYyYaBMRERERERHJiIk2ERERERERkYyYaBMRERERERHJiIk2ERERERERkYxszR1AXeoSuwfaMkWt1nF5RbhM0RAREREREVFjwDPaRERERERERDJiok1EREREREQkI6u+dFwOvvO+MXcIVqm6/aqyEVjVq/KfAfDSfiIiIiIiamh4RpuIiIiIiIhIRky0iYiIiIiIiGTERJuIiIiIiIhIRky0iYiIiIiIiGTERJuIiIiIiIhIRrzrOFk0Oe4KzzuXExERERGRnMx6Rjs+Ph6+vr5wcHBAcHAwjh07Zs5wiIiIiIiIiGrNbIn2Z599hpiYGCxevBg//PADunfvjrCwMOTl5ZkrJCIiIiIiIqJaM9ul4++88w6mTp2KSZMmAQDWr1+Pb775Bp988gnmzZtnrrCoEeLl50REREREJCezJNolJSXIyMjA/PnzpTKlUomQkBCkp6eXq6/VaqHVav9fe/cfE3X9xwH8ecDdB8idR57cgROCVFiEqDhut2Vb88aPMafWFhFr1Cz74T+FWnP7BvqXpq21Gln9E/WPBn9oq5Rmp8hUoiLMX8Skrij1UEG6UyCOu9f3D8cnPztSgo9cHM/Hdhufz/t178/r+eGvFwcf1OM///wTANDX14dAIBBWHwgEMDAwgLhADIIhw11I8N8QFxIMDISiOud0ybhgU/2k3q/ECP63NITe3l4YjcYxa/x+PwBARCZ1LSIiIiIiursiMmhfvXoVwWAQNptNc95ms+Gnn34Kq9++fTu2bdsWdj4jI+Ou9ThdPBnpBqbATMgIjD+n3+/H7Nmz72ovREREREQ0cdPiqeNbtmxBVVWVehwKhdDX14c5c+bAYAj/lNPn82H+/Pn4/fffYTabp7LVKTUTcs6EjMD4cooI/H4/UlNTp7g7IiIiIiL6NyIyaFutVsTGxqKnp0dzvqenB3a7PaxeURQoiqI5Z7FY7ngds9kc1cPZqJmQcyZkBO6ck59kExERERH990XkqeMmkwn5+flwu93quVAoBLfbDafTGYmWiIiIiIiIiHQRsV8dr6qqQmVlJZYvX46CggK8/fbbuHHjhvoUciIiIiIiIqLpKGKDdllZGa5cuYLq6mp4vV4sWbIEjY2NYQ9ImwhFUVBTUxP26+bRZibknAkZgZmTk4iIiIhoJjAI/1cQERERERERkW4i8jfaRERERERERNGKgzYRERERERGRjjhoExEREREREemIgzYRERERERGRjqJy0K6trcV9992H+Ph4OBwOfPvtt5FuCQCwdetWGAwGzSs7O1tdHxoawoYNGzBnzhzMmjULjz32GHp6ejR7dHd3o7S0FImJiUhOTsbmzZsxMjKiqWlqasKyZcugKAoWLFiAurq6sF70ukfNzc1YtWoVUlNTYTAYsH//fs26iKC6uhopKSlISEiAy+XC+fPnNTV9fX2oqKiA2WyGxWLBunXrcP36dU3NqVOnsGLFCsTHx2P+/PnYuXNnWC8NDQ3Izs5GfHw8cnNzceDAgX/dy0RzPv3002Hf2+Li4mmXk4iIiIiIJi/qBu1PP/0UVVVVqKmpwQ8//IC8vDwUFRXh8uXLkW4NAJCTk4NLly6pr2PHjqlrr7zyCj7//HM0NDTg6NGjuHjxIh599FF1PRgMorS0FMPDwzhx4gQ+/vhj1NXVobq6Wq3xeDwoLS3FI488gpMnT+Lll1/Gs88+i6+++kqt0fMe3bhxA3l5eaitrR1zfefOnXjnnXfw/vvvo7W1Fffccw+KioowNDSk1lRUVODs2bM4dOgQvvjiCzQ3N2P9+vXqus/nQ2FhIdLT09HW1oZdu3Zh69at+PDDD9WaEydOoLy8HOvWrUN7ezvWrFmDNWvW4MyZM/+ql4nmBIDi4mLN93bPnj2a9emQk4iIiIiIdCBRpqCgQDZs2KAeB4NBSU1Nle3bt0ewq5tqamokLy9vzLX+/n4xGo3S0NCgnuvo6BAA0tLSIiIiBw4ckJiYGPF6vWrN7t27xWw2y19//SUiIq+++qrk5ORo9i4rK5OioiL1+G7dIwCyb98+9TgUCondbpddu3ZpciqKInv27BERkXPnzgkA+e6779SagwcPisFgkAsXLoiIyHvvvSdJSUlqRhGR1157TbKystTjxx9/XEpLSzX9OBwOef7558fdy0RziohUVlbK6tWr//E90zEnERERERFNTFR9oj08PIy2tja4XC71XExMDFwuF1paWiLY2d/Onz+P1NRUZGZmoqKiAt3d3QCAtrY2BAIBTe/Z2dlIS0tTe29paUFubi5sNptaU1RUBJ/Ph7Nnz6o1t+4xWjO6x1TeI4/HA6/Xq7nW7Nmz4XA4NJksFguWL1+u1rhcLsTExKC1tVWtefjhh2EymTSZOjs7ce3atXHlHk8vk9XU1ITk5GRkZWXhxRdfRG9vr7oWTTmJiIiIiOj2omrQvnr1KoLBoGYQBQCbzQav1xuhrv7mcDhQV1eHxsZG7N69Gx6PBytWrIDf74fX64XJZILFYtG859bevV7vmNlG125X4/P5MDg4OKX3aHS/213L6/UiOTlZsx4XF4d7771Xl9y3rt+pl8koLi7GJ598ArfbjTfeeANHjx5FSUkJgsFgVOUkIiIiIqI7i4t0AzNJSUmJ+vXixYvhcDiQnp6O+vp6JCQkRLAzmqwnnnhC/To3NxeLFy/G/fffj6amJqxcuTKCnRERERER0VSLqk+0rVYrYmNjw57U3dPTA7vdHqGu/pnFYsGiRYvQ1dUFu92O4eFh9Pf3a2pu7d1ut4+ZbXTtdjVmsxkJCQlTeo9G97vdtex2e9hD2EZGRtDX16dL7lvX79SLnjIzM2G1WtHV1aVePxpzEhERERFRuKgatE0mE/Lz8+F2u9VzoVAIbrcbTqczgp2N7fr16/j555+RkpKC/Px8GI1GTe+dnZ3o7u5We3c6nTh9+rRmYDt06BDMZjMeeOABtebWPUZrRveYynuUkZEBu92uuZbP50Nra6smU39/P9ra2tSaw4cPIxQKweFwqDXNzc0IBAKaTFlZWUhKShpX7vH0oqc//vgDvb29SElJieqcREREREQ0hkg/jU1ve/fuFUVRpK6uTs6dOyfr168Xi8WieVJ3pGzcuFGamprE4/HI8ePHxeVyidVqlcuXL4uIyAsvvCBpaWly+PBh+f7778XpdIrT6VTfPzIyIg8++KAUFhbKyZMnpbGxUebOnStbtmxRa3755RdJTEyUzZs3S0dHh9TW1kpsbKw0NjaqNXreI7/fL+3t7dLe3i4A5K233pL29nb57bffRERkx44dYrFY5LPPPpNTp07J6tWrJSMjQwYHB9U9iouLZenSpdLa2irHjh2ThQsXSnl5ubre398vNptNnnrqKTlz5ozs3btXEhMT5YMPPlBrjh8/LnFxcfLmm29KR0eH1NTUiNFolNOnT6s14+llIjn9fr9s2rRJWlpaxOPxyNdffy3Lli2ThQsXytDQ0LTKSUREREREkxd1g7aIyLvvvitpaWliMpmkoKBAvvnmm0i3JCI3/81WSkqKmEwmmTdvnpSVlUlXV5e6Pjg4KC+99JIkJSVJYmKirF27Vi5duqTZ49dff5WSkhJJSEgQq9UqGzdulEAgoKk5cuSILFmyREwmk2RmZspHH30U1ote9+jIkSMCIOxVWVkpIjf/3dTrr78uNptNFEWRlStXSmdnp2aP3t5eKS8vl1mzZonZbJZnnnlG/H6/pubHH3+Uhx56SBRFkXnz5smOHTvCeqmvr5dFixaJyWSSnJwc+fLLLzXr4+llIjkHBgaksLBQ5s6dK0ajUdLT0+W5554L+8HFdMhJRERERESTZxARicxn6URERERERETRJ6r+RpuIiIiIiIgo0jhoExEREREREemIgzYRERERERGRjjhoExEREREREemIgzYRERERERGRjjhoExEREREREemIgzYRERERERGRjjhoExEREREREemIgzYRERERERGRjjhoExEREREREemIgzYRERERERGRjjhoExEREREREeno/5B+ZA4pOa7EAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x1000 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 981 entries, 0 to 980\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   id                  981 non-null    int64  \n",
      " 1   lat                 981 non-null    float64\n",
      " 2   lon                 981 non-null    float64\n",
      " 3   price_mod           981 non-null    float64\n",
      " 4   since_value         981 non-null    int64  \n",
      " 5   days_on_site        981 non-null    float64\n",
      " 6   age_in_years        981 non-null    float64\n",
      " 7   bathrooms           981 non-null    float64\n",
      " 8   parking_lots        981 non-null    int64  \n",
      " 9   num_bedrooms        981 non-null    float64\n",
      " 10  m2                  981 non-null    float64\n",
      " 11  final_price         981 non-null    float64\n",
      " 12  price_square_meter  981 non-null    float64\n",
      "dtypes: float64(10), int64(3)\n",
      "memory usage: 99.8 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "combined = raw_data[num_cols]\n",
    "combined.hist(figsize = (12,10))\n",
    "plt.show()\n",
    "print(combined.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante un análisis de la correlación entre los datos numéricos podemos notar que el precio por metro cuadrado depende principalmente de la ubicación y cantidad de baños, aunque también es posible apreciar que el precio final tiene una correlación grande con la cantidad de habitaciones y lugares de estacionamiento disponibles. Por la correlación existente entre el precio total y el precio por metro cuadrado, podemos suponer que todas las features mencionadas son parte importante en la predicción del costo por metro cuadrado en los inmuebles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = raw_data[num_cols]\n",
    "\n",
    "C_mat = train_data.corr()\n",
    "fig = plt.figure(figsize = (15,15))\n",
    "\n",
    "sb.heatmap(C_mat, vmax = .8, square = True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se generó la división del data set en training set y test set, con 600 observaciones de entrenamiento y el resto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_combined():\n",
    "    global train_data\n",
    "    train = train_data[:700]\n",
    "    test = train_data[700:]\n",
    "\n",
    "    return train , test \n",
    "  \n",
    "train, test = split_combined()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como consecuencia del análisis de los datos, dividimos nuestros dataframes de prueba y entrenamiento entre datos de entrada y salida.\n",
    "Así mismo se optó por eliminar el la antiguedad del inmuble pues podría causar problemas en la convergencia del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 700 entries, 0 to 699\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   lat           700 non-null    float64\n",
      " 1   lon           700 non-null    float64\n",
      " 2   bathrooms     700 non-null    float64\n",
      " 3   parking_lots  700 non-null    int64  \n",
      " 4   num_bedrooms  700 non-null    float64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 27.5 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "train_x = train.drop(['final_price','price_square_meter','price_mod','id','age_in_years','m2','since_value','days_on_site'], axis=1)\n",
    "train_y = train['price_square_meter']\n",
    "test_x = test.drop(['final_price','price_square_meter','price_mod','id','age_in_years','m2','since_value','days_on_site'], axis=1)\n",
    "test_y = test['price_square_meter']\n",
    "print(train_x.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposición y entrenamiento del modelo\n",
    "Por la naturaleza del problema así como la cantidad \"baja\" de features en el dataset, se decidió entrenar tres modelos diferentes y llevar al primer ciclo de producción el más certero de ellos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Red Neuronal \n",
    "Para este modelo se decidió utilizar 3 capas escondidas cada una cond 256 neuronas, la función de activación de estas es una función ReLU y la función de activación de la capa de salida es una regresión lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               768       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 165,633\n",
      "Trainable params: 165,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_model = Sequential()\n",
    "\n",
    "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = train_x.shape[1], activation='relu'))\n",
    "\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se agregó un check_point para guardar la iteración con los valores más precisos dentro de 500 epochs de entrenamiento secuencial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'Weights-{epoch:05d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 62631.4297 - mean_absolute_error: 62631.4297 \n",
      "Epoch 1: val_loss improved from inf to 64780.65625, saving model to Weights-00001--64780.65625.hdf5\n",
      "18/18 [==============================] - 1s 18ms/step - loss: 62631.4297 - mean_absolute_error: 62631.4297 - val_loss: 64780.6562 - val_mean_absolute_error: 64780.6562\n",
      "Epoch 2/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 61346.6953 - mean_absolute_error: 61346.6953\n",
      "Epoch 2: val_loss improved from 64780.65625 to 62204.58594, saving model to Weights-00002--62204.58594.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 61811.4141 - mean_absolute_error: 61811.4141 - val_loss: 62204.5859 - val_mean_absolute_error: 62204.5859\n",
      "Epoch 3/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 55332.9648 - mean_absolute_error: 55332.9648\n",
      "Epoch 3: val_loss improved from 62204.58594 to 41718.34766, saving model to Weights-00003--41718.34766.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 53733.7266 - mean_absolute_error: 53733.7266 - val_loss: 41718.3477 - val_mean_absolute_error: 41718.3477\n",
      "Epoch 4/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 21361.4453 - mean_absolute_error: 21361.4453\n",
      "Epoch 4: val_loss improved from 41718.34766 to 15523.58887, saving model to Weights-00004--15523.58887.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 20674.8906 - mean_absolute_error: 20674.8906 - val_loss: 15523.5889 - val_mean_absolute_error: 15523.5889\n",
      "Epoch 5/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 11439.5195 - mean_absolute_error: 11439.5195\n",
      "Epoch 5: val_loss improved from 15523.58887 to 13887.86133, saving model to Weights-00005--13887.86133.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11286.9854 - mean_absolute_error: 11286.9854 - val_loss: 13887.8613 - val_mean_absolute_error: 13887.8613\n",
      "Epoch 6/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 10772.7822 - mean_absolute_error: 10772.7822\n",
      "Epoch 6: val_loss did not improve from 13887.86133\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 10612.7344 - mean_absolute_error: 10612.7344 - val_loss: 13932.5645 - val_mean_absolute_error: 13932.5645\n",
      "Epoch 7/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 10095.3438 - mean_absolute_error: 10095.3438\n",
      "Epoch 7: val_loss improved from 13887.86133 to 13829.41797, saving model to Weights-00007--13829.41797.hdf5\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 10229.5146 - mean_absolute_error: 10229.5146 - val_loss: 13829.4180 - val_mean_absolute_error: 13829.4180\n",
      "Epoch 8/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 10316.4443 - mean_absolute_error: 10316.4443\n",
      "Epoch 8: val_loss did not improve from 13829.41797\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 10199.9424 - mean_absolute_error: 10199.9424 - val_loss: 13980.7549 - val_mean_absolute_error: 13980.7549\n",
      "Epoch 9/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 10440.5449 - mean_absolute_error: 10440.5449\n",
      "Epoch 9: val_loss did not improve from 13829.41797\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 10235.7197 - mean_absolute_error: 10235.7197 - val_loss: 13850.8428 - val_mean_absolute_error: 13850.8428\n",
      "Epoch 10/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 10275.2246 - mean_absolute_error: 10275.2246\n",
      "Epoch 10: val_loss improved from 13829.41797 to 13729.73730, saving model to Weights-00010--13729.73730.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 10194.4697 - mean_absolute_error: 10194.4697 - val_loss: 13729.7373 - val_mean_absolute_error: 13729.7373\n",
      "Epoch 11/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 10747.4980 - mean_absolute_error: 10747.4980\n",
      "Epoch 11: val_loss did not improve from 13729.73730\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 10261.2900 - mean_absolute_error: 10261.2900 - val_loss: 13891.8760 - val_mean_absolute_error: 13891.8760\n",
      "Epoch 12/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 10218.4375 - mean_absolute_error: 10218.4375\n",
      "Epoch 12: val_loss did not improve from 13729.73730\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 10213.4590 - mean_absolute_error: 10213.4590 - val_loss: 13806.9600 - val_mean_absolute_error: 13806.9600\n",
      "Epoch 13/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9942.6904 - mean_absolute_error: 9942.6904\n",
      "Epoch 13: val_loss improved from 13729.73730 to 13695.53906, saving model to Weights-00013--13695.53906.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 10195.8242 - mean_absolute_error: 10195.8242 - val_loss: 13695.5391 - val_mean_absolute_error: 13695.5391\n",
      "Epoch 14/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 10083.7852 - mean_absolute_error: 10083.7852\n",
      "Epoch 14: val_loss did not improve from 13695.53906\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 10146.6162 - mean_absolute_error: 10146.6162 - val_loss: 13697.0645 - val_mean_absolute_error: 13697.0645\n",
      "Epoch 15/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 10316.3525 - mean_absolute_error: 10316.3525\n",
      "Epoch 15: val_loss did not improve from 13695.53906\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 10133.0127 - mean_absolute_error: 10133.0127 - val_loss: 14230.8555 - val_mean_absolute_error: 14230.8555\n",
      "Epoch 16/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 10474.0840 - mean_absolute_error: 10474.0840\n",
      "Epoch 16: val_loss did not improve from 13695.53906\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 10260.4766 - mean_absolute_error: 10260.4766 - val_loss: 13904.2910 - val_mean_absolute_error: 13904.2910\n",
      "Epoch 17/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 10089.1709 - mean_absolute_error: 10089.1709\n",
      "Epoch 17: val_loss improved from 13695.53906 to 13695.24414, saving model to Weights-00017--13695.24414.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 10088.6436 - mean_absolute_error: 10088.6436 - val_loss: 13695.2441 - val_mean_absolute_error: 13695.2441\n",
      "Epoch 18/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 10094.0879 - mean_absolute_error: 10094.0879\n",
      "Epoch 18: val_loss did not improve from 13695.24414\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 10117.1738 - mean_absolute_error: 10117.1738 - val_loss: 13702.8877 - val_mean_absolute_error: 13702.8877\n",
      "Epoch 19/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 10239.5225 - mean_absolute_error: 10239.5225\n",
      "Epoch 19: val_loss did not improve from 13695.24414\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10137.8291 - mean_absolute_error: 10137.8291 - val_loss: 13967.2764 - val_mean_absolute_error: 13967.2764\n",
      "Epoch 20/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 10127.5186 - mean_absolute_error: 10127.5186\n",
      "Epoch 20: val_loss did not improve from 13695.24414\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10144.4854 - mean_absolute_error: 10144.4854 - val_loss: 13750.4053 - val_mean_absolute_error: 13750.4053\n",
      "Epoch 21/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 10291.1797 - mean_absolute_error: 10291.1797\n",
      "Epoch 21: val_loss did not improve from 13695.24414\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10150.4229 - mean_absolute_error: 10150.4229 - val_loss: 13741.0342 - val_mean_absolute_error: 13741.0342\n",
      "Epoch 22/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 10206.0752 - mean_absolute_error: 10206.0752\n",
      "Epoch 22: val_loss did not improve from 13695.24414\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10155.5781 - mean_absolute_error: 10155.5781 - val_loss: 13871.3428 - val_mean_absolute_error: 13871.3438\n",
      "Epoch 23/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 10053.1123 - mean_absolute_error: 10053.1123\n",
      "Epoch 23: val_loss did not improve from 13695.24414\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 10127.7822 - mean_absolute_error: 10127.7822 - val_loss: 13709.3555 - val_mean_absolute_error: 13709.3555\n",
      "Epoch 24/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9882.8613 - mean_absolute_error: 9882.8613  \n",
      "Epoch 24: val_loss did not improve from 13695.24414\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 10095.7139 - mean_absolute_error: 10095.7139 - val_loss: 13710.9951 - val_mean_absolute_error: 13710.9951\n",
      "Epoch 25/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 10193.6816 - mean_absolute_error: 10193.6816\n",
      "Epoch 25: val_loss did not improve from 13695.24414\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 10086.2705 - mean_absolute_error: 10086.2705 - val_loss: 13695.4785 - val_mean_absolute_error: 13695.4785\n",
      "Epoch 26/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 10050.9893 - mean_absolute_error: 10050.9893\n",
      "Epoch 26: val_loss did not improve from 13695.24414\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 10059.4648 - mean_absolute_error: 10059.4648 - val_loss: 13721.4316 - val_mean_absolute_error: 13721.4316\n",
      "Epoch 27/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 10150.7588 - mean_absolute_error: 10150.7588\n",
      "Epoch 27: val_loss did not improve from 13695.24414\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 10035.8711 - mean_absolute_error: 10035.8711 - val_loss: 13722.9238 - val_mean_absolute_error: 13722.9238\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 10103.2236 - mean_absolute_error: 10103.2236\n",
      "Epoch 28: val_loss did not improve from 13695.24414\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10103.2236 - mean_absolute_error: 10103.2236 - val_loss: 13726.6641 - val_mean_absolute_error: 13726.6641\n",
      "Epoch 29/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 10230.6074 - mean_absolute_error: 10230.6074\n",
      "Epoch 29: val_loss did not improve from 13695.24414\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10160.4902 - mean_absolute_error: 10160.4902 - val_loss: 13708.8438 - val_mean_absolute_error: 13708.8438\n",
      "Epoch 30/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 10073.9609 - mean_absolute_error: 10073.9609\n",
      "Epoch 30: val_loss did not improve from 13695.24414\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10184.8799 - mean_absolute_error: 10184.8799 - val_loss: 13794.5439 - val_mean_absolute_error: 13794.5439\n",
      "Epoch 31/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 10379.7930 - mean_absolute_error: 10379.7930\n",
      "Epoch 31: val_loss did not improve from 13695.24414\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10252.5713 - mean_absolute_error: 10252.5713 - val_loss: 13713.7988 - val_mean_absolute_error: 13713.7988\n",
      "Epoch 32/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9883.1172 - mean_absolute_error: 9883.1172\n",
      "Epoch 32: val_loss did not improve from 13695.24414\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9966.4121 - mean_absolute_error: 9966.4121 - val_loss: 13727.1680 - val_mean_absolute_error: 13727.1680\n",
      "Epoch 33/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 10336.1230 - mean_absolute_error: 10336.1230\n",
      "Epoch 33: val_loss improved from 13695.24414 to 13680.79297, saving model to Weights-00033--13680.79297.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 10190.3994 - mean_absolute_error: 10190.3994 - val_loss: 13680.7930 - val_mean_absolute_error: 13680.7930\n",
      "Epoch 34/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9686.2725 - mean_absolute_error: 9686.2725\n",
      "Epoch 34: val_loss did not improve from 13680.79297\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 10043.1787 - mean_absolute_error: 10043.1787 - val_loss: 13682.3506 - val_mean_absolute_error: 13682.3506\n",
      "Epoch 35/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 10087.5928 - mean_absolute_error: 10087.5928\n",
      "Epoch 35: val_loss did not improve from 13680.79297\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 10015.3535 - mean_absolute_error: 10015.3535 - val_loss: 13887.3135 - val_mean_absolute_error: 13887.3135\n",
      "Epoch 36/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 10192.5732 - mean_absolute_error: 10192.5732\n",
      "Epoch 36: val_loss did not improve from 13680.79297\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10121.6660 - mean_absolute_error: 10121.6660 - val_loss: 13742.0381 - val_mean_absolute_error: 13742.0381\n",
      "Epoch 37/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 10179.6289 - mean_absolute_error: 10179.6289\n",
      "Epoch 37: val_loss did not improve from 13680.79297\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 10056.2109 - mean_absolute_error: 10056.2109 - val_loss: 13726.2178 - val_mean_absolute_error: 13726.2178\n",
      "Epoch 38/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9964.5723 - mean_absolute_error: 9964.5723\n",
      "Epoch 38: val_loss did not improve from 13680.79297\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9981.6689 - mean_absolute_error: 9981.6689 - val_loss: 13717.4912 - val_mean_absolute_error: 13717.4912\n",
      "Epoch 39/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 10061.2207 - mean_absolute_error: 10061.2207\n",
      "Epoch 39: val_loss did not improve from 13680.79297\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 10092.5771 - mean_absolute_error: 10092.5771 - val_loss: 13778.7900 - val_mean_absolute_error: 13778.7900\n",
      "Epoch 40/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9994.4248 - mean_absolute_error: 9994.4248\n",
      "Epoch 40: val_loss did not improve from 13680.79297\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10018.6660 - mean_absolute_error: 10018.6660 - val_loss: 14309.3115 - val_mean_absolute_error: 14309.3115\n",
      "Epoch 41/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 10166.7578 - mean_absolute_error: 10166.7578\n",
      "Epoch 41: val_loss did not improve from 13680.79297\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10296.7031 - mean_absolute_error: 10296.7031 - val_loss: 14163.4258 - val_mean_absolute_error: 14163.4258\n",
      "Epoch 42/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 10344.2764 - mean_absolute_error: 10344.2764\n",
      "Epoch 42: val_loss did not improve from 13680.79297\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10443.7979 - mean_absolute_error: 10443.7979 - val_loss: 14162.9619 - val_mean_absolute_error: 14162.9619\n",
      "Epoch 43/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 10264.8955 - mean_absolute_error: 10264.8955\n",
      "Epoch 43: val_loss did not improve from 13680.79297\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10183.9062 - mean_absolute_error: 10183.9062 - val_loss: 14706.6318 - val_mean_absolute_error: 14706.6318\n",
      "Epoch 44/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 10175.7822 - mean_absolute_error: 10175.7822\n",
      "Epoch 44: val_loss did not improve from 13680.79297\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 10231.2305 - mean_absolute_error: 10231.2305 - val_loss: 13758.9082 - val_mean_absolute_error: 13758.9082\n",
      "Epoch 45/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 10192.1240 - mean_absolute_error: 10192.1240\n",
      "Epoch 45: val_loss improved from 13680.79297 to 13679.35059, saving model to Weights-00045--13679.35059.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9969.5469 - mean_absolute_error: 9969.5469 - val_loss: 13679.3506 - val_mean_absolute_error: 13679.3506\n",
      "Epoch 46/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9785.3740 - mean_absolute_error: 9785.3740  \n",
      "Epoch 46: val_loss did not improve from 13679.35059\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9915.8154 - mean_absolute_error: 9915.8154 - val_loss: 13694.9756 - val_mean_absolute_error: 13694.9756\n",
      "Epoch 47/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9949.7949 - mean_absolute_error: 9949.7949  \n",
      "Epoch 47: val_loss did not improve from 13679.35059\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9948.5488 - mean_absolute_error: 9948.5488 - val_loss: 13911.2656 - val_mean_absolute_error: 13911.2656\n",
      "Epoch 48/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 10072.9561 - mean_absolute_error: 10072.9561\n",
      "Epoch 48: val_loss did not improve from 13679.35059\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 10105.7373 - mean_absolute_error: 10105.7373 - val_loss: 13730.7090 - val_mean_absolute_error: 13730.7090\n",
      "Epoch 49/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9973.1924 - mean_absolute_error: 9973.1924\n",
      "Epoch 49: val_loss did not improve from 13679.35059\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 10062.2305 - mean_absolute_error: 10062.2305 - val_loss: 13684.0410 - val_mean_absolute_error: 13684.0410\n",
      "Epoch 50/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 10123.8574 - mean_absolute_error: 10123.8574\n",
      "Epoch 50: val_loss improved from 13679.35059 to 13677.38379, saving model to Weights-00050--13677.38379.hdf5\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9974.9307 - mean_absolute_error: 9974.9307 - val_loss: 13677.3838 - val_mean_absolute_error: 13677.3838\n",
      "Epoch 51/1000\n",
      "10/18 [===============>..............] - ETA: 0s - loss: 10127.8623 - mean_absolute_error: 10127.8623\n",
      "Epoch 51: val_loss did not improve from 13677.38379\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9890.0439 - mean_absolute_error: 9890.0439 - val_loss: 13721.1377 - val_mean_absolute_error: 13721.1377\n",
      "Epoch 52/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 10123.3818 - mean_absolute_error: 10123.3818\n",
      "Epoch 52: val_loss did not improve from 13677.38379\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10087.3672 - mean_absolute_error: 10087.3672 - val_loss: 13695.0303 - val_mean_absolute_error: 13695.0303\n",
      "Epoch 53/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9814.9883 - mean_absolute_error: 9814.9883  \n",
      "Epoch 53: val_loss did not improve from 13677.38379\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 10015.8945 - mean_absolute_error: 10015.8945 - val_loss: 13677.6855 - val_mean_absolute_error: 13677.6855\n",
      "Epoch 54/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 10368.5010 - mean_absolute_error: 10368.5010\n",
      "Epoch 54: val_loss did not improve from 13677.38379\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 10021.3750 - mean_absolute_error: 10021.3750 - val_loss: 13685.7715 - val_mean_absolute_error: 13685.7715\n",
      "Epoch 55/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 10021.4570 - mean_absolute_error: 10021.4570\n",
      "Epoch 55: val_loss did not improve from 13677.38379\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 10059.3760 - mean_absolute_error: 10059.3760 - val_loss: 13684.6768 - val_mean_absolute_error: 13684.6768\n",
      "Epoch 56/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9902.2334 - mean_absolute_error: 9902.2334\n",
      "Epoch 56: val_loss did not improve from 13677.38379\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9922.5664 - mean_absolute_error: 9922.5664 - val_loss: 13683.0469 - val_mean_absolute_error: 13683.0469\n",
      "Epoch 57/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9803.4736 - mean_absolute_error: 9803.4736  \n",
      "Epoch 57: val_loss improved from 13677.38379 to 13677.18848, saving model to Weights-00057--13677.18848.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9929.1357 - mean_absolute_error: 9929.1357 - val_loss: 13677.1885 - val_mean_absolute_error: 13677.1885\n",
      "Epoch 58/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 10221.5625 - mean_absolute_error: 10221.5625\n",
      "Epoch 58: val_loss did not improve from 13677.18848\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9971.6172 - mean_absolute_error: 9971.6172 - val_loss: 13680.0234 - val_mean_absolute_error: 13680.0234\n",
      "Epoch 59/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9911.1592 - mean_absolute_error: 9911.1592\n",
      "Epoch 59: val_loss did not improve from 13677.18848\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9899.3018 - mean_absolute_error: 9899.3018 - val_loss: 13679.7930 - val_mean_absolute_error: 13679.7930\n",
      "Epoch 60/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9915.3096 - mean_absolute_error: 9915.3096  \n",
      "Epoch 60: val_loss improved from 13677.18848 to 13674.84473, saving model to Weights-00060--13674.84473.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9991.7266 - mean_absolute_error: 9991.7266 - val_loss: 13674.8447 - val_mean_absolute_error: 13674.8447\n",
      "Epoch 61/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9860.2715 - mean_absolute_error: 9860.2715\n",
      "Epoch 61: val_loss did not improve from 13674.84473\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9853.7549 - mean_absolute_error: 9853.7549 - val_loss: 13758.7578 - val_mean_absolute_error: 13758.7578\n",
      "Epoch 62/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 10058.5625 - mean_absolute_error: 10058.5625\n",
      "Epoch 62: val_loss did not improve from 13674.84473\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9962.1758 - mean_absolute_error: 9962.1758 - val_loss: 13713.4160 - val_mean_absolute_error: 13713.4160\n",
      "Epoch 63/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9850.6816 - mean_absolute_error: 9850.6816  \n",
      "Epoch 63: val_loss did not improve from 13674.84473\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9859.8682 - mean_absolute_error: 9859.8682 - val_loss: 13920.1426 - val_mean_absolute_error: 13920.1426\n",
      "Epoch 64/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9724.0723 - mean_absolute_error: 9724.0723\n",
      "Epoch 64: val_loss improved from 13674.84473 to 13673.68359, saving model to Weights-00064--13673.68359.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9850.1240 - mean_absolute_error: 9850.1240 - val_loss: 13673.6836 - val_mean_absolute_error: 13673.6836\n",
      "Epoch 65/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9840.6367 - mean_absolute_error: 9840.6367\n",
      "Epoch 65: val_loss improved from 13673.68359 to 13672.97559, saving model to Weights-00065--13672.97559.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9928.4824 - mean_absolute_error: 9928.4824 - val_loss: 13672.9756 - val_mean_absolute_error: 13672.9756\n",
      "Epoch 66/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 10016.1875 - mean_absolute_error: 10016.1875\n",
      "Epoch 66: val_loss did not improve from 13672.97559\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9954.0625 - mean_absolute_error: 9954.0625 - val_loss: 13704.1982 - val_mean_absolute_error: 13704.1982\n",
      "Epoch 67/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 10207.0654 - mean_absolute_error: 10207.0654\n",
      "Epoch 67: val_loss did not improve from 13672.97559\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9895.4502 - mean_absolute_error: 9895.4502 - val_loss: 13712.6025 - val_mean_absolute_error: 13712.6025\n",
      "Epoch 68/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 10126.1475 - mean_absolute_error: 10126.1475\n",
      "Epoch 68: val_loss did not improve from 13672.97559\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9937.0176 - mean_absolute_error: 9937.0176 - val_loss: 13673.2490 - val_mean_absolute_error: 13673.2490\n",
      "Epoch 69/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9587.9678 - mean_absolute_error: 9587.9678  \n",
      "Epoch 69: val_loss did not improve from 13672.97559\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9814.5742 - mean_absolute_error: 9814.5742 - val_loss: 13675.3711 - val_mean_absolute_error: 13675.3711\n",
      "Epoch 70/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9979.9512 - mean_absolute_error: 9979.9512  \n",
      "Epoch 70: val_loss improved from 13672.97559 to 13671.83789, saving model to Weights-00070--13671.83789.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9848.2725 - mean_absolute_error: 9848.2725 - val_loss: 13671.8379 - val_mean_absolute_error: 13671.8379\n",
      "Epoch 71/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9651.0723 - mean_absolute_error: 9651.0723  \n",
      "Epoch 71: val_loss did not improve from 13671.83789\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9824.9629 - mean_absolute_error: 9824.9629 - val_loss: 13747.6377 - val_mean_absolute_error: 13747.6377\n",
      "Epoch 72/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 10189.4688 - mean_absolute_error: 10189.4688\n",
      "Epoch 72: val_loss did not improve from 13671.83789\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10127.1318 - mean_absolute_error: 10127.1318 - val_loss: 13946.9873 - val_mean_absolute_error: 13946.9873\n",
      "Epoch 73/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9977.0957 - mean_absolute_error: 9977.0957\n",
      "Epoch 73: val_loss did not improve from 13671.83789\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9936.5283 - mean_absolute_error: 9936.5283 - val_loss: 13888.8125 - val_mean_absolute_error: 13888.8125\n",
      "Epoch 74/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9740.5322 - mean_absolute_error: 9740.5322\n",
      "Epoch 74: val_loss did not improve from 13671.83789\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9848.6064 - mean_absolute_error: 9848.6064 - val_loss: 13824.7617 - val_mean_absolute_error: 13824.7617\n",
      "Epoch 75/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9793.4785 - mean_absolute_error: 9793.4785  \n",
      "Epoch 75: val_loss did not improve from 13671.83789\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9830.0381 - mean_absolute_error: 9830.0381 - val_loss: 13848.5469 - val_mean_absolute_error: 13848.5469\n",
      "Epoch 76/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9953.3516 - mean_absolute_error: 9953.3516  \n",
      "Epoch 76: val_loss did not improve from 13671.83789\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9833.4863 - mean_absolute_error: 9833.4863 - val_loss: 13673.3809 - val_mean_absolute_error: 13673.3809\n",
      "Epoch 77/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9824.9268 - mean_absolute_error: 9824.9268  \n",
      "Epoch 77: val_loss did not improve from 13671.83789\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9810.0020 - mean_absolute_error: 9810.0020 - val_loss: 13678.7910 - val_mean_absolute_error: 13678.7910\n",
      "Epoch 78/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9982.4863 - mean_absolute_error: 9982.4863\n",
      "Epoch 78: val_loss did not improve from 13671.83789\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9784.5713 - mean_absolute_error: 9784.5713 - val_loss: 13764.5586 - val_mean_absolute_error: 13764.5586\n",
      "Epoch 79/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9990.0820 - mean_absolute_error: 9990.0820\n",
      "Epoch 79: val_loss did not improve from 13671.83789\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9998.4893 - mean_absolute_error: 9998.4893 - val_loss: 14248.9268 - val_mean_absolute_error: 14248.9268\n",
      "Epoch 80/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9964.6621 - mean_absolute_error: 9964.6621  \n",
      "Epoch 80: val_loss did not improve from 13671.83789\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9918.8145 - mean_absolute_error: 9918.8145 - val_loss: 14185.8838 - val_mean_absolute_error: 14185.8838\n",
      "Epoch 81/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 10147.7773 - mean_absolute_error: 10147.7773\n",
      "Epoch 81: val_loss did not improve from 13671.83789\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9999.4404 - mean_absolute_error: 9999.4404 - val_loss: 13930.2324 - val_mean_absolute_error: 13930.2334\n",
      "Epoch 82/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9777.1729 - mean_absolute_error: 9777.1729  \n",
      "Epoch 82: val_loss did not improve from 13671.83789\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9831.3125 - mean_absolute_error: 9831.3125 - val_loss: 13710.5947 - val_mean_absolute_error: 13710.5947\n",
      "Epoch 83/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9853.8760 - mean_absolute_error: 9853.8760\n",
      "Epoch 83: val_loss did not improve from 13671.83789\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9816.3008 - mean_absolute_error: 9816.3008 - val_loss: 13766.1611 - val_mean_absolute_error: 13766.1611\n",
      "Epoch 84/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 10004.8047 - mean_absolute_error: 10004.8047\n",
      "Epoch 84: val_loss improved from 13671.83789 to 13665.19434, saving model to Weights-00084--13665.19434.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9760.1816 - mean_absolute_error: 9760.1816 - val_loss: 13665.1943 - val_mean_absolute_error: 13665.1943\n",
      "Epoch 85/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 10114.7324 - mean_absolute_error: 10114.7324\n",
      "Epoch 85: val_loss did not improve from 13665.19434\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9844.7275 - mean_absolute_error: 9844.7275 - val_loss: 13722.1465 - val_mean_absolute_error: 13722.1465\n",
      "Epoch 86/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 10074.1006 - mean_absolute_error: 10074.1006\n",
      "Epoch 86: val_loss did not improve from 13665.19434\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9870.1787 - mean_absolute_error: 9870.1787 - val_loss: 13681.3271 - val_mean_absolute_error: 13681.3271\n",
      "Epoch 87/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 9732.5605 - mean_absolute_error: 9732.5605  \n",
      "Epoch 87: val_loss improved from 13665.19434 to 13663.39160, saving model to Weights-00087--13663.39160.hdf5\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9745.4648 - mean_absolute_error: 9745.4648 - val_loss: 13663.3916 - val_mean_absolute_error: 13663.3916\n",
      "Epoch 88/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9604.4111 - mean_absolute_error: 9604.4111  \n",
      "Epoch 88: val_loss improved from 13663.39160 to 13662.56348, saving model to Weights-00088--13662.56348.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9735.6885 - mean_absolute_error: 9735.6885 - val_loss: 13662.5635 - val_mean_absolute_error: 13662.5635\n",
      "Epoch 89/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9420.5566 - mean_absolute_error: 9420.5566  \n",
      "Epoch 89: val_loss did not improve from 13662.56348\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9719.0234 - mean_absolute_error: 9719.0234 - val_loss: 13702.6611 - val_mean_absolute_error: 13702.6611\n",
      "Epoch 90/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9805.1299 - mean_absolute_error: 9805.1299  \n",
      "Epoch 90: val_loss did not improve from 13662.56348\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9769.4277 - mean_absolute_error: 9769.4277 - val_loss: 13725.8604 - val_mean_absolute_error: 13725.8604\n",
      "Epoch 91/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9578.4316 - mean_absolute_error: 9578.4316  \n",
      "Epoch 91: val_loss did not improve from 13662.56348\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9764.1465 - mean_absolute_error: 9764.1465 - val_loss: 13760.1016 - val_mean_absolute_error: 13760.1016\n",
      "Epoch 92/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 10009.0889 - mean_absolute_error: 10009.0889\n",
      "Epoch 92: val_loss did not improve from 13662.56348\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9787.8955 - mean_absolute_error: 9787.8955 - val_loss: 13764.0938 - val_mean_absolute_error: 13764.0938\n",
      "Epoch 93/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9469.8252 - mean_absolute_error: 9469.8252\n",
      "Epoch 93: val_loss did not improve from 13662.56348\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9759.0342 - mean_absolute_error: 9759.0342 - val_loss: 13705.6533 - val_mean_absolute_error: 13705.6533\n",
      "Epoch 94/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9553.6162 - mean_absolute_error: 9553.6162\n",
      "Epoch 94: val_loss improved from 13662.56348 to 13658.60742, saving model to Weights-00094--13658.60742.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9690.5938 - mean_absolute_error: 9690.5938 - val_loss: 13658.6074 - val_mean_absolute_error: 13658.6074\n",
      "Epoch 95/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9616.1582 - mean_absolute_error: 9616.1582  \n",
      "Epoch 95: val_loss did not improve from 13658.60742\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9694.5361 - mean_absolute_error: 9694.5361 - val_loss: 13696.8643 - val_mean_absolute_error: 13696.8643\n",
      "Epoch 96/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 10133.0967 - mean_absolute_error: 10133.0967\n",
      "Epoch 96: val_loss did not improve from 13658.60742\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9767.9629 - mean_absolute_error: 9767.9629 - val_loss: 13671.3516 - val_mean_absolute_error: 13671.3516\n",
      "Epoch 97/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9289.8301 - mean_absolute_error: 9289.8301\n",
      "Epoch 97: val_loss did not improve from 13658.60742\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9725.1768 - mean_absolute_error: 9725.1768 - val_loss: 13675.7646 - val_mean_absolute_error: 13675.7646\n",
      "Epoch 98/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9508.5615 - mean_absolute_error: 9508.5615\n",
      "Epoch 98: val_loss improved from 13658.60742 to 13655.64062, saving model to Weights-00098--13655.64062.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9730.6797 - mean_absolute_error: 9730.6797 - val_loss: 13655.6406 - val_mean_absolute_error: 13655.6406\n",
      "Epoch 99/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9676.9912 - mean_absolute_error: 9676.9912\n",
      "Epoch 99: val_loss improved from 13655.64062 to 13654.70312, saving model to Weights-00099--13654.70312.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9752.0352 - mean_absolute_error: 9752.0352 - val_loss: 13654.7031 - val_mean_absolute_error: 13654.7031\n",
      "Epoch 100/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9727.4082 - mean_absolute_error: 9727.4082  \n",
      "Epoch 100: val_loss did not improve from 13654.70312\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9886.9229 - mean_absolute_error: 9886.9229 - val_loss: 13671.9385 - val_mean_absolute_error: 13671.9385\n",
      "Epoch 101/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9814.7324 - mean_absolute_error: 9814.7324  \n",
      "Epoch 101: val_loss did not improve from 13654.70312\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9651.8301 - mean_absolute_error: 9651.8301 - val_loss: 13657.5625 - val_mean_absolute_error: 13657.5625\n",
      "Epoch 102/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 10051.9082 - mean_absolute_error: 10051.9082\n",
      "Epoch 102: val_loss improved from 13654.70312 to 13651.77344, saving model to Weights-00102--13651.77344.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9857.6201 - mean_absolute_error: 9857.6201 - val_loss: 13651.7734 - val_mean_absolute_error: 13651.7734\n",
      "Epoch 103/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9561.2900 - mean_absolute_error: 9561.2900  \n",
      "Epoch 103: val_loss did not improve from 13651.77344\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9788.2539 - mean_absolute_error: 9788.2539 - val_loss: 13652.2529 - val_mean_absolute_error: 13652.2529\n",
      "Epoch 104/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 10028.9678 - mean_absolute_error: 10028.9678\n",
      "Epoch 104: val_loss did not improve from 13651.77344\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9868.0752 - mean_absolute_error: 9868.0752 - val_loss: 13653.6230 - val_mean_absolute_error: 13653.6230\n",
      "Epoch 105/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9604.7500 - mean_absolute_error: 9604.7500\n",
      "Epoch 105: val_loss did not improve from 13651.77344\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9700.6309 - mean_absolute_error: 9700.6309 - val_loss: 13656.2354 - val_mean_absolute_error: 13656.2354\n",
      "Epoch 106/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 10095.3389 - mean_absolute_error: 10095.3389\n",
      "Epoch 106: val_loss improved from 13651.77344 to 13648.25391, saving model to Weights-00106--13648.25391.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9911.9336 - mean_absolute_error: 9911.9336 - val_loss: 13648.2539 - val_mean_absolute_error: 13648.2539\n",
      "Epoch 107/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9872.1963 - mean_absolute_error: 9872.1963\n",
      "Epoch 107: val_loss did not improve from 13648.25391\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9674.0840 - mean_absolute_error: 9674.0840 - val_loss: 13678.5088 - val_mean_absolute_error: 13678.5088\n",
      "Epoch 108/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9615.8252 - mean_absolute_error: 9615.8252\n",
      "Epoch 108: val_loss did not improve from 13648.25391\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9702.5957 - mean_absolute_error: 9702.5957 - val_loss: 13652.3789 - val_mean_absolute_error: 13652.3789\n",
      "Epoch 109/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9586.3516 - mean_absolute_error: 9586.3516  \n",
      "Epoch 109: val_loss did not improve from 13648.25391\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9649.9014 - mean_absolute_error: 9649.9014 - val_loss: 13751.2119 - val_mean_absolute_error: 13751.2119\n",
      "Epoch 110/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9701.3838 - mean_absolute_error: 9701.3838\n",
      "Epoch 110: val_loss did not improve from 13648.25391\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9762.1211 - mean_absolute_error: 9762.1211 - val_loss: 13702.6924 - val_mean_absolute_error: 13702.6924\n",
      "Epoch 111/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9818.5830 - mean_absolute_error: 9818.5830\n",
      "Epoch 111: val_loss improved from 13648.25391 to 13642.60645, saving model to Weights-00111--13642.60645.hdf5\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 9772.9375 - mean_absolute_error: 9772.9375 - val_loss: 13642.6064 - val_mean_absolute_error: 13642.6064\n",
      "Epoch 112/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9797.3340 - mean_absolute_error: 9797.3340\n",
      "Epoch 112: val_loss did not improve from 13642.60645\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9707.2773 - mean_absolute_error: 9707.2773 - val_loss: 13659.5400 - val_mean_absolute_error: 13659.5400\n",
      "Epoch 113/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9583.6660 - mean_absolute_error: 9583.6660  \n",
      "Epoch 113: val_loss improved from 13642.60645 to 13640.67285, saving model to Weights-00113--13640.67285.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9730.3662 - mean_absolute_error: 9730.3662 - val_loss: 13640.6729 - val_mean_absolute_error: 13640.6729\n",
      "Epoch 114/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 10227.5625 - mean_absolute_error: 10227.5625\n",
      "Epoch 114: val_loss improved from 13640.67285 to 13639.10938, saving model to Weights-00114--13639.10938.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9659.9707 - mean_absolute_error: 9659.9707 - val_loss: 13639.1094 - val_mean_absolute_error: 13639.1094\n",
      "Epoch 115/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9804.1250 - mean_absolute_error: 9804.1250\n",
      "Epoch 115: val_loss did not improve from 13639.10938\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9687.8818 - mean_absolute_error: 9687.8818 - val_loss: 13977.1504 - val_mean_absolute_error: 13977.1504\n",
      "Epoch 116/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9667.6191 - mean_absolute_error: 9667.6191\n",
      "Epoch 116: val_loss did not improve from 13639.10938\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9739.1045 - mean_absolute_error: 9739.1045 - val_loss: 13652.7158 - val_mean_absolute_error: 13652.7158\n",
      "Epoch 117/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9748.5645 - mean_absolute_error: 9748.5645\n",
      "Epoch 117: val_loss did not improve from 13639.10938\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9651.5850 - mean_absolute_error: 9651.5850 - val_loss: 13648.9648 - val_mean_absolute_error: 13648.9648\n",
      "Epoch 118/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9390.9209 - mean_absolute_error: 9390.9209\n",
      "Epoch 118: val_loss did not improve from 13639.10938\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9636.1074 - mean_absolute_error: 9636.1074 - val_loss: 13649.0303 - val_mean_absolute_error: 13649.0303\n",
      "Epoch 119/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9621.9746 - mean_absolute_error: 9621.9746\n",
      "Epoch 119: val_loss improved from 13639.10938 to 13633.41797, saving model to Weights-00119--13633.41797.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9700.5869 - mean_absolute_error: 9700.5869 - val_loss: 13633.4180 - val_mean_absolute_error: 13633.4180\n",
      "Epoch 120/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9615.9824 - mean_absolute_error: 9615.9824\n",
      "Epoch 120: val_loss did not improve from 13633.41797\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9648.2539 - mean_absolute_error: 9648.2539 - val_loss: 13842.1680 - val_mean_absolute_error: 13842.1680\n",
      "Epoch 121/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9703.2402 - mean_absolute_error: 9703.2402  \n",
      "Epoch 121: val_loss did not improve from 13633.41797\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9569.4883 - mean_absolute_error: 9569.4883 - val_loss: 13699.7471 - val_mean_absolute_error: 13699.7471\n",
      "Epoch 122/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9788.6162 - mean_absolute_error: 9788.6162\n",
      "Epoch 122: val_loss did not improve from 13633.41797\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9717.1064 - mean_absolute_error: 9717.1064 - val_loss: 13677.1025 - val_mean_absolute_error: 13677.1025\n",
      "Epoch 123/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9563.8291 - mean_absolute_error: 9563.8291\n",
      "Epoch 123: val_loss did not improve from 13633.41797\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9755.4219 - mean_absolute_error: 9755.4219 - val_loss: 13672.1182 - val_mean_absolute_error: 13672.1182\n",
      "Epoch 124/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9734.1094 - mean_absolute_error: 9734.1094  \n",
      "Epoch 124: val_loss did not improve from 13633.41797\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9666.5430 - mean_absolute_error: 9666.5430 - val_loss: 13635.7852 - val_mean_absolute_error: 13635.7852\n",
      "Epoch 125/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9828.6846 - mean_absolute_error: 9828.6846\n",
      "Epoch 125: val_loss improved from 13633.41797 to 13626.04688, saving model to Weights-00125--13626.04688.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9690.2090 - mean_absolute_error: 9690.2090 - val_loss: 13626.0469 - val_mean_absolute_error: 13626.0469\n",
      "Epoch 126/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9774.0938 - mean_absolute_error: 9774.0938  \n",
      "Epoch 126: val_loss did not improve from 13626.04688\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9672.0283 - mean_absolute_error: 9672.0283 - val_loss: 13644.1904 - val_mean_absolute_error: 13644.1904\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 9675.7480 - mean_absolute_error: 9675.7480  \n",
      "Epoch 127: val_loss improved from 13626.04688 to 13622.49316, saving model to Weights-00127--13622.49316.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9675.7480 - mean_absolute_error: 9675.7480 - val_loss: 13622.4932 - val_mean_absolute_error: 13622.4932\n",
      "Epoch 128/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9769.0518 - mean_absolute_error: 9769.0518  \n",
      "Epoch 128: val_loss did not improve from 13622.49316\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9663.6406 - mean_absolute_error: 9663.6406 - val_loss: 13626.1270 - val_mean_absolute_error: 13626.1270\n",
      "Epoch 129/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9937.4775 - mean_absolute_error: 9937.4775\n",
      "Epoch 129: val_loss did not improve from 13622.49316\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9622.1455 - mean_absolute_error: 9622.1455 - val_loss: 13637.9551 - val_mean_absolute_error: 13637.9551\n",
      "Epoch 130/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9749.4150 - mean_absolute_error: 9749.4150  \n",
      "Epoch 130: val_loss did not improve from 13622.49316\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9687.0850 - mean_absolute_error: 9687.0850 - val_loss: 13832.4229 - val_mean_absolute_error: 13832.4229\n",
      "Epoch 131/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9487.1406 - mean_absolute_error: 9487.1406\n",
      "Epoch 131: val_loss did not improve from 13622.49316\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9561.6016 - mean_absolute_error: 9561.6016 - val_loss: 13646.9277 - val_mean_absolute_error: 13646.9277\n",
      "Epoch 132/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9472.0762 - mean_absolute_error: 9472.0762\n",
      "Epoch 132: val_loss did not improve from 13622.49316\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9709.7441 - mean_absolute_error: 9709.7441 - val_loss: 13684.6680 - val_mean_absolute_error: 13684.6680\n",
      "Epoch 133/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9609.5791 - mean_absolute_error: 9609.5791\n",
      "Epoch 133: val_loss did not improve from 13622.49316\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9709.8779 - mean_absolute_error: 9709.8779 - val_loss: 13625.4717 - val_mean_absolute_error: 13625.4717\n",
      "Epoch 134/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9595.1533 - mean_absolute_error: 9595.1533  \n",
      "Epoch 134: val_loss did not improve from 13622.49316\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9576.8076 - mean_absolute_error: 9576.8076 - val_loss: 13676.0410 - val_mean_absolute_error: 13676.0410\n",
      "Epoch 135/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9745.9746 - mean_absolute_error: 9745.9746  \n",
      "Epoch 135: val_loss improved from 13622.49316 to 13610.25293, saving model to Weights-00135--13610.25293.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9737.7549 - mean_absolute_error: 9737.7549 - val_loss: 13610.2529 - val_mean_absolute_error: 13610.2529\n",
      "Epoch 136/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 10384.6309 - mean_absolute_error: 10384.6309\n",
      "Epoch 136: val_loss did not improve from 13610.25293\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9877.3359 - mean_absolute_error: 9877.3359 - val_loss: 13686.0361 - val_mean_absolute_error: 13686.0361\n",
      "Epoch 137/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9953.9961 - mean_absolute_error: 9953.9961\n",
      "Epoch 137: val_loss did not improve from 13610.25293\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9843.9326 - mean_absolute_error: 9843.9326 - val_loss: 13613.1143 - val_mean_absolute_error: 13613.1143\n",
      "Epoch 138/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9592.3574 - mean_absolute_error: 9592.3574\n",
      "Epoch 138: val_loss did not improve from 13610.25293\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9618.5762 - mean_absolute_error: 9618.5762 - val_loss: 13630.6436 - val_mean_absolute_error: 13630.6436\n",
      "Epoch 139/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9756.8359 - mean_absolute_error: 9756.8359\n",
      "Epoch 139: val_loss did not improve from 13610.25293\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9630.0488 - mean_absolute_error: 9630.0488 - val_loss: 13740.7139 - val_mean_absolute_error: 13740.7139\n",
      "Epoch 140/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9776.5000 - mean_absolute_error: 9776.5000  \n",
      "Epoch 140: val_loss did not improve from 13610.25293\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9596.3252 - mean_absolute_error: 9596.3252 - val_loss: 13715.4824 - val_mean_absolute_error: 13715.4824\n",
      "Epoch 141/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9337.7920 - mean_absolute_error: 9337.7920\n",
      "Epoch 141: val_loss improved from 13610.25293 to 13606.69238, saving model to Weights-00141--13606.69238.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9607.1797 - mean_absolute_error: 9607.1797 - val_loss: 13606.6924 - val_mean_absolute_error: 13606.6924\n",
      "Epoch 142/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9474.1777 - mean_absolute_error: 9474.1777\n",
      "Epoch 142: val_loss did not improve from 13606.69238\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9563.7480 - mean_absolute_error: 9563.7480 - val_loss: 13673.6162 - val_mean_absolute_error: 13673.6162\n",
      "Epoch 143/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9702.4180 - mean_absolute_error: 9702.4180  \n",
      "Epoch 143: val_loss did not improve from 13606.69238\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9692.1514 - mean_absolute_error: 9692.1514 - val_loss: 13924.2852 - val_mean_absolute_error: 13924.2852\n",
      "Epoch 144/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9473.4111 - mean_absolute_error: 9473.4111\n",
      "Epoch 144: val_loss did not improve from 13606.69238\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9717.5957 - mean_absolute_error: 9717.5957 - val_loss: 13982.1533 - val_mean_absolute_error: 13982.1533\n",
      "Epoch 145/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9240.4756 - mean_absolute_error: 9240.4756\n",
      "Epoch 145: val_loss did not improve from 13606.69238\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9661.7139 - mean_absolute_error: 9661.7139 - val_loss: 13885.8574 - val_mean_absolute_error: 13885.8574\n",
      "Epoch 146/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9792.2129 - mean_absolute_error: 9792.2129  \n",
      "Epoch 146: val_loss did not improve from 13606.69238\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9595.3535 - mean_absolute_error: 9595.3535 - val_loss: 14272.8271 - val_mean_absolute_error: 14272.8271\n",
      "Epoch 147/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9794.0410 - mean_absolute_error: 9794.0410\n",
      "Epoch 147: val_loss did not improve from 13606.69238\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9938.1377 - mean_absolute_error: 9938.1377 - val_loss: 13927.0137 - val_mean_absolute_error: 13927.0137\n",
      "Epoch 148/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9840.2803 - mean_absolute_error: 9840.2803  \n",
      "Epoch 148: val_loss did not improve from 13606.69238\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9672.8594 - mean_absolute_error: 9672.8594 - val_loss: 13644.3750 - val_mean_absolute_error: 13644.3750\n",
      "Epoch 149/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9754.8252 - mean_absolute_error: 9754.8252  \n",
      "Epoch 149: val_loss did not improve from 13606.69238\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9537.7656 - mean_absolute_error: 9537.7656 - val_loss: 13678.7354 - val_mean_absolute_error: 13678.7354\n",
      "Epoch 150/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 8926.2402 - mean_absolute_error: 8926.2402\n",
      "Epoch 150: val_loss did not improve from 13606.69238\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9542.6104 - mean_absolute_error: 9542.6104 - val_loss: 13614.5820 - val_mean_absolute_error: 13614.5820\n",
      "Epoch 151/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9856.5088 - mean_absolute_error: 9856.5088  \n",
      "Epoch 151: val_loss improved from 13606.69238 to 13604.69629, saving model to Weights-00151--13604.69629.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9614.0225 - mean_absolute_error: 9614.0225 - val_loss: 13604.6963 - val_mean_absolute_error: 13604.6963\n",
      "Epoch 152/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9483.9473 - mean_absolute_error: 9483.9473\n",
      "Epoch 152: val_loss did not improve from 13604.69629\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9541.0273 - mean_absolute_error: 9541.0273 - val_loss: 13609.8838 - val_mean_absolute_error: 13609.8838\n",
      "Epoch 153/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9884.8662 - mean_absolute_error: 9884.8662  \n",
      "Epoch 153: val_loss did not improve from 13604.69629\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9654.9746 - mean_absolute_error: 9654.9746 - val_loss: 13632.0156 - val_mean_absolute_error: 13632.0156\n",
      "Epoch 154/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9607.3350 - mean_absolute_error: 9607.3350  \n",
      "Epoch 154: val_loss did not improve from 13604.69629\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9549.6514 - mean_absolute_error: 9549.6514 - val_loss: 13644.0996 - val_mean_absolute_error: 13644.0996\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 9580.7314 - mean_absolute_error: 9580.7314\n",
      "Epoch 155: val_loss did not improve from 13604.69629\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9580.7314 - mean_absolute_error: 9580.7314 - val_loss: 13618.3447 - val_mean_absolute_error: 13618.3447\n",
      "Epoch 156/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9726.5605 - mean_absolute_error: 9726.5605\n",
      "Epoch 156: val_loss improved from 13604.69629 to 13579.93066, saving model to Weights-00156--13579.93066.hdf5\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 9647.4629 - mean_absolute_error: 9647.4629 - val_loss: 13579.9307 - val_mean_absolute_error: 13579.9307\n",
      "Epoch 157/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 10053.3877 - mean_absolute_error: 10053.3877\n",
      "Epoch 157: val_loss did not improve from 13579.93066\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9550.8076 - mean_absolute_error: 9550.8076 - val_loss: 13619.5469 - val_mean_absolute_error: 13619.5469\n",
      "Epoch 158/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9416.2812 - mean_absolute_error: 9416.2812\n",
      "Epoch 158: val_loss did not improve from 13579.93066\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9410.7539 - mean_absolute_error: 9410.7539 - val_loss: 13980.0371 - val_mean_absolute_error: 13980.0371\n",
      "Epoch 159/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9866.6348 - mean_absolute_error: 9866.6348  \n",
      "Epoch 159: val_loss did not improve from 13579.93066\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9724.7393 - mean_absolute_error: 9724.7393 - val_loss: 13593.7949 - val_mean_absolute_error: 13593.7949\n",
      "Epoch 160/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9637.6055 - mean_absolute_error: 9637.6055\n",
      "Epoch 160: val_loss improved from 13579.93066 to 13573.37402, saving model to Weights-00160--13573.37402.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9547.9111 - mean_absolute_error: 9547.9111 - val_loss: 13573.3740 - val_mean_absolute_error: 13573.3740\n",
      "Epoch 161/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9688.2695 - mean_absolute_error: 9688.2695  \n",
      "Epoch 161: val_loss did not improve from 13573.37402\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9493.5596 - mean_absolute_error: 9493.5596 - val_loss: 13805.3281 - val_mean_absolute_error: 13805.3281\n",
      "Epoch 162/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9846.7080 - mean_absolute_error: 9846.7080\n",
      "Epoch 162: val_loss did not improve from 13573.37402\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9528.0371 - mean_absolute_error: 9528.0371 - val_loss: 13658.3408 - val_mean_absolute_error: 13658.3408\n",
      "Epoch 163/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9628.0645 - mean_absolute_error: 9628.0645  \n",
      "Epoch 163: val_loss did not improve from 13573.37402\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9544.3379 - mean_absolute_error: 9544.3379 - val_loss: 13698.4307 - val_mean_absolute_error: 13698.4307\n",
      "Epoch 164/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9430.1709 - mean_absolute_error: 9430.1709\n",
      "Epoch 164: val_loss did not improve from 13573.37402\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9581.3955 - mean_absolute_error: 9581.3955 - val_loss: 13800.1143 - val_mean_absolute_error: 13800.1143\n",
      "Epoch 165/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9796.0420 - mean_absolute_error: 9796.0420  \n",
      "Epoch 165: val_loss did not improve from 13573.37402\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9603.6982 - mean_absolute_error: 9603.6982 - val_loss: 13841.4629 - val_mean_absolute_error: 13841.4629\n",
      "Epoch 166/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9524.8926 - mean_absolute_error: 9524.8926  \n",
      "Epoch 166: val_loss did not improve from 13573.37402\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9603.9639 - mean_absolute_error: 9603.9639 - val_loss: 13834.4424 - val_mean_absolute_error: 13834.4424\n",
      "Epoch 167/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9638.7529 - mean_absolute_error: 9638.7529  \n",
      "Epoch 167: val_loss did not improve from 13573.37402\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9623.3076 - mean_absolute_error: 9623.3076 - val_loss: 14189.4531 - val_mean_absolute_error: 14189.4531\n",
      "Epoch 168/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9554.8906 - mean_absolute_error: 9554.8906  \n",
      "Epoch 168: val_loss did not improve from 13573.37402\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9480.6426 - mean_absolute_error: 9480.6426 - val_loss: 13583.1025 - val_mean_absolute_error: 13583.1025\n",
      "Epoch 169/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9584.0205 - mean_absolute_error: 9584.0205\n",
      "Epoch 169: val_loss did not improve from 13573.37402\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9518.2451 - mean_absolute_error: 9518.2451 - val_loss: 13612.6377 - val_mean_absolute_error: 13612.6377\n",
      "Epoch 170/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9739.1797 - mean_absolute_error: 9739.1797\n",
      "Epoch 170: val_loss did not improve from 13573.37402\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9588.0312 - mean_absolute_error: 9588.0312 - val_loss: 13596.1562 - val_mean_absolute_error: 13596.1562\n",
      "Epoch 171/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9475.3145 - mean_absolute_error: 9475.3145\n",
      "Epoch 171: val_loss did not improve from 13573.37402\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9543.7686 - mean_absolute_error: 9543.7686 - val_loss: 13690.5254 - val_mean_absolute_error: 13690.5254\n",
      "Epoch 172/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9878.9580 - mean_absolute_error: 9878.9580\n",
      "Epoch 172: val_loss did not improve from 13573.37402\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9872.3057 - mean_absolute_error: 9872.3057 - val_loss: 13581.2979 - val_mean_absolute_error: 13581.2979\n",
      "Epoch 173/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9441.0459 - mean_absolute_error: 9441.0459\n",
      "Epoch 173: val_loss improved from 13573.37402 to 13572.92871, saving model to Weights-00173--13572.92871.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9497.6514 - mean_absolute_error: 9497.6514 - val_loss: 13572.9287 - val_mean_absolute_error: 13572.9287\n",
      "Epoch 174/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9877.2910 - mean_absolute_error: 9877.2910\n",
      "Epoch 174: val_loss did not improve from 13572.92871\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9493.6484 - mean_absolute_error: 9493.6484 - val_loss: 13592.3340 - val_mean_absolute_error: 13592.3340\n",
      "Epoch 175/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 10060.4639 - mean_absolute_error: 10060.4639\n",
      "Epoch 175: val_loss did not improve from 13572.92871\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9601.9971 - mean_absolute_error: 9601.9971 - val_loss: 13649.4736 - val_mean_absolute_error: 13649.4736\n",
      "Epoch 176/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 9203.6162 - mean_absolute_error: 9203.6162\n",
      "Epoch 176: val_loss did not improve from 13572.92871\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9622.7607 - mean_absolute_error: 9622.7607 - val_loss: 13642.9590 - val_mean_absolute_error: 13642.9590\n",
      "Epoch 177/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9681.9238 - mean_absolute_error: 9681.9238  \n",
      "Epoch 177: val_loss did not improve from 13572.92871\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9591.4619 - mean_absolute_error: 9591.4619 - val_loss: 13687.3057 - val_mean_absolute_error: 13687.3057\n",
      "Epoch 178/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9657.8926 - mean_absolute_error: 9657.8926  \n",
      "Epoch 178: val_loss did not improve from 13572.92871\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9687.1416 - mean_absolute_error: 9687.1416 - val_loss: 13673.6826 - val_mean_absolute_error: 13673.6826\n",
      "Epoch 179/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9809.2998 - mean_absolute_error: 9809.2998  \n",
      "Epoch 179: val_loss did not improve from 13572.92871\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9867.9639 - mean_absolute_error: 9867.9639 - val_loss: 13943.4492 - val_mean_absolute_error: 13943.4492\n",
      "Epoch 180/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9552.9492 - mean_absolute_error: 9552.9492\n",
      "Epoch 180: val_loss did not improve from 13572.92871\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9642.4746 - mean_absolute_error: 9642.4746 - val_loss: 13599.4619 - val_mean_absolute_error: 13599.4619\n",
      "Epoch 181/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9575.2295 - mean_absolute_error: 9575.2295  \n",
      "Epoch 181: val_loss did not improve from 13572.92871\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9542.7754 - mean_absolute_error: 9542.7754 - val_loss: 14214.9424 - val_mean_absolute_error: 14214.9424\n",
      "Epoch 182/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9859.9160 - mean_absolute_error: 9859.9160\n",
      "Epoch 182: val_loss did not improve from 13572.92871\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9778.0518 - mean_absolute_error: 9778.0518 - val_loss: 13839.6094 - val_mean_absolute_error: 13839.6094\n",
      "Epoch 183/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9711.9863 - mean_absolute_error: 9711.9863  \n",
      "Epoch 183: val_loss improved from 13572.92871 to 13550.09668, saving model to Weights-00183--13550.09668.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9571.5264 - mean_absolute_error: 9571.5264 - val_loss: 13550.0967 - val_mean_absolute_error: 13550.0967\n",
      "Epoch 184/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9696.8887 - mean_absolute_error: 9696.8887\n",
      "Epoch 184: val_loss did not improve from 13550.09668\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9599.8623 - mean_absolute_error: 9599.8623 - val_loss: 13597.4951 - val_mean_absolute_error: 13597.4951\n",
      "Epoch 185/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9561.6074 - mean_absolute_error: 9561.6074  \n",
      "Epoch 185: val_loss did not improve from 13550.09668\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9497.7764 - mean_absolute_error: 9497.7764 - val_loss: 13592.4424 - val_mean_absolute_error: 13592.4424\n",
      "Epoch 186/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9119.4502 - mean_absolute_error: 9119.4502\n",
      "Epoch 186: val_loss did not improve from 13550.09668\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9468.5342 - mean_absolute_error: 9468.5342 - val_loss: 13677.9600 - val_mean_absolute_error: 13677.9600\n",
      "Epoch 187/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9501.2861 - mean_absolute_error: 9501.2861\n",
      "Epoch 187: val_loss did not improve from 13550.09668\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9530.0117 - mean_absolute_error: 9530.0117 - val_loss: 13583.0752 - val_mean_absolute_error: 13583.0752\n",
      "Epoch 188/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9512.4258 - mean_absolute_error: 9512.4258\n",
      "Epoch 188: val_loss improved from 13550.09668 to 13541.26270, saving model to Weights-00188--13541.26270.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9507.8281 - mean_absolute_error: 9507.8281 - val_loss: 13541.2627 - val_mean_absolute_error: 13541.2627\n",
      "Epoch 189/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9979.3369 - mean_absolute_error: 9979.3369\n",
      "Epoch 189: val_loss did not improve from 13541.26270\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9645.9541 - mean_absolute_error: 9645.9541 - val_loss: 13614.4229 - val_mean_absolute_error: 13614.4229\n",
      "Epoch 190/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9866.9619 - mean_absolute_error: 9866.9619  \n",
      "Epoch 190: val_loss did not improve from 13541.26270\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9642.5830 - mean_absolute_error: 9642.5830 - val_loss: 13552.5088 - val_mean_absolute_error: 13552.5088\n",
      "Epoch 191/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9230.7637 - mean_absolute_error: 9230.7637  \n",
      "Epoch 191: val_loss did not improve from 13541.26270\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9483.4424 - mean_absolute_error: 9483.4424 - val_loss: 13631.3994 - val_mean_absolute_error: 13631.3994\n",
      "Epoch 192/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9563.5957 - mean_absolute_error: 9563.5957  \n",
      "Epoch 192: val_loss did not improve from 13541.26270\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9531.4102 - mean_absolute_error: 9531.4102 - val_loss: 13567.7021 - val_mean_absolute_error: 13567.7021\n",
      "Epoch 193/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9858.7412 - mean_absolute_error: 9858.7412  \n",
      "Epoch 193: val_loss did not improve from 13541.26270\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9574.3086 - mean_absolute_error: 9574.3086 - val_loss: 13552.4590 - val_mean_absolute_error: 13552.4590\n",
      "Epoch 194/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 9527.0361 - mean_absolute_error: 9527.0361\n",
      "Epoch 194: val_loss did not improve from 13541.26270\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9501.6289 - mean_absolute_error: 9501.6289 - val_loss: 13682.3457 - val_mean_absolute_error: 13682.3457\n",
      "Epoch 195/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9758.0537 - mean_absolute_error: 9758.0537  \n",
      "Epoch 195: val_loss did not improve from 13541.26270\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9585.5400 - mean_absolute_error: 9585.5400 - val_loss: 13543.9990 - val_mean_absolute_error: 13543.9990\n",
      "Epoch 196/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9000.2607 - mean_absolute_error: 9000.2607\n",
      "Epoch 196: val_loss did not improve from 13541.26270\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9483.4912 - mean_absolute_error: 9483.4912 - val_loss: 13717.8486 - val_mean_absolute_error: 13717.8486\n",
      "Epoch 197/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9905.3555 - mean_absolute_error: 9905.3555\n",
      "Epoch 197: val_loss did not improve from 13541.26270\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9630.4961 - mean_absolute_error: 9630.4961 - val_loss: 13575.1523 - val_mean_absolute_error: 13575.1523\n",
      "Epoch 198/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9656.8262 - mean_absolute_error: 9656.8262  \n",
      "Epoch 198: val_loss did not improve from 13541.26270\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9506.4346 - mean_absolute_error: 9506.4346 - val_loss: 13589.3193 - val_mean_absolute_error: 13589.3193\n",
      "Epoch 199/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9886.0420 - mean_absolute_error: 9886.0420\n",
      "Epoch 199: val_loss did not improve from 13541.26270\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9488.2139 - mean_absolute_error: 9488.2139 - val_loss: 14308.0459 - val_mean_absolute_error: 14308.0459\n",
      "Epoch 200/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9785.8701 - mean_absolute_error: 9785.8701  \n",
      "Epoch 200: val_loss did not improve from 13541.26270\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9715.2705 - mean_absolute_error: 9715.2705 - val_loss: 13827.0928 - val_mean_absolute_error: 13827.0928\n",
      "Epoch 201/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9645.2930 - mean_absolute_error: 9645.2930  \n",
      "Epoch 201: val_loss did not improve from 13541.26270\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9508.3027 - mean_absolute_error: 9508.3027 - val_loss: 13574.8818 - val_mean_absolute_error: 13574.8818\n",
      "Epoch 202/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9556.7432 - mean_absolute_error: 9556.7432\n",
      "Epoch 202: val_loss did not improve from 13541.26270\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9694.0811 - mean_absolute_error: 9694.0811 - val_loss: 13601.7236 - val_mean_absolute_error: 13601.7236\n",
      "Epoch 203/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9835.3740 - mean_absolute_error: 9835.3740\n",
      "Epoch 203: val_loss improved from 13541.26270 to 13539.01855, saving model to Weights-00203--13539.01855.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9748.5352 - mean_absolute_error: 9748.5352 - val_loss: 13539.0186 - val_mean_absolute_error: 13539.0186\n",
      "Epoch 204/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9753.4814 - mean_absolute_error: 9753.4814\n",
      "Epoch 204: val_loss did not improve from 13539.01855\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9692.1826 - mean_absolute_error: 9692.1826 - val_loss: 13584.5576 - val_mean_absolute_error: 13584.5576\n",
      "Epoch 205/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9653.0176 - mean_absolute_error: 9653.0176  \n",
      "Epoch 205: val_loss did not improve from 13539.01855\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9673.6260 - mean_absolute_error: 9673.6260 - val_loss: 13542.4111 - val_mean_absolute_error: 13542.4111\n",
      "Epoch 206/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9276.8438 - mean_absolute_error: 9276.8438\n",
      "Epoch 206: val_loss did not improve from 13539.01855\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9503.3857 - mean_absolute_error: 9503.3857 - val_loss: 13568.7451 - val_mean_absolute_error: 13568.7451\n",
      "Epoch 207/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9456.0137 - mean_absolute_error: 9456.0137\n",
      "Epoch 207: val_loss did not improve from 13539.01855\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9487.6621 - mean_absolute_error: 9487.6621 - val_loss: 13553.7393 - val_mean_absolute_error: 13553.7393\n",
      "Epoch 208/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9388.7402 - mean_absolute_error: 9388.7402\n",
      "Epoch 208: val_loss did not improve from 13539.01855\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9442.1914 - mean_absolute_error: 9442.1914 - val_loss: 13693.2627 - val_mean_absolute_error: 13693.2627\n",
      "Epoch 209/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9587.4014 - mean_absolute_error: 9587.4014\n",
      "Epoch 209: val_loss did not improve from 13539.01855\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9515.9873 - mean_absolute_error: 9515.9873 - val_loss: 13855.5420 - val_mean_absolute_error: 13855.5420\n",
      "Epoch 210/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 9169.7178 - mean_absolute_error: 9169.7178\n",
      "Epoch 210: val_loss improved from 13539.01855 to 13536.18359, saving model to Weights-00210--13536.18359.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9479.5469 - mean_absolute_error: 9479.5469 - val_loss: 13536.1836 - val_mean_absolute_error: 13536.1836\n",
      "Epoch 211/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9175.0791 - mean_absolute_error: 9175.0791\n",
      "Epoch 211: val_loss did not improve from 13536.18359\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9426.0420 - mean_absolute_error: 9426.0420 - val_loss: 13774.3496 - val_mean_absolute_error: 13774.3496\n",
      "Epoch 212/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9267.1143 - mean_absolute_error: 9267.1143\n",
      "Epoch 212: val_loss did not improve from 13536.18359\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9527.2715 - mean_absolute_error: 9527.2715 - val_loss: 13628.3457 - val_mean_absolute_error: 13628.3457\n",
      "Epoch 213/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9564.9912 - mean_absolute_error: 9564.9912\n",
      "Epoch 213: val_loss did not improve from 13536.18359\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9509.8652 - mean_absolute_error: 9509.8652 - val_loss: 13727.9482 - val_mean_absolute_error: 13727.9482\n",
      "Epoch 214/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9877.1074 - mean_absolute_error: 9877.1074\n",
      "Epoch 214: val_loss did not improve from 13536.18359\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9483.7178 - mean_absolute_error: 9483.7178 - val_loss: 13868.6123 - val_mean_absolute_error: 13868.6123\n",
      "Epoch 215/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9718.2607 - mean_absolute_error: 9718.2607  \n",
      "Epoch 215: val_loss did not improve from 13536.18359\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9776.8281 - mean_absolute_error: 9776.8281 - val_loss: 13706.6611 - val_mean_absolute_error: 13706.6611\n",
      "Epoch 216/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9955.8115 - mean_absolute_error: 9955.8115\n",
      "Epoch 216: val_loss did not improve from 13536.18359\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9695.3037 - mean_absolute_error: 9695.3037 - val_loss: 14355.3916 - val_mean_absolute_error: 14355.3916\n",
      "Epoch 217/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9497.4561 - mean_absolute_error: 9497.4561  \n",
      "Epoch 217: val_loss did not improve from 13536.18359\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9447.9736 - mean_absolute_error: 9447.9736 - val_loss: 13542.2676 - val_mean_absolute_error: 13542.2676\n",
      "Epoch 218/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9619.9385 - mean_absolute_error: 9619.9385\n",
      "Epoch 218: val_loss did not improve from 13536.18359\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9474.9111 - mean_absolute_error: 9474.9111 - val_loss: 13561.7920 - val_mean_absolute_error: 13561.7920\n",
      "Epoch 219/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9462.7285 - mean_absolute_error: 9462.7285  \n",
      "Epoch 219: val_loss did not improve from 13536.18359\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9452.1465 - mean_absolute_error: 9452.1465 - val_loss: 13615.6582 - val_mean_absolute_error: 13615.6582\n",
      "Epoch 220/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9853.4170 - mean_absolute_error: 9853.4170  \n",
      "Epoch 220: val_loss did not improve from 13536.18359\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9600.9307 - mean_absolute_error: 9600.9307 - val_loss: 13550.6377 - val_mean_absolute_error: 13550.6377\n",
      "Epoch 221/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9370.0449 - mean_absolute_error: 9370.0449\n",
      "Epoch 221: val_loss improved from 13536.18359 to 13532.82910, saving model to Weights-00221--13532.82910.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9398.2764 - mean_absolute_error: 9398.2764 - val_loss: 13532.8291 - val_mean_absolute_error: 13532.8291\n",
      "Epoch 222/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9546.5029 - mean_absolute_error: 9546.5029\n",
      "Epoch 222: val_loss did not improve from 13532.82910\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9497.8594 - mean_absolute_error: 9497.8594 - val_loss: 13543.7568 - val_mean_absolute_error: 13543.7568\n",
      "Epoch 223/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9932.0977 - mean_absolute_error: 9932.0977\n",
      "Epoch 223: val_loss did not improve from 13532.82910\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9722.1465 - mean_absolute_error: 9722.1465 - val_loss: 13548.1924 - val_mean_absolute_error: 13548.1924\n",
      "Epoch 224/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9457.5811 - mean_absolute_error: 9457.5811\n",
      "Epoch 224: val_loss did not improve from 13532.82910\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9411.0312 - mean_absolute_error: 9411.0312 - val_loss: 13930.3623 - val_mean_absolute_error: 13930.3623\n",
      "Epoch 225/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9624.8975 - mean_absolute_error: 9624.8975\n",
      "Epoch 225: val_loss improved from 13532.82910 to 13529.17188, saving model to Weights-00225--13529.17188.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9615.5781 - mean_absolute_error: 9615.5781 - val_loss: 13529.1719 - val_mean_absolute_error: 13529.1719\n",
      "Epoch 226/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9529.7949 - mean_absolute_error: 9529.7949\n",
      "Epoch 226: val_loss did not improve from 13529.17188\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9571.5186 - mean_absolute_error: 9571.5186 - val_loss: 13688.0625 - val_mean_absolute_error: 13688.0625\n",
      "Epoch 227/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9380.1035 - mean_absolute_error: 9380.1035  \n",
      "Epoch 227: val_loss improved from 13529.17188 to 13525.28613, saving model to Weights-00227--13525.28613.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9377.1094 - mean_absolute_error: 9377.1094 - val_loss: 13525.2861 - val_mean_absolute_error: 13525.2861\n",
      "Epoch 228/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9557.8232 - mean_absolute_error: 9557.8232\n",
      "Epoch 228: val_loss did not improve from 13525.28613\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9447.6572 - mean_absolute_error: 9447.6572 - val_loss: 13557.9844 - val_mean_absolute_error: 13557.9844\n",
      "Epoch 229/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9375.4971 - mean_absolute_error: 9375.4971\n",
      "Epoch 229: val_loss did not improve from 13525.28613\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9427.4521 - mean_absolute_error: 9427.4521 - val_loss: 13543.2607 - val_mean_absolute_error: 13543.2607\n",
      "Epoch 230/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9402.6533 - mean_absolute_error: 9402.6533  \n",
      "Epoch 230: val_loss did not improve from 13525.28613\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9664.9834 - mean_absolute_error: 9664.9834 - val_loss: 13566.1299 - val_mean_absolute_error: 13566.1299\n",
      "Epoch 231/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9842.0664 - mean_absolute_error: 9842.0664  \n",
      "Epoch 231: val_loss did not improve from 13525.28613\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9607.8018 - mean_absolute_error: 9607.8018 - val_loss: 13537.1172 - val_mean_absolute_error: 13537.1172\n",
      "Epoch 232/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9392.1299 - mean_absolute_error: 9392.1299\n",
      "Epoch 232: val_loss improved from 13525.28613 to 13515.12109, saving model to Weights-00232--13515.12109.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9441.7559 - mean_absolute_error: 9441.7559 - val_loss: 13515.1211 - val_mean_absolute_error: 13515.1211\n",
      "Epoch 233/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8957.7822 - mean_absolute_error: 8957.7822\n",
      "Epoch 233: val_loss did not improve from 13515.12109\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9450.5098 - mean_absolute_error: 9450.5098 - val_loss: 13537.0254 - val_mean_absolute_error: 13537.0254\n",
      "Epoch 234/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9466.6299 - mean_absolute_error: 9466.6299\n",
      "Epoch 234: val_loss did not improve from 13515.12109\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9538.9824 - mean_absolute_error: 9538.9824 - val_loss: 13580.3789 - val_mean_absolute_error: 13580.3789\n",
      "Epoch 235/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9495.9355 - mean_absolute_error: 9495.9355  \n",
      "Epoch 235: val_loss improved from 13515.12109 to 13511.01758, saving model to Weights-00235--13511.01758.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9484.2168 - mean_absolute_error: 9484.2168 - val_loss: 13511.0176 - val_mean_absolute_error: 13511.0176\n",
      "Epoch 236/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9593.4053 - mean_absolute_error: 9593.4053\n",
      "Epoch 236: val_loss did not improve from 13511.01758\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9390.6533 - mean_absolute_error: 9390.6533 - val_loss: 13530.2559 - val_mean_absolute_error: 13530.2559\n",
      "Epoch 237/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9789.0127 - mean_absolute_error: 9789.0127  \n",
      "Epoch 237: val_loss did not improve from 13511.01758\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9546.6846 - mean_absolute_error: 9546.6846 - val_loss: 13978.2656 - val_mean_absolute_error: 13978.2656\n",
      "Epoch 238/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9615.6182 - mean_absolute_error: 9615.6182  \n",
      "Epoch 238: val_loss did not improve from 13511.01758\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9531.5908 - mean_absolute_error: 9531.5908 - val_loss: 13698.6826 - val_mean_absolute_error: 13698.6826\n",
      "Epoch 239/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9573.4014 - mean_absolute_error: 9573.4014 \n",
      "Epoch 239: val_loss did not improve from 13511.01758\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 9446.3604 - mean_absolute_error: 9446.3604 - val_loss: 13531.2031 - val_mean_absolute_error: 13531.2031\n",
      "Epoch 240/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9297.1436 - mean_absolute_error: 9297.1436\n",
      "Epoch 240: val_loss did not improve from 13511.01758\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9385.6582 - mean_absolute_error: 9385.6582 - val_loss: 13513.9248 - val_mean_absolute_error: 13513.9248\n",
      "Epoch 241/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9441.1836 - mean_absolute_error: 9441.1836\n",
      "Epoch 241: val_loss did not improve from 13511.01758\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9377.3721 - mean_absolute_error: 9377.3721 - val_loss: 13516.0049 - val_mean_absolute_error: 13516.0049\n",
      "Epoch 242/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9574.2793 - mean_absolute_error: 9574.2793\n",
      "Epoch 242: val_loss did not improve from 13511.01758\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9443.5127 - mean_absolute_error: 9443.5127 - val_loss: 13608.0664 - val_mean_absolute_error: 13608.0664\n",
      "Epoch 243/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9488.0938 - mean_absolute_error: 9488.0938\n",
      "Epoch 243: val_loss did not improve from 13511.01758\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9445.9219 - mean_absolute_error: 9445.9219 - val_loss: 13952.5615 - val_mean_absolute_error: 13952.5615\n",
      "Epoch 244/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9661.4961 - mean_absolute_error: 9661.4961\n",
      "Epoch 244: val_loss did not improve from 13511.01758\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9590.4502 - mean_absolute_error: 9590.4502 - val_loss: 13570.4717 - val_mean_absolute_error: 13570.4717\n",
      "Epoch 245/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9745.7100 - mean_absolute_error: 9745.7100  \n",
      "Epoch 245: val_loss improved from 13511.01758 to 13502.75488, saving model to Weights-00245--13502.75488.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9599.7744 - mean_absolute_error: 9599.7744 - val_loss: 13502.7549 - val_mean_absolute_error: 13502.7549\n",
      "Epoch 246/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9387.1582 - mean_absolute_error: 9387.1582  \n",
      "Epoch 246: val_loss did not improve from 13502.75488\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9405.3115 - mean_absolute_error: 9405.3115 - val_loss: 13503.2168 - val_mean_absolute_error: 13503.2168\n",
      "Epoch 247/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9663.0781 - mean_absolute_error: 9663.0781  \n",
      "Epoch 247: val_loss did not improve from 13502.75488\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9470.1143 - mean_absolute_error: 9470.1143 - val_loss: 13541.2168 - val_mean_absolute_error: 13541.2168\n",
      "Epoch 248/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9454.4785 - mean_absolute_error: 9454.4785  \n",
      "Epoch 248: val_loss improved from 13502.75488 to 13492.26562, saving model to Weights-00248--13492.26562.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9400.0889 - mean_absolute_error: 9400.0889 - val_loss: 13492.2656 - val_mean_absolute_error: 13492.2656\n",
      "Epoch 249/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9635.9814 - mean_absolute_error: 9635.9814\n",
      "Epoch 249: val_loss did not improve from 13492.26562\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9415.6270 - mean_absolute_error: 9415.6270 - val_loss: 13503.5273 - val_mean_absolute_error: 13503.5273\n",
      "Epoch 250/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9411.8193 - mean_absolute_error: 9411.8193\n",
      "Epoch 250: val_loss improved from 13492.26562 to 13490.31641, saving model to Weights-00250--13490.31641.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9409.4785 - mean_absolute_error: 9409.4785 - val_loss: 13490.3164 - val_mean_absolute_error: 13490.3164\n",
      "Epoch 251/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9437.4980 - mean_absolute_error: 9437.4980  \n",
      "Epoch 251: val_loss improved from 13490.31641 to 13489.38770, saving model to Weights-00251--13489.38770.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9450.2930 - mean_absolute_error: 9450.2930 - val_loss: 13489.3877 - val_mean_absolute_error: 13489.3877\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 9394.2861 - mean_absolute_error: 9394.2861\n",
      "Epoch 252: val_loss did not improve from 13489.38770\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9394.2861 - mean_absolute_error: 9394.2861 - val_loss: 13503.7451 - val_mean_absolute_error: 13503.7451\n",
      "Epoch 253/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9271.3262 - mean_absolute_error: 9271.3262\n",
      "Epoch 253: val_loss improved from 13489.38770 to 13487.54785, saving model to Weights-00253--13487.54785.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9408.2051 - mean_absolute_error: 9408.2051 - val_loss: 13487.5479 - val_mean_absolute_error: 13487.5479\n",
      "Epoch 254/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9316.0918 - mean_absolute_error: 9316.0918\n",
      "Epoch 254: val_loss did not improve from 13487.54785\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9468.0605 - mean_absolute_error: 9468.0605 - val_loss: 13506.2451 - val_mean_absolute_error: 13506.2451\n",
      "Epoch 255/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9171.4541 - mean_absolute_error: 9171.4541  \n",
      "Epoch 255: val_loss did not improve from 13487.54785\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9394.5361 - mean_absolute_error: 9394.5361 - val_loss: 13501.2803 - val_mean_absolute_error: 13501.2803\n",
      "Epoch 256/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9437.2988 - mean_absolute_error: 9437.2988\n",
      "Epoch 256: val_loss improved from 13487.54785 to 13485.21387, saving model to Weights-00256--13485.21387.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9424.1113 - mean_absolute_error: 9424.1113 - val_loss: 13485.2139 - val_mean_absolute_error: 13485.2139\n",
      "Epoch 257/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9536.4561 - mean_absolute_error: 9536.4561\n",
      "Epoch 257: val_loss did not improve from 13485.21387\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9466.6396 - mean_absolute_error: 9466.6396 - val_loss: 13507.1904 - val_mean_absolute_error: 13507.1904\n",
      "Epoch 258/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9582.4805 - mean_absolute_error: 9582.4805  \n",
      "Epoch 258: val_loss did not improve from 13485.21387\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9529.8740 - mean_absolute_error: 9529.8740 - val_loss: 13492.6680 - val_mean_absolute_error: 13492.6680\n",
      "Epoch 259/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9739.1650 - mean_absolute_error: 9739.1650\n",
      "Epoch 259: val_loss improved from 13485.21387 to 13478.71387, saving model to Weights-00259--13478.71387.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9410.0020 - mean_absolute_error: 9410.0020 - val_loss: 13478.7139 - val_mean_absolute_error: 13478.7139\n",
      "Epoch 260/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9415.3096 - mean_absolute_error: 9415.3096\n",
      "Epoch 260: val_loss improved from 13478.71387 to 13477.58203, saving model to Weights-00260--13477.58203.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9397.2158 - mean_absolute_error: 9397.2158 - val_loss: 13477.5820 - val_mean_absolute_error: 13477.5820\n",
      "Epoch 261/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9523.1357 - mean_absolute_error: 9523.1357  \n",
      "Epoch 261: val_loss did not improve from 13477.58203\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9408.8604 - mean_absolute_error: 9408.8604 - val_loss: 13546.0254 - val_mean_absolute_error: 13546.0254\n",
      "Epoch 262/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9506.2568 - mean_absolute_error: 9506.2568\n",
      "Epoch 262: val_loss did not improve from 13477.58203\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9451.0996 - mean_absolute_error: 9451.0996 - val_loss: 13551.0566 - val_mean_absolute_error: 13551.0566\n",
      "Epoch 263/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 10004.1035 - mean_absolute_error: 10004.1035\n",
      "Epoch 263: val_loss did not improve from 13477.58203\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9854.0244 - mean_absolute_error: 9854.0244 - val_loss: 14213.1104 - val_mean_absolute_error: 14213.1104\n",
      "Epoch 264/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9249.2637 - mean_absolute_error: 9249.2637  \n",
      "Epoch 264: val_loss did not improve from 13477.58203\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9745.1104 - mean_absolute_error: 9745.1104 - val_loss: 14300.5479 - val_mean_absolute_error: 14300.5479\n",
      "Epoch 265/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9567.6602 - mean_absolute_error: 9567.6602\n",
      "Epoch 265: val_loss did not improve from 13477.58203\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9757.5537 - mean_absolute_error: 9757.5537 - val_loss: 13507.6895 - val_mean_absolute_error: 13507.6895\n",
      "Epoch 266/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9486.7451 - mean_absolute_error: 9486.7451  \n",
      "Epoch 266: val_loss did not improve from 13477.58203\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9366.8984 - mean_absolute_error: 9366.8984 - val_loss: 13525.8193 - val_mean_absolute_error: 13525.8193\n",
      "Epoch 267/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9430.2393 - mean_absolute_error: 9430.2393\n",
      "Epoch 267: val_loss did not improve from 13477.58203\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9409.6006 - mean_absolute_error: 9409.6006 - val_loss: 13495.2012 - val_mean_absolute_error: 13495.2012\n",
      "Epoch 268/1000\n",
      "11/18 [=================>............] - ETA: 0s - loss: 9597.9453 - mean_absolute_error: 9597.9453\n",
      "Epoch 268: val_loss did not improve from 13477.58203\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9449.7656 - mean_absolute_error: 9449.7656 - val_loss: 13482.6484 - val_mean_absolute_error: 13482.6484\n",
      "Epoch 269/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9427.0020 - mean_absolute_error: 9427.0020\n",
      "Epoch 269: val_loss improved from 13477.58203 to 13471.31152, saving model to Weights-00269--13471.31152.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9394.8916 - mean_absolute_error: 9394.8916 - val_loss: 13471.3115 - val_mean_absolute_error: 13471.3115\n",
      "Epoch 270/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9482.0469 - mean_absolute_error: 9482.0469\n",
      "Epoch 270: val_loss improved from 13471.31152 to 13465.40039, saving model to Weights-00270--13465.40039.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9535.5830 - mean_absolute_error: 9535.5830 - val_loss: 13465.4004 - val_mean_absolute_error: 13465.4004\n",
      "Epoch 271/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9686.6182 - mean_absolute_error: 9686.6182  \n",
      "Epoch 271: val_loss did not improve from 13465.40039\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9425.1963 - mean_absolute_error: 9425.1963 - val_loss: 13478.8320 - val_mean_absolute_error: 13478.8320\n",
      "Epoch 272/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9302.4893 - mean_absolute_error: 9302.4893  \n",
      "Epoch 272: val_loss did not improve from 13465.40039\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9441.9590 - mean_absolute_error: 9441.9590 - val_loss: 13466.2949 - val_mean_absolute_error: 13466.2949\n",
      "Epoch 273/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9531.6660 - mean_absolute_error: 9531.6660\n",
      "Epoch 273: val_loss improved from 13465.40039 to 13462.04297, saving model to Weights-00273--13462.04297.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9396.3164 - mean_absolute_error: 9396.3164 - val_loss: 13462.0430 - val_mean_absolute_error: 13462.0430\n",
      "Epoch 274/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9424.8594 - mean_absolute_error: 9424.8594  \n",
      "Epoch 274: val_loss did not improve from 13462.04297\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9379.1162 - mean_absolute_error: 9379.1162 - val_loss: 13462.0625 - val_mean_absolute_error: 13462.0625\n",
      "Epoch 275/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9405.0273 - mean_absolute_error: 9405.0273\n",
      "Epoch 275: val_loss improved from 13462.04297 to 13461.30664, saving model to Weights-00275--13461.30664.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9484.1562 - mean_absolute_error: 9484.1562 - val_loss: 13461.3066 - val_mean_absolute_error: 13461.3066\n",
      "Epoch 276/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9478.8926 - mean_absolute_error: 9478.8926\n",
      "Epoch 276: val_loss did not improve from 13461.30664\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9438.2236 - mean_absolute_error: 9438.2236 - val_loss: 13461.3584 - val_mean_absolute_error: 13461.3584\n",
      "Epoch 277/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9537.2158 - mean_absolute_error: 9537.2158\n",
      "Epoch 277: val_loss improved from 13461.30664 to 13455.18652, saving model to Weights-00277--13455.18652.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9504.4814 - mean_absolute_error: 9504.4814 - val_loss: 13455.1865 - val_mean_absolute_error: 13455.1865\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 9354.1250 - mean_absolute_error: 9354.1250  \n",
      "Epoch 278: val_loss did not improve from 13455.18652\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9354.1250 - mean_absolute_error: 9354.1250 - val_loss: 13554.3086 - val_mean_absolute_error: 13554.3086\n",
      "Epoch 279/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9372.3955 - mean_absolute_error: 9372.3955 \n",
      "Epoch 279: val_loss did not improve from 13455.18652\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 9359.3223 - mean_absolute_error: 9359.3223 - val_loss: 13461.1045 - val_mean_absolute_error: 13461.1045\n",
      "Epoch 280/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9509.8965 - mean_absolute_error: 9509.8965\n",
      "Epoch 280: val_loss did not improve from 13455.18652\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9535.8545 - mean_absolute_error: 9535.8545 - val_loss: 13461.8154 - val_mean_absolute_error: 13461.8154\n",
      "Epoch 281/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9548.8770 - mean_absolute_error: 9548.8770  \n",
      "Epoch 281: val_loss did not improve from 13455.18652\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9357.6768 - mean_absolute_error: 9357.6768 - val_loss: 13488.5508 - val_mean_absolute_error: 13488.5508\n",
      "Epoch 282/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9684.4160 - mean_absolute_error: 9684.4160\n",
      "Epoch 282: val_loss did not improve from 13455.18652\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9393.0098 - mean_absolute_error: 9393.0098 - val_loss: 13494.6406 - val_mean_absolute_error: 13494.6406\n",
      "Epoch 283/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9503.3838 - mean_absolute_error: 9503.3838\n",
      "Epoch 283: val_loss did not improve from 13455.18652\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9395.9736 - mean_absolute_error: 9395.9736 - val_loss: 13482.8887 - val_mean_absolute_error: 13482.8887\n",
      "Epoch 284/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9539.1689 - mean_absolute_error: 9539.1689\n",
      "Epoch 284: val_loss did not improve from 13455.18652\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9453.5166 - mean_absolute_error: 9453.5166 - val_loss: 14152.1699 - val_mean_absolute_error: 14152.1699\n",
      "Epoch 285/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9530.3848 - mean_absolute_error: 9530.3848  \n",
      "Epoch 285: val_loss improved from 13455.18652 to 13455.05078, saving model to Weights-00285--13455.05078.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9532.4609 - mean_absolute_error: 9532.4609 - val_loss: 13455.0508 - val_mean_absolute_error: 13455.0508\n",
      "Epoch 286/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9681.2021 - mean_absolute_error: 9681.2021\n",
      "Epoch 286: val_loss did not improve from 13455.05078\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9540.6270 - mean_absolute_error: 9540.6270 - val_loss: 13819.1074 - val_mean_absolute_error: 13819.1074\n",
      "Epoch 287/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9273.0791 - mean_absolute_error: 9273.0791  \n",
      "Epoch 287: val_loss improved from 13455.05078 to 13450.12207, saving model to Weights-00287--13450.12207.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9454.5566 - mean_absolute_error: 9454.5566 - val_loss: 13450.1221 - val_mean_absolute_error: 13450.1221\n",
      "Epoch 288/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9797.7725 - mean_absolute_error: 9797.7725\n",
      "Epoch 288: val_loss improved from 13450.12207 to 13439.64355, saving model to Weights-00288--13439.64355.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9490.0127 - mean_absolute_error: 9490.0127 - val_loss: 13439.6436 - val_mean_absolute_error: 13439.6436\n",
      "Epoch 289/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9750.3750 - mean_absolute_error: 9750.3750\n",
      "Epoch 289: val_loss did not improve from 13439.64355\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9397.7266 - mean_absolute_error: 9397.7266 - val_loss: 13512.1348 - val_mean_absolute_error: 13512.1348\n",
      "Epoch 290/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9594.1377 - mean_absolute_error: 9594.1377\n",
      "Epoch 290: val_loss did not improve from 13439.64355\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9499.5332 - mean_absolute_error: 9499.5332 - val_loss: 13498.9150 - val_mean_absolute_error: 13498.9150\n",
      "Epoch 291/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9508.3965 - mean_absolute_error: 9508.3965\n",
      "Epoch 291: val_loss improved from 13439.64355 to 13439.51562, saving model to Weights-00291--13439.51562.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9371.8467 - mean_absolute_error: 9371.8467 - val_loss: 13439.5156 - val_mean_absolute_error: 13439.5156\n",
      "Epoch 292/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9640.9170 - mean_absolute_error: 9640.9170\n",
      "Epoch 292: val_loss did not improve from 13439.51562\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9628.6641 - mean_absolute_error: 9628.6641 - val_loss: 13444.7412 - val_mean_absolute_error: 13444.7412\n",
      "Epoch 293/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9420.9443 - mean_absolute_error: 9420.9443\n",
      "Epoch 293: val_loss did not improve from 13439.51562\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9386.8369 - mean_absolute_error: 9386.8369 - val_loss: 13460.8730 - val_mean_absolute_error: 13460.8730\n",
      "Epoch 294/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9602.9219 - mean_absolute_error: 9602.9219\n",
      "Epoch 294: val_loss did not improve from 13439.51562\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9586.6973 - mean_absolute_error: 9586.6973 - val_loss: 13744.5127 - val_mean_absolute_error: 13744.5127\n",
      "Epoch 295/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9812.0352 - mean_absolute_error: 9812.0352\n",
      "Epoch 295: val_loss did not improve from 13439.51562\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9460.3369 - mean_absolute_error: 9460.3369 - val_loss: 13444.4102 - val_mean_absolute_error: 13444.4102\n",
      "Epoch 296/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9556.4463 - mean_absolute_error: 9556.4463\n",
      "Epoch 296: val_loss did not improve from 13439.51562\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9493.8115 - mean_absolute_error: 9493.8115 - val_loss: 13873.8623 - val_mean_absolute_error: 13873.8623\n",
      "Epoch 297/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9595.6133 - mean_absolute_error: 9595.6133  \n",
      "Epoch 297: val_loss improved from 13439.51562 to 13431.98828, saving model to Weights-00297--13431.98828.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9385.9209 - mean_absolute_error: 9385.9209 - val_loss: 13431.9883 - val_mean_absolute_error: 13431.9883\n",
      "Epoch 298/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9052.0820 - mean_absolute_error: 9052.0820\n",
      "Epoch 298: val_loss did not improve from 13431.98828\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9409.8086 - mean_absolute_error: 9409.8086 - val_loss: 13451.8066 - val_mean_absolute_error: 13451.8066\n",
      "Epoch 299/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9373.8438 - mean_absolute_error: 9373.8438\n",
      "Epoch 299: val_loss did not improve from 13431.98828\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 9358.4121 - mean_absolute_error: 9358.4121 - val_loss: 13436.6504 - val_mean_absolute_error: 13436.6504\n",
      "Epoch 300/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9362.1875 - mean_absolute_error: 9362.1875\n",
      "Epoch 300: val_loss did not improve from 13431.98828\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9373.3711 - mean_absolute_error: 9373.3711 - val_loss: 13552.9111 - val_mean_absolute_error: 13552.9111\n",
      "Epoch 301/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9483.2783 - mean_absolute_error: 9483.2783\n",
      "Epoch 301: val_loss did not improve from 13431.98828\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9423.3125 - mean_absolute_error: 9423.3125 - val_loss: 13439.0586 - val_mean_absolute_error: 13439.0586\n",
      "Epoch 302/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9375.5771 - mean_absolute_error: 9375.5771\n",
      "Epoch 302: val_loss did not improve from 13431.98828\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9358.1182 - mean_absolute_error: 9358.1182 - val_loss: 13434.3213 - val_mean_absolute_error: 13434.3213\n",
      "Epoch 303/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9277.2705 - mean_absolute_error: 9277.2705\n",
      "Epoch 303: val_loss did not improve from 13431.98828\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9353.5811 - mean_absolute_error: 9353.5811 - val_loss: 13432.2627 - val_mean_absolute_error: 13432.2617\n",
      "Epoch 304/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9346.2139 - mean_absolute_error: 9346.2139  \n",
      "Epoch 304: val_loss did not improve from 13431.98828\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9347.6855 - mean_absolute_error: 9347.6855 - val_loss: 13433.1641 - val_mean_absolute_error: 13433.1641\n",
      "Epoch 305/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9380.9658 - mean_absolute_error: 9380.9658\n",
      "Epoch 305: val_loss did not improve from 13431.98828\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9406.3213 - mean_absolute_error: 9406.3213 - val_loss: 13635.8750 - val_mean_absolute_error: 13635.8750\n",
      "Epoch 306/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9293.7822 - mean_absolute_error: 9293.7822  \n",
      "Epoch 306: val_loss improved from 13431.98828 to 13425.54492, saving model to Weights-00306--13425.54492.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9413.1045 - mean_absolute_error: 9413.1045 - val_loss: 13425.5449 - val_mean_absolute_error: 13425.5449\n",
      "Epoch 307/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9091.8613 - mean_absolute_error: 9091.8613\n",
      "Epoch 307: val_loss improved from 13425.54492 to 13425.11133, saving model to Weights-00307--13425.11133.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9379.6162 - mean_absolute_error: 9379.6162 - val_loss: 13425.1113 - val_mean_absolute_error: 13425.1113\n",
      "Epoch 308/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9467.4648 - mean_absolute_error: 9467.4648\n",
      "Epoch 308: val_loss did not improve from 13425.11133\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9303.7051 - mean_absolute_error: 9303.7051 - val_loss: 13659.5488 - val_mean_absolute_error: 13659.5488\n",
      "Epoch 309/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9182.3662 - mean_absolute_error: 9182.3662  \n",
      "Epoch 309: val_loss did not improve from 13425.11133\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9324.5967 - mean_absolute_error: 9324.5967 - val_loss: 13490.0869 - val_mean_absolute_error: 13490.0869\n",
      "Epoch 310/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9590.8398 - mean_absolute_error: 9590.8398\n",
      "Epoch 310: val_loss did not improve from 13425.11133\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9426.3945 - mean_absolute_error: 9426.3945 - val_loss: 13479.0312 - val_mean_absolute_error: 13479.0312\n",
      "Epoch 311/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9526.5400 - mean_absolute_error: 9526.5400\n",
      "Epoch 311: val_loss improved from 13425.11133 to 13419.94629, saving model to Weights-00311--13419.94629.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9420.8525 - mean_absolute_error: 9420.8525 - val_loss: 13419.9463 - val_mean_absolute_error: 13419.9463\n",
      "Epoch 312/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9226.3311 - mean_absolute_error: 9226.3311  \n",
      "Epoch 312: val_loss did not improve from 13419.94629\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9355.2998 - mean_absolute_error: 9355.2998 - val_loss: 13433.2041 - val_mean_absolute_error: 13433.2041\n",
      "Epoch 313/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9426.1826 - mean_absolute_error: 9426.1826\n",
      "Epoch 313: val_loss did not improve from 13419.94629\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9422.4189 - mean_absolute_error: 9422.4189 - val_loss: 13444.9814 - val_mean_absolute_error: 13444.9814\n",
      "Epoch 314/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9310.6162 - mean_absolute_error: 9310.6162  \n",
      "Epoch 314: val_loss did not improve from 13419.94629\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9436.7334 - mean_absolute_error: 9436.7334 - val_loss: 13426.9512 - val_mean_absolute_error: 13426.9512\n",
      "Epoch 315/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9021.0342 - mean_absolute_error: 9021.0342\n",
      "Epoch 315: val_loss did not improve from 13419.94629\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9574.4414 - mean_absolute_error: 9574.4414 - val_loss: 13423.4141 - val_mean_absolute_error: 13423.4141\n",
      "Epoch 316/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9521.3467 - mean_absolute_error: 9521.3467  \n",
      "Epoch 316: val_loss did not improve from 13419.94629\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9565.9424 - mean_absolute_error: 9565.9424 - val_loss: 13472.2158 - val_mean_absolute_error: 13472.2158\n",
      "Epoch 317/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9382.8633 - mean_absolute_error: 9382.8633\n",
      "Epoch 317: val_loss improved from 13419.94629 to 13415.78125, saving model to Weights-00317--13415.78125.hdf5\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 9370.5508 - mean_absolute_error: 9370.5508 - val_loss: 13415.7812 - val_mean_absolute_error: 13415.7812\n",
      "Epoch 318/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 9138.0264 - mean_absolute_error: 9138.0264  \n",
      "Epoch 318: val_loss improved from 13415.78125 to 13415.33398, saving model to Weights-00318--13415.33398.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9426.2021 - mean_absolute_error: 9426.2021 - val_loss: 13415.3340 - val_mean_absolute_error: 13415.3340\n",
      "Epoch 319/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9425.5352 - mean_absolute_error: 9425.5352  \n",
      "Epoch 319: val_loss did not improve from 13415.33398\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9348.3945 - mean_absolute_error: 9348.3945 - val_loss: 13469.5459 - val_mean_absolute_error: 13469.5459\n",
      "Epoch 320/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9468.4043 - mean_absolute_error: 9468.4043  \n",
      "Epoch 320: val_loss did not improve from 13415.33398\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9377.6494 - mean_absolute_error: 9377.6494 - val_loss: 13423.0908 - val_mean_absolute_error: 13423.0908\n",
      "Epoch 321/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9162.5996 - mean_absolute_error: 9162.5996\n",
      "Epoch 321: val_loss did not improve from 13415.33398\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9389.0332 - mean_absolute_error: 9389.0332 - val_loss: 13476.2236 - val_mean_absolute_error: 13476.2236\n",
      "Epoch 322/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9686.5225 - mean_absolute_error: 9686.5225  \n",
      "Epoch 322: val_loss did not improve from 13415.33398\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9456.0518 - mean_absolute_error: 9456.0518 - val_loss: 13797.0986 - val_mean_absolute_error: 13797.0986\n",
      "Epoch 323/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9662.5537 - mean_absolute_error: 9662.5537\n",
      "Epoch 323: val_loss did not improve from 13415.33398\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9622.2344 - mean_absolute_error: 9622.2344 - val_loss: 14067.6445 - val_mean_absolute_error: 14067.6445\n",
      "Epoch 324/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9501.1328 - mean_absolute_error: 9501.1328\n",
      "Epoch 324: val_loss improved from 13415.33398 to 13410.66992, saving model to Weights-00324--13410.66992.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9439.1699 - mean_absolute_error: 9439.1699 - val_loss: 13410.6699 - val_mean_absolute_error: 13410.6699\n",
      "Epoch 325/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9696.0781 - mean_absolute_error: 9696.0781\n",
      "Epoch 325: val_loss did not improve from 13410.66992\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9484.8506 - mean_absolute_error: 9484.8506 - val_loss: 13416.5273 - val_mean_absolute_error: 13416.5273\n",
      "Epoch 326/1000\n",
      "11/18 [=================>............] - ETA: 0s - loss: 9220.6885 - mean_absolute_error: 9220.6885\n",
      "Epoch 326: val_loss improved from 13410.66992 to 13410.52051, saving model to Weights-00326--13410.52051.hdf5\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9373.3018 - mean_absolute_error: 9373.3018 - val_loss: 13410.5205 - val_mean_absolute_error: 13410.5205\n",
      "Epoch 327/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9203.2021 - mean_absolute_error: 9203.2021\n",
      "Epoch 327: val_loss improved from 13410.52051 to 13406.43164, saving model to Weights-00327--13406.43164.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9366.5586 - mean_absolute_error: 9366.5586 - val_loss: 13406.4316 - val_mean_absolute_error: 13406.4316\n",
      "Epoch 328/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9458.7041 - mean_absolute_error: 9458.7041  \n",
      "Epoch 328: val_loss did not improve from 13406.43164\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9370.2373 - mean_absolute_error: 9370.2373 - val_loss: 13536.6787 - val_mean_absolute_error: 13536.6787\n",
      "Epoch 329/1000\n",
      "11/18 [=================>............] - ETA: 0s - loss: 9436.0205 - mean_absolute_error: 9436.0205  \n",
      "Epoch 329: val_loss did not improve from 13406.43164\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9574.7246 - mean_absolute_error: 9574.7246 - val_loss: 13416.5664 - val_mean_absolute_error: 13416.5664\n",
      "Epoch 330/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 10260.3916 - mean_absolute_error: 10260.3916\n",
      "Epoch 330: val_loss improved from 13406.43164 to 13405.56641, saving model to Weights-00330--13405.56641.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9882.5127 - mean_absolute_error: 9882.5127 - val_loss: 13405.5664 - val_mean_absolute_error: 13405.5664\n",
      "Epoch 331/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9478.6680 - mean_absolute_error: 9478.6680\n",
      "Epoch 331: val_loss improved from 13405.56641 to 13399.07812, saving model to Weights-00331--13399.07812.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9456.8232 - mean_absolute_error: 9456.8232 - val_loss: 13399.0781 - val_mean_absolute_error: 13399.0781\n",
      "Epoch 332/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9165.6494 - mean_absolute_error: 9165.6494\n",
      "Epoch 332: val_loss did not improve from 13399.07812\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9420.7275 - mean_absolute_error: 9420.7275 - val_loss: 13422.4902 - val_mean_absolute_error: 13422.4902\n",
      "Epoch 333/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9257.9238 - mean_absolute_error: 9257.9238\n",
      "Epoch 333: val_loss did not improve from 13399.07812\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9379.8408 - mean_absolute_error: 9379.8408 - val_loss: 13571.3447 - val_mean_absolute_error: 13571.3447\n",
      "Epoch 334/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9361.7734 - mean_absolute_error: 9361.7734\n",
      "Epoch 334: val_loss did not improve from 13399.07812\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9409.1533 - mean_absolute_error: 9409.1533 - val_loss: 13570.6660 - val_mean_absolute_error: 13570.6660\n",
      "Epoch 335/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9507.3350 - mean_absolute_error: 9507.3350\n",
      "Epoch 335: val_loss did not improve from 13399.07812\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9446.3750 - mean_absolute_error: 9446.3750 - val_loss: 13409.6670 - val_mean_absolute_error: 13409.6670\n",
      "Epoch 336/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9459.6924 - mean_absolute_error: 9459.6924  \n",
      "Epoch 336: val_loss did not improve from 13399.07812\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9376.4775 - mean_absolute_error: 9376.4775 - val_loss: 13422.4658 - val_mean_absolute_error: 13422.4658\n",
      "Epoch 337/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9507.8145 - mean_absolute_error: 9507.8145\n",
      "Epoch 337: val_loss improved from 13399.07812 to 13394.34668, saving model to Weights-00337--13394.34668.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9416.3135 - mean_absolute_error: 9416.3135 - val_loss: 13394.3467 - val_mean_absolute_error: 13394.3467\n",
      "Epoch 338/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9258.0498 - mean_absolute_error: 9258.0498\n",
      "Epoch 338: val_loss improved from 13394.34668 to 13391.47656, saving model to Weights-00338--13391.47656.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9327.2627 - mean_absolute_error: 9327.2627 - val_loss: 13391.4766 - val_mean_absolute_error: 13391.4766\n",
      "Epoch 339/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9330.7988 - mean_absolute_error: 9330.7988\n",
      "Epoch 339: val_loss did not improve from 13391.47656\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9364.8223 - mean_absolute_error: 9364.8223 - val_loss: 13428.8740 - val_mean_absolute_error: 13428.8740\n",
      "Epoch 340/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9082.0889 - mean_absolute_error: 9082.0889  \n",
      "Epoch 340: val_loss did not improve from 13391.47656\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9377.0615 - mean_absolute_error: 9377.0615 - val_loss: 13850.0820 - val_mean_absolute_error: 13850.0820\n",
      "Epoch 341/1000\n",
      "11/18 [=================>............] - ETA: 0s - loss: 9617.6689 - mean_absolute_error: 9617.6689\n",
      "Epoch 341: val_loss did not improve from 13391.47656\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9392.2148 - mean_absolute_error: 9392.2148 - val_loss: 13391.5498 - val_mean_absolute_error: 13391.5498\n",
      "Epoch 342/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9610.7598 - mean_absolute_error: 9610.7598\n",
      "Epoch 342: val_loss did not improve from 13391.47656\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9349.0674 - mean_absolute_error: 9349.0674 - val_loss: 13398.3916 - val_mean_absolute_error: 13398.3916\n",
      "Epoch 343/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9095.8096 - mean_absolute_error: 9095.8096\n",
      "Epoch 343: val_loss did not improve from 13391.47656\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9458.7031 - mean_absolute_error: 9458.7031 - val_loss: 13484.4717 - val_mean_absolute_error: 13484.4717\n",
      "Epoch 344/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9120.0654 - mean_absolute_error: 9120.0654\n",
      "Epoch 344: val_loss did not improve from 13391.47656\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9370.0801 - mean_absolute_error: 9370.0801 - val_loss: 13413.6719 - val_mean_absolute_error: 13413.6719\n",
      "Epoch 345/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9506.3613 - mean_absolute_error: 9506.3613\n",
      "Epoch 345: val_loss did not improve from 13391.47656\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9471.3701 - mean_absolute_error: 9471.3701 - val_loss: 13412.4375 - val_mean_absolute_error: 13412.4375\n",
      "Epoch 346/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 9719.8213 - mean_absolute_error: 9719.8213  \n",
      "Epoch 346: val_loss improved from 13391.47656 to 13388.57324, saving model to Weights-00346--13388.57324.hdf5\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9467.2979 - mean_absolute_error: 9467.2979 - val_loss: 13388.5732 - val_mean_absolute_error: 13388.5732\n",
      "Epoch 347/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9309.5791 - mean_absolute_error: 9309.5791\n",
      "Epoch 347: val_loss did not improve from 13388.57324\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9358.8379 - mean_absolute_error: 9358.8379 - val_loss: 13419.8857 - val_mean_absolute_error: 13419.8857\n",
      "Epoch 348/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9463.0430 - mean_absolute_error: 9463.0430\n",
      "Epoch 348: val_loss did not improve from 13388.57324\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9330.8750 - mean_absolute_error: 9330.8750 - val_loss: 13389.8643 - val_mean_absolute_error: 13389.8643\n",
      "Epoch 349/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9380.6875 - mean_absolute_error: 9380.6875\n",
      "Epoch 349: val_loss did not improve from 13388.57324\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9334.6279 - mean_absolute_error: 9334.6279 - val_loss: 13391.8936 - val_mean_absolute_error: 13391.8936\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 9340.0723 - mean_absolute_error: 9340.0723\n",
      "Epoch 350: val_loss did not improve from 13388.57324\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9340.0723 - mean_absolute_error: 9340.0723 - val_loss: 13507.8428 - val_mean_absolute_error: 13507.8428\n",
      "Epoch 351/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 9294.4277 - mean_absolute_error: 9294.4277  \n",
      "Epoch 351: val_loss did not improve from 13388.57324\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9429.7314 - mean_absolute_error: 9429.7314 - val_loss: 13407.2490 - val_mean_absolute_error: 13407.2490\n",
      "Epoch 352/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9565.7607 - mean_absolute_error: 9565.7607  \n",
      "Epoch 352: val_loss improved from 13388.57324 to 13385.31641, saving model to Weights-00352--13385.31641.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9570.5732 - mean_absolute_error: 9570.5732 - val_loss: 13385.3164 - val_mean_absolute_error: 13385.3164\n",
      "Epoch 353/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9426.7061 - mean_absolute_error: 9426.7061\n",
      "Epoch 353: val_loss did not improve from 13385.31641\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9456.8857 - mean_absolute_error: 9456.8857 - val_loss: 13451.0010 - val_mean_absolute_error: 13451.0010\n",
      "Epoch 354/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9559.0898 - mean_absolute_error: 9559.0898\n",
      "Epoch 354: val_loss did not improve from 13385.31641\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9390.0723 - mean_absolute_error: 9390.0723 - val_loss: 13422.2451 - val_mean_absolute_error: 13422.2451\n",
      "Epoch 355/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9243.8379 - mean_absolute_error: 9243.8379  \n",
      "Epoch 355: val_loss did not improve from 13385.31641\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9432.8057 - mean_absolute_error: 9432.8057 - val_loss: 13435.4727 - val_mean_absolute_error: 13435.4727\n",
      "Epoch 356/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9586.0830 - mean_absolute_error: 9586.0830  \n",
      "Epoch 356: val_loss did not improve from 13385.31641\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9479.3008 - mean_absolute_error: 9479.3008 - val_loss: 13534.0674 - val_mean_absolute_error: 13534.0674\n",
      "Epoch 357/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9368.1816 - mean_absolute_error: 9368.1816\n",
      "Epoch 357: val_loss improved from 13385.31641 to 13376.82031, saving model to Weights-00357--13376.82031.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9419.0713 - mean_absolute_error: 9419.0713 - val_loss: 13376.8203 - val_mean_absolute_error: 13376.8203\n",
      "Epoch 358/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9447.2510 - mean_absolute_error: 9447.2510\n",
      "Epoch 358: val_loss did not improve from 13376.82031\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9336.2891 - mean_absolute_error: 9336.2891 - val_loss: 13425.5127 - val_mean_absolute_error: 13425.5127\n",
      "Epoch 359/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9329.4785 - mean_absolute_error: 9329.4785\n",
      "Epoch 359: val_loss did not improve from 13376.82031\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9400.8955 - mean_absolute_error: 9400.8955 - val_loss: 13407.9287 - val_mean_absolute_error: 13407.9287\n",
      "Epoch 360/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9438.3926 - mean_absolute_error: 9438.3926  \n",
      "Epoch 360: val_loss did not improve from 13376.82031\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9442.1104 - mean_absolute_error: 9442.1104 - val_loss: 13388.9717 - val_mean_absolute_error: 13388.9717\n",
      "Epoch 361/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9660.6387 - mean_absolute_error: 9660.6387\n",
      "Epoch 361: val_loss improved from 13376.82031 to 13371.12305, saving model to Weights-00361--13371.12305.hdf5\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9409.7256 - mean_absolute_error: 9409.7256 - val_loss: 13371.1230 - val_mean_absolute_error: 13371.1230\n",
      "Epoch 362/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9500.1514 - mean_absolute_error: 9500.1514  \n",
      "Epoch 362: val_loss improved from 13371.12305 to 13368.87988, saving model to Weights-00362--13368.87988.hdf5\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9662.6611 - mean_absolute_error: 9662.6611 - val_loss: 13368.8799 - val_mean_absolute_error: 13368.8799\n",
      "Epoch 363/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9892.1709 - mean_absolute_error: 9892.1709  \n",
      "Epoch 363: val_loss improved from 13368.87988 to 13367.50000, saving model to Weights-00363--13367.50000.hdf5\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9382.4180 - mean_absolute_error: 9382.4180 - val_loss: 13367.5000 - val_mean_absolute_error: 13367.5000\n",
      "Epoch 364/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 9614.8291 - mean_absolute_error: 9614.8291  \n",
      "Epoch 364: val_loss did not improve from 13367.50000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9461.5244 - mean_absolute_error: 9461.5244 - val_loss: 13562.3408 - val_mean_absolute_error: 13562.3408\n",
      "Epoch 365/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9524.6377 - mean_absolute_error: 9524.6377  \n",
      "Epoch 365: val_loss did not improve from 13367.50000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 9668.2744 - mean_absolute_error: 9668.2744 - val_loss: 13631.3086 - val_mean_absolute_error: 13631.3086\n",
      "Epoch 366/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 9503.5527 - mean_absolute_error: 9503.5527  \n",
      "Epoch 366: val_loss did not improve from 13367.50000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9410.7705 - mean_absolute_error: 9410.7705 - val_loss: 13371.0996 - val_mean_absolute_error: 13371.0996\n",
      "Epoch 367/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9698.7490 - mean_absolute_error: 9698.7490  \n",
      "Epoch 367: val_loss did not improve from 13367.50000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9339.1426 - mean_absolute_error: 9339.1426 - val_loss: 13378.4492 - val_mean_absolute_error: 13378.4492\n",
      "Epoch 368/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9216.8691 - mean_absolute_error: 9216.8691\n",
      "Epoch 368: val_loss did not improve from 13367.50000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9374.4053 - mean_absolute_error: 9374.4053 - val_loss: 13371.3145 - val_mean_absolute_error: 13371.3145\n",
      "Epoch 369/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9408.6982 - mean_absolute_error: 9408.6982\n",
      "Epoch 369: val_loss did not improve from 13367.50000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9388.7090 - mean_absolute_error: 9388.7090 - val_loss: 13457.0947 - val_mean_absolute_error: 13457.0947\n",
      "Epoch 370/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9607.1104 - mean_absolute_error: 9607.1104\n",
      "Epoch 370: val_loss did not improve from 13367.50000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9602.9209 - mean_absolute_error: 9602.9209 - val_loss: 13388.9150 - val_mean_absolute_error: 13388.9150\n",
      "Epoch 371/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9340.3799 - mean_absolute_error: 9340.3799\n",
      "Epoch 371: val_loss did not improve from 13367.50000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9329.1357 - mean_absolute_error: 9329.1357 - val_loss: 13414.0117 - val_mean_absolute_error: 13414.0117\n",
      "Epoch 372/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9404.7158 - mean_absolute_error: 9404.7158\n",
      "Epoch 372: val_loss did not improve from 13367.50000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9376.5459 - mean_absolute_error: 9376.5459 - val_loss: 13372.6631 - val_mean_absolute_error: 13372.6631\n",
      "Epoch 373/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9263.6113 - mean_absolute_error: 9263.6113\n",
      "Epoch 373: val_loss did not improve from 13367.50000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9344.0420 - mean_absolute_error: 9344.0420 - val_loss: 13371.9023 - val_mean_absolute_error: 13371.9023\n",
      "Epoch 374/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9442.3594 - mean_absolute_error: 9442.3594\n",
      "Epoch 374: val_loss improved from 13367.50000 to 13365.93457, saving model to Weights-00374--13365.93457.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9486.4570 - mean_absolute_error: 9486.4570 - val_loss: 13365.9346 - val_mean_absolute_error: 13365.9346\n",
      "Epoch 375/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9339.5244 - mean_absolute_error: 9339.5244\n",
      "Epoch 375: val_loss did not improve from 13365.93457\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9302.5098 - mean_absolute_error: 9302.5098 - val_loss: 14218.1787 - val_mean_absolute_error: 14218.1787\n",
      "Epoch 376/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9639.1943 - mean_absolute_error: 9639.1943  \n",
      "Epoch 376: val_loss did not improve from 13365.93457\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9526.5381 - mean_absolute_error: 9526.5381 - val_loss: 13371.6992 - val_mean_absolute_error: 13371.6992\n",
      "Epoch 377/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9583.0332 - mean_absolute_error: 9583.0332  \n",
      "Epoch 377: val_loss did not improve from 13365.93457\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9325.1074 - mean_absolute_error: 9325.1074 - val_loss: 13377.2676 - val_mean_absolute_error: 13377.2676\n",
      "Epoch 378/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9799.2949 - mean_absolute_error: 9799.2949  \n",
      "Epoch 378: val_loss improved from 13365.93457 to 13363.44824, saving model to Weights-00378--13363.44824.hdf5\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9335.0781 - mean_absolute_error: 9335.0781 - val_loss: 13363.4482 - val_mean_absolute_error: 13363.4482\n",
      "Epoch 379/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9376.7969 - mean_absolute_error: 9376.7969\n",
      "Epoch 379: val_loss did not improve from 13363.44824\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9421.1152 - mean_absolute_error: 9421.1152 - val_loss: 13399.0039 - val_mean_absolute_error: 13399.0039\n",
      "Epoch 380/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9582.2715 - mean_absolute_error: 9582.2715\n",
      "Epoch 380: val_loss did not improve from 13363.44824\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9483.7510 - mean_absolute_error: 9483.7510 - val_loss: 13375.3271 - val_mean_absolute_error: 13375.3281\n",
      "Epoch 381/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9138.3906 - mean_absolute_error: 9138.3906\n",
      "Epoch 381: val_loss did not improve from 13363.44824\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9453.4189 - mean_absolute_error: 9453.4189 - val_loss: 13390.5537 - val_mean_absolute_error: 13390.5537\n",
      "Epoch 382/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9560.1240 - mean_absolute_error: 9560.1240\n",
      "Epoch 382: val_loss did not improve from 13363.44824\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9298.7021 - mean_absolute_error: 9298.7021 - val_loss: 13541.5713 - val_mean_absolute_error: 13541.5713\n",
      "Epoch 383/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9586.1533 - mean_absolute_error: 9586.1533  \n",
      "Epoch 383: val_loss did not improve from 13363.44824\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9385.3887 - mean_absolute_error: 9385.3887 - val_loss: 13363.4902 - val_mean_absolute_error: 13363.4902\n",
      "Epoch 384/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9359.1875 - mean_absolute_error: 9359.1875\n",
      "Epoch 384: val_loss did not improve from 13363.44824\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9403.8066 - mean_absolute_error: 9403.8066 - val_loss: 13377.9932 - val_mean_absolute_error: 13377.9932\n",
      "Epoch 385/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9371.2832 - mean_absolute_error: 9371.2832\n",
      "Epoch 385: val_loss did not improve from 13363.44824\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9385.2979 - mean_absolute_error: 9385.2979 - val_loss: 13655.2549 - val_mean_absolute_error: 13655.2549\n",
      "Epoch 386/1000\n",
      "10/18 [===============>..............] - ETA: 0s - loss: 9487.9082 - mean_absolute_error: 9487.9082  \n",
      "Epoch 386: val_loss improved from 13363.44824 to 13361.11035, saving model to Weights-00386--13361.11035.hdf5\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 9425.6934 - mean_absolute_error: 9425.6934 - val_loss: 13361.1104 - val_mean_absolute_error: 13361.1104\n",
      "Epoch 387/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9411.9746 - mean_absolute_error: 9411.9746  \n",
      "Epoch 387: val_loss did not improve from 13361.11035\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9402.3789 - mean_absolute_error: 9402.3789 - val_loss: 13385.4902 - val_mean_absolute_error: 13385.4902\n",
      "Epoch 388/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9192.4736 - mean_absolute_error: 9192.4736\n",
      "Epoch 388: val_loss did not improve from 13361.11035\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9519.1924 - mean_absolute_error: 9519.1924 - val_loss: 13411.0605 - val_mean_absolute_error: 13411.0605\n",
      "Epoch 389/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9274.8887 - mean_absolute_error: 9274.8887\n",
      "Epoch 389: val_loss did not improve from 13361.11035\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9428.3574 - mean_absolute_error: 9428.3574 - val_loss: 13371.2998 - val_mean_absolute_error: 13371.2998\n",
      "Epoch 390/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9769.9990 - mean_absolute_error: 9769.9990  \n",
      "Epoch 390: val_loss improved from 13361.11035 to 13344.05371, saving model to Weights-00390--13344.05371.hdf5\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9545.0674 - mean_absolute_error: 9545.0674 - val_loss: 13344.0537 - val_mean_absolute_error: 13344.0537\n",
      "Epoch 391/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9494.2256 - mean_absolute_error: 9494.2256  \n",
      "Epoch 391: val_loss did not improve from 13344.05371\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9352.6230 - mean_absolute_error: 9352.6230 - val_loss: 13433.0908 - val_mean_absolute_error: 13433.0908\n",
      "Epoch 392/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9561.6738 - mean_absolute_error: 9561.6738  \n",
      "Epoch 392: val_loss improved from 13344.05371 to 13339.90527, saving model to Weights-00392--13339.90527.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9412.3711 - mean_absolute_error: 9412.3711 - val_loss: 13339.9053 - val_mean_absolute_error: 13339.9053\n",
      "Epoch 393/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9050.3008 - mean_absolute_error: 9050.3008\n",
      "Epoch 393: val_loss did not improve from 13339.90527\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9452.5938 - mean_absolute_error: 9452.5938 - val_loss: 13704.3447 - val_mean_absolute_error: 13704.3447\n",
      "Epoch 394/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 9391.2070 - mean_absolute_error: 9391.2070\n",
      "Epoch 394: val_loss did not improve from 13339.90527\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9518.1162 - mean_absolute_error: 9518.1162 - val_loss: 13715.9326 - val_mean_absolute_error: 13715.9326\n",
      "Epoch 395/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9517.3320 - mean_absolute_error: 9517.3320  \n",
      "Epoch 395: val_loss did not improve from 13339.90527\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9439.9287 - mean_absolute_error: 9439.9287 - val_loss: 13353.5498 - val_mean_absolute_error: 13353.5498\n",
      "Epoch 396/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 10015.7041 - mean_absolute_error: 10015.7041\n",
      "Epoch 396: val_loss did not improve from 13339.90527\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9690.9531 - mean_absolute_error: 9690.9531 - val_loss: 13342.3037 - val_mean_absolute_error: 13342.3037\n",
      "Epoch 397/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9425.9297 - mean_absolute_error: 9425.9297\n",
      "Epoch 397: val_loss did not improve from 13339.90527\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9334.1865 - mean_absolute_error: 9334.1865 - val_loss: 13389.8906 - val_mean_absolute_error: 13389.8906\n",
      "Epoch 398/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9308.1914 - mean_absolute_error: 9308.1914\n",
      "Epoch 398: val_loss did not improve from 13339.90527\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9319.8330 - mean_absolute_error: 9319.8330 - val_loss: 13370.8906 - val_mean_absolute_error: 13370.8906\n",
      "Epoch 399/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9353.5371 - mean_absolute_error: 9353.5371\n",
      "Epoch 399: val_loss improved from 13339.90527 to 13338.85938, saving model to Weights-00399--13338.85938.hdf5\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 9564.5244 - mean_absolute_error: 9564.5244 - val_loss: 13338.8594 - val_mean_absolute_error: 13338.8594\n",
      "Epoch 400/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 9242.5322 - mean_absolute_error: 9242.5322\n",
      "Epoch 400: val_loss did not improve from 13338.85938\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9500.4951 - mean_absolute_error: 9500.4951 - val_loss: 13485.4131 - val_mean_absolute_error: 13485.4131\n",
      "Epoch 401/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9400.8613 - mean_absolute_error: 9400.8613\n",
      "Epoch 401: val_loss did not improve from 13338.85938\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9366.2373 - mean_absolute_error: 9366.2373 - val_loss: 13366.1406 - val_mean_absolute_error: 13366.1406\n",
      "Epoch 402/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9462.9287 - mean_absolute_error: 9462.9287\n",
      "Epoch 402: val_loss did not improve from 13338.85938\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9309.0820 - mean_absolute_error: 9309.0820 - val_loss: 13351.7734 - val_mean_absolute_error: 13351.7734\n",
      "Epoch 403/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9428.2715 - mean_absolute_error: 9428.2715  \n",
      "Epoch 403: val_loss did not improve from 13338.85938\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9355.4854 - mean_absolute_error: 9355.4854 - val_loss: 13384.4111 - val_mean_absolute_error: 13384.4111\n",
      "Epoch 404/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9535.5762 - mean_absolute_error: 9535.5762\n",
      "Epoch 404: val_loss did not improve from 13338.85938\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9443.1152 - mean_absolute_error: 9443.1152 - val_loss: 13587.2051 - val_mean_absolute_error: 13587.2051\n",
      "Epoch 405/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9296.3994 - mean_absolute_error: 9296.3994  \n",
      "Epoch 405: val_loss did not improve from 13338.85938\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9376.3438 - mean_absolute_error: 9376.3438 - val_loss: 13351.4932 - val_mean_absolute_error: 13351.4932\n",
      "Epoch 406/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9232.8848 - mean_absolute_error: 9232.8848\n",
      "Epoch 406: val_loss improved from 13338.85938 to 13338.83789, saving model to Weights-00406--13338.83789.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9391.1455 - mean_absolute_error: 9391.1455 - val_loss: 13338.8379 - val_mean_absolute_error: 13338.8379\n",
      "Epoch 407/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9296.6738 - mean_absolute_error: 9296.6738  \n",
      "Epoch 407: val_loss did not improve from 13338.83789\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9313.6807 - mean_absolute_error: 9313.6807 - val_loss: 13348.9590 - val_mean_absolute_error: 13348.9590\n",
      "Epoch 408/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9090.6074 - mean_absolute_error: 9090.6074  \n",
      "Epoch 408: val_loss did not improve from 13338.83789\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9329.6680 - mean_absolute_error: 9329.6680 - val_loss: 13352.5498 - val_mean_absolute_error: 13352.5498\n",
      "Epoch 409/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9209.0537 - mean_absolute_error: 9209.0537  \n",
      "Epoch 409: val_loss did not improve from 13338.83789\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9356.7988 - mean_absolute_error: 9356.7988 - val_loss: 13371.0254 - val_mean_absolute_error: 13371.0254\n",
      "Epoch 410/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9422.5840 - mean_absolute_error: 9422.5840  \n",
      "Epoch 410: val_loss did not improve from 13338.83789\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9323.8877 - mean_absolute_error: 9323.8877 - val_loss: 13368.3320 - val_mean_absolute_error: 13368.3320\n",
      "Epoch 411/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8948.4346 - mean_absolute_error: 8948.4346\n",
      "Epoch 411: val_loss did not improve from 13338.83789\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9406.5947 - mean_absolute_error: 9406.5947 - val_loss: 13352.3486 - val_mean_absolute_error: 13352.3486\n",
      "Epoch 412/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9604.7842 - mean_absolute_error: 9604.7842\n",
      "Epoch 412: val_loss did not improve from 13338.83789\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9490.1826 - mean_absolute_error: 9490.1826 - val_loss: 13356.0840 - val_mean_absolute_error: 13356.0840\n",
      "Epoch 413/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9406.5254 - mean_absolute_error: 9406.5254  \n",
      "Epoch 413: val_loss did not improve from 13338.83789\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9540.0801 - mean_absolute_error: 9540.0801 - val_loss: 13607.2900 - val_mean_absolute_error: 13607.2900\n",
      "Epoch 414/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9192.9297 - mean_absolute_error: 9192.9297  \n",
      "Epoch 414: val_loss improved from 13338.83789 to 13332.27344, saving model to Weights-00414--13332.27344.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9386.2637 - mean_absolute_error: 9386.2637 - val_loss: 13332.2734 - val_mean_absolute_error: 13332.2734\n",
      "Epoch 415/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9166.5703 - mean_absolute_error: 9166.5703\n",
      "Epoch 415: val_loss improved from 13332.27344 to 13326.75781, saving model to Weights-00415--13326.75781.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9344.4600 - mean_absolute_error: 9344.4600 - val_loss: 13326.7578 - val_mean_absolute_error: 13326.7578\n",
      "Epoch 416/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9240.5039 - mean_absolute_error: 9240.5039\n",
      "Epoch 416: val_loss did not improve from 13326.75781\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9391.3467 - mean_absolute_error: 9391.3467 - val_loss: 13339.7891 - val_mean_absolute_error: 13339.7891\n",
      "Epoch 417/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9682.7021 - mean_absolute_error: 9682.7021  \n",
      "Epoch 417: val_loss did not improve from 13326.75781\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9781.9736 - mean_absolute_error: 9781.9736 - val_loss: 13358.1816 - val_mean_absolute_error: 13358.1816\n",
      "Epoch 418/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9681.7285 - mean_absolute_error: 9681.7285\n",
      "Epoch 418: val_loss did not improve from 13326.75781\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9663.4707 - mean_absolute_error: 9663.4707 - val_loss: 13360.3594 - val_mean_absolute_error: 13360.3594\n",
      "Epoch 419/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9502.3506 - mean_absolute_error: 9502.3506\n",
      "Epoch 419: val_loss did not improve from 13326.75781\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9366.6914 - mean_absolute_error: 9366.6914 - val_loss: 13366.2139 - val_mean_absolute_error: 13366.2139\n",
      "Epoch 420/1000\n",
      "11/18 [=================>............] - ETA: 0s - loss: 9442.8213 - mean_absolute_error: 9442.8213  \n",
      "Epoch 420: val_loss improved from 13326.75781 to 13326.50195, saving model to Weights-00420--13326.50195.hdf5\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 9335.4932 - mean_absolute_error: 9335.4932 - val_loss: 13326.5020 - val_mean_absolute_error: 13326.5020\n",
      "Epoch 421/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9268.7471 - mean_absolute_error: 9268.7471\n",
      "Epoch 421: val_loss did not improve from 13326.50195\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9375.9258 - mean_absolute_error: 9375.9258 - val_loss: 13380.1299 - val_mean_absolute_error: 13380.1299\n",
      "Epoch 422/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9430.7207 - mean_absolute_error: 9430.7207  \n",
      "Epoch 422: val_loss did not improve from 13326.50195\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9375.2021 - mean_absolute_error: 9375.2021 - val_loss: 13330.9551 - val_mean_absolute_error: 13330.9551\n",
      "Epoch 423/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9367.7900 - mean_absolute_error: 9367.7900\n",
      "Epoch 423: val_loss improved from 13326.50195 to 13324.24121, saving model to Weights-00423--13324.24121.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9367.0889 - mean_absolute_error: 9367.0889 - val_loss: 13324.2412 - val_mean_absolute_error: 13324.2412\n",
      "Epoch 424/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 8930.4326 - mean_absolute_error: 8930.4326  \n",
      "Epoch 424: val_loss improved from 13324.24121 to 13323.58008, saving model to Weights-00424--13323.58008.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9318.4727 - mean_absolute_error: 9318.4727 - val_loss: 13323.5801 - val_mean_absolute_error: 13323.5801\n",
      "Epoch 425/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9318.5557 - mean_absolute_error: 9318.5557\n",
      "Epoch 425: val_loss did not improve from 13323.58008\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9309.1562 - mean_absolute_error: 9309.1562 - val_loss: 13330.0156 - val_mean_absolute_error: 13330.0156\n",
      "Epoch 426/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9279.8252 - mean_absolute_error: 9279.8252\n",
      "Epoch 426: val_loss did not improve from 13323.58008\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9310.4746 - mean_absolute_error: 9310.4746 - val_loss: 13339.6982 - val_mean_absolute_error: 13339.6982\n",
      "Epoch 427/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9346.4072 - mean_absolute_error: 9346.4072\n",
      "Epoch 427: val_loss improved from 13323.58008 to 13315.16211, saving model to Weights-00427--13315.16211.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9359.3428 - mean_absolute_error: 9359.3428 - val_loss: 13315.1621 - val_mean_absolute_error: 13315.1621\n",
      "Epoch 428/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9633.1377 - mean_absolute_error: 9633.1377\n",
      "Epoch 428: val_loss did not improve from 13315.16211\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9455.6982 - mean_absolute_error: 9455.6982 - val_loss: 13345.8740 - val_mean_absolute_error: 13345.8740\n",
      "Epoch 429/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9796.1895 - mean_absolute_error: 9796.1895\n",
      "Epoch 429: val_loss did not improve from 13315.16211\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9436.1211 - mean_absolute_error: 9436.1211 - val_loss: 13319.6064 - val_mean_absolute_error: 13319.6064\n",
      "Epoch 430/1000\n",
      "10/18 [===============>..............] - ETA: 0s - loss: 9500.8770 - mean_absolute_error: 9500.8770\n",
      "Epoch 430: val_loss did not improve from 13315.16211\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9661.8877 - mean_absolute_error: 9661.8877 - val_loss: 13318.0391 - val_mean_absolute_error: 13318.0391\n",
      "Epoch 431/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9343.0352 - mean_absolute_error: 9343.0352\n",
      "Epoch 431: val_loss did not improve from 13315.16211\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9486.7559 - mean_absolute_error: 9486.7559 - val_loss: 13720.9131 - val_mean_absolute_error: 13720.9131\n",
      "Epoch 432/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9564.8311 - mean_absolute_error: 9564.8311\n",
      "Epoch 432: val_loss did not improve from 13315.16211\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9594.4795 - mean_absolute_error: 9594.4795 - val_loss: 13328.7139 - val_mean_absolute_error: 13328.7139\n",
      "Epoch 433/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9270.2891 - mean_absolute_error: 9270.2891  \n",
      "Epoch 433: val_loss did not improve from 13315.16211\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9368.7500 - mean_absolute_error: 9368.7500 - val_loss: 13405.3115 - val_mean_absolute_error: 13405.3115\n",
      "Epoch 434/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9315.1289 - mean_absolute_error: 9315.1289\n",
      "Epoch 434: val_loss did not improve from 13315.16211\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9335.7852 - mean_absolute_error: 9335.7852 - val_loss: 13383.8652 - val_mean_absolute_error: 13383.8652\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 9320.3174 - mean_absolute_error: 9320.3174  \n",
      "Epoch 435: val_loss improved from 13315.16211 to 13312.64453, saving model to Weights-00435--13312.64453.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9320.3174 - mean_absolute_error: 9320.3174 - val_loss: 13312.6445 - val_mean_absolute_error: 13312.6445\n",
      "Epoch 436/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9271.9756 - mean_absolute_error: 9271.9756\n",
      "Epoch 436: val_loss did not improve from 13312.64453\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9299.1768 - mean_absolute_error: 9299.1768 - val_loss: 13326.8926 - val_mean_absolute_error: 13326.8926\n",
      "Epoch 437/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9046.5537 - mean_absolute_error: 9046.5537  \n",
      "Epoch 437: val_loss improved from 13312.64453 to 13296.12891, saving model to Weights-00437--13296.12891.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9374.1748 - mean_absolute_error: 9374.1748 - val_loss: 13296.1289 - val_mean_absolute_error: 13296.1289\n",
      "Epoch 438/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9239.7529 - mean_absolute_error: 9239.7529  \n",
      "Epoch 438: val_loss did not improve from 13296.12891\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9328.4912 - mean_absolute_error: 9328.4912 - val_loss: 13420.2568 - val_mean_absolute_error: 13420.2568\n",
      "Epoch 439/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9060.8525 - mean_absolute_error: 9060.8525  \n",
      "Epoch 439: val_loss did not improve from 13296.12891\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9386.1250 - mean_absolute_error: 9386.1250 - val_loss: 13306.1289 - val_mean_absolute_error: 13306.1289\n",
      "Epoch 440/1000\n",
      "10/18 [===============>..............] - ETA: 0s - loss: 8691.7705 - mean_absolute_error: 8691.7705\n",
      "Epoch 440: val_loss did not improve from 13296.12891\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9305.7031 - mean_absolute_error: 9305.7031 - val_loss: 13423.8203 - val_mean_absolute_error: 13423.8203\n",
      "Epoch 441/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9253.3203 - mean_absolute_error: 9253.3203\n",
      "Epoch 441: val_loss did not improve from 13296.12891\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9320.7832 - mean_absolute_error: 9320.7832 - val_loss: 13326.6729 - val_mean_absolute_error: 13326.6729\n",
      "Epoch 442/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9475.5938 - mean_absolute_error: 9475.5938\n",
      "Epoch 442: val_loss did not improve from 13296.12891\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9393.5635 - mean_absolute_error: 9393.5635 - val_loss: 13304.9834 - val_mean_absolute_error: 13304.9834\n",
      "Epoch 443/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9195.1855 - mean_absolute_error: 9195.1855\n",
      "Epoch 443: val_loss did not improve from 13296.12891\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9366.7656 - mean_absolute_error: 9366.7656 - val_loss: 13745.0244 - val_mean_absolute_error: 13745.0244\n",
      "Epoch 444/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9455.5723 - mean_absolute_error: 9455.5723\n",
      "Epoch 444: val_loss did not improve from 13296.12891\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9366.9229 - mean_absolute_error: 9366.9229 - val_loss: 13302.3232 - val_mean_absolute_error: 13302.3232\n",
      "Epoch 445/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9245.8877 - mean_absolute_error: 9245.8877\n",
      "Epoch 445: val_loss did not improve from 13296.12891\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9326.5830 - mean_absolute_error: 9326.5830 - val_loss: 13422.0781 - val_mean_absolute_error: 13422.0781\n",
      "Epoch 446/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9683.1895 - mean_absolute_error: 9683.1895\n",
      "Epoch 446: val_loss improved from 13296.12891 to 13290.94238, saving model to Weights-00446--13290.94238.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9522.5762 - mean_absolute_error: 9522.5762 - val_loss: 13290.9424 - val_mean_absolute_error: 13290.9424\n",
      "Epoch 447/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9169.5371 - mean_absolute_error: 9169.5371\n",
      "Epoch 447: val_loss did not improve from 13290.94238\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9378.1250 - mean_absolute_error: 9378.1250 - val_loss: 13315.2500 - val_mean_absolute_error: 13315.2500\n",
      "Epoch 448/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9247.7637 - mean_absolute_error: 9247.7637  \n",
      "Epoch 448: val_loss did not improve from 13290.94238\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9397.9170 - mean_absolute_error: 9397.9170 - val_loss: 13299.1973 - val_mean_absolute_error: 13299.1973\n",
      "Epoch 449/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9663.9512 - mean_absolute_error: 9663.9512  \n",
      "Epoch 449: val_loss did not improve from 13290.94238\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9447.7627 - mean_absolute_error: 9447.7627 - val_loss: 13333.4824 - val_mean_absolute_error: 13333.4824\n",
      "Epoch 450/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9525.8457 - mean_absolute_error: 9525.8457\n",
      "Epoch 450: val_loss did not improve from 13290.94238\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9403.7461 - mean_absolute_error: 9403.7461 - val_loss: 13303.5430 - val_mean_absolute_error: 13303.5430\n",
      "Epoch 451/1000\n",
      " 8/18 [============>.................] - ETA: 0s - loss: 9847.4258 - mean_absolute_error: 9847.4258\n",
      "Epoch 451: val_loss did not improve from 13290.94238\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9321.0908 - mean_absolute_error: 9321.0908 - val_loss: 13296.7324 - val_mean_absolute_error: 13296.7324\n",
      "Epoch 452/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9494.1650 - mean_absolute_error: 9494.1650\n",
      "Epoch 452: val_loss did not improve from 13290.94238\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9337.4062 - mean_absolute_error: 9337.4062 - val_loss: 13305.8125 - val_mean_absolute_error: 13305.8125\n",
      "Epoch 453/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9311.2793 - mean_absolute_error: 9311.2793\n",
      "Epoch 453: val_loss did not improve from 13290.94238\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9517.6787 - mean_absolute_error: 9517.6787 - val_loss: 13293.0811 - val_mean_absolute_error: 13293.0811\n",
      "Epoch 454/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9371.7383 - mean_absolute_error: 9371.7383\n",
      "Epoch 454: val_loss did not improve from 13290.94238\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9363.6875 - mean_absolute_error: 9363.6875 - val_loss: 13308.9658 - val_mean_absolute_error: 13308.9658\n",
      "Epoch 455/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9039.2676 - mean_absolute_error: 9039.2676\n",
      "Epoch 455: val_loss did not improve from 13290.94238\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9308.1777 - mean_absolute_error: 9308.1777 - val_loss: 13296.0713 - val_mean_absolute_error: 13296.0713\n",
      "Epoch 456/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9358.0020 - mean_absolute_error: 9358.0020\n",
      "Epoch 456: val_loss improved from 13290.94238 to 13280.46094, saving model to Weights-00456--13280.46094.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9337.1279 - mean_absolute_error: 9337.1279 - val_loss: 13280.4609 - val_mean_absolute_error: 13280.4609\n",
      "Epoch 457/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 8907.5303 - mean_absolute_error: 8907.5303\n",
      "Epoch 457: val_loss did not improve from 13280.46094\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9325.8457 - mean_absolute_error: 9325.8457 - val_loss: 13301.4082 - val_mean_absolute_error: 13301.4082\n",
      "Epoch 458/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9270.8008 - mean_absolute_error: 9270.8008\n",
      "Epoch 458: val_loss did not improve from 13280.46094\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9297.8486 - mean_absolute_error: 9297.8486 - val_loss: 13392.1797 - val_mean_absolute_error: 13392.1797\n",
      "Epoch 459/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 8948.5361 - mean_absolute_error: 8948.5361  \n",
      "Epoch 459: val_loss did not improve from 13280.46094\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9363.9990 - mean_absolute_error: 9363.9990 - val_loss: 13343.5645 - val_mean_absolute_error: 13343.5645\n",
      "Epoch 460/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9724.2148 - mean_absolute_error: 9724.2148\n",
      "Epoch 460: val_loss did not improve from 13280.46094\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9671.5400 - mean_absolute_error: 9671.5400 - val_loss: 13283.2256 - val_mean_absolute_error: 13283.2256\n",
      "Epoch 461/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9334.0889 - mean_absolute_error: 9334.0889  \n",
      "Epoch 461: val_loss did not improve from 13280.46094\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9326.5742 - mean_absolute_error: 9326.5742 - val_loss: 13310.1689 - val_mean_absolute_error: 13310.1689\n",
      "Epoch 462/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9409.0068 - mean_absolute_error: 9409.0068  \n",
      "Epoch 462: val_loss did not improve from 13280.46094\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9310.9072 - mean_absolute_error: 9310.9072 - val_loss: 13320.2803 - val_mean_absolute_error: 13320.2803\n",
      "Epoch 463/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9167.9443 - mean_absolute_error: 9167.9443\n",
      "Epoch 463: val_loss did not improve from 13280.46094\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9289.6924 - mean_absolute_error: 9289.6924 - val_loss: 13298.2344 - val_mean_absolute_error: 13298.2344\n",
      "Epoch 464/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9209.8184 - mean_absolute_error: 9209.8184  \n",
      "Epoch 464: val_loss improved from 13280.46094 to 13278.08301, saving model to Weights-00464--13278.08301.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9327.4219 - mean_absolute_error: 9327.4219 - val_loss: 13278.0830 - val_mean_absolute_error: 13278.0830\n",
      "Epoch 465/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9669.5537 - mean_absolute_error: 9669.5537  \n",
      "Epoch 465: val_loss did not improve from 13278.08301\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9322.8291 - mean_absolute_error: 9322.8291 - val_loss: 13590.3154 - val_mean_absolute_error: 13590.3154\n",
      "Epoch 466/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9221.1748 - mean_absolute_error: 9221.1748\n",
      "Epoch 466: val_loss did not improve from 13278.08301\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9334.7402 - mean_absolute_error: 9334.7402 - val_loss: 13292.8438 - val_mean_absolute_error: 13292.8438\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 9430.1660 - mean_absolute_error: 9430.1660  \n",
      "Epoch 467: val_loss did not improve from 13278.08301\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9430.1660 - mean_absolute_error: 9430.1660 - val_loss: 13284.9170 - val_mean_absolute_error: 13284.9170\n",
      "Epoch 468/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9458.6562 - mean_absolute_error: 9458.6562\n",
      "Epoch 468: val_loss did not improve from 13278.08301\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9304.5840 - mean_absolute_error: 9304.5840 - val_loss: 13307.6396 - val_mean_absolute_error: 13307.6396\n",
      "Epoch 469/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9372.3379 - mean_absolute_error: 9372.3379\n",
      "Epoch 469: val_loss did not improve from 13278.08301\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9375.6953 - mean_absolute_error: 9375.6953 - val_loss: 13304.7227 - val_mean_absolute_error: 13304.7227\n",
      "Epoch 470/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9026.6572 - mean_absolute_error: 9026.6572\n",
      "Epoch 470: val_loss improved from 13278.08301 to 13271.06055, saving model to Weights-00470--13271.06055.hdf5\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 9390.3301 - mean_absolute_error: 9390.3301 - val_loss: 13271.0605 - val_mean_absolute_error: 13271.0605\n",
      "Epoch 471/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9436.3828 - mean_absolute_error: 9436.3828\n",
      "Epoch 471: val_loss did not improve from 13271.06055\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9332.0049 - mean_absolute_error: 9332.0049 - val_loss: 13272.1230 - val_mean_absolute_error: 13272.1230\n",
      "Epoch 472/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9112.0869 - mean_absolute_error: 9112.0869  \n",
      "Epoch 472: val_loss improved from 13271.06055 to 13257.49707, saving model to Weights-00472--13257.49707.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9325.6484 - mean_absolute_error: 9325.6484 - val_loss: 13257.4971 - val_mean_absolute_error: 13257.4971\n",
      "Epoch 473/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9524.4131 - mean_absolute_error: 9524.4131\n",
      "Epoch 473: val_loss did not improve from 13257.49707\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9375.9180 - mean_absolute_error: 9375.9180 - val_loss: 13274.6875 - val_mean_absolute_error: 13274.6875\n",
      "Epoch 474/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9338.5898 - mean_absolute_error: 9338.5898\n",
      "Epoch 474: val_loss did not improve from 13257.49707\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9415.9824 - mean_absolute_error: 9415.9824 - val_loss: 13525.4941 - val_mean_absolute_error: 13525.4941\n",
      "Epoch 475/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9661.4209 - mean_absolute_error: 9661.4209  \n",
      "Epoch 475: val_loss did not improve from 13257.49707\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9486.5244 - mean_absolute_error: 9486.5244 - val_loss: 13510.6533 - val_mean_absolute_error: 13510.6533\n",
      "Epoch 476/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9211.1855 - mean_absolute_error: 9211.1855  \n",
      "Epoch 476: val_loss did not improve from 13257.49707\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9348.9473 - mean_absolute_error: 9348.9473 - val_loss: 13847.2549 - val_mean_absolute_error: 13847.2549\n",
      "Epoch 477/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9178.6348 - mean_absolute_error: 9178.6348\n",
      "Epoch 477: val_loss did not improve from 13257.49707\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9403.0459 - mean_absolute_error: 9403.0459 - val_loss: 13288.1836 - val_mean_absolute_error: 13288.1836\n",
      "Epoch 478/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9567.0547 - mean_absolute_error: 9567.0547\n",
      "Epoch 478: val_loss did not improve from 13257.49707\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9670.0283 - mean_absolute_error: 9670.0283 - val_loss: 13272.0469 - val_mean_absolute_error: 13272.0469\n",
      "Epoch 479/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9449.3760 - mean_absolute_error: 9449.3760  \n",
      "Epoch 479: val_loss did not improve from 13257.49707\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9360.9111 - mean_absolute_error: 9360.9111 - val_loss: 13312.1816 - val_mean_absolute_error: 13312.1816\n",
      "Epoch 480/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9465.9365 - mean_absolute_error: 9465.9365\n",
      "Epoch 480: val_loss improved from 13257.49707 to 13249.07324, saving model to Weights-00480--13249.07324.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9329.5312 - mean_absolute_error: 9329.5312 - val_loss: 13249.0732 - val_mean_absolute_error: 13249.0732\n",
      "Epoch 481/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8970.8369 - mean_absolute_error: 8970.8369  \n",
      "Epoch 481: val_loss did not improve from 13249.07324\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9304.8135 - mean_absolute_error: 9304.8135 - val_loss: 13250.1885 - val_mean_absolute_error: 13250.1885\n",
      "Epoch 482/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 9910.8984 - mean_absolute_error: 9910.8984\n",
      "Epoch 482: val_loss did not improve from 13249.07324\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9316.1045 - mean_absolute_error: 9316.1045 - val_loss: 13266.7139 - val_mean_absolute_error: 13266.7139\n",
      "Epoch 483/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9356.8506 - mean_absolute_error: 9356.8506\n",
      "Epoch 483: val_loss did not improve from 13249.07324\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9350.3203 - mean_absolute_error: 9350.3203 - val_loss: 13263.9395 - val_mean_absolute_error: 13263.9395\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 9358.4180 - mean_absolute_error: 9358.4180\n",
      "Epoch 484: val_loss did not improve from 13249.07324\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9358.4180 - mean_absolute_error: 9358.4180 - val_loss: 13284.8770 - val_mean_absolute_error: 13284.8770\n",
      "Epoch 485/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9138.3496 - mean_absolute_error: 9138.3496  \n",
      "Epoch 485: val_loss did not improve from 13249.07324\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9330.9434 - mean_absolute_error: 9330.9434 - val_loss: 13264.9189 - val_mean_absolute_error: 13264.9189\n",
      "Epoch 486/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9001.2578 - mean_absolute_error: 9001.2578  \n",
      "Epoch 486: val_loss improved from 13249.07324 to 13233.92090, saving model to Weights-00486--13233.92090.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9309.5713 - mean_absolute_error: 9309.5713 - val_loss: 13233.9209 - val_mean_absolute_error: 13233.9209\n",
      "Epoch 487/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9030.7236 - mean_absolute_error: 9030.7236\n",
      "Epoch 487: val_loss did not improve from 13233.92090\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9235.1768 - mean_absolute_error: 9235.1768 - val_loss: 13386.3115 - val_mean_absolute_error: 13386.3115\n",
      "Epoch 488/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9312.3711 - mean_absolute_error: 9312.3711\n",
      "Epoch 488: val_loss did not improve from 13233.92090\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9478.0938 - mean_absolute_error: 9478.0938 - val_loss: 13596.2637 - val_mean_absolute_error: 13596.2637\n",
      "Epoch 489/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9875.1113 - mean_absolute_error: 9875.1113  \n",
      "Epoch 489: val_loss did not improve from 13233.92090\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9710.0498 - mean_absolute_error: 9710.0498 - val_loss: 13347.0059 - val_mean_absolute_error: 13347.0059\n",
      "Epoch 490/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9079.6611 - mean_absolute_error: 9079.6611\n",
      "Epoch 490: val_loss did not improve from 13233.92090\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9332.2764 - mean_absolute_error: 9332.2764 - val_loss: 13234.4268 - val_mean_absolute_error: 13234.4268\n",
      "Epoch 491/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9304.6836 - mean_absolute_error: 9304.6836\n",
      "Epoch 491: val_loss did not improve from 13233.92090\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9493.7051 - mean_absolute_error: 9493.7051 - val_loss: 13317.3037 - val_mean_absolute_error: 13317.3037\n",
      "Epoch 492/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 9532.2217 - mean_absolute_error: 9532.2217  \n",
      "Epoch 492: val_loss did not improve from 13233.92090\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9692.5361 - mean_absolute_error: 9692.5361 - val_loss: 13236.0234 - val_mean_absolute_error: 13236.0234\n",
      "Epoch 493/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9234.3535 - mean_absolute_error: 9234.3535\n",
      "Epoch 493: val_loss improved from 13233.92090 to 13231.01270, saving model to Weights-00493--13231.01270.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9265.4375 - mean_absolute_error: 9265.4375 - val_loss: 13231.0127 - val_mean_absolute_error: 13231.0127\n",
      "Epoch 494/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9579.1963 - mean_absolute_error: 9579.1963\n",
      "Epoch 494: val_loss did not improve from 13231.01270\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9305.1055 - mean_absolute_error: 9305.1055 - val_loss: 13295.2402 - val_mean_absolute_error: 13295.2402\n",
      "Epoch 495/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9391.2861 - mean_absolute_error: 9391.2861  \n",
      "Epoch 495: val_loss did not improve from 13231.01270\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9354.9248 - mean_absolute_error: 9354.9248 - val_loss: 13254.1201 - val_mean_absolute_error: 13254.1201\n",
      "Epoch 496/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9644.7607 - mean_absolute_error: 9644.7607  \n",
      "Epoch 496: val_loss did not improve from 13231.01270\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9438.4111 - mean_absolute_error: 9438.4111 - val_loss: 13340.3896 - val_mean_absolute_error: 13340.3896\n",
      "Epoch 497/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9408.3730 - mean_absolute_error: 9408.3730\n",
      "Epoch 497: val_loss did not improve from 13231.01270\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9461.2598 - mean_absolute_error: 9461.2598 - val_loss: 13238.1523 - val_mean_absolute_error: 13238.1523\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 9360.5410 - mean_absolute_error: 9360.5410  \n",
      "Epoch 498: val_loss did not improve from 13231.01270\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9360.5410 - mean_absolute_error: 9360.5410 - val_loss: 13237.6211 - val_mean_absolute_error: 13237.6211\n",
      "Epoch 499/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9419.8418 - mean_absolute_error: 9419.8418\n",
      "Epoch 499: val_loss did not improve from 13231.01270\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9265.1299 - mean_absolute_error: 9265.1299 - val_loss: 13765.1377 - val_mean_absolute_error: 13765.1377\n",
      "Epoch 500/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9287.4512 - mean_absolute_error: 9287.4512\n",
      "Epoch 500: val_loss did not improve from 13231.01270\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9511.3281 - mean_absolute_error: 9511.3281 - val_loss: 13686.2061 - val_mean_absolute_error: 13686.2061\n",
      "Epoch 501/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9673.1367 - mean_absolute_error: 9673.1367  \n",
      "Epoch 501: val_loss did not improve from 13231.01270\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9453.8555 - mean_absolute_error: 9453.8555 - val_loss: 13327.6992 - val_mean_absolute_error: 13327.6992\n",
      "Epoch 502/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9233.3057 - mean_absolute_error: 9233.3057\n",
      "Epoch 502: val_loss did not improve from 13231.01270\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9234.1201 - mean_absolute_error: 9234.1201 - val_loss: 13252.8154 - val_mean_absolute_error: 13252.8154\n",
      "Epoch 503/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9366.7549 - mean_absolute_error: 9366.7549\n",
      "Epoch 503: val_loss did not improve from 13231.01270\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9386.7051 - mean_absolute_error: 9386.7051 - val_loss: 13244.7705 - val_mean_absolute_error: 13244.7705\n",
      "Epoch 504/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9120.5410 - mean_absolute_error: 9120.5410\n",
      "Epoch 504: val_loss improved from 13231.01270 to 13209.57422, saving model to Weights-00504--13209.57422.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9316.2061 - mean_absolute_error: 9316.2061 - val_loss: 13209.5742 - val_mean_absolute_error: 13209.5742\n",
      "Epoch 505/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9375.9375 - mean_absolute_error: 9375.9375  \n",
      "Epoch 505: val_loss did not improve from 13209.57422\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9368.0693 - mean_absolute_error: 9368.0693 - val_loss: 13383.2246 - val_mean_absolute_error: 13383.2246\n",
      "Epoch 506/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9285.3838 - mean_absolute_error: 9285.3838  \n",
      "Epoch 506: val_loss did not improve from 13209.57422\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9414.9326 - mean_absolute_error: 9414.9326 - val_loss: 13779.6650 - val_mean_absolute_error: 13779.6650\n",
      "Epoch 507/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9828.7354 - mean_absolute_error: 9828.7354\n",
      "Epoch 507: val_loss did not improve from 13209.57422\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9701.8779 - mean_absolute_error: 9701.8779 - val_loss: 13445.8496 - val_mean_absolute_error: 13445.8496\n",
      "Epoch 508/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9536.0234 - mean_absolute_error: 9536.0234\n",
      "Epoch 508: val_loss did not improve from 13209.57422\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9692.9756 - mean_absolute_error: 9692.9756 - val_loss: 13266.7969 - val_mean_absolute_error: 13266.7969\n",
      "Epoch 509/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 8864.0781 - mean_absolute_error: 8864.0781  \n",
      "Epoch 509: val_loss did not improve from 13209.57422\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9402.3682 - mean_absolute_error: 9402.3682 - val_loss: 13249.3867 - val_mean_absolute_error: 13249.3867\n",
      "Epoch 510/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9038.2363 - mean_absolute_error: 9038.2363  \n",
      "Epoch 510: val_loss did not improve from 13209.57422\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9445.3486 - mean_absolute_error: 9445.3486 - val_loss: 13213.8076 - val_mean_absolute_error: 13213.8076\n",
      "Epoch 511/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9736.2676 - mean_absolute_error: 9736.2676  \n",
      "Epoch 511: val_loss improved from 13209.57422 to 13204.88184, saving model to Weights-00511--13204.88184.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9565.0391 - mean_absolute_error: 9565.0391 - val_loss: 13204.8818 - val_mean_absolute_error: 13204.8828\n",
      "Epoch 512/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 8644.1025 - mean_absolute_error: 8644.1025  \n",
      "Epoch 512: val_loss did not improve from 13204.88184\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9289.8086 - mean_absolute_error: 9289.8086 - val_loss: 13251.8311 - val_mean_absolute_error: 13251.8311\n",
      "Epoch 513/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9285.5850 - mean_absolute_error: 9285.5850  \n",
      "Epoch 513: val_loss improved from 13204.88184 to 13199.26953, saving model to Weights-00513--13199.26953.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9283.8369 - mean_absolute_error: 9283.8369 - val_loss: 13199.2695 - val_mean_absolute_error: 13199.2695\n",
      "Epoch 514/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 9386.4170 - mean_absolute_error: 9386.4170  \n",
      "Epoch 514: val_loss did not improve from 13199.26953\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9228.4443 - mean_absolute_error: 9228.4443 - val_loss: 13222.5771 - val_mean_absolute_error: 13222.5771\n",
      "Epoch 515/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9181.0068 - mean_absolute_error: 9181.0068\n",
      "Epoch 515: val_loss did not improve from 13199.26953\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9235.8262 - mean_absolute_error: 9235.8262 - val_loss: 13240.2217 - val_mean_absolute_error: 13240.2217\n",
      "Epoch 516/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9278.8340 - mean_absolute_error: 9278.8340\n",
      "Epoch 516: val_loss did not improve from 13199.26953\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9309.1006 - mean_absolute_error: 9309.1006 - val_loss: 13477.3877 - val_mean_absolute_error: 13477.3877\n",
      "Epoch 517/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9420.3721 - mean_absolute_error: 9420.3721\n",
      "Epoch 517: val_loss did not improve from 13199.26953\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9276.1514 - mean_absolute_error: 9276.1514 - val_loss: 13465.5586 - val_mean_absolute_error: 13465.5586\n",
      "Epoch 518/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9365.9668 - mean_absolute_error: 9365.9668\n",
      "Epoch 518: val_loss improved from 13199.26953 to 13185.32910, saving model to Weights-00518--13185.32910.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9293.1729 - mean_absolute_error: 9293.1729 - val_loss: 13185.3291 - val_mean_absolute_error: 13185.3291\n",
      "Epoch 519/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9423.1836 - mean_absolute_error: 9423.1836  \n",
      "Epoch 519: val_loss did not improve from 13185.32910\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9339.9453 - mean_absolute_error: 9339.9453 - val_loss: 13354.5137 - val_mean_absolute_error: 13354.5137\n",
      "Epoch 520/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9203.6543 - mean_absolute_error: 9203.6543\n",
      "Epoch 520: val_loss did not improve from 13185.32910\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9231.7812 - mean_absolute_error: 9231.7812 - val_loss: 13205.3535 - val_mean_absolute_error: 13205.3535\n",
      "Epoch 521/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9292.2139 - mean_absolute_error: 9292.2139  \n",
      "Epoch 521: val_loss did not improve from 13185.32910\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9237.6699 - mean_absolute_error: 9237.6699 - val_loss: 13192.9609 - val_mean_absolute_error: 13192.9609\n",
      "Epoch 522/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9169.5801 - mean_absolute_error: 9169.5801\n",
      "Epoch 522: val_loss did not improve from 13185.32910\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9263.1768 - mean_absolute_error: 9263.1768 - val_loss: 13229.5127 - val_mean_absolute_error: 13229.5127\n",
      "Epoch 523/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9345.5703 - mean_absolute_error: 9345.5703\n",
      "Epoch 523: val_loss improved from 13185.32910 to 13179.24121, saving model to Weights-00523--13179.24121.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9338.3662 - mean_absolute_error: 9338.3662 - val_loss: 13179.2412 - val_mean_absolute_error: 13179.2412\n",
      "Epoch 524/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 9320.4170 - mean_absolute_error: 9320.4170  \n",
      "Epoch 524: val_loss did not improve from 13179.24121\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9259.9912 - mean_absolute_error: 9259.9912 - val_loss: 13314.4277 - val_mean_absolute_error: 13314.4277\n",
      "Epoch 525/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9663.9238 - mean_absolute_error: 9663.9238\n",
      "Epoch 525: val_loss did not improve from 13179.24121\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9281.9375 - mean_absolute_error: 9281.9375 - val_loss: 13180.8828 - val_mean_absolute_error: 13180.8828\n",
      "Epoch 526/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9055.9473 - mean_absolute_error: 9055.9473\n",
      "Epoch 526: val_loss did not improve from 13179.24121\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9260.7041 - mean_absolute_error: 9260.7041 - val_loss: 13413.1191 - val_mean_absolute_error: 13413.1191\n",
      "Epoch 527/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9742.0107 - mean_absolute_error: 9742.0107  \n",
      "Epoch 527: val_loss did not improve from 13179.24121\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9459.0264 - mean_absolute_error: 9459.0264 - val_loss: 13285.2988 - val_mean_absolute_error: 13285.2988\n",
      "Epoch 528/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9322.5850 - mean_absolute_error: 9322.5850\n",
      "Epoch 528: val_loss improved from 13179.24121 to 13173.70312, saving model to Weights-00528--13173.70312.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9356.7051 - mean_absolute_error: 9356.7051 - val_loss: 13173.7031 - val_mean_absolute_error: 13173.7031\n",
      "Epoch 529/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9164.4229 - mean_absolute_error: 9164.4229  \n",
      "Epoch 529: val_loss did not improve from 13173.70312\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9259.4590 - mean_absolute_error: 9259.4590 - val_loss: 13241.0859 - val_mean_absolute_error: 13241.0859\n",
      "Epoch 530/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9282.0225 - mean_absolute_error: 9282.0225  \n",
      "Epoch 530: val_loss improved from 13173.70312 to 13166.10645, saving model to Weights-00530--13166.10645.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9274.9014 - mean_absolute_error: 9274.9014 - val_loss: 13166.1064 - val_mean_absolute_error: 13166.1064\n",
      "Epoch 531/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9293.7188 - mean_absolute_error: 9293.7188  \n",
      "Epoch 531: val_loss did not improve from 13166.10645\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9215.6777 - mean_absolute_error: 9215.6777 - val_loss: 13194.5928 - val_mean_absolute_error: 13194.5928\n",
      "Epoch 532/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9077.7383 - mean_absolute_error: 9077.7383\n",
      "Epoch 532: val_loss did not improve from 13166.10645\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9226.3223 - mean_absolute_error: 9226.3223 - val_loss: 13269.9531 - val_mean_absolute_error: 13269.9531\n",
      "Epoch 533/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9273.6992 - mean_absolute_error: 9273.6992\n",
      "Epoch 533: val_loss did not improve from 13166.10645\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9316.0195 - mean_absolute_error: 9316.0195 - val_loss: 13339.6885 - val_mean_absolute_error: 13339.6885\n",
      "Epoch 534/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9269.0215 - mean_absolute_error: 9269.0215  \n",
      "Epoch 534: val_loss did not improve from 13166.10645\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9310.2900 - mean_absolute_error: 9310.2900 - val_loss: 13404.3301 - val_mean_absolute_error: 13404.3301\n",
      "Epoch 535/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9609.1992 - mean_absolute_error: 9609.1992  \n",
      "Epoch 535: val_loss did not improve from 13166.10645\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9313.1465 - mean_absolute_error: 9313.1465 - val_loss: 13333.6055 - val_mean_absolute_error: 13333.6055\n",
      "Epoch 536/1000\n",
      "11/18 [=================>............] - ETA: 0s - loss: 9729.5312 - mean_absolute_error: 9729.5312  \n",
      "Epoch 536: val_loss did not improve from 13166.10645\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9445.1553 - mean_absolute_error: 9445.1553 - val_loss: 13364.6182 - val_mean_absolute_error: 13364.6182\n",
      "Epoch 537/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9427.4961 - mean_absolute_error: 9427.4961\n",
      "Epoch 537: val_loss improved from 13166.10645 to 13161.50781, saving model to Weights-00537--13161.50781.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9366.5625 - mean_absolute_error: 9366.5625 - val_loss: 13161.5078 - val_mean_absolute_error: 13161.5078\n",
      "Epoch 538/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 10046.6582 - mean_absolute_error: 10046.6582\n",
      "Epoch 538: val_loss improved from 13161.50781 to 13136.50391, saving model to Weights-00538--13136.50391.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9582.3926 - mean_absolute_error: 9582.3926 - val_loss: 13136.5039 - val_mean_absolute_error: 13136.5039\n",
      "Epoch 539/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9414.6621 - mean_absolute_error: 9414.6621  \n",
      "Epoch 539: val_loss did not improve from 13136.50391\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9272.0264 - mean_absolute_error: 9272.0264 - val_loss: 13157.6377 - val_mean_absolute_error: 13157.6377\n",
      "Epoch 540/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8980.3301 - mean_absolute_error: 8980.3301  \n",
      "Epoch 540: val_loss did not improve from 13136.50391\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9235.9043 - mean_absolute_error: 9235.9043 - val_loss: 13205.3516 - val_mean_absolute_error: 13205.3516\n",
      "Epoch 541/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9163.0254 - mean_absolute_error: 9163.0254\n",
      "Epoch 541: val_loss improved from 13136.50391 to 13127.58398, saving model to Weights-00541--13127.58398.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9298.7256 - mean_absolute_error: 9298.7256 - val_loss: 13127.5840 - val_mean_absolute_error: 13127.5840\n",
      "Epoch 542/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9366.0869 - mean_absolute_error: 9366.0869\n",
      "Epoch 542: val_loss did not improve from 13127.58398\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9260.5264 - mean_absolute_error: 9260.5264 - val_loss: 13144.9453 - val_mean_absolute_error: 13144.9453\n",
      "Epoch 543/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9228.9619 - mean_absolute_error: 9228.9619  \n",
      "Epoch 543: val_loss did not improve from 13127.58398\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9218.6865 - mean_absolute_error: 9218.6865 - val_loss: 13205.4531 - val_mean_absolute_error: 13205.4531\n",
      "Epoch 544/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9697.5732 - mean_absolute_error: 9697.5732\n",
      "Epoch 544: val_loss improved from 13127.58398 to 13126.07812, saving model to Weights-00544--13126.07812.hdf5\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 9309.9277 - mean_absolute_error: 9309.9277 - val_loss: 13126.0781 - val_mean_absolute_error: 13126.0781\n",
      "Epoch 545/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 8904.6758 - mean_absolute_error: 8904.6758\n",
      "Epoch 545: val_loss did not improve from 13126.07812\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9441.9229 - mean_absolute_error: 9441.9229 - val_loss: 13354.8428 - val_mean_absolute_error: 13354.8428\n",
      "Epoch 546/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9068.3896 - mean_absolute_error: 9068.3896  \n",
      "Epoch 546: val_loss did not improve from 13126.07812\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9308.9482 - mean_absolute_error: 9308.9482 - val_loss: 13192.7432 - val_mean_absolute_error: 13192.7432\n",
      "Epoch 547/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9423.7617 - mean_absolute_error: 9423.7617\n",
      "Epoch 547: val_loss did not improve from 13126.07812\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9242.5488 - mean_absolute_error: 9242.5488 - val_loss: 13145.1553 - val_mean_absolute_error: 13145.1543\n",
      "Epoch 548/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9058.5498 - mean_absolute_error: 9058.5498  \n",
      "Epoch 548: val_loss improved from 13126.07812 to 13116.18262, saving model to Weights-00548--13116.18262.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9231.2109 - mean_absolute_error: 9231.2109 - val_loss: 13116.1826 - val_mean_absolute_error: 13116.1826\n",
      "Epoch 549/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 9507.3066 - mean_absolute_error: 9507.3066\n",
      "Epoch 549: val_loss did not improve from 13116.18262\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9363.5869 - mean_absolute_error: 9363.5869 - val_loss: 13124.7129 - val_mean_absolute_error: 13124.7129\n",
      "Epoch 550/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9478.7754 - mean_absolute_error: 9478.7754\n",
      "Epoch 550: val_loss did not improve from 13116.18262\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9333.7539 - mean_absolute_error: 9333.7539 - val_loss: 13121.1787 - val_mean_absolute_error: 13121.1787\n",
      "Epoch 551/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8937.9268 - mean_absolute_error: 8937.9268  \n",
      "Epoch 551: val_loss did not improve from 13116.18262\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9270.9307 - mean_absolute_error: 9270.9307 - val_loss: 13118.1406 - val_mean_absolute_error: 13118.1406\n",
      "Epoch 552/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9131.5605 - mean_absolute_error: 9131.5605\n",
      "Epoch 552: val_loss did not improve from 13116.18262\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9276.2510 - mean_absolute_error: 9276.2510 - val_loss: 13136.9238 - val_mean_absolute_error: 13136.9238\n",
      "Epoch 553/1000\n",
      " 8/18 [============>.................] - ETA: 0s - loss: 9084.6533 - mean_absolute_error: 9084.6533\n",
      "Epoch 553: val_loss improved from 13116.18262 to 13106.11133, saving model to Weights-00553--13106.11133.hdf5\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 9215.8496 - mean_absolute_error: 9215.8496 - val_loss: 13106.1113 - val_mean_absolute_error: 13106.1113\n",
      "Epoch 554/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8983.5322 - mean_absolute_error: 8983.5322\n",
      "Epoch 554: val_loss did not improve from 13106.11133\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9190.6328 - mean_absolute_error: 9190.6328 - val_loss: 13410.6221 - val_mean_absolute_error: 13410.6221\n",
      "Epoch 555/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9328.1055 - mean_absolute_error: 9328.1055  \n",
      "Epoch 555: val_loss did not improve from 13106.11133\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9195.7012 - mean_absolute_error: 9195.7012 - val_loss: 13119.4893 - val_mean_absolute_error: 13119.4893\n",
      "Epoch 556/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9334.6123 - mean_absolute_error: 9334.6123\n",
      "Epoch 556: val_loss did not improve from 13106.11133\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9201.9111 - mean_absolute_error: 9201.9111 - val_loss: 13106.6885 - val_mean_absolute_error: 13106.6885\n",
      "Epoch 557/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9129.4990 - mean_absolute_error: 9129.4990\n",
      "Epoch 557: val_loss did not improve from 13106.11133\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9217.1689 - mean_absolute_error: 9217.1689 - val_loss: 13186.0732 - val_mean_absolute_error: 13186.0732\n",
      "Epoch 558/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9226.3057 - mean_absolute_error: 9226.3057  \n",
      "Epoch 558: val_loss did not improve from 13106.11133\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9246.9424 - mean_absolute_error: 9246.9424 - val_loss: 13330.4648 - val_mean_absolute_error: 13330.4648\n",
      "Epoch 559/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9807.8262 - mean_absolute_error: 9807.8262  \n",
      "Epoch 559: val_loss did not improve from 13106.11133\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9368.1162 - mean_absolute_error: 9368.1162 - val_loss: 13338.4668 - val_mean_absolute_error: 13338.4668\n",
      "Epoch 560/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9090.9961 - mean_absolute_error: 9090.9961\n",
      "Epoch 560: val_loss did not improve from 13106.11133\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9211.0176 - mean_absolute_error: 9211.0176 - val_loss: 13125.0898 - val_mean_absolute_error: 13125.0898\n",
      "Epoch 561/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9406.9014 - mean_absolute_error: 9406.9014  \n",
      "Epoch 561: val_loss did not improve from 13106.11133\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9233.2861 - mean_absolute_error: 9233.2861 - val_loss: 13156.6758 - val_mean_absolute_error: 13156.6758\n",
      "Epoch 562/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9282.5742 - mean_absolute_error: 9282.5742\n",
      "Epoch 562: val_loss did not improve from 13106.11133\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9294.3232 - mean_absolute_error: 9294.3232 - val_loss: 13112.6396 - val_mean_absolute_error: 13112.6396\n",
      "Epoch 563/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9188.8584 - mean_absolute_error: 9188.8584\n",
      "Epoch 563: val_loss did not improve from 13106.11133\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9233.6943 - mean_absolute_error: 9233.6943 - val_loss: 13221.5967 - val_mean_absolute_error: 13221.5967\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 9142.4404 - mean_absolute_error: 9142.4404 \n",
      "Epoch 564: val_loss improved from 13106.11133 to 13100.48730, saving model to Weights-00564--13100.48730.hdf5\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 9142.4404 - mean_absolute_error: 9142.4404 - val_loss: 13100.4873 - val_mean_absolute_error: 13100.4873\n",
      "Epoch 565/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9465.3105 - mean_absolute_error: 9465.3105\n",
      "Epoch 565: val_loss did not improve from 13100.48730\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9195.2227 - mean_absolute_error: 9195.2227 - val_loss: 13144.4951 - val_mean_absolute_error: 13144.4951\n",
      "Epoch 566/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9180.0391 - mean_absolute_error: 9180.0391\n",
      "Epoch 566: val_loss did not improve from 13100.48730\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9188.2549 - mean_absolute_error: 9188.2549 - val_loss: 13294.9141 - val_mean_absolute_error: 13294.9141\n",
      "Epoch 567/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9190.7822 - mean_absolute_error: 9190.7822\n",
      "Epoch 567: val_loss did not improve from 13100.48730\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9361.6406 - mean_absolute_error: 9361.6406 - val_loss: 13539.4414 - val_mean_absolute_error: 13539.4414\n",
      "Epoch 568/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9653.4365 - mean_absolute_error: 9653.4365  \n",
      "Epoch 568: val_loss did not improve from 13100.48730\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9624.7002 - mean_absolute_error: 9624.7002 - val_loss: 13730.5605 - val_mean_absolute_error: 13730.5605\n",
      "Epoch 569/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9419.8838 - mean_absolute_error: 9419.8838\n",
      "Epoch 569: val_loss improved from 13100.48730 to 13098.85449, saving model to Weights-00569--13098.85449.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9329.8555 - mean_absolute_error: 9329.8555 - val_loss: 13098.8545 - val_mean_absolute_error: 13098.8545\n",
      "Epoch 570/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9404.9619 - mean_absolute_error: 9404.9619  \n",
      "Epoch 570: val_loss did not improve from 13098.85449\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9301.1523 - mean_absolute_error: 9301.1523 - val_loss: 13129.2432 - val_mean_absolute_error: 13129.2432\n",
      "Epoch 571/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9098.6855 - mean_absolute_error: 9098.6855\n",
      "Epoch 571: val_loss did not improve from 13098.85449\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9174.5049 - mean_absolute_error: 9174.5049 - val_loss: 13115.7754 - val_mean_absolute_error: 13115.7754\n",
      "Epoch 572/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9246.6211 - mean_absolute_error: 9246.6211\n",
      "Epoch 572: val_loss improved from 13098.85449 to 13064.02832, saving model to Weights-00572--13064.02832.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9153.1064 - mean_absolute_error: 9153.1064 - val_loss: 13064.0283 - val_mean_absolute_error: 13064.0283\n",
      "Epoch 573/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9329.9873 - mean_absolute_error: 9329.9873\n",
      "Epoch 573: val_loss did not improve from 13064.02832\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9113.5967 - mean_absolute_error: 9113.5967 - val_loss: 13299.5244 - val_mean_absolute_error: 13299.5244\n",
      "Epoch 574/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9383.8994 - mean_absolute_error: 9383.8994  \n",
      "Epoch 574: val_loss did not improve from 13064.02832\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9296.9102 - mean_absolute_error: 9296.9102 - val_loss: 13086.4619 - val_mean_absolute_error: 13086.4619\n",
      "Epoch 575/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9319.2285 - mean_absolute_error: 9319.2285\n",
      "Epoch 575: val_loss did not improve from 13064.02832\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9193.5723 - mean_absolute_error: 9193.5723 - val_loss: 13070.4873 - val_mean_absolute_error: 13070.4873\n",
      "Epoch 576/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9051.9023 - mean_absolute_error: 9051.9023  \n",
      "Epoch 576: val_loss improved from 13064.02832 to 13058.87695, saving model to Weights-00576--13058.87695.hdf5\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9174.8037 - mean_absolute_error: 9174.8037 - val_loss: 13058.8770 - val_mean_absolute_error: 13058.8770\n",
      "Epoch 577/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 9300.2207 - mean_absolute_error: 9300.2207\n",
      "Epoch 577: val_loss did not improve from 13058.87695\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9260.0059 - mean_absolute_error: 9260.0059 - val_loss: 13505.4717 - val_mean_absolute_error: 13505.4717\n",
      "Epoch 578/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8663.8252 - mean_absolute_error: 8663.8252  \n",
      "Epoch 578: val_loss did not improve from 13058.87695\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9190.2383 - mean_absolute_error: 9190.2383 - val_loss: 13073.3711 - val_mean_absolute_error: 13073.3711\n",
      "Epoch 579/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9470.7852 - mean_absolute_error: 9470.7852\n",
      "Epoch 579: val_loss did not improve from 13058.87695\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9356.5430 - mean_absolute_error: 9356.5430 - val_loss: 13100.7061 - val_mean_absolute_error: 13100.7061\n",
      "Epoch 580/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9384.2930 - mean_absolute_error: 9384.2930\n",
      "Epoch 580: val_loss improved from 13058.87695 to 13048.12305, saving model to Weights-00580--13048.12305.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9322.0049 - mean_absolute_error: 9322.0049 - val_loss: 13048.1230 - val_mean_absolute_error: 13048.1230\n",
      "Epoch 581/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9291.8018 - mean_absolute_error: 9291.8018  \n",
      "Epoch 581: val_loss did not improve from 13048.12305\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9211.3779 - mean_absolute_error: 9211.3779 - val_loss: 13247.5195 - val_mean_absolute_error: 13247.5195\n",
      "Epoch 582/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9364.2422 - mean_absolute_error: 9364.2422  \n",
      "Epoch 582: val_loss improved from 13048.12305 to 13042.50879, saving model to Weights-00582--13042.50879.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9202.9551 - mean_absolute_error: 9202.9551 - val_loss: 13042.5088 - val_mean_absolute_error: 13042.5088\n",
      "Epoch 583/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9354.8564 - mean_absolute_error: 9354.8564  \n",
      "Epoch 583: val_loss improved from 13042.50879 to 13027.53906, saving model to Weights-00583--13027.53906.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9184.5479 - mean_absolute_error: 9184.5479 - val_loss: 13027.5391 - val_mean_absolute_error: 13027.5391\n",
      "Epoch 584/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9267.3496 - mean_absolute_error: 9267.3496  \n",
      "Epoch 584: val_loss did not improve from 13027.53906\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9271.6621 - mean_absolute_error: 9271.6621 - val_loss: 13098.1729 - val_mean_absolute_error: 13098.1729\n",
      "Epoch 585/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9479.1660 - mean_absolute_error: 9479.1660\n",
      "Epoch 585: val_loss did not improve from 13027.53906\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9394.3584 - mean_absolute_error: 9394.3584 - val_loss: 13111.6094 - val_mean_absolute_error: 13111.6094\n",
      "Epoch 586/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9046.9404 - mean_absolute_error: 9046.9404  \n",
      "Epoch 586: val_loss did not improve from 13027.53906\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9218.0762 - mean_absolute_error: 9218.0762 - val_loss: 13035.3701 - val_mean_absolute_error: 13035.3701\n",
      "Epoch 587/1000\n",
      "11/18 [=================>............] - ETA: 0s - loss: 9050.4814 - mean_absolute_error: 9050.4814\n",
      "Epoch 587: val_loss did not improve from 13027.53906\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9279.5195 - mean_absolute_error: 9279.5195 - val_loss: 13042.8662 - val_mean_absolute_error: 13042.8662\n",
      "Epoch 588/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 9408.4307 - mean_absolute_error: 9408.4307  \n",
      "Epoch 588: val_loss improved from 13027.53906 to 13025.62012, saving model to Weights-00588--13025.62012.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9212.1035 - mean_absolute_error: 9212.1035 - val_loss: 13025.6201 - val_mean_absolute_error: 13025.6201\n",
      "Epoch 589/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9128.7510 - mean_absolute_error: 9128.7510\n",
      "Epoch 589: val_loss did not improve from 13025.62012\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9212.3711 - mean_absolute_error: 9212.3711 - val_loss: 13032.2148 - val_mean_absolute_error: 13032.2148\n",
      "Epoch 590/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9167.7930 - mean_absolute_error: 9167.7930\n",
      "Epoch 590: val_loss did not improve from 13025.62012\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9194.9482 - mean_absolute_error: 9194.9482 - val_loss: 13032.4287 - val_mean_absolute_error: 13032.4287\n",
      "Epoch 591/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9189.9639 - mean_absolute_error: 9189.9639  \n",
      "Epoch 591: val_loss did not improve from 13025.62012\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9175.3555 - mean_absolute_error: 9175.3555 - val_loss: 13042.4473 - val_mean_absolute_error: 13042.4473\n",
      "Epoch 592/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9066.3936 - mean_absolute_error: 9066.3936\n",
      "Epoch 592: val_loss did not improve from 13025.62012\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9226.0986 - mean_absolute_error: 9226.0986 - val_loss: 13027.6318 - val_mean_absolute_error: 13027.6318\n",
      "Epoch 593/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9269.6484 - mean_absolute_error: 9269.6484\n",
      "Epoch 593: val_loss did not improve from 13025.62012\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9214.9570 - mean_absolute_error: 9214.9570 - val_loss: 13033.9502 - val_mean_absolute_error: 13033.9502\n",
      "Epoch 594/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8960.0625 - mean_absolute_error: 8960.0625\n",
      "Epoch 594: val_loss did not improve from 13025.62012\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9234.9619 - mean_absolute_error: 9234.9619 - val_loss: 13387.9766 - val_mean_absolute_error: 13387.9766\n",
      "Epoch 595/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9442.4404 - mean_absolute_error: 9442.4404\n",
      "Epoch 595: val_loss did not improve from 13025.62012\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9477.9736 - mean_absolute_error: 9477.9736 - val_loss: 13058.7793 - val_mean_absolute_error: 13058.7793\n",
      "Epoch 596/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9566.5156 - mean_absolute_error: 9566.5156\n",
      "Epoch 596: val_loss did not improve from 13025.62012\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9536.4170 - mean_absolute_error: 9536.4170 - val_loss: 13025.7334 - val_mean_absolute_error: 13025.7334\n",
      "Epoch 597/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9164.0010 - mean_absolute_error: 9164.0010\n",
      "Epoch 597: val_loss did not improve from 13025.62012\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9159.9463 - mean_absolute_error: 9159.9463 - val_loss: 13408.2324 - val_mean_absolute_error: 13408.2324\n",
      "Epoch 598/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9326.1465 - mean_absolute_error: 9326.1465\n",
      "Epoch 598: val_loss improved from 13025.62012 to 13001.26172, saving model to Weights-00598--13001.26172.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9231.9287 - mean_absolute_error: 9231.9287 - val_loss: 13001.2617 - val_mean_absolute_error: 13001.2617\n",
      "Epoch 599/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9115.0000 - mean_absolute_error: 9115.0000\n",
      "Epoch 599: val_loss did not improve from 13001.26172\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9203.1699 - mean_absolute_error: 9203.1699 - val_loss: 13206.3926 - val_mean_absolute_error: 13206.3926\n",
      "Epoch 600/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9096.4219 - mean_absolute_error: 9096.4219\n",
      "Epoch 600: val_loss improved from 13001.26172 to 12988.97070, saving model to Weights-00600--12988.97070.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9166.2461 - mean_absolute_error: 9166.2461 - val_loss: 12988.9707 - val_mean_absolute_error: 12988.9707\n",
      "Epoch 601/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9106.6611 - mean_absolute_error: 9106.6611\n",
      "Epoch 601: val_loss did not improve from 12988.97070\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9163.1113 - mean_absolute_error: 9163.1113 - val_loss: 13001.2373 - val_mean_absolute_error: 13001.2373\n",
      "Epoch 602/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9275.4941 - mean_absolute_error: 9275.4941\n",
      "Epoch 602: val_loss did not improve from 12988.97070\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9236.8223 - mean_absolute_error: 9236.8223 - val_loss: 13205.0137 - val_mean_absolute_error: 13205.0137\n",
      "Epoch 603/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 9318.7432 - mean_absolute_error: 9318.7432  \n",
      "Epoch 603: val_loss did not improve from 12988.97070\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9288.4355 - mean_absolute_error: 9288.4355 - val_loss: 13116.4746 - val_mean_absolute_error: 13116.4746\n",
      "Epoch 604/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9114.0771 - mean_absolute_error: 9114.0771\n",
      "Epoch 604: val_loss did not improve from 12988.97070\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9181.5576 - mean_absolute_error: 9181.5576 - val_loss: 13389.7734 - val_mean_absolute_error: 13389.7734\n",
      "Epoch 605/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9349.6172 - mean_absolute_error: 9349.6172\n",
      "Epoch 605: val_loss did not improve from 12988.97070\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9354.7969 - mean_absolute_error: 9354.7969 - val_loss: 13158.5986 - val_mean_absolute_error: 13158.5986\n",
      "Epoch 606/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9331.3428 - mean_absolute_error: 9331.3428  \n",
      "Epoch 606: val_loss did not improve from 12988.97070\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9280.4795 - mean_absolute_error: 9280.4795 - val_loss: 13191.0537 - val_mean_absolute_error: 13191.0537\n",
      "Epoch 607/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9227.4131 - mean_absolute_error: 9227.4131\n",
      "Epoch 607: val_loss did not improve from 12988.97070\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9210.5713 - mean_absolute_error: 9210.5713 - val_loss: 13023.1182 - val_mean_absolute_error: 13023.1182\n",
      "Epoch 608/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9485.2598 - mean_absolute_error: 9485.2598  \n",
      "Epoch 608: val_loss did not improve from 12988.97070\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9270.8379 - mean_absolute_error: 9270.8379 - val_loss: 13004.7852 - val_mean_absolute_error: 13004.7852\n",
      "Epoch 609/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9248.9736 - mean_absolute_error: 9248.9736\n",
      "Epoch 609: val_loss improved from 12988.97070 to 12970.83984, saving model to Weights-00609--12970.83984.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9135.2773 - mean_absolute_error: 9135.2773 - val_loss: 12970.8398 - val_mean_absolute_error: 12970.8398\n",
      "Epoch 610/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9337.9385 - mean_absolute_error: 9337.9385  \n",
      "Epoch 610: val_loss did not improve from 12970.83984\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9147.8564 - mean_absolute_error: 9147.8564 - val_loss: 13006.5801 - val_mean_absolute_error: 13006.5801\n",
      "Epoch 611/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9087.1328 - mean_absolute_error: 9087.1328  \n",
      "Epoch 611: val_loss did not improve from 12970.83984\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9176.3877 - mean_absolute_error: 9176.3877 - val_loss: 13017.7744 - val_mean_absolute_error: 13017.7744\n",
      "Epoch 612/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8485.6895 - mean_absolute_error: 8485.6895\n",
      "Epoch 612: val_loss improved from 12970.83984 to 12967.20898, saving model to Weights-00612--12967.20898.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9161.8066 - mean_absolute_error: 9161.8066 - val_loss: 12967.2090 - val_mean_absolute_error: 12967.2090\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 9299.7734 - mean_absolute_error: 9299.7734\n",
      "Epoch 613: val_loss did not improve from 12967.20898\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9299.7734 - mean_absolute_error: 9299.7734 - val_loss: 13200.3564 - val_mean_absolute_error: 13200.3564\n",
      "Epoch 614/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 9012.9756 - mean_absolute_error: 9012.9756\n",
      "Epoch 614: val_loss did not improve from 12967.20898\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9339.4863 - mean_absolute_error: 9339.4863 - val_loss: 12987.0391 - val_mean_absolute_error: 12987.0391\n",
      "Epoch 615/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9374.3936 - mean_absolute_error: 9374.3936\n",
      "Epoch 615: val_loss did not improve from 12967.20898\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9251.9326 - mean_absolute_error: 9251.9326 - val_loss: 13060.7461 - val_mean_absolute_error: 13060.7461\n",
      "Epoch 616/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9207.5742 - mean_absolute_error: 9207.5742\n",
      "Epoch 616: val_loss did not improve from 12967.20898\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9136.0225 - mean_absolute_error: 9136.0225 - val_loss: 12992.7920 - val_mean_absolute_error: 12992.7920\n",
      "Epoch 617/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9355.8174 - mean_absolute_error: 9355.8174\n",
      "Epoch 617: val_loss did not improve from 12967.20898\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9260.8379 - mean_absolute_error: 9260.8379 - val_loss: 13013.3711 - val_mean_absolute_error: 13013.3711\n",
      "Epoch 618/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9055.1885 - mean_absolute_error: 9055.1885\n",
      "Epoch 618: val_loss did not improve from 12967.20898\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9102.9766 - mean_absolute_error: 9102.9766 - val_loss: 13038.2158 - val_mean_absolute_error: 13038.2158\n",
      "Epoch 619/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9328.4180 - mean_absolute_error: 9328.4180\n",
      "Epoch 619: val_loss did not improve from 12967.20898\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9354.9268 - mean_absolute_error: 9354.9268 - val_loss: 13209.0049 - val_mean_absolute_error: 13209.0049\n",
      "Epoch 620/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9601.3418 - mean_absolute_error: 9601.3418\n",
      "Epoch 620: val_loss did not improve from 12967.20898\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9166.3545 - mean_absolute_error: 9166.3545 - val_loss: 13022.4531 - val_mean_absolute_error: 13022.4531\n",
      "Epoch 621/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9010.7256 - mean_absolute_error: 9010.7256\n",
      "Epoch 621: val_loss did not improve from 12967.20898\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9065.0820 - mean_absolute_error: 9065.0820 - val_loss: 13178.1943 - val_mean_absolute_error: 13178.1943\n",
      "Epoch 622/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9273.6074 - mean_absolute_error: 9273.6074\n",
      "Epoch 622: val_loss did not improve from 12967.20898\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9255.2178 - mean_absolute_error: 9255.2178 - val_loss: 13259.3145 - val_mean_absolute_error: 13259.3145\n",
      "Epoch 623/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9168.8223 - mean_absolute_error: 9168.8223\n",
      "Epoch 623: val_loss did not improve from 12967.20898\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9233.1299 - mean_absolute_error: 9233.1299 - val_loss: 13503.2324 - val_mean_absolute_error: 13503.2324\n",
      "Epoch 624/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9446.4277 - mean_absolute_error: 9446.4277  \n",
      "Epoch 624: val_loss did not improve from 12967.20898\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9375.4531 - mean_absolute_error: 9375.4531 - val_loss: 13590.3037 - val_mean_absolute_error: 13590.3037\n",
      "Epoch 625/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9110.1748 - mean_absolute_error: 9110.1748\n",
      "Epoch 625: val_loss did not improve from 12967.20898\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9288.8691 - mean_absolute_error: 9288.8691 - val_loss: 13076.9492 - val_mean_absolute_error: 13076.9492\n",
      "Epoch 626/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9086.5488 - mean_absolute_error: 9086.5488\n",
      "Epoch 626: val_loss improved from 12967.20898 to 12948.28125, saving model to Weights-00626--12948.28125.hdf5\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 9085.6123 - mean_absolute_error: 9085.6123 - val_loss: 12948.2812 - val_mean_absolute_error: 12948.2812\n",
      "Epoch 627/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9415.9600 - mean_absolute_error: 9415.9600  \n",
      "Epoch 627: val_loss improved from 12948.28125 to 12938.17871, saving model to Weights-00627--12938.17871.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9200.6250 - mean_absolute_error: 9200.6250 - val_loss: 12938.1787 - val_mean_absolute_error: 12938.1787\n",
      "Epoch 628/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9390.6348 - mean_absolute_error: 9390.6348\n",
      "Epoch 628: val_loss did not improve from 12938.17871\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9249.5049 - mean_absolute_error: 9249.5049 - val_loss: 12957.0879 - val_mean_absolute_error: 12957.0879\n",
      "Epoch 629/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9228.9980 - mean_absolute_error: 9228.9980\n",
      "Epoch 629: val_loss improved from 12938.17871 to 12931.15625, saving model to Weights-00629--12931.15625.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9170.3428 - mean_absolute_error: 9170.3428 - val_loss: 12931.1562 - val_mean_absolute_error: 12931.1562\n",
      "Epoch 630/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9269.0664 - mean_absolute_error: 9269.0664\n",
      "Epoch 630: val_loss improved from 12931.15625 to 12912.51562, saving model to Weights-00630--12912.51562.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9113.6660 - mean_absolute_error: 9113.6660 - val_loss: 12912.5156 - val_mean_absolute_error: 12912.5156\n",
      "Epoch 631/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9107.3545 - mean_absolute_error: 9107.3545\n",
      "Epoch 631: val_loss did not improve from 12912.51562\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9144.4365 - mean_absolute_error: 9144.4365 - val_loss: 12940.6426 - val_mean_absolute_error: 12940.6426\n",
      "Epoch 632/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9214.8496 - mean_absolute_error: 9214.8496\n",
      "Epoch 632: val_loss did not improve from 12912.51562\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9101.3418 - mean_absolute_error: 9101.3418 - val_loss: 13207.5898 - val_mean_absolute_error: 13207.5898\n",
      "Epoch 633/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9322.9590 - mean_absolute_error: 9322.9590  \n",
      "Epoch 633: val_loss did not improve from 12912.51562\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9289.1094 - mean_absolute_error: 9289.1094 - val_loss: 12966.2393 - val_mean_absolute_error: 12966.2393\n",
      "Epoch 634/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9240.2500 - mean_absolute_error: 9240.2500  \n",
      "Epoch 634: val_loss did not improve from 12912.51562\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9146.6738 - mean_absolute_error: 9146.6738 - val_loss: 12953.9238 - val_mean_absolute_error: 12953.9238\n",
      "Epoch 635/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9132.9521 - mean_absolute_error: 9132.9521\n",
      "Epoch 635: val_loss did not improve from 12912.51562\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9081.3350 - mean_absolute_error: 9081.3350 - val_loss: 13017.0986 - val_mean_absolute_error: 13017.0986\n",
      "Epoch 636/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 9019.4424 - mean_absolute_error: 9019.4424  \n",
      "Epoch 636: val_loss did not improve from 12912.51562\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9091.5312 - mean_absolute_error: 9091.5312 - val_loss: 12930.3271 - val_mean_absolute_error: 12930.3271\n",
      "Epoch 637/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8951.2559 - mean_absolute_error: 8951.2559\n",
      "Epoch 637: val_loss improved from 12912.51562 to 12898.95996, saving model to Weights-00637--12898.95996.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9155.1260 - mean_absolute_error: 9155.1260 - val_loss: 12898.9600 - val_mean_absolute_error: 12898.9600\n",
      "Epoch 638/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8751.6748 - mean_absolute_error: 8751.6748\n",
      "Epoch 638: val_loss did not improve from 12898.95996\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9174.1992 - mean_absolute_error: 9174.1992 - val_loss: 12934.4141 - val_mean_absolute_error: 12934.4141\n",
      "Epoch 639/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9125.1738 - mean_absolute_error: 9125.1738\n",
      "Epoch 639: val_loss did not improve from 12898.95996\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9082.0605 - mean_absolute_error: 9082.0605 - val_loss: 12959.4424 - val_mean_absolute_error: 12959.4424\n",
      "Epoch 640/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8857.3369 - mean_absolute_error: 8857.3369  \n",
      "Epoch 640: val_loss did not improve from 12898.95996\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9105.5156 - mean_absolute_error: 9105.5156 - val_loss: 12952.0791 - val_mean_absolute_error: 12952.0791\n",
      "Epoch 641/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9005.3691 - mean_absolute_error: 9005.3691  \n",
      "Epoch 641: val_loss improved from 12898.95996 to 12881.90918, saving model to Weights-00641--12881.90918.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9061.2783 - mean_absolute_error: 9061.2783 - val_loss: 12881.9092 - val_mean_absolute_error: 12881.9092\n",
      "Epoch 642/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9055.7705 - mean_absolute_error: 9055.7705  \n",
      "Epoch 642: val_loss did not improve from 12881.90918\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9055.1387 - mean_absolute_error: 9055.1387 - val_loss: 13277.0518 - val_mean_absolute_error: 13277.0518\n",
      "Epoch 643/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9007.0957 - mean_absolute_error: 9007.0957  \n",
      "Epoch 643: val_loss did not improve from 12881.90918\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9254.6650 - mean_absolute_error: 9254.6650 - val_loss: 13129.1436 - val_mean_absolute_error: 13129.1436\n",
      "Epoch 644/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9077.6855 - mean_absolute_error: 9077.6855\n",
      "Epoch 644: val_loss did not improve from 12881.90918\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9122.0732 - mean_absolute_error: 9122.0732 - val_loss: 12884.7402 - val_mean_absolute_error: 12884.7402\n",
      "Epoch 645/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9033.7363 - mean_absolute_error: 9033.7363\n",
      "Epoch 645: val_loss did not improve from 12881.90918\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9150.6973 - mean_absolute_error: 9150.6973 - val_loss: 12903.0674 - val_mean_absolute_error: 12903.0674\n",
      "Epoch 646/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8950.2441 - mean_absolute_error: 8950.2441\n",
      "Epoch 646: val_loss improved from 12881.90918 to 12878.03906, saving model to Weights-00646--12878.03906.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9169.4531 - mean_absolute_error: 9169.4531 - val_loss: 12878.0391 - val_mean_absolute_error: 12878.0391\n",
      "Epoch 647/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9533.3076 - mean_absolute_error: 9533.3076\n",
      "Epoch 647: val_loss improved from 12878.03906 to 12869.82129, saving model to Weights-00647--12869.82129.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9116.1484 - mean_absolute_error: 9116.1484 - val_loss: 12869.8213 - val_mean_absolute_error: 12869.8213\n",
      "Epoch 648/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 8770.7930 - mean_absolute_error: 8770.7930\n",
      "Epoch 648: val_loss did not improve from 12869.82129\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9159.0566 - mean_absolute_error: 9159.0566 - val_loss: 12897.6035 - val_mean_absolute_error: 12897.6035\n",
      "Epoch 649/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9019.2061 - mean_absolute_error: 9019.2061\n",
      "Epoch 649: val_loss did not improve from 12869.82129\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9169.3604 - mean_absolute_error: 9169.3604 - val_loss: 12892.3672 - val_mean_absolute_error: 12892.3672\n",
      "Epoch 650/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9277.1367 - mean_absolute_error: 9277.1367\n",
      "Epoch 650: val_loss did not improve from 12869.82129\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9143.9580 - mean_absolute_error: 9143.9580 - val_loss: 12900.3672 - val_mean_absolute_error: 12900.3672\n",
      "Epoch 651/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9092.9541 - mean_absolute_error: 9092.9541\n",
      "Epoch 651: val_loss did not improve from 12869.82129\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9060.7490 - mean_absolute_error: 9060.7490 - val_loss: 12881.3389 - val_mean_absolute_error: 12881.3389\n",
      "Epoch 652/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9116.4395 - mean_absolute_error: 9116.4395\n",
      "Epoch 652: val_loss did not improve from 12869.82129\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9302.7559 - mean_absolute_error: 9302.7559 - val_loss: 13024.1475 - val_mean_absolute_error: 13024.1475\n",
      "Epoch 653/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9110.0225 - mean_absolute_error: 9110.0225\n",
      "Epoch 653: val_loss did not improve from 12869.82129\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 9185.4873 - mean_absolute_error: 9185.4873 - val_loss: 12907.1084 - val_mean_absolute_error: 12907.1084\n",
      "Epoch 654/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9376.9355 - mean_absolute_error: 9376.9355\n",
      "Epoch 654: val_loss did not improve from 12869.82129\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9164.2568 - mean_absolute_error: 9164.2568 - val_loss: 12894.4717 - val_mean_absolute_error: 12894.4717\n",
      "Epoch 655/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9060.3301 - mean_absolute_error: 9060.3301\n",
      "Epoch 655: val_loss did not improve from 12869.82129\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9264.8350 - mean_absolute_error: 9264.8350 - val_loss: 12898.5391 - val_mean_absolute_error: 12898.5391\n",
      "Epoch 656/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9297.3164 - mean_absolute_error: 9297.3164\n",
      "Epoch 656: val_loss improved from 12869.82129 to 12858.03809, saving model to Weights-00656--12858.03809.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9091.1162 - mean_absolute_error: 9091.1162 - val_loss: 12858.0381 - val_mean_absolute_error: 12858.0381\n",
      "Epoch 657/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9210.5889 - mean_absolute_error: 9210.5889\n",
      "Epoch 657: val_loss did not improve from 12858.03809\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9083.5430 - mean_absolute_error: 9083.5430 - val_loss: 13037.4424 - val_mean_absolute_error: 13037.4424\n",
      "Epoch 658/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9345.6191 - mean_absolute_error: 9345.6191  \n",
      "Epoch 658: val_loss did not improve from 12858.03809\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9308.2285 - mean_absolute_error: 9308.2285 - val_loss: 12947.0186 - val_mean_absolute_error: 12947.0186\n",
      "Epoch 659/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9246.1562 - mean_absolute_error: 9246.1562\n",
      "Epoch 659: val_loss did not improve from 12858.03809\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9156.7744 - mean_absolute_error: 9156.7744 - val_loss: 12902.2236 - val_mean_absolute_error: 12902.2236\n",
      "Epoch 660/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9302.5586 - mean_absolute_error: 9302.5586\n",
      "Epoch 660: val_loss improved from 12858.03809 to 12846.98438, saving model to Weights-00660--12846.98438.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9031.7861 - mean_absolute_error: 9031.7861 - val_loss: 12846.9844 - val_mean_absolute_error: 12846.9844\n",
      "Epoch 661/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9047.0508 - mean_absolute_error: 9047.0508\n",
      "Epoch 661: val_loss improved from 12846.98438 to 12829.30762, saving model to Weights-00661--12829.30762.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9053.7471 - mean_absolute_error: 9053.7471 - val_loss: 12829.3076 - val_mean_absolute_error: 12829.3076\n",
      "Epoch 662/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8965.3105 - mean_absolute_error: 8965.3105  \n",
      "Epoch 662: val_loss did not improve from 12829.30762\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9047.5566 - mean_absolute_error: 9047.5566 - val_loss: 12887.7676 - val_mean_absolute_error: 12887.7676\n",
      "Epoch 663/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9374.4746 - mean_absolute_error: 9374.4746\n",
      "Epoch 663: val_loss did not improve from 12829.30762\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9147.2598 - mean_absolute_error: 9147.2598 - val_loss: 12908.7471 - val_mean_absolute_error: 12908.7471\n",
      "Epoch 664/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 8879.3164 - mean_absolute_error: 8879.3164  \n",
      "Epoch 664: val_loss did not improve from 12829.30762\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9097.3818 - mean_absolute_error: 9097.3818 - val_loss: 12831.9336 - val_mean_absolute_error: 12831.9336\n",
      "Epoch 665/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9127.1084 - mean_absolute_error: 9127.1084\n",
      "Epoch 665: val_loss did not improve from 12829.30762\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9054.6729 - mean_absolute_error: 9054.6729 - val_loss: 12865.9482 - val_mean_absolute_error: 12865.9482\n",
      "Epoch 666/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9122.5234 - mean_absolute_error: 9122.5234\n",
      "Epoch 666: val_loss did not improve from 12829.30762\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9118.5322 - mean_absolute_error: 9118.5322 - val_loss: 12863.2773 - val_mean_absolute_error: 12863.2773\n",
      "Epoch 667/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8936.2402 - mean_absolute_error: 8936.2402\n",
      "Epoch 667: val_loss did not improve from 12829.30762\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9087.2920 - mean_absolute_error: 9087.2920 - val_loss: 12867.9834 - val_mean_absolute_error: 12867.9834\n",
      "Epoch 668/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9154.9785 - mean_absolute_error: 9154.9785  \n",
      "Epoch 668: val_loss did not improve from 12829.30762\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9042.0771 - mean_absolute_error: 9042.0771 - val_loss: 12889.4482 - val_mean_absolute_error: 12889.4482\n",
      "Epoch 669/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9018.2881 - mean_absolute_error: 9018.2881  \n",
      "Epoch 669: val_loss did not improve from 12829.30762\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9127.1270 - mean_absolute_error: 9127.1270 - val_loss: 12943.4844 - val_mean_absolute_error: 12943.4844\n",
      "Epoch 670/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9056.0420 - mean_absolute_error: 9056.0420\n",
      "Epoch 670: val_loss did not improve from 12829.30762\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9080.0361 - mean_absolute_error: 9080.0361 - val_loss: 13008.1797 - val_mean_absolute_error: 13008.1797\n",
      "Epoch 671/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9547.0127 - mean_absolute_error: 9547.0127\n",
      "Epoch 671: val_loss did not improve from 12829.30762\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9259.3799 - mean_absolute_error: 9259.3799 - val_loss: 12867.3369 - val_mean_absolute_error: 12867.3369\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 9100.3750 - mean_absolute_error: 9100.3750 \n",
      "Epoch 672: val_loss did not improve from 12829.30762\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9100.3750 - mean_absolute_error: 9100.3750 - val_loss: 12975.9639 - val_mean_absolute_error: 12975.9639\n",
      "Epoch 673/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9128.0820 - mean_absolute_error: 9128.0820  \n",
      "Epoch 673: val_loss did not improve from 12829.30762\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9126.9014 - mean_absolute_error: 9126.9014 - val_loss: 13125.8887 - val_mean_absolute_error: 13125.8887\n",
      "Epoch 674/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9203.6299 - mean_absolute_error: 9203.6299\n",
      "Epoch 674: val_loss did not improve from 12829.30762\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9117.7051 - mean_absolute_error: 9117.7051 - val_loss: 12862.8613 - val_mean_absolute_error: 12862.8613\n",
      "Epoch 675/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 8729.3135 - mean_absolute_error: 8729.3135\n",
      "Epoch 675: val_loss improved from 12829.30762 to 12813.70996, saving model to Weights-00675--12813.70996.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9141.2695 - mean_absolute_error: 9141.2695 - val_loss: 12813.7100 - val_mean_absolute_error: 12813.7100\n",
      "Epoch 676/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 8932.4404 - mean_absolute_error: 8932.4404\n",
      "Epoch 676: val_loss did not improve from 12813.70996\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9089.9209 - mean_absolute_error: 9089.9209 - val_loss: 12873.6885 - val_mean_absolute_error: 12873.6885\n",
      "Epoch 677/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9175.9229 - mean_absolute_error: 9175.9229  \n",
      "Epoch 677: val_loss did not improve from 12813.70996\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9077.2510 - mean_absolute_error: 9077.2510 - val_loss: 12852.1299 - val_mean_absolute_error: 12852.1299\n",
      "Epoch 678/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9062.4297 - mean_absolute_error: 9062.4297\n",
      "Epoch 678: val_loss did not improve from 12813.70996\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9144.3398 - mean_absolute_error: 9144.3398 - val_loss: 13252.1094 - val_mean_absolute_error: 13252.1094\n",
      "Epoch 679/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9151.6621 - mean_absolute_error: 9151.6621\n",
      "Epoch 679: val_loss did not improve from 12813.70996\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9155.7930 - mean_absolute_error: 9155.7930 - val_loss: 12903.9766 - val_mean_absolute_error: 12903.9766\n",
      "Epoch 680/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9213.6113 - mean_absolute_error: 9213.6113  \n",
      "Epoch 680: val_loss did not improve from 12813.70996\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9216.6445 - mean_absolute_error: 9216.6445 - val_loss: 12992.6553 - val_mean_absolute_error: 12992.6553\n",
      "Epoch 681/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8931.4707 - mean_absolute_error: 8931.4707  \n",
      "Epoch 681: val_loss did not improve from 12813.70996\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9080.9326 - mean_absolute_error: 9080.9326 - val_loss: 12878.6230 - val_mean_absolute_error: 12878.6230\n",
      "Epoch 682/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8989.7910 - mean_absolute_error: 8989.7910\n",
      "Epoch 682: val_loss did not improve from 12813.70996\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9010.7578 - mean_absolute_error: 9010.7578 - val_loss: 12850.2510 - val_mean_absolute_error: 12850.2510\n",
      "Epoch 683/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8758.5322 - mean_absolute_error: 8758.5322\n",
      "Epoch 683: val_loss improved from 12813.70996 to 12811.62793, saving model to Weights-00683--12811.62793.hdf5\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 9116.5840 - mean_absolute_error: 9116.5840 - val_loss: 12811.6279 - val_mean_absolute_error: 12811.6279\n",
      "Epoch 684/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9046.5049 - mean_absolute_error: 9046.5049\n",
      "Epoch 684: val_loss improved from 12811.62793 to 12784.76465, saving model to Weights-00684--12784.76465.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9048.9082 - mean_absolute_error: 9048.9082 - val_loss: 12784.7646 - val_mean_absolute_error: 12784.7646\n",
      "Epoch 685/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9137.7715 - mean_absolute_error: 9137.7715  \n",
      "Epoch 685: val_loss did not improve from 12784.76465\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9134.4180 - mean_absolute_error: 9134.4180 - val_loss: 12941.3945 - val_mean_absolute_error: 12941.3945\n",
      "Epoch 686/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9255.5400 - mean_absolute_error: 9255.5400  \n",
      "Epoch 686: val_loss did not improve from 12784.76465\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9113.7129 - mean_absolute_error: 9113.7129 - val_loss: 12897.3799 - val_mean_absolute_error: 12897.3799\n",
      "Epoch 687/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9151.7490 - mean_absolute_error: 9151.7490\n",
      "Epoch 687: val_loss did not improve from 12784.76465\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9088.4736 - mean_absolute_error: 9088.4736 - val_loss: 12832.8799 - val_mean_absolute_error: 12832.8799\n",
      "Epoch 688/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8648.6895 - mean_absolute_error: 8648.6895\n",
      "Epoch 688: val_loss improved from 12784.76465 to 12780.49902, saving model to Weights-00688--12780.49902.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 8989.9395 - mean_absolute_error: 8989.9395 - val_loss: 12780.4990 - val_mean_absolute_error: 12780.4990\n",
      "Epoch 689/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 8952.3086 - mean_absolute_error: 8952.3086\n",
      "Epoch 689: val_loss did not improve from 12780.49902\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9228.3184 - mean_absolute_error: 9228.3184 - val_loss: 12839.7637 - val_mean_absolute_error: 12839.7637\n",
      "Epoch 690/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9012.5527 - mean_absolute_error: 9012.5527\n",
      "Epoch 690: val_loss did not improve from 12780.49902\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9144.2988 - mean_absolute_error: 9144.2988 - val_loss: 12793.5586 - val_mean_absolute_error: 12793.5586\n",
      "Epoch 691/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9347.6777 - mean_absolute_error: 9347.6777\n",
      "Epoch 691: val_loss did not improve from 12780.49902\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9250.8711 - mean_absolute_error: 9250.8711 - val_loss: 13100.6426 - val_mean_absolute_error: 13100.6426\n",
      "Epoch 692/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9101.2168 - mean_absolute_error: 9101.2168  \n",
      "Epoch 692: val_loss did not improve from 12780.49902\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9095.4814 - mean_absolute_error: 9095.4814 - val_loss: 12856.5059 - val_mean_absolute_error: 12856.5059\n",
      "Epoch 693/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9161.1572 - mean_absolute_error: 9161.1572\n",
      "Epoch 693: val_loss did not improve from 12780.49902\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9079.1689 - mean_absolute_error: 9079.1689 - val_loss: 12961.5283 - val_mean_absolute_error: 12961.5283\n",
      "Epoch 694/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9315.0684 - mean_absolute_error: 9315.0684  \n",
      "Epoch 694: val_loss did not improve from 12780.49902\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9326.5049 - mean_absolute_error: 9326.5049 - val_loss: 13199.3604 - val_mean_absolute_error: 13199.3604\n",
      "Epoch 695/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 10174.0410 - mean_absolute_error: 10174.0410\n",
      "Epoch 695: val_loss did not improve from 12780.49902\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9223.4814 - mean_absolute_error: 9223.4814 - val_loss: 13025.0049 - val_mean_absolute_error: 13025.0049\n",
      "Epoch 696/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9563.5488 - mean_absolute_error: 9563.5488\n",
      "Epoch 696: val_loss did not improve from 12780.49902\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9456.1465 - mean_absolute_error: 9456.1465 - val_loss: 12984.7881 - val_mean_absolute_error: 12984.7881\n",
      "Epoch 697/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9136.1191 - mean_absolute_error: 9136.1191\n",
      "Epoch 697: val_loss did not improve from 12780.49902\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9165.8438 - mean_absolute_error: 9165.8438 - val_loss: 12809.2988 - val_mean_absolute_error: 12809.2988\n",
      "Epoch 698/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9225.3984 - mean_absolute_error: 9225.3984\n",
      "Epoch 698: val_loss did not improve from 12780.49902\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9146.4043 - mean_absolute_error: 9146.4043 - val_loss: 12881.8047 - val_mean_absolute_error: 12881.8047\n",
      "Epoch 699/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9043.1357 - mean_absolute_error: 9043.1357\n",
      "Epoch 699: val_loss did not improve from 12780.49902\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9064.4580 - mean_absolute_error: 9064.4580 - val_loss: 12989.2266 - val_mean_absolute_error: 12989.2256\n",
      "Epoch 700/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9112.7910 - mean_absolute_error: 9112.7910\n",
      "Epoch 700: val_loss did not improve from 12780.49902\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9099.2529 - mean_absolute_error: 9099.2529 - val_loss: 12832.9307 - val_mean_absolute_error: 12832.9307\n",
      "Epoch 701/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9195.6475 - mean_absolute_error: 9195.6475\n",
      "Epoch 701: val_loss did not improve from 12780.49902\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9098.8281 - mean_absolute_error: 9098.8281 - val_loss: 12805.7754 - val_mean_absolute_error: 12805.7754\n",
      "Epoch 702/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9494.3340 - mean_absolute_error: 9494.3340\n",
      "Epoch 702: val_loss did not improve from 12780.49902\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9241.8613 - mean_absolute_error: 9241.8613 - val_loss: 12805.2676 - val_mean_absolute_error: 12805.2676\n",
      "Epoch 703/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9204.4355 - mean_absolute_error: 9204.4355  \n",
      "Epoch 703: val_loss did not improve from 12780.49902\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9010.1885 - mean_absolute_error: 9010.1885 - val_loss: 12827.6377 - val_mean_absolute_error: 12827.6377\n",
      "Epoch 704/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9016.3809 - mean_absolute_error: 9016.3809\n",
      "Epoch 704: val_loss did not improve from 12780.49902\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9035.2529 - mean_absolute_error: 9035.2529 - val_loss: 12835.5566 - val_mean_absolute_error: 12835.5566\n",
      "Epoch 705/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9181.3252 - mean_absolute_error: 9181.3252\n",
      "Epoch 705: val_loss did not improve from 12780.49902\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9101.0273 - mean_absolute_error: 9101.0273 - val_loss: 12972.0547 - val_mean_absolute_error: 12972.0547\n",
      "Epoch 706/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9005.0566 - mean_absolute_error: 9005.0566\n",
      "Epoch 706: val_loss improved from 12780.49902 to 12768.31152, saving model to Weights-00706--12768.31152.hdf5\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 9100.0713 - mean_absolute_error: 9100.0713 - val_loss: 12768.3115 - val_mean_absolute_error: 12768.3115\n",
      "Epoch 707/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9077.5791 - mean_absolute_error: 9077.5791\n",
      "Epoch 707: val_loss did not improve from 12768.31152\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9054.6104 - mean_absolute_error: 9054.6104 - val_loss: 12870.6133 - val_mean_absolute_error: 12870.6133\n",
      "Epoch 708/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9200.3486 - mean_absolute_error: 9200.3486  \n",
      "Epoch 708: val_loss did not improve from 12768.31152\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9074.7900 - mean_absolute_error: 9074.7900 - val_loss: 12864.6836 - val_mean_absolute_error: 12864.6836\n",
      "Epoch 709/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9023.3389 - mean_absolute_error: 9023.3389\n",
      "Epoch 709: val_loss improved from 12768.31152 to 12752.20703, saving model to Weights-00709--12752.20703.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9071.2588 - mean_absolute_error: 9071.2588 - val_loss: 12752.2070 - val_mean_absolute_error: 12752.2070\n",
      "Epoch 710/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9028.7871 - mean_absolute_error: 9028.7871  \n",
      "Epoch 710: val_loss did not improve from 12752.20703\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8995.6953 - mean_absolute_error: 8995.6953 - val_loss: 12808.7695 - val_mean_absolute_error: 12808.7695\n",
      "Epoch 711/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8937.4375 - mean_absolute_error: 8937.4375\n",
      "Epoch 711: val_loss did not improve from 12752.20703\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9184.8438 - mean_absolute_error: 9184.8438 - val_loss: 12891.4824 - val_mean_absolute_error: 12891.4824\n",
      "Epoch 712/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8991.3594 - mean_absolute_error: 8991.3594\n",
      "Epoch 712: val_loss did not improve from 12752.20703\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8984.9414 - mean_absolute_error: 8984.9414 - val_loss: 12763.4180 - val_mean_absolute_error: 12763.4180\n",
      "Epoch 713/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9023.2061 - mean_absolute_error: 9023.2061\n",
      "Epoch 713: val_loss did not improve from 12752.20703\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9112.5537 - mean_absolute_error: 9112.5537 - val_loss: 12814.4346 - val_mean_absolute_error: 12814.4346\n",
      "Epoch 714/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9200.3438 - mean_absolute_error: 9200.3438\n",
      "Epoch 714: val_loss did not improve from 12752.20703\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9104.1914 - mean_absolute_error: 9104.1914 - val_loss: 12802.2656 - val_mean_absolute_error: 12802.2656\n",
      "Epoch 715/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9180.7373 - mean_absolute_error: 9180.7373  \n",
      "Epoch 715: val_loss did not improve from 12752.20703\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9162.3643 - mean_absolute_error: 9162.3643 - val_loss: 13280.1504 - val_mean_absolute_error: 13280.1504\n",
      "Epoch 716/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8844.5850 - mean_absolute_error: 8844.5850\n",
      "Epoch 716: val_loss did not improve from 12752.20703\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9135.3428 - mean_absolute_error: 9135.3428 - val_loss: 12760.3096 - val_mean_absolute_error: 12760.3096\n",
      "Epoch 717/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9213.1836 - mean_absolute_error: 9213.1836\n",
      "Epoch 717: val_loss did not improve from 12752.20703\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9049.5039 - mean_absolute_error: 9049.5039 - val_loss: 12920.5020 - val_mean_absolute_error: 12920.5020\n",
      "Epoch 718/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9098.4287 - mean_absolute_error: 9098.4287  \n",
      "Epoch 718: val_loss did not improve from 12752.20703\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8997.5127 - mean_absolute_error: 8997.5127 - val_loss: 12776.9229 - val_mean_absolute_error: 12776.9229\n",
      "Epoch 719/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9096.9229 - mean_absolute_error: 9096.9229\n",
      "Epoch 719: val_loss did not improve from 12752.20703\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 8970.2490 - mean_absolute_error: 8970.2490 - val_loss: 13008.2451 - val_mean_absolute_error: 13008.2451\n",
      "Epoch 720/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 8837.6396 - mean_absolute_error: 8837.6396\n",
      "Epoch 720: val_loss did not improve from 12752.20703\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9059.7598 - mean_absolute_error: 9059.7598 - val_loss: 12920.7471 - val_mean_absolute_error: 12920.7471\n",
      "Epoch 721/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9127.9873 - mean_absolute_error: 9127.9873\n",
      "Epoch 721: val_loss did not improve from 12752.20703\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9050.2061 - mean_absolute_error: 9050.2061 - val_loss: 12754.6348 - val_mean_absolute_error: 12754.6348\n",
      "Epoch 722/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9185.3828 - mean_absolute_error: 9185.3828\n",
      "Epoch 722: val_loss did not improve from 12752.20703\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9163.3076 - mean_absolute_error: 9163.3076 - val_loss: 12970.0840 - val_mean_absolute_error: 12970.0840\n",
      "Epoch 723/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9321.7061 - mean_absolute_error: 9321.7061  \n",
      "Epoch 723: val_loss improved from 12752.20703 to 12750.64746, saving model to Weights-00723--12750.64746.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9195.5361 - mean_absolute_error: 9195.5361 - val_loss: 12750.6475 - val_mean_absolute_error: 12750.6475\n",
      "Epoch 724/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 8955.5869 - mean_absolute_error: 8955.5869\n",
      "Epoch 724: val_loss improved from 12750.64746 to 12744.30566, saving model to Weights-00724--12744.30566.hdf5\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 8996.6074 - mean_absolute_error: 8996.6074 - val_loss: 12744.3057 - val_mean_absolute_error: 12744.3057\n",
      "Epoch 725/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9149.1533 - mean_absolute_error: 9149.1533\n",
      "Epoch 725: val_loss did not improve from 12744.30566\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9007.2637 - mean_absolute_error: 9007.2637 - val_loss: 12746.1016 - val_mean_absolute_error: 12746.1016\n",
      "Epoch 726/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9056.7559 - mean_absolute_error: 9056.7559\n",
      "Epoch 726: val_loss improved from 12744.30566 to 12721.32520, saving model to Weights-00726--12721.32520.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9029.5068 - mean_absolute_error: 9029.5068 - val_loss: 12721.3252 - val_mean_absolute_error: 12721.3252\n",
      "Epoch 727/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8976.6943 - mean_absolute_error: 8976.6943\n",
      "Epoch 727: val_loss did not improve from 12721.32520\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9068.9092 - mean_absolute_error: 9068.9092 - val_loss: 12778.2959 - val_mean_absolute_error: 12778.2959\n",
      "Epoch 728/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9226.2539 - mean_absolute_error: 9226.2539  \n",
      "Epoch 728: val_loss did not improve from 12721.32520\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8974.1982 - mean_absolute_error: 8974.1982 - val_loss: 12963.2070 - val_mean_absolute_error: 12963.2070\n",
      "Epoch 729/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9302.2744 - mean_absolute_error: 9302.2744  \n",
      "Epoch 729: val_loss did not improve from 12721.32520\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9041.7900 - mean_absolute_error: 9041.7900 - val_loss: 13063.8252 - val_mean_absolute_error: 13063.8252\n",
      "Epoch 730/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 8763.4639 - mean_absolute_error: 8763.4639\n",
      "Epoch 730: val_loss did not improve from 12721.32520\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9234.2227 - mean_absolute_error: 9234.2227 - val_loss: 12830.9297 - val_mean_absolute_error: 12830.9297\n",
      "Epoch 731/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9184.1475 - mean_absolute_error: 9184.1475\n",
      "Epoch 731: val_loss did not improve from 12721.32520\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9117.0889 - mean_absolute_error: 9117.0889 - val_loss: 12736.7930 - val_mean_absolute_error: 12736.7930\n",
      "Epoch 732/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9123.1104 - mean_absolute_error: 9123.1104\n",
      "Epoch 732: val_loss did not improve from 12721.32520\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9033.3721 - mean_absolute_error: 9033.3721 - val_loss: 12946.0137 - val_mean_absolute_error: 12946.0137\n",
      "Epoch 733/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8873.6289 - mean_absolute_error: 8873.6289\n",
      "Epoch 733: val_loss did not improve from 12721.32520\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9058.3398 - mean_absolute_error: 9058.3398 - val_loss: 12737.9707 - val_mean_absolute_error: 12737.9707\n",
      "Epoch 734/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8887.7207 - mean_absolute_error: 8887.7207  \n",
      "Epoch 734: val_loss did not improve from 12721.32520\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9000.9688 - mean_absolute_error: 9000.9688 - val_loss: 12734.8301 - val_mean_absolute_error: 12734.8301\n",
      "Epoch 735/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9273.3799 - mean_absolute_error: 9273.3799\n",
      "Epoch 735: val_loss did not improve from 12721.32520\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9039.1357 - mean_absolute_error: 9039.1357 - val_loss: 12777.6348 - val_mean_absolute_error: 12777.6348\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 9034.0898 - mean_absolute_error: 9034.0898\n",
      "Epoch 736: val_loss did not improve from 12721.32520\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9034.0898 - mean_absolute_error: 9034.0898 - val_loss: 12830.1299 - val_mean_absolute_error: 12830.1299\n",
      "Epoch 737/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9013.6611 - mean_absolute_error: 9013.6611\n",
      "Epoch 737: val_loss did not improve from 12721.32520\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9143.7656 - mean_absolute_error: 9143.7656 - val_loss: 12845.8213 - val_mean_absolute_error: 12845.8213\n",
      "Epoch 738/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9176.8301 - mean_absolute_error: 9176.8301\n",
      "Epoch 738: val_loss did not improve from 12721.32520\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9253.7959 - mean_absolute_error: 9253.7959 - val_loss: 13214.6074 - val_mean_absolute_error: 13214.6084\n",
      "Epoch 739/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9106.8008 - mean_absolute_error: 9106.8008\n",
      "Epoch 739: val_loss did not improve from 12721.32520\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9111.4482 - mean_absolute_error: 9111.4482 - val_loss: 12817.2656 - val_mean_absolute_error: 12817.2656\n",
      "Epoch 740/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9240.2939 - mean_absolute_error: 9240.2939\n",
      "Epoch 740: val_loss improved from 12721.32520 to 12686.92969, saving model to Weights-00740--12686.92969.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9006.1318 - mean_absolute_error: 9006.1318 - val_loss: 12686.9297 - val_mean_absolute_error: 12686.9297\n",
      "Epoch 741/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9102.7246 - mean_absolute_error: 9102.7246  \n",
      "Epoch 741: val_loss did not improve from 12686.92969\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9038.4375 - mean_absolute_error: 9038.4375 - val_loss: 12700.2861 - val_mean_absolute_error: 12700.2861\n",
      "Epoch 742/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9251.4473 - mean_absolute_error: 9251.4473\n",
      "Epoch 742: val_loss did not improve from 12686.92969\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9200.3516 - mean_absolute_error: 9200.3516 - val_loss: 12908.3311 - val_mean_absolute_error: 12908.3311\n",
      "Epoch 743/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9255.3164 - mean_absolute_error: 9255.3164\n",
      "Epoch 743: val_loss did not improve from 12686.92969\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9289.8496 - mean_absolute_error: 9289.8496 - val_loss: 13001.7324 - val_mean_absolute_error: 13001.7324\n",
      "Epoch 744/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9196.1357 - mean_absolute_error: 9196.1357\n",
      "Epoch 744: val_loss did not improve from 12686.92969\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9126.3447 - mean_absolute_error: 9126.3447 - val_loss: 12850.4902 - val_mean_absolute_error: 12850.4902\n",
      "Epoch 745/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9144.8184 - mean_absolute_error: 9144.8184\n",
      "Epoch 745: val_loss did not improve from 12686.92969\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9086.2383 - mean_absolute_error: 9086.2383 - val_loss: 12735.4492 - val_mean_absolute_error: 12735.4492\n",
      "Epoch 746/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 8960.5820 - mean_absolute_error: 8960.5820\n",
      "Epoch 746: val_loss did not improve from 12686.92969\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8971.4658 - mean_absolute_error: 8971.4658 - val_loss: 12981.4824 - val_mean_absolute_error: 12981.4824\n",
      "Epoch 747/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8750.7998 - mean_absolute_error: 8750.7998\n",
      "Epoch 747: val_loss did not improve from 12686.92969\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8986.5312 - mean_absolute_error: 8986.5312 - val_loss: 12732.8291 - val_mean_absolute_error: 12732.8291\n",
      "Epoch 748/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8810.9141 - mean_absolute_error: 8810.9141\n",
      "Epoch 748: val_loss did not improve from 12686.92969\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8997.1201 - mean_absolute_error: 8997.1201 - val_loss: 12753.0264 - val_mean_absolute_error: 12753.0264\n",
      "Epoch 749/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9085.7715 - mean_absolute_error: 9085.7715\n",
      "Epoch 749: val_loss did not improve from 12686.92969\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9011.2080 - mean_absolute_error: 9011.2080 - val_loss: 12692.4795 - val_mean_absolute_error: 12692.4795\n",
      "Epoch 750/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8860.2285 - mean_absolute_error: 8860.2285\n",
      "Epoch 750: val_loss did not improve from 12686.92969\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8987.6475 - mean_absolute_error: 8987.6475 - val_loss: 12981.7773 - val_mean_absolute_error: 12981.7773\n",
      "Epoch 751/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9051.0449 - mean_absolute_error: 9051.0449\n",
      "Epoch 751: val_loss did not improve from 12686.92969\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9023.8135 - mean_absolute_error: 9023.8135 - val_loss: 12807.1689 - val_mean_absolute_error: 12807.1689\n",
      "Epoch 752/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9021.4717 - mean_absolute_error: 9021.4717\n",
      "Epoch 752: val_loss did not improve from 12686.92969\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8973.2354 - mean_absolute_error: 8973.2354 - val_loss: 12762.0693 - val_mean_absolute_error: 12762.0693\n",
      "Epoch 753/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9081.5781 - mean_absolute_error: 9081.5781\n",
      "Epoch 753: val_loss did not improve from 12686.92969\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9079.6299 - mean_absolute_error: 9079.6299 - val_loss: 12772.3057 - val_mean_absolute_error: 12772.3057\n",
      "Epoch 754/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9259.7432 - mean_absolute_error: 9259.7432\n",
      "Epoch 754: val_loss did not improve from 12686.92969\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9089.2900 - mean_absolute_error: 9089.2900 - val_loss: 12687.5420 - val_mean_absolute_error: 12687.5420\n",
      "Epoch 755/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9045.7734 - mean_absolute_error: 9045.7734\n",
      "Epoch 755: val_loss did not improve from 12686.92969\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9001.2764 - mean_absolute_error: 9001.2764 - val_loss: 12727.9062 - val_mean_absolute_error: 12727.9062\n",
      "Epoch 756/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9255.4619 - mean_absolute_error: 9255.4619  \n",
      "Epoch 756: val_loss did not improve from 12686.92969\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9179.2539 - mean_absolute_error: 9179.2539 - val_loss: 12852.9951 - val_mean_absolute_error: 12852.9951\n",
      "Epoch 757/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9021.2500 - mean_absolute_error: 9021.2500\n",
      "Epoch 757: val_loss did not improve from 12686.92969\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9104.5762 - mean_absolute_error: 9104.5762 - val_loss: 12725.3496 - val_mean_absolute_error: 12725.3496\n",
      "Epoch 758/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8857.7070 - mean_absolute_error: 8857.7070\n",
      "Epoch 758: val_loss improved from 12686.92969 to 12663.68262, saving model to Weights-00758--12663.68262.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8971.0439 - mean_absolute_error: 8971.0439 - val_loss: 12663.6826 - val_mean_absolute_error: 12663.6826\n",
      "Epoch 759/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8908.2637 - mean_absolute_error: 8908.2637\n",
      "Epoch 759: val_loss did not improve from 12663.68262\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8965.1250 - mean_absolute_error: 8965.1250 - val_loss: 12724.3594 - val_mean_absolute_error: 12724.3594\n",
      "Epoch 760/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9563.3799 - mean_absolute_error: 9563.3799\n",
      "Epoch 760: val_loss did not improve from 12663.68262\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9040.5791 - mean_absolute_error: 9040.5791 - val_loss: 12752.9824 - val_mean_absolute_error: 12752.9824\n",
      "Epoch 761/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9045.1035 - mean_absolute_error: 9045.1035\n",
      "Epoch 761: val_loss did not improve from 12663.68262\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9081.3174 - mean_absolute_error: 9081.3174 - val_loss: 12688.6943 - val_mean_absolute_error: 12688.6943\n",
      "Epoch 762/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9347.1758 - mean_absolute_error: 9347.1758\n",
      "Epoch 762: val_loss did not improve from 12663.68262\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9155.0850 - mean_absolute_error: 9155.0850 - val_loss: 12807.2021 - val_mean_absolute_error: 12807.2021\n",
      "Epoch 763/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 8946.6709 - mean_absolute_error: 8946.6709\n",
      "Epoch 763: val_loss did not improve from 12663.68262\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9016.5332 - mean_absolute_error: 9016.5332 - val_loss: 12680.7617 - val_mean_absolute_error: 12680.7617\n",
      "Epoch 764/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9138.5889 - mean_absolute_error: 9138.5889\n",
      "Epoch 764: val_loss did not improve from 12663.68262\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 8964.2549 - mean_absolute_error: 8964.2549 - val_loss: 12699.3730 - val_mean_absolute_error: 12699.3730\n",
      "Epoch 765/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8866.7871 - mean_absolute_error: 8866.7871\n",
      "Epoch 765: val_loss did not improve from 12663.68262\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8976.7568 - mean_absolute_error: 8976.7568 - val_loss: 13002.9375 - val_mean_absolute_error: 13002.9375\n",
      "Epoch 766/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9873.0186 - mean_absolute_error: 9873.0186\n",
      "Epoch 766: val_loss did not improve from 12663.68262\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9426.6660 - mean_absolute_error: 9426.6660 - val_loss: 13991.0010 - val_mean_absolute_error: 13991.0010\n",
      "Epoch 767/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9271.9922 - mean_absolute_error: 9271.9922  \n",
      "Epoch 767: val_loss did not improve from 12663.68262\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9240.6553 - mean_absolute_error: 9240.6553 - val_loss: 12889.7891 - val_mean_absolute_error: 12889.7891\n",
      "Epoch 768/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9003.4209 - mean_absolute_error: 9003.4209\n",
      "Epoch 768: val_loss did not improve from 12663.68262\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9058.6309 - mean_absolute_error: 9058.6309 - val_loss: 12728.4170 - val_mean_absolute_error: 12728.4170\n",
      "Epoch 769/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9149.0605 - mean_absolute_error: 9149.0605\n",
      "Epoch 769: val_loss did not improve from 12663.68262\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9173.8564 - mean_absolute_error: 9173.8564 - val_loss: 12836.4404 - val_mean_absolute_error: 12836.4404\n",
      "Epoch 770/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9192.5312 - mean_absolute_error: 9192.5312  \n",
      "Epoch 770: val_loss did not improve from 12663.68262\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9156.0215 - mean_absolute_error: 9156.0215 - val_loss: 12930.4893 - val_mean_absolute_error: 12930.4893\n",
      "Epoch 771/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9025.8496 - mean_absolute_error: 9025.8496\n",
      "Epoch 771: val_loss did not improve from 12663.68262\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9041.3574 - mean_absolute_error: 9041.3574 - val_loss: 12685.1865 - val_mean_absolute_error: 12685.1865\n",
      "Epoch 772/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9051.0195 - mean_absolute_error: 9051.0195\n",
      "Epoch 772: val_loss did not improve from 12663.68262\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8996.1816 - mean_absolute_error: 8996.1816 - val_loss: 12690.5439 - val_mean_absolute_error: 12690.5439\n",
      "Epoch 773/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9002.3486 - mean_absolute_error: 9002.3486  \n",
      "Epoch 773: val_loss did not improve from 12663.68262\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9016.5674 - mean_absolute_error: 9016.5674 - val_loss: 12731.5625 - val_mean_absolute_error: 12731.5625\n",
      "Epoch 774/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9019.6436 - mean_absolute_error: 9019.6436\n",
      "Epoch 774: val_loss did not improve from 12663.68262\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9095.5459 - mean_absolute_error: 9095.5459 - val_loss: 12786.9951 - val_mean_absolute_error: 12786.9951\n",
      "Epoch 775/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9014.1699 - mean_absolute_error: 9014.1699\n",
      "Epoch 775: val_loss improved from 12663.68262 to 12654.53809, saving model to Weights-00775--12654.53809.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 8983.1523 - mean_absolute_error: 8983.1523 - val_loss: 12654.5381 - val_mean_absolute_error: 12654.5381\n",
      "Epoch 776/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8850.7588 - mean_absolute_error: 8850.7588\n",
      "Epoch 776: val_loss improved from 12654.53809 to 12650.18555, saving model to Weights-00776--12650.18555.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 8940.1318 - mean_absolute_error: 8940.1318 - val_loss: 12650.1855 - val_mean_absolute_error: 12650.1855\n",
      "Epoch 777/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9060.1553 - mean_absolute_error: 9060.1553\n",
      "Epoch 777: val_loss did not improve from 12650.18555\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8948.4678 - mean_absolute_error: 8948.4678 - val_loss: 12850.9082 - val_mean_absolute_error: 12850.9082\n",
      "Epoch 778/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9121.1543 - mean_absolute_error: 9121.1543  \n",
      "Epoch 778: val_loss improved from 12650.18555 to 12647.62988, saving model to Weights-00778--12647.62988.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8949.6201 - mean_absolute_error: 8949.6201 - val_loss: 12647.6299 - val_mean_absolute_error: 12647.6299\n",
      "Epoch 779/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8892.5732 - mean_absolute_error: 8892.5732\n",
      "Epoch 779: val_loss did not improve from 12647.62988\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8925.1406 - mean_absolute_error: 8925.1406 - val_loss: 12648.6533 - val_mean_absolute_error: 12648.6533\n",
      "Epoch 780/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 8998.1357 - mean_absolute_error: 8998.1357\n",
      "Epoch 780: val_loss improved from 12647.62988 to 12614.23145, saving model to Weights-00780--12614.23145.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 8931.9609 - mean_absolute_error: 8931.9609 - val_loss: 12614.2314 - val_mean_absolute_error: 12614.2314\n",
      "Epoch 781/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8936.7412 - mean_absolute_error: 8936.7412\n",
      "Epoch 781: val_loss did not improve from 12614.23145\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8885.2900 - mean_absolute_error: 8885.2900 - val_loss: 12813.8174 - val_mean_absolute_error: 12813.8174\n",
      "Epoch 782/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9286.4258 - mean_absolute_error: 9286.4258  \n",
      "Epoch 782: val_loss did not improve from 12614.23145\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9096.3369 - mean_absolute_error: 9096.3369 - val_loss: 12748.1084 - val_mean_absolute_error: 12748.1084\n",
      "Epoch 783/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8793.4219 - mean_absolute_error: 8793.4219  \n",
      "Epoch 783: val_loss did not improve from 12614.23145\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8966.6943 - mean_absolute_error: 8966.6943 - val_loss: 12651.0820 - val_mean_absolute_error: 12651.0820\n",
      "Epoch 784/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9030.3604 - mean_absolute_error: 9030.3604  \n",
      "Epoch 784: val_loss did not improve from 12614.23145\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8959.0430 - mean_absolute_error: 8959.0430 - val_loss: 12665.3057 - val_mean_absolute_error: 12665.3057\n",
      "Epoch 785/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9003.3750 - mean_absolute_error: 9003.3750\n",
      "Epoch 785: val_loss did not improve from 12614.23145\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8933.1729 - mean_absolute_error: 8933.1729 - val_loss: 12682.7998 - val_mean_absolute_error: 12682.7998\n",
      "Epoch 786/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9126.9912 - mean_absolute_error: 9126.9912\n",
      "Epoch 786: val_loss did not improve from 12614.23145\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9076.4805 - mean_absolute_error: 9076.4805 - val_loss: 12736.3369 - val_mean_absolute_error: 12736.3369\n",
      "Epoch 787/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9195.1787 - mean_absolute_error: 9195.1787\n",
      "Epoch 787: val_loss did not improve from 12614.23145\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8973.9492 - mean_absolute_error: 8973.9492 - val_loss: 12683.3232 - val_mean_absolute_error: 12683.3232\n",
      "Epoch 788/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9409.9482 - mean_absolute_error: 9409.9482\n",
      "Epoch 788: val_loss did not improve from 12614.23145\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9182.8447 - mean_absolute_error: 9182.8447 - val_loss: 12633.9551 - val_mean_absolute_error: 12633.9551\n",
      "Epoch 789/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9155.2607 - mean_absolute_error: 9155.2607\n",
      "Epoch 789: val_loss did not improve from 12614.23145\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9064.9326 - mean_absolute_error: 9064.9326 - val_loss: 12886.4307 - val_mean_absolute_error: 12886.4307\n",
      "Epoch 790/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9076.2461 - mean_absolute_error: 9076.2461  \n",
      "Epoch 790: val_loss improved from 12614.23145 to 12599.99023, saving model to Weights-00790--12599.99023.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 8988.0342 - mean_absolute_error: 8988.0342 - val_loss: 12599.9902 - val_mean_absolute_error: 12599.9902\n",
      "Epoch 791/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 8871.4941 - mean_absolute_error: 8871.4941\n",
      "Epoch 791: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8941.8096 - mean_absolute_error: 8941.8096 - val_loss: 12635.3496 - val_mean_absolute_error: 12635.3496\n",
      "Epoch 792/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9012.1143 - mean_absolute_error: 9012.1143\n",
      "Epoch 792: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9019.9834 - mean_absolute_error: 9019.9834 - val_loss: 12759.6865 - val_mean_absolute_error: 12759.6865\n",
      "Epoch 793/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 8606.3164 - mean_absolute_error: 8606.3164\n",
      "Epoch 793: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9003.3418 - mean_absolute_error: 9003.3418 - val_loss: 12684.6826 - val_mean_absolute_error: 12684.6826\n",
      "Epoch 794/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 8728.0518 - mean_absolute_error: 8728.0518\n",
      "Epoch 794: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8942.7500 - mean_absolute_error: 8942.7500 - val_loss: 12630.1504 - val_mean_absolute_error: 12630.1504\n",
      "Epoch 795/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9125.4736 - mean_absolute_error: 9125.4736\n",
      "Epoch 795: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8953.9141 - mean_absolute_error: 8953.9141 - val_loss: 13115.3154 - val_mean_absolute_error: 13115.3154\n",
      "Epoch 796/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8717.0215 - mean_absolute_error: 8717.0215\n",
      "Epoch 796: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9033.5439 - mean_absolute_error: 9033.5439 - val_loss: 12756.9131 - val_mean_absolute_error: 12756.9131\n",
      "Epoch 797/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 8985.8545 - mean_absolute_error: 8985.8545  \n",
      "Epoch 797: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9007.3223 - mean_absolute_error: 9007.3223 - val_loss: 12788.8232 - val_mean_absolute_error: 12788.8232\n",
      "Epoch 798/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9059.7881 - mean_absolute_error: 9059.7881\n",
      "Epoch 798: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8993.7451 - mean_absolute_error: 8993.7451 - val_loss: 12680.1211 - val_mean_absolute_error: 12680.1211\n",
      "Epoch 799/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9028.9727 - mean_absolute_error: 9028.9727\n",
      "Epoch 799: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9045.1758 - mean_absolute_error: 9045.1758 - val_loss: 12646.6416 - val_mean_absolute_error: 12646.6416\n",
      "Epoch 800/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8925.9482 - mean_absolute_error: 8925.9482  \n",
      "Epoch 800: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9031.2158 - mean_absolute_error: 9031.2158 - val_loss: 12788.7734 - val_mean_absolute_error: 12788.7734\n",
      "Epoch 801/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9030.6221 - mean_absolute_error: 9030.6221\n",
      "Epoch 801: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9142.1768 - mean_absolute_error: 9142.1768 - val_loss: 12684.4004 - val_mean_absolute_error: 12684.4004\n",
      "Epoch 802/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9022.5479 - mean_absolute_error: 9022.5479\n",
      "Epoch 802: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8949.3271 - mean_absolute_error: 8949.3271 - val_loss: 12712.4570 - val_mean_absolute_error: 12712.4570\n",
      "Epoch 803/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8704.2471 - mean_absolute_error: 8704.2471\n",
      "Epoch 803: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8911.2627 - mean_absolute_error: 8911.2627 - val_loss: 13357.7822 - val_mean_absolute_error: 13357.7822\n",
      "Epoch 804/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9143.4395 - mean_absolute_error: 9143.4395  \n",
      "Epoch 804: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9080.7139 - mean_absolute_error: 9080.7139 - val_loss: 12645.2158 - val_mean_absolute_error: 12645.2158\n",
      "Epoch 805/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9014.4092 - mean_absolute_error: 9014.4092\n",
      "Epoch 805: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8989.1367 - mean_absolute_error: 8989.1367 - val_loss: 12643.6279 - val_mean_absolute_error: 12643.6279\n",
      "Epoch 806/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9117.6143 - mean_absolute_error: 9117.6143\n",
      "Epoch 806: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9028.7959 - mean_absolute_error: 9028.7959 - val_loss: 12649.5625 - val_mean_absolute_error: 12649.5625\n",
      "Epoch 807/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 8935.0547 - mean_absolute_error: 8935.0547\n",
      "Epoch 807: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8941.8936 - mean_absolute_error: 8941.8936 - val_loss: 12632.0889 - val_mean_absolute_error: 12632.0889\n",
      "Epoch 808/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9137.0430 - mean_absolute_error: 9137.0430\n",
      "Epoch 808: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9014.7080 - mean_absolute_error: 9014.7080 - val_loss: 12750.5723 - val_mean_absolute_error: 12750.5723\n",
      "Epoch 809/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9042.1436 - mean_absolute_error: 9042.1436\n",
      "Epoch 809: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8973.8809 - mean_absolute_error: 8973.8809 - val_loss: 12667.5459 - val_mean_absolute_error: 12667.5459\n",
      "Epoch 810/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8983.3486 - mean_absolute_error: 8983.3486\n",
      "Epoch 810: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9095.2402 - mean_absolute_error: 9095.2402 - val_loss: 12698.4912 - val_mean_absolute_error: 12698.4912\n",
      "Epoch 811/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9002.1875 - mean_absolute_error: 9002.1875\n",
      "Epoch 811: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9015.4131 - mean_absolute_error: 9015.4131 - val_loss: 12698.1338 - val_mean_absolute_error: 12698.1338\n",
      "Epoch 812/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8855.7354 - mean_absolute_error: 8855.7354\n",
      "Epoch 812: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9000.8125 - mean_absolute_error: 9000.8125 - val_loss: 12651.7451 - val_mean_absolute_error: 12651.7451\n",
      "Epoch 813/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9127.9346 - mean_absolute_error: 9127.9346\n",
      "Epoch 813: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9213.6943 - mean_absolute_error: 9213.6943 - val_loss: 12714.5127 - val_mean_absolute_error: 12714.5127\n",
      "Epoch 814/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9094.1631 - mean_absolute_error: 9094.1631\n",
      "Epoch 814: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9170.6572 - mean_absolute_error: 9170.6572 - val_loss: 12685.7119 - val_mean_absolute_error: 12685.7119\n",
      "Epoch 815/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8977.4189 - mean_absolute_error: 8977.4189\n",
      "Epoch 815: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8889.8223 - mean_absolute_error: 8889.8223 - val_loss: 12974.3994 - val_mean_absolute_error: 12974.3994\n",
      "Epoch 816/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9104.4453 - mean_absolute_error: 9104.4453\n",
      "Epoch 816: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8982.2783 - mean_absolute_error: 8982.2783 - val_loss: 12653.6562 - val_mean_absolute_error: 12653.6562\n",
      "Epoch 817/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9104.8984 - mean_absolute_error: 9104.8984\n",
      "Epoch 817: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9052.4531 - mean_absolute_error: 9052.4531 - val_loss: 12668.7256 - val_mean_absolute_error: 12668.7256\n",
      "Epoch 818/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9113.5361 - mean_absolute_error: 9113.5361\n",
      "Epoch 818: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9073.3359 - mean_absolute_error: 9073.3359 - val_loss: 12633.6543 - val_mean_absolute_error: 12633.6543\n",
      "Epoch 819/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 8294.0146 - mean_absolute_error: 8294.0146\n",
      "Epoch 819: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8921.8203 - mean_absolute_error: 8921.8203 - val_loss: 12873.5811 - val_mean_absolute_error: 12873.5811\n",
      "Epoch 820/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8961.6602 - mean_absolute_error: 8961.6602  \n",
      "Epoch 820: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8999.6016 - mean_absolute_error: 8999.6016 - val_loss: 12638.5322 - val_mean_absolute_error: 12638.5322\n",
      "Epoch 821/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8844.1934 - mean_absolute_error: 8844.1934\n",
      "Epoch 821: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8899.3457 - mean_absolute_error: 8899.3457 - val_loss: 12611.8750 - val_mean_absolute_error: 12611.8750\n",
      "Epoch 822/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9051.9346 - mean_absolute_error: 9051.9346\n",
      "Epoch 822: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8998.3057 - mean_absolute_error: 8998.3057 - val_loss: 12871.4219 - val_mean_absolute_error: 12871.4219\n",
      "Epoch 823/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9139.3682 - mean_absolute_error: 9139.3682\n",
      "Epoch 823: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9103.3301 - mean_absolute_error: 9103.3301 - val_loss: 12994.3213 - val_mean_absolute_error: 12994.3213\n",
      "Epoch 824/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8679.1748 - mean_absolute_error: 8679.1748\n",
      "Epoch 824: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9144.1074 - mean_absolute_error: 9144.1074 - val_loss: 12959.8535 - val_mean_absolute_error: 12959.8535\n",
      "Epoch 825/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 8929.2520 - mean_absolute_error: 8929.2520  \n",
      "Epoch 825: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8946.2012 - mean_absolute_error: 8946.2012 - val_loss: 12794.9053 - val_mean_absolute_error: 12794.9053\n",
      "Epoch 826/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9139.1221 - mean_absolute_error: 9139.1221  \n",
      "Epoch 826: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9120.5537 - mean_absolute_error: 9120.5537 - val_loss: 12626.5762 - val_mean_absolute_error: 12626.5762\n",
      "Epoch 827/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9165.2529 - mean_absolute_error: 9165.2529\n",
      "Epoch 827: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8965.8174 - mean_absolute_error: 8965.8174 - val_loss: 12664.5215 - val_mean_absolute_error: 12664.5215\n",
      "Epoch 828/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9302.1904 - mean_absolute_error: 9302.1904\n",
      "Epoch 828: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9046.9492 - mean_absolute_error: 9046.9492 - val_loss: 12687.9141 - val_mean_absolute_error: 12687.9141\n",
      "Epoch 829/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 8861.0557 - mean_absolute_error: 8861.0557\n",
      "Epoch 829: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 8934.1650 - mean_absolute_error: 8934.1650 - val_loss: 12957.8936 - val_mean_absolute_error: 12957.8936\n",
      "Epoch 830/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 8977.3662 - mean_absolute_error: 8977.3662  \n",
      "Epoch 830: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9200.0908 - mean_absolute_error: 9200.0908 - val_loss: 13192.9854 - val_mean_absolute_error: 13192.9854\n",
      "Epoch 831/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9267.9746 - mean_absolute_error: 9267.9746\n",
      "Epoch 831: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9183.4932 - mean_absolute_error: 9183.4932 - val_loss: 12668.0674 - val_mean_absolute_error: 12668.0674\n",
      "Epoch 832/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9026.2588 - mean_absolute_error: 9026.2588\n",
      "Epoch 832: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8978.7979 - mean_absolute_error: 8978.7979 - val_loss: 12653.1465 - val_mean_absolute_error: 12653.1465\n",
      "Epoch 833/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9164.2246 - mean_absolute_error: 9164.2246  \n",
      "Epoch 833: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9046.7412 - mean_absolute_error: 9046.7412 - val_loss: 12618.9082 - val_mean_absolute_error: 12618.9082\n",
      "Epoch 834/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9008.9463 - mean_absolute_error: 9008.9463\n",
      "Epoch 834: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8920.6299 - mean_absolute_error: 8920.6299 - val_loss: 12637.2354 - val_mean_absolute_error: 12637.2354\n",
      "Epoch 835/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9094.2129 - mean_absolute_error: 9094.2129  \n",
      "Epoch 835: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8977.5400 - mean_absolute_error: 8977.5400 - val_loss: 13000.8984 - val_mean_absolute_error: 13000.8984\n",
      "Epoch 836/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 8690.9521 - mean_absolute_error: 8690.9521\n",
      "Epoch 836: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 9025.2383 - mean_absolute_error: 9025.2383 - val_loss: 12701.2012 - val_mean_absolute_error: 12701.2012\n",
      "Epoch 837/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 8981.1338 - mean_absolute_error: 8981.1338\n",
      "Epoch 837: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9043.0410 - mean_absolute_error: 9043.0410 - val_loss: 12696.6328 - val_mean_absolute_error: 12696.6328\n",
      "Epoch 838/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9591.5137 - mean_absolute_error: 9591.5137  \n",
      "Epoch 838: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9260.8818 - mean_absolute_error: 9260.8818 - val_loss: 12663.8311 - val_mean_absolute_error: 12663.8311\n",
      "Epoch 839/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9394.9580 - mean_absolute_error: 9394.9580\n",
      "Epoch 839: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9289.6211 - mean_absolute_error: 9289.6211 - val_loss: 12706.1250 - val_mean_absolute_error: 12706.1250\n",
      "Epoch 840/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9079.0928 - mean_absolute_error: 9079.0928\n",
      "Epoch 840: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8985.0244 - mean_absolute_error: 8985.0244 - val_loss: 12681.4180 - val_mean_absolute_error: 12681.4180\n",
      "Epoch 841/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 8913.9150 - mean_absolute_error: 8913.9150\n",
      "Epoch 841: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8984.9111 - mean_absolute_error: 8984.9111 - val_loss: 12769.6406 - val_mean_absolute_error: 12769.6406\n",
      "Epoch 842/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9002.2734 - mean_absolute_error: 9002.2734  \n",
      "Epoch 842: val_loss did not improve from 12599.99023\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9023.0127 - mean_absolute_error: 9023.0127 - val_loss: 12612.9824 - val_mean_absolute_error: 12612.9824\n",
      "Epoch 843/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8611.9844 - mean_absolute_error: 8611.9844\n",
      "Epoch 843: val_loss improved from 12599.99023 to 12599.29883, saving model to Weights-00843--12599.29883.hdf5\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 8907.9219 - mean_absolute_error: 8907.9219 - val_loss: 12599.2988 - val_mean_absolute_error: 12599.2988\n",
      "Epoch 844/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 8909.5088 - mean_absolute_error: 8909.5088  \n",
      "Epoch 844: val_loss improved from 12599.29883 to 12593.56055, saving model to Weights-00844--12593.56055.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 8999.1484 - mean_absolute_error: 8999.1484 - val_loss: 12593.5605 - val_mean_absolute_error: 12593.5605\n",
      "Epoch 845/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8869.3887 - mean_absolute_error: 8869.3887\n",
      "Epoch 845: val_loss did not improve from 12593.56055\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9010.2383 - mean_absolute_error: 9010.2383 - val_loss: 12988.1201 - val_mean_absolute_error: 12988.1201\n",
      "Epoch 846/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9449.7158 - mean_absolute_error: 9449.7158\n",
      "Epoch 846: val_loss did not improve from 12593.56055\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9154.6514 - mean_absolute_error: 9154.6514 - val_loss: 12799.9189 - val_mean_absolute_error: 12799.9189\n",
      "Epoch 847/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9293.5469 - mean_absolute_error: 9293.5469  \n",
      "Epoch 847: val_loss did not improve from 12593.56055\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9008.9854 - mean_absolute_error: 9008.9854 - val_loss: 12609.8232 - val_mean_absolute_error: 12609.8232\n",
      "Epoch 848/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8967.9023 - mean_absolute_error: 8967.9023\n",
      "Epoch 848: val_loss did not improve from 12593.56055\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8969.4600 - mean_absolute_error: 8969.4600 - val_loss: 12595.0205 - val_mean_absolute_error: 12595.0205\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 8919.8613 - mean_absolute_error: 8919.8613\n",
      "Epoch 849: val_loss improved from 12593.56055 to 12592.59277, saving model to Weights-00849--12592.59277.hdf5\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 8919.8613 - mean_absolute_error: 8919.8613 - val_loss: 12592.5928 - val_mean_absolute_error: 12592.5928\n",
      "Epoch 850/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 8958.1406 - mean_absolute_error: 8958.1406\n",
      "Epoch 850: val_loss did not improve from 12592.59277\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8913.1016 - mean_absolute_error: 8913.1016 - val_loss: 12616.5049 - val_mean_absolute_error: 12616.5049\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 8914.5830 - mean_absolute_error: 8914.5830\n",
      "Epoch 851: val_loss did not improve from 12592.59277\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8914.5830 - mean_absolute_error: 8914.5830 - val_loss: 12711.4092 - val_mean_absolute_error: 12711.4092\n",
      "Epoch 852/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9052.2070 - mean_absolute_error: 9052.2070\n",
      "Epoch 852: val_loss did not improve from 12592.59277\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9109.3486 - mean_absolute_error: 9109.3486 - val_loss: 12627.5352 - val_mean_absolute_error: 12627.5352\n",
      "Epoch 853/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9414.7783 - mean_absolute_error: 9414.7783\n",
      "Epoch 853: val_loss did not improve from 12592.59277\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8990.4414 - mean_absolute_error: 8990.4414 - val_loss: 12607.9199 - val_mean_absolute_error: 12607.9199\n",
      "Epoch 854/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9123.6445 - mean_absolute_error: 9123.6445  \n",
      "Epoch 854: val_loss did not improve from 12592.59277\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8934.5596 - mean_absolute_error: 8934.5596 - val_loss: 12783.2520 - val_mean_absolute_error: 12783.2520\n",
      "Epoch 855/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 8957.3438 - mean_absolute_error: 8957.3438\n",
      "Epoch 855: val_loss did not improve from 12592.59277\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 8969.3242 - mean_absolute_error: 8969.3242 - val_loss: 12738.8066 - val_mean_absolute_error: 12738.8066\n",
      "Epoch 856/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 9033.0371 - mean_absolute_error: 9033.0371\n",
      "Epoch 856: val_loss did not improve from 12592.59277\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9033.0371 - mean_absolute_error: 9033.0371 - val_loss: 12598.1553 - val_mean_absolute_error: 12598.1553\n",
      "Epoch 857/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9094.7490 - mean_absolute_error: 9094.7490\n",
      "Epoch 857: val_loss did not improve from 12592.59277\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8923.5479 - mean_absolute_error: 8923.5479 - val_loss: 12608.3584 - val_mean_absolute_error: 12608.3584\n",
      "Epoch 858/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 8845.2207 - mean_absolute_error: 8845.2207\n",
      "Epoch 858: val_loss improved from 12592.59277 to 12561.59961, saving model to Weights-00858--12561.59961.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 8988.6562 - mean_absolute_error: 8988.6562 - val_loss: 12561.5996 - val_mean_absolute_error: 12561.5996\n",
      "Epoch 859/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8908.9043 - mean_absolute_error: 8908.9043\n",
      "Epoch 859: val_loss did not improve from 12561.59961\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8948.7480 - mean_absolute_error: 8948.7480 - val_loss: 12592.0049 - val_mean_absolute_error: 12592.0049\n",
      "Epoch 860/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8786.3291 - mean_absolute_error: 8786.3291  \n",
      "Epoch 860: val_loss did not improve from 12561.59961\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8895.3340 - mean_absolute_error: 8895.3340 - val_loss: 12635.1357 - val_mean_absolute_error: 12635.1357\n",
      "Epoch 861/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8927.4092 - mean_absolute_error: 8927.4092  \n",
      "Epoch 861: val_loss did not improve from 12561.59961\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9002.2578 - mean_absolute_error: 9002.2578 - val_loss: 12606.0098 - val_mean_absolute_error: 12606.0098\n",
      "Epoch 862/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8741.0635 - mean_absolute_error: 8741.0635\n",
      "Epoch 862: val_loss did not improve from 12561.59961\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8965.5469 - mean_absolute_error: 8965.5469 - val_loss: 12630.4062 - val_mean_absolute_error: 12630.4062\n",
      "Epoch 863/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8869.7607 - mean_absolute_error: 8869.7607\n",
      "Epoch 863: val_loss did not improve from 12561.59961\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8890.2490 - mean_absolute_error: 8890.2490 - val_loss: 12614.4814 - val_mean_absolute_error: 12614.4814\n",
      "Epoch 864/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9201.1924 - mean_absolute_error: 9201.1924\n",
      "Epoch 864: val_loss did not improve from 12561.59961\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8976.6455 - mean_absolute_error: 8976.6455 - val_loss: 12653.2637 - val_mean_absolute_error: 12653.2637\n",
      "Epoch 865/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9101.7852 - mean_absolute_error: 9101.7852\n",
      "Epoch 865: val_loss did not improve from 12561.59961\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9096.9248 - mean_absolute_error: 9096.9248 - val_loss: 12600.3223 - val_mean_absolute_error: 12600.3223\n",
      "Epoch 866/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8947.3086 - mean_absolute_error: 8947.3086  \n",
      "Epoch 866: val_loss did not improve from 12561.59961\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9063.1455 - mean_absolute_error: 9063.1455 - val_loss: 12719.2891 - val_mean_absolute_error: 12719.2891\n",
      "Epoch 867/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9035.2002 - mean_absolute_error: 9035.2002\n",
      "Epoch 867: val_loss did not improve from 12561.59961\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8912.0811 - mean_absolute_error: 8912.0811 - val_loss: 12705.2021 - val_mean_absolute_error: 12705.2021\n",
      "Epoch 868/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9001.9805 - mean_absolute_error: 9001.9805\n",
      "Epoch 868: val_loss did not improve from 12561.59961\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8970.9209 - mean_absolute_error: 8970.9209 - val_loss: 13053.9561 - val_mean_absolute_error: 13053.9561\n",
      "Epoch 869/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 8783.6211 - mean_absolute_error: 8783.6211 \n",
      "Epoch 869: val_loss improved from 12561.59961 to 12535.41797, saving model to Weights-00869--12535.41797.hdf5\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 8952.4180 - mean_absolute_error: 8952.4180 - val_loss: 12535.4180 - val_mean_absolute_error: 12535.4180\n",
      "Epoch 870/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8975.5820 - mean_absolute_error: 8975.5820  \n",
      "Epoch 870: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8968.2842 - mean_absolute_error: 8968.2842 - val_loss: 12591.0293 - val_mean_absolute_error: 12591.0293\n",
      "Epoch 871/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 8953.4023 - mean_absolute_error: 8953.4023\n",
      "Epoch 871: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8901.7549 - mean_absolute_error: 8901.7549 - val_loss: 12602.2266 - val_mean_absolute_error: 12602.2266\n",
      "Epoch 872/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8925.3760 - mean_absolute_error: 8925.3760\n",
      "Epoch 872: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8914.9521 - mean_absolute_error: 8914.9521 - val_loss: 12541.8154 - val_mean_absolute_error: 12541.8154\n",
      "Epoch 873/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9080.1348 - mean_absolute_error: 9080.1348\n",
      "Epoch 873: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8993.2266 - mean_absolute_error: 8993.2266 - val_loss: 12648.7920 - val_mean_absolute_error: 12648.7920\n",
      "Epoch 874/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8889.5078 - mean_absolute_error: 8889.5078  \n",
      "Epoch 874: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8987.1943 - mean_absolute_error: 8987.1943 - val_loss: 12547.3350 - val_mean_absolute_error: 12547.3350\n",
      "Epoch 875/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9387.4131 - mean_absolute_error: 9387.4131\n",
      "Epoch 875: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9064.2314 - mean_absolute_error: 9064.2314 - val_loss: 12552.2451 - val_mean_absolute_error: 12552.2451\n",
      "Epoch 876/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8864.2910 - mean_absolute_error: 8864.2910  \n",
      "Epoch 876: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8977.0742 - mean_absolute_error: 8977.0742 - val_loss: 12615.3359 - val_mean_absolute_error: 12615.3359\n",
      "Epoch 877/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9192.6797 - mean_absolute_error: 9192.6797  \n",
      "Epoch 877: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9063.7539 - mean_absolute_error: 9063.7539 - val_loss: 12653.6807 - val_mean_absolute_error: 12653.6807\n",
      "Epoch 878/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9140.6182 - mean_absolute_error: 9140.6182\n",
      "Epoch 878: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9132.1826 - mean_absolute_error: 9132.1826 - val_loss: 12658.5537 - val_mean_absolute_error: 12658.5537\n",
      "Epoch 879/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8488.8662 - mean_absolute_error: 8488.8662\n",
      "Epoch 879: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8859.3213 - mean_absolute_error: 8859.3213 - val_loss: 12564.8477 - val_mean_absolute_error: 12564.8477\n",
      "Epoch 880/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9257.1357 - mean_absolute_error: 9257.1357\n",
      "Epoch 880: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8977.3008 - mean_absolute_error: 8977.3008 - val_loss: 12603.6436 - val_mean_absolute_error: 12603.6436\n",
      "Epoch 881/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8998.0801 - mean_absolute_error: 8998.0801\n",
      "Epoch 881: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8976.0723 - mean_absolute_error: 8976.0723 - val_loss: 12562.3633 - val_mean_absolute_error: 12562.3633\n",
      "Epoch 882/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9223.9043 - mean_absolute_error: 9223.9043\n",
      "Epoch 882: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9102.4424 - mean_absolute_error: 9102.4424 - val_loss: 12935.0449 - val_mean_absolute_error: 12935.0449\n",
      "Epoch 883/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9144.9707 - mean_absolute_error: 9144.9707\n",
      "Epoch 883: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9139.1006 - mean_absolute_error: 9139.1006 - val_loss: 13276.5469 - val_mean_absolute_error: 13276.5469\n",
      "Epoch 884/1000\n",
      " 8/18 [============>.................] - ETA: 0s - loss: 9251.6162 - mean_absolute_error: 9251.6162\n",
      "Epoch 884: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9156.7656 - mean_absolute_error: 9156.7656 - val_loss: 12601.5225 - val_mean_absolute_error: 12601.5225\n",
      "Epoch 885/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 8898.1992 - mean_absolute_error: 8898.1992\n",
      "Epoch 885: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9075.8398 - mean_absolute_error: 9075.8398 - val_loss: 12588.0332 - val_mean_absolute_error: 12588.0332\n",
      "Epoch 886/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8900.9160 - mean_absolute_error: 8900.9160\n",
      "Epoch 886: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8934.1230 - mean_absolute_error: 8934.1230 - val_loss: 12634.4248 - val_mean_absolute_error: 12634.4248\n",
      "Epoch 887/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8628.3066 - mean_absolute_error: 8628.3066\n",
      "Epoch 887: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8910.4238 - mean_absolute_error: 8910.4238 - val_loss: 12755.2559 - val_mean_absolute_error: 12755.2559\n",
      "Epoch 888/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9003.8945 - mean_absolute_error: 9003.8945  \n",
      "Epoch 888: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9008.6846 - mean_absolute_error: 9008.6846 - val_loss: 12925.5625 - val_mean_absolute_error: 12925.5625\n",
      "Epoch 889/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8910.2832 - mean_absolute_error: 8910.2832  \n",
      "Epoch 889: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8953.1055 - mean_absolute_error: 8953.1055 - val_loss: 12806.8984 - val_mean_absolute_error: 12806.8984\n",
      "Epoch 890/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9250.6543 - mean_absolute_error: 9250.6543\n",
      "Epoch 890: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9047.3213 - mean_absolute_error: 9047.3213 - val_loss: 12770.4160 - val_mean_absolute_error: 12770.4160\n",
      "Epoch 891/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9205.7920 - mean_absolute_error: 9205.7920\n",
      "Epoch 891: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9033.2578 - mean_absolute_error: 9033.2578 - val_loss: 12579.2959 - val_mean_absolute_error: 12579.2959\n",
      "Epoch 892/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9129.5674 - mean_absolute_error: 9129.5674\n",
      "Epoch 892: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9041.1045 - mean_absolute_error: 9041.1045 - val_loss: 13119.0068 - val_mean_absolute_error: 13119.0068\n",
      "Epoch 893/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9127.9766 - mean_absolute_error: 9127.9766\n",
      "Epoch 893: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9076.6533 - mean_absolute_error: 9076.6533 - val_loss: 12673.3398 - val_mean_absolute_error: 12673.3398\n",
      "Epoch 894/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9127.8691 - mean_absolute_error: 9127.8691\n",
      "Epoch 894: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 8903.8418 - mean_absolute_error: 8903.8418 - val_loss: 12566.4717 - val_mean_absolute_error: 12566.4717\n",
      "Epoch 895/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 8977.1182 - mean_absolute_error: 8977.1182\n",
      "Epoch 895: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8876.0566 - mean_absolute_error: 8876.0566 - val_loss: 12557.2334 - val_mean_absolute_error: 12557.2334\n",
      "Epoch 896/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8906.5527 - mean_absolute_error: 8906.5527  \n",
      "Epoch 896: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8933.3271 - mean_absolute_error: 8933.3271 - val_loss: 12891.9180 - val_mean_absolute_error: 12891.9180\n",
      "Epoch 897/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8844.5205 - mean_absolute_error: 8844.5205  \n",
      "Epoch 897: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8885.1670 - mean_absolute_error: 8885.1670 - val_loss: 12627.0010 - val_mean_absolute_error: 12627.0010\n",
      "Epoch 898/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9053.2695 - mean_absolute_error: 9053.2695  \n",
      "Epoch 898: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8961.5908 - mean_absolute_error: 8961.5908 - val_loss: 12696.1055 - val_mean_absolute_error: 12696.1055\n",
      "Epoch 899/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9003.2891 - mean_absolute_error: 9003.2891\n",
      "Epoch 899: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8884.5283 - mean_absolute_error: 8884.5283 - val_loss: 12626.0215 - val_mean_absolute_error: 12626.0215\n",
      "Epoch 900/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9094.9248 - mean_absolute_error: 9094.9248  \n",
      "Epoch 900: val_loss did not improve from 12535.41797\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8977.0820 - mean_absolute_error: 8977.0820 - val_loss: 12581.2207 - val_mean_absolute_error: 12581.2207\n",
      "Epoch 901/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9045.8086 - mean_absolute_error: 9045.8086\n",
      "Epoch 901: val_loss improved from 12535.41797 to 12518.20996, saving model to Weights-00901--12518.20996.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9025.0332 - mean_absolute_error: 9025.0332 - val_loss: 12518.2100 - val_mean_absolute_error: 12518.2100\n",
      "Epoch 902/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9000.3506 - mean_absolute_error: 9000.3506\n",
      "Epoch 902: val_loss did not improve from 12518.20996\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8925.6738 - mean_absolute_error: 8925.6738 - val_loss: 12554.5293 - val_mean_absolute_error: 12554.5293\n",
      "Epoch 903/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 8937.7441 - mean_absolute_error: 8937.7441  \n",
      "Epoch 903: val_loss did not improve from 12518.20996\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8902.5146 - mean_absolute_error: 8902.5146 - val_loss: 12625.0361 - val_mean_absolute_error: 12625.0361\n",
      "Epoch 904/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 8799.4248 - mean_absolute_error: 8799.4248\n",
      "Epoch 904: val_loss did not improve from 12518.20996\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8906.4961 - mean_absolute_error: 8906.4961 - val_loss: 12560.1826 - val_mean_absolute_error: 12560.1826\n",
      "Epoch 905/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 8981.5488 - mean_absolute_error: 8981.5488\n",
      "Epoch 905: val_loss did not improve from 12518.20996\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8918.5215 - mean_absolute_error: 8918.5215 - val_loss: 12860.3945 - val_mean_absolute_error: 12860.3945\n",
      "Epoch 906/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8820.1221 - mean_absolute_error: 8820.1221\n",
      "Epoch 906: val_loss did not improve from 12518.20996\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9082.7822 - mean_absolute_error: 9082.7822 - val_loss: 12866.0498 - val_mean_absolute_error: 12866.0498\n",
      "Epoch 907/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9071.5527 - mean_absolute_error: 9071.5527\n",
      "Epoch 907: val_loss did not improve from 12518.20996\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8917.8770 - mean_absolute_error: 8917.8770 - val_loss: 12526.8389 - val_mean_absolute_error: 12526.8389\n",
      "Epoch 908/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 8732.9951 - mean_absolute_error: 8732.9951\n",
      "Epoch 908: val_loss did not improve from 12518.20996\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9002.6641 - mean_absolute_error: 9002.6641 - val_loss: 12519.7803 - val_mean_absolute_error: 12519.7803\n",
      "Epoch 909/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8879.2314 - mean_absolute_error: 8879.2314  \n",
      "Epoch 909: val_loss did not improve from 12518.20996\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8864.3545 - mean_absolute_error: 8864.3545 - val_loss: 12573.4883 - val_mean_absolute_error: 12573.4883\n",
      "Epoch 910/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9053.1777 - mean_absolute_error: 9053.1777  \n",
      "Epoch 910: val_loss improved from 12518.20996 to 12506.62207, saving model to Weights-00910--12506.62207.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 8960.3232 - mean_absolute_error: 8960.3232 - val_loss: 12506.6221 - val_mean_absolute_error: 12506.6221\n",
      "Epoch 911/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 8453.5947 - mean_absolute_error: 8453.5947  \n",
      "Epoch 911: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 8906.8232 - mean_absolute_error: 8906.8232 - val_loss: 12731.7461 - val_mean_absolute_error: 12731.7461\n",
      "Epoch 912/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 8711.4619 - mean_absolute_error: 8711.4619\n",
      "Epoch 912: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8955.3740 - mean_absolute_error: 8955.3740 - val_loss: 12565.9482 - val_mean_absolute_error: 12565.9482\n",
      "Epoch 913/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9159.5869 - mean_absolute_error: 9159.5869\n",
      "Epoch 913: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9177.3789 - mean_absolute_error: 9177.3789 - val_loss: 12645.4678 - val_mean_absolute_error: 12645.4678\n",
      "Epoch 914/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9090.9756 - mean_absolute_error: 9090.9756  \n",
      "Epoch 914: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9032.6348 - mean_absolute_error: 9032.6348 - val_loss: 12664.5850 - val_mean_absolute_error: 12664.5850\n",
      "Epoch 915/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 8889.5547 - mean_absolute_error: 8889.5547\n",
      "Epoch 915: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9020.4248 - mean_absolute_error: 9020.4248 - val_loss: 12762.4775 - val_mean_absolute_error: 12762.4775\n",
      "Epoch 916/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 8931.2090 - mean_absolute_error: 8931.2090  \n",
      "Epoch 916: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8885.0273 - mean_absolute_error: 8885.0273 - val_loss: 12530.8252 - val_mean_absolute_error: 12530.8252\n",
      "Epoch 917/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 8917.5850 - mean_absolute_error: 8917.5850  \n",
      "Epoch 917: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9031.9795 - mean_absolute_error: 9031.9795 - val_loss: 12595.5693 - val_mean_absolute_error: 12595.5693\n",
      "Epoch 918/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9074.7178 - mean_absolute_error: 9074.7178  \n",
      "Epoch 918: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9077.1504 - mean_absolute_error: 9077.1504 - val_loss: 12538.8223 - val_mean_absolute_error: 12538.8223\n",
      "Epoch 919/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8831.1514 - mean_absolute_error: 8831.1514  \n",
      "Epoch 919: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8906.8701 - mean_absolute_error: 8906.8701 - val_loss: 12590.8506 - val_mean_absolute_error: 12590.8506\n",
      "Epoch 920/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9106.6201 - mean_absolute_error: 9106.6201\n",
      "Epoch 920: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8997.7451 - mean_absolute_error: 8997.7451 - val_loss: 12589.4111 - val_mean_absolute_error: 12589.4111\n",
      "Epoch 921/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 8586.1230 - mean_absolute_error: 8586.1230  \n",
      "Epoch 921: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8861.9961 - mean_absolute_error: 8861.9961 - val_loss: 12663.1758 - val_mean_absolute_error: 12663.1758\n",
      "Epoch 922/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9290.6143 - mean_absolute_error: 9290.6143  \n",
      "Epoch 922: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9010.0713 - mean_absolute_error: 9010.0713 - val_loss: 12515.0400 - val_mean_absolute_error: 12515.0400\n",
      "Epoch 923/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8712.3232 - mean_absolute_error: 8712.3232  \n",
      "Epoch 923: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8914.9004 - mean_absolute_error: 8914.9004 - val_loss: 12519.8535 - val_mean_absolute_error: 12519.8535\n",
      "Epoch 924/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9284.2539 - mean_absolute_error: 9284.2539\n",
      "Epoch 924: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8919.8877 - mean_absolute_error: 8919.8877 - val_loss: 12622.1924 - val_mean_absolute_error: 12622.1924\n",
      "Epoch 925/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 8723.1553 - mean_absolute_error: 8723.1553\n",
      "Epoch 925: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8853.0049 - mean_absolute_error: 8853.0049 - val_loss: 13033.4248 - val_mean_absolute_error: 13033.4248\n",
      "Epoch 926/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9165.0996 - mean_absolute_error: 9165.0996  \n",
      "Epoch 926: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9064.0312 - mean_absolute_error: 9064.0312 - val_loss: 12712.5205 - val_mean_absolute_error: 12712.5205\n",
      "Epoch 927/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9055.1465 - mean_absolute_error: 9055.1465\n",
      "Epoch 927: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8934.6592 - mean_absolute_error: 8934.6592 - val_loss: 12518.0342 - val_mean_absolute_error: 12518.0342\n",
      "Epoch 928/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9067.4375 - mean_absolute_error: 9067.4375\n",
      "Epoch 928: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8969.7568 - mean_absolute_error: 8969.7568 - val_loss: 12542.7031 - val_mean_absolute_error: 12542.7031\n",
      "Epoch 929/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 8647.7939 - mean_absolute_error: 8647.7939\n",
      "Epoch 929: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 8876.1270 - mean_absolute_error: 8876.1270 - val_loss: 12508.5908 - val_mean_absolute_error: 12508.5908\n",
      "Epoch 930/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8849.5996 - mean_absolute_error: 8849.5996  \n",
      "Epoch 930: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8952.6348 - mean_absolute_error: 8952.6348 - val_loss: 12563.1045 - val_mean_absolute_error: 12563.1045\n",
      "Epoch 931/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9175.9521 - mean_absolute_error: 9175.9521  \n",
      "Epoch 931: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9056.7461 - mean_absolute_error: 9056.7461 - val_loss: 12559.5811 - val_mean_absolute_error: 12559.5811\n",
      "Epoch 932/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 8924.2236 - mean_absolute_error: 8924.2236\n",
      "Epoch 932: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8982.7061 - mean_absolute_error: 8982.7061 - val_loss: 12537.2129 - val_mean_absolute_error: 12537.2129\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 9069.3711 - mean_absolute_error: 9069.3711\n",
      "Epoch 933: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9069.3711 - mean_absolute_error: 9069.3711 - val_loss: 12547.1719 - val_mean_absolute_error: 12547.1719\n",
      "Epoch 934/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8872.7051 - mean_absolute_error: 8872.7051\n",
      "Epoch 934: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9026.7119 - mean_absolute_error: 9026.7119 - val_loss: 12556.8926 - val_mean_absolute_error: 12556.8926\n",
      "Epoch 935/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 8895.1660 - mean_absolute_error: 8895.1660\n",
      "Epoch 935: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8934.1611 - mean_absolute_error: 8934.1611 - val_loss: 12648.7939 - val_mean_absolute_error: 12648.7939\n",
      "Epoch 936/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 8942.5078 - mean_absolute_error: 8942.5078\n",
      "Epoch 936: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8882.1162 - mean_absolute_error: 8882.1162 - val_loss: 12526.3906 - val_mean_absolute_error: 12526.3906\n",
      "Epoch 937/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9043.5098 - mean_absolute_error: 9043.5098  \n",
      "Epoch 937: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9027.6885 - mean_absolute_error: 9027.6885 - val_loss: 12589.0781 - val_mean_absolute_error: 12589.0781\n",
      "Epoch 938/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 8952.3584 - mean_absolute_error: 8952.3584  \n",
      "Epoch 938: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9023.0781 - mean_absolute_error: 9023.0781 - val_loss: 12725.1406 - val_mean_absolute_error: 12725.1406\n",
      "Epoch 939/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 8067.8540 - mean_absolute_error: 8067.8540  \n",
      "Epoch 939: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 8868.2822 - mean_absolute_error: 8868.2822 - val_loss: 12518.6240 - val_mean_absolute_error: 12518.6240\n",
      "Epoch 940/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 8951.4873 - mean_absolute_error: 8951.4873\n",
      "Epoch 940: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8878.8555 - mean_absolute_error: 8878.8555 - val_loss: 12627.4844 - val_mean_absolute_error: 12627.4844\n",
      "Epoch 941/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 8925.1709 - mean_absolute_error: 8925.1709\n",
      "Epoch 941: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8998.2393 - mean_absolute_error: 8998.2393 - val_loss: 12561.0752 - val_mean_absolute_error: 12561.0752\n",
      "Epoch 942/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9053.1484 - mean_absolute_error: 9053.1484\n",
      "Epoch 942: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9020.7803 - mean_absolute_error: 9020.7803 - val_loss: 12589.0117 - val_mean_absolute_error: 12589.0117\n",
      "Epoch 943/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9233.2402 - mean_absolute_error: 9233.2402\n",
      "Epoch 943: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9080.2217 - mean_absolute_error: 9080.2217 - val_loss: 12602.9629 - val_mean_absolute_error: 12602.9629\n",
      "Epoch 944/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9220.5078 - mean_absolute_error: 9220.5078\n",
      "Epoch 944: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9197.5557 - mean_absolute_error: 9197.5557 - val_loss: 12990.8896 - val_mean_absolute_error: 12990.8896\n",
      "Epoch 945/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9077.0352 - mean_absolute_error: 9077.0352  \n",
      "Epoch 945: val_loss did not improve from 12506.62207\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9061.7910 - mean_absolute_error: 9061.7910 - val_loss: 12632.7979 - val_mean_absolute_error: 12632.7979\n",
      "Epoch 946/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9057.2607 - mean_absolute_error: 9057.2607\n",
      "Epoch 946: val_loss improved from 12506.62207 to 12487.27539, saving model to Weights-00946--12487.27539.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8985.6514 - mean_absolute_error: 8985.6514 - val_loss: 12487.2754 - val_mean_absolute_error: 12487.2754\n",
      "Epoch 947/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8907.6475 - mean_absolute_error: 8907.6475\n",
      "Epoch 947: val_loss did not improve from 12487.27539\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8917.3896 - mean_absolute_error: 8917.3896 - val_loss: 12603.7432 - val_mean_absolute_error: 12603.7432\n",
      "Epoch 948/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8419.4072 - mean_absolute_error: 8419.4072\n",
      "Epoch 948: val_loss did not improve from 12487.27539\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8937.4141 - mean_absolute_error: 8937.4141 - val_loss: 12546.2119 - val_mean_absolute_error: 12546.2119\n",
      "Epoch 949/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 8826.9834 - mean_absolute_error: 8826.9834  \n",
      "Epoch 949: val_loss did not improve from 12487.27539\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8942.8672 - mean_absolute_error: 8942.8672 - val_loss: 12519.3262 - val_mean_absolute_error: 12519.3262\n",
      "Epoch 950/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8770.5156 - mean_absolute_error: 8770.5156\n",
      "Epoch 950: val_loss improved from 12487.27539 to 12484.93066, saving model to Weights-00950--12484.93066.hdf5\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 8921.4150 - mean_absolute_error: 8921.4150 - val_loss: 12484.9307 - val_mean_absolute_error: 12484.9307\n",
      "Epoch 951/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 8890.7529 - mean_absolute_error: 8890.7529\n",
      "Epoch 951: val_loss did not improve from 12484.93066\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 8929.5342 - mean_absolute_error: 8929.5342 - val_loss: 12547.3984 - val_mean_absolute_error: 12547.3984\n",
      "Epoch 952/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 8612.3652 - mean_absolute_error: 8612.3652\n",
      "Epoch 952: val_loss did not improve from 12484.93066\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8984.2773 - mean_absolute_error: 8984.2773 - val_loss: 12500.7578 - val_mean_absolute_error: 12500.7578\n",
      "Epoch 953/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9164.5811 - mean_absolute_error: 9164.5811\n",
      "Epoch 953: val_loss did not improve from 12484.93066\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8987.8242 - mean_absolute_error: 8987.8242 - val_loss: 12807.8096 - val_mean_absolute_error: 12807.8096\n",
      "Epoch 954/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8794.7686 - mean_absolute_error: 8794.7686\n",
      "Epoch 954: val_loss did not improve from 12484.93066\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8934.0527 - mean_absolute_error: 8934.0527 - val_loss: 12735.0664 - val_mean_absolute_error: 12735.0664\n",
      "Epoch 955/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8781.0303 - mean_absolute_error: 8781.0303  \n",
      "Epoch 955: val_loss did not improve from 12484.93066\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8853.4502 - mean_absolute_error: 8853.4502 - val_loss: 12898.3086 - val_mean_absolute_error: 12898.3086\n",
      "Epoch 956/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 9018.9639 - mean_absolute_error: 9018.9639  \n",
      "Epoch 956: val_loss improved from 12484.93066 to 12463.25879, saving model to Weights-00956--12463.25879.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9122.1348 - mean_absolute_error: 9122.1348 - val_loss: 12463.2588 - val_mean_absolute_error: 12463.2588\n",
      "Epoch 957/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9240.5225 - mean_absolute_error: 9240.5225  \n",
      "Epoch 957: val_loss did not improve from 12463.25879\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8911.9775 - mean_absolute_error: 8911.9775 - val_loss: 12552.2363 - val_mean_absolute_error: 12552.2363\n",
      "Epoch 958/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8834.8291 - mean_absolute_error: 8834.8291\n",
      "Epoch 958: val_loss did not improve from 12463.25879\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8871.0137 - mean_absolute_error: 8871.0137 - val_loss: 12467.0762 - val_mean_absolute_error: 12467.0762\n",
      "Epoch 959/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8733.4180 - mean_absolute_error: 8733.4180\n",
      "Epoch 959: val_loss did not improve from 12463.25879\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8881.3906 - mean_absolute_error: 8881.3906 - val_loss: 12614.7734 - val_mean_absolute_error: 12614.7734\n",
      "Epoch 960/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9332.7383 - mean_absolute_error: 9332.7383\n",
      "Epoch 960: val_loss did not improve from 12463.25879\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8927.0400 - mean_absolute_error: 8927.0400 - val_loss: 12575.1514 - val_mean_absolute_error: 12575.1514\n",
      "Epoch 961/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9164.8887 - mean_absolute_error: 9164.8887  \n",
      "Epoch 961: val_loss did not improve from 12463.25879\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9088.3975 - mean_absolute_error: 9088.3975 - val_loss: 12576.5352 - val_mean_absolute_error: 12576.5352\n",
      "Epoch 962/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 8770.2646 - mean_absolute_error: 8770.2646\n",
      "Epoch 962: val_loss did not improve from 12463.25879\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8906.2549 - mean_absolute_error: 8906.2549 - val_loss: 12605.5771 - val_mean_absolute_error: 12605.5771\n",
      "Epoch 963/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 8703.8398 - mean_absolute_error: 8703.8398\n",
      "Epoch 963: val_loss did not improve from 12463.25879\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8922.2725 - mean_absolute_error: 8922.2725 - val_loss: 12680.0215 - val_mean_absolute_error: 12680.0215\n",
      "Epoch 964/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8883.0723 - mean_absolute_error: 8883.0723  \n",
      "Epoch 964: val_loss did not improve from 12463.25879\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8888.8857 - mean_absolute_error: 8888.8857 - val_loss: 12767.5938 - val_mean_absolute_error: 12767.5938\n",
      "Epoch 965/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 9289.0469 - mean_absolute_error: 9289.0469\n",
      "Epoch 965: val_loss did not improve from 12463.25879\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8985.4482 - mean_absolute_error: 8985.4482 - val_loss: 12488.9346 - val_mean_absolute_error: 12488.9346\n",
      "Epoch 966/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8717.0645 - mean_absolute_error: 8717.0645\n",
      "Epoch 966: val_loss did not improve from 12463.25879\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8946.7607 - mean_absolute_error: 8946.7607 - val_loss: 12559.6670 - val_mean_absolute_error: 12559.6670\n",
      "Epoch 967/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 8985.9736 - mean_absolute_error: 8985.9736  \n",
      "Epoch 967: val_loss did not improve from 12463.25879\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8832.4639 - mean_absolute_error: 8832.4639 - val_loss: 12969.4736 - val_mean_absolute_error: 12969.4736\n",
      "Epoch 968/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 8994.9150 - mean_absolute_error: 8994.9150  \n",
      "Epoch 968: val_loss did not improve from 12463.25879\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 8926.5137 - mean_absolute_error: 8926.5137 - val_loss: 12644.0049 - val_mean_absolute_error: 12644.0049\n",
      "Epoch 969/1000\n",
      "10/18 [===============>..............] - ETA: 0s - loss: 9421.4395 - mean_absolute_error: 9421.4395\n",
      "Epoch 969: val_loss did not improve from 12463.25879\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9091.9229 - mean_absolute_error: 9091.9229 - val_loss: 13207.4678 - val_mean_absolute_error: 13207.4678\n",
      "Epoch 970/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9001.6670 - mean_absolute_error: 9001.6670\n",
      "Epoch 970: val_loss did not improve from 12463.25879\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9032.1113 - mean_absolute_error: 9032.1113 - val_loss: 12504.2861 - val_mean_absolute_error: 12504.2861\n",
      "Epoch 971/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 8922.4795 - mean_absolute_error: 8922.4795\n",
      "Epoch 971: val_loss did not improve from 12463.25879\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8904.4131 - mean_absolute_error: 8904.4131 - val_loss: 12491.9785 - val_mean_absolute_error: 12491.9785\n",
      "Epoch 972/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 8807.3750 - mean_absolute_error: 8807.3750\n",
      "Epoch 972: val_loss did not improve from 12463.25879\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8894.9229 - mean_absolute_error: 8894.9229 - val_loss: 12593.1777 - val_mean_absolute_error: 12593.1777\n",
      "Epoch 973/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9161.4258 - mean_absolute_error: 9161.4258\n",
      "Epoch 973: val_loss did not improve from 12463.25879\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8995.3252 - mean_absolute_error: 8995.3252 - val_loss: 12471.8154 - val_mean_absolute_error: 12471.8154\n",
      "Epoch 974/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8875.1426 - mean_absolute_error: 8875.1426\n",
      "Epoch 974: val_loss did not improve from 12463.25879\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8930.3018 - mean_absolute_error: 8930.3018 - val_loss: 12517.0342 - val_mean_absolute_error: 12517.0342\n",
      "Epoch 975/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8944.2734 - mean_absolute_error: 8944.2734  \n",
      "Epoch 975: val_loss did not improve from 12463.25879\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8912.5352 - mean_absolute_error: 8912.5352 - val_loss: 12597.2803 - val_mean_absolute_error: 12597.2803\n",
      "Epoch 976/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8805.7920 - mean_absolute_error: 8805.7920\n",
      "Epoch 976: val_loss did not improve from 12463.25879\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8954.1494 - mean_absolute_error: 8954.1494 - val_loss: 12526.6895 - val_mean_absolute_error: 12526.6895\n",
      "Epoch 977/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8829.0801 - mean_absolute_error: 8829.0801\n",
      "Epoch 977: val_loss did not improve from 12463.25879\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8903.3555 - mean_absolute_error: 8903.3555 - val_loss: 12500.9922 - val_mean_absolute_error: 12500.9922\n",
      "Epoch 978/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8883.5918 - mean_absolute_error: 8883.5918\n",
      "Epoch 978: val_loss did not improve from 12463.25879\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8884.9033 - mean_absolute_error: 8884.9033 - val_loss: 12583.2725 - val_mean_absolute_error: 12583.2725\n",
      "Epoch 979/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8806.9180 - mean_absolute_error: 8806.9180\n",
      "Epoch 979: val_loss did not improve from 12463.25879\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8935.9111 - mean_absolute_error: 8935.9111 - val_loss: 12484.9443 - val_mean_absolute_error: 12484.9443\n",
      "Epoch 980/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 8991.5127 - mean_absolute_error: 8991.5127\n",
      "Epoch 980: val_loss did not improve from 12463.25879\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8942.6191 - mean_absolute_error: 8942.6191 - val_loss: 12498.3301 - val_mean_absolute_error: 12498.3301\n",
      "Epoch 981/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 8670.4482 - mean_absolute_error: 8670.4482\n",
      "Epoch 981: val_loss did not improve from 12463.25879\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 8930.4863 - mean_absolute_error: 8930.4863 - val_loss: 12525.2119 - val_mean_absolute_error: 12525.2119\n",
      "Epoch 982/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 8391.7090 - mean_absolute_error: 8391.7090\n",
      "Epoch 982: val_loss did not improve from 12463.25879\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8973.6445 - mean_absolute_error: 8973.6445 - val_loss: 12510.2783 - val_mean_absolute_error: 12510.2783\n",
      "Epoch 983/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8815.0693 - mean_absolute_error: 8815.0693  \n",
      "Epoch 983: val_loss did not improve from 12463.25879\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8912.6523 - mean_absolute_error: 8912.6523 - val_loss: 12538.4502 - val_mean_absolute_error: 12538.4502\n",
      "Epoch 984/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9104.1855 - mean_absolute_error: 9104.1855\n",
      "Epoch 984: val_loss did not improve from 12463.25879\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8847.6934 - mean_absolute_error: 8847.6934 - val_loss: 12531.2812 - val_mean_absolute_error: 12531.2812\n",
      "Epoch 985/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 8941.3701 - mean_absolute_error: 8941.3701  \n",
      "Epoch 985: val_loss did not improve from 12463.25879\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8969.4619 - mean_absolute_error: 8969.4619 - val_loss: 12522.3564 - val_mean_absolute_error: 12522.3564\n",
      "Epoch 986/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8960.3613 - mean_absolute_error: 8960.3613\n",
      "Epoch 986: val_loss improved from 12463.25879 to 12446.45801, saving model to Weights-00986--12446.45801.hdf5\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8907.7617 - mean_absolute_error: 8907.7617 - val_loss: 12446.4580 - val_mean_absolute_error: 12446.4580\n",
      "Epoch 987/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 8823.8242 - mean_absolute_error: 8823.8242  \n",
      "Epoch 987: val_loss did not improve from 12446.45801\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9009.5977 - mean_absolute_error: 9009.5977 - val_loss: 12487.8809 - val_mean_absolute_error: 12487.8809\n",
      "Epoch 988/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 8862.5713 - mean_absolute_error: 8862.5713\n",
      "Epoch 988: val_loss did not improve from 12446.45801\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 8889.7412 - mean_absolute_error: 8889.7412 - val_loss: 12488.0273 - val_mean_absolute_error: 12488.0273\n",
      "Epoch 989/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8968.7363 - mean_absolute_error: 8968.7363\n",
      "Epoch 989: val_loss did not improve from 12446.45801\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8926.5518 - mean_absolute_error: 8926.5518 - val_loss: 12549.4570 - val_mean_absolute_error: 12549.4570\n",
      "Epoch 990/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9012.5664 - mean_absolute_error: 9012.5664  \n",
      "Epoch 990: val_loss did not improve from 12446.45801\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8900.3369 - mean_absolute_error: 8900.3369 - val_loss: 13064.1406 - val_mean_absolute_error: 13064.1406\n",
      "Epoch 991/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8949.3789 - mean_absolute_error: 8949.3789\n",
      "Epoch 991: val_loss did not improve from 12446.45801\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9004.2979 - mean_absolute_error: 9004.2979 - val_loss: 12655.6309 - val_mean_absolute_error: 12655.6309\n",
      "Epoch 992/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8975.6943 - mean_absolute_error: 8975.6943\n",
      "Epoch 992: val_loss did not improve from 12446.45801\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8971.8525 - mean_absolute_error: 8971.8525 - val_loss: 12494.2158 - val_mean_absolute_error: 12494.2158\n",
      "Epoch 993/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 9107.3291 - mean_absolute_error: 9107.3291\n",
      "Epoch 993: val_loss did not improve from 12446.45801\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8985.3984 - mean_absolute_error: 8985.3984 - val_loss: 12481.1250 - val_mean_absolute_error: 12481.1250\n",
      "Epoch 994/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 8902.1240 - mean_absolute_error: 8902.1240  \n",
      "Epoch 994: val_loss did not improve from 12446.45801\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8924.7227 - mean_absolute_error: 8924.7227 - val_loss: 12493.8086 - val_mean_absolute_error: 12493.8086\n",
      "Epoch 995/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 8931.7949 - mean_absolute_error: 8931.7949  \n",
      "Epoch 995: val_loss did not improve from 12446.45801\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8915.9326 - mean_absolute_error: 8915.9326 - val_loss: 12486.3105 - val_mean_absolute_error: 12486.3105\n",
      "Epoch 996/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 8886.3896 - mean_absolute_error: 8886.3896\n",
      "Epoch 996: val_loss did not improve from 12446.45801\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8811.2988 - mean_absolute_error: 8811.2988 - val_loss: 12723.3594 - val_mean_absolute_error: 12723.3594\n",
      "Epoch 997/1000\n",
      "11/18 [=================>............] - ETA: 0s - loss: 9091.3506 - mean_absolute_error: 9091.3506  \n",
      "Epoch 997: val_loss did not improve from 12446.45801\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9073.0928 - mean_absolute_error: 9073.0928 - val_loss: 12555.3486 - val_mean_absolute_error: 12555.3486\n",
      "Epoch 998/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 9318.1191 - mean_absolute_error: 9318.1191\n",
      "Epoch 998: val_loss did not improve from 12446.45801\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8908.4756 - mean_absolute_error: 8908.4756 - val_loss: 12461.8213 - val_mean_absolute_error: 12461.8213\n",
      "Epoch 999/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 9014.0225 - mean_absolute_error: 9014.0225  \n",
      "Epoch 999: val_loss did not improve from 12446.45801\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8961.6025 - mean_absolute_error: 8961.6025 - val_loss: 12476.1396 - val_mean_absolute_error: 12476.1396\n",
      "Epoch 1000/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 8900.3662 - mean_absolute_error: 8900.3662\n",
      "Epoch 1000: val_loss did not improve from 12446.45801\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 8884.0547 - mean_absolute_error: 8884.0547 - val_loss: 12588.5049 - val_mean_absolute_error: 12588.5049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6b4c2372b0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model.fit(train_x, train_y, epochs=500, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "wights_file = 'Weights-03012--12071.99512.hdf5' \n",
    "NN_model.load_weights(wights_file) \n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "predictions = NN_model.predict(test_x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Regresión de Gradiente Extremo (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBModel = XGBRegressor(objective=\"reg:squarederror\", random_state=42,max_depth=10)\n",
    "XGBModel.fit(train_x,train_y, verbose=False)\n",
    "\n",
    "XGBpredictions = XGBModel.predict(test_x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Bosque Aleatorio (Random Forest Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor()\n",
    "model.fit(train_x,train_y)\n",
    "\n",
    "RF_predictions = model.predict(test_x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de Resultados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluación de la precisión de los tres modelos entrenados mediante tres métricas diferentes; MAE, MAPE y MSE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17185.188757711272\n",
      "17236.941343043854\n",
      "16241.219621868739\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NN_MAE = mean_absolute_error(test_y, predictions)\n",
    "NN_MAPE = mean_absolute_percentage_error(test_y, predictions)\n",
    "NN_MSE = mean_squared_error(test_y, predictions)\n",
    "\n",
    "XGB_MAE = mean_absolute_error(test_y , XGBpredictions)\n",
    "XGB_MAPE = mean_absolute_percentage_error(test_y , XGBpredictions)\n",
    "XGB_MSE = mean_squared_error(test_y , XGBpredictions)\n",
    "\n",
    "RF_MAE = mean_absolute_error(test_y , RF_predictions)\n",
    "RF_MAPE = mean_absolute_percentage_error(test_y , RF_predictions)\n",
    "RF_MSE = mean_squared_error(test_y , RF_predictions)\n",
    "print(NN_MAE)\n",
    "print(XGB_MAE)\n",
    "print(RF_MAE)\n",
    "\n",
    "MAE_scores = [NN_MAE, XGB_MAE, RF_MAE]\n",
    "MAPE_scores = [NN_MAPE, XGB_MAPE, RF_MAPE]\n",
    "MSE_scores = [NN_MSE, XGB_MSE, RF_MSE]\n",
    "results = [MAE_scores,MAPE_scores, MSE_scores]\n",
    "models = ['Neural Network', \"XGBoost\", \"Random Forest\"]\n",
    "labels = ['MAE', 'MAPE', 'MSE']\n",
    "colors = ['Turquoise', 'Orange', 'Darkslategrey']\n",
    "fig,ax = plt.subplots(1,3,figsize=(12,3))\n",
    "for i in range(len(labels)):\n",
    "    for j in range(len(colors)):\n",
    "        ax[i].bar(models[j],results[i][j], color=colors[j])\n",
    "    ax[i].set_xlabel(labels[i])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nótese que los mejores resultados fueron obtenidos por los modelos de regresión XGBoost y Random Forest, puede que esto se deba a un bajo poder de cómputo a la hora de entrenar a la raíz neuronal o algún fallo en la parametrización/normalización del dataframe. \n",
    "Así entonces se optó por implementar el modelo de XGBoost Regression en el despliegue a producción."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
